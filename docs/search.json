[
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html",
    "title": "00. MP (1)",
    "section": "",
    "text": "pandas와 numpy 라라이브러리를 불러오기\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n\n\n\n\n- 데이터를 불러온 후 상위 10개 행 확인\n\n\nCode\nimport openpyxl\ndata = pd.read_excel(\"data04.xlsx\")\ndata.head(10)\n\n\n\n\n\n\n\n\n\nID\nSeq\nGender\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\nStudent ID\n\n\n\n\n0\n1\n1\nM\n1973\n181\n173\n354\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주3-4회\n6.0\n알고 있지 않음\n6\nstudent1\n\n\n1\n1\n2\nM\n1973\n227\n213\n440\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n주1-2회\n3.0\n알고 있음\n5\nstudent1\n\n\n2\n1\n3\nM\n1973\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\nstudent1\n\n\n3\n2\n1\nF\n1982\n330\n290\n620\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n매일(주 7회)\n8.0\n알고 있지 않음\n19\nstudent2\n\n\n4\n2\n2\nF\n1982\n354\n339\n693\n승진\n온라인강의\n영상 교재\n주5-6회\n2.0\n알고 있음\n15\nstudent2\n\n\n5\n2\n3\nF\n1982\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n4.0\n알고 있음\n14\nstudent2\n\n\n6\n3\n1\nF\n1995\n367\n309\n676\n취업\n온라인강의\n영상 교재\n매일(주 7회)\n9.0\n알고 있지 않음\n7\nstudent3\n\n\n7\n3\n2\nF\n1995\n396\n365\n761\n자기계발\n온라인강의\n영상 교재\n주3-4회\n7.0\n알고 있지 않음\n6\nstudent3\n\n\n8\n3\n3\nF\n1995\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n4.0\n알고 있음\n4\nstudent3\n\n\n9\n4\n1\nM\n1987\n470\n285\n755\n자기계발\n온라인강의\n뉴스/이슈 기반 교재\n주1-2회\n7.0\n알고 있지 않음\n4\nstudent4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(f\"전체 데이터는 {data.shape[0]}개의 행과 {data.shape[1]}열로 구성되어 있습니다.\")\n\n\n전체 데이터는 1500개의 행과 15열로 구성되어 있습니다.\n\n\n\n\n\n\n\nCode\ndata.tail(5)\n\n\n\n\n\n\n\n\n\nID\nSeq\nGender\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\nStudent ID\n\n\n\n\n1495\n499\n2\nF\n1990\n378\n326\n704\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n6.0\n알고 있지 않음\n12\nstudent499\n\n\n1496\n499\n3\nF\n1990\n422\n370\n792\n자기계발\n오프라인강의\n비즈니스 시뮬레이션(Role Play)\n주3-4회\n4.0\n알고 있음\n7\nstudent499\n\n\n1497\n500\n1\nM\n1984\n169\n188\n357\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주3-4회\n8.0\n알고 있지 않음\n2\nstudent500\n\n\n1498\n500\n2\nM\n1984\n172\n190\n362\n자기계발\n참고서\n뉴스/이슈 기반 교재\n매일(주 7회)\n10.0\n알고 있음\n16\nstudent500\n\n\n1499\n500\n3\nM\n1984\n235\n226\n461\n승진\n오프라인강의\n비즈니스 시뮬레이션(Role Play)\n주5-6회\n7.0\n알고 있음\n15\nstudent500\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(list(data.columns))\n\n\n['ID', 'Seq', 'Gender', 'Birth_Year', 'LC_Score', 'RC_Score', 'Total Score', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수', 'Student ID']\n\n\n\n\n\n\n\nCode\nprint(data.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 15 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   ID           1500 non-null   int64  \n 1   Seq          1500 non-null   int64  \n 2   Gender       1500 non-null   object \n 3   Birth_Year   1500 non-null   int64  \n 4   LC_Score     1500 non-null   int64  \n 5   RC_Score     1500 non-null   int64  \n 6   Total Score  1500 non-null   int64  \n 7   학습목표         1500 non-null   object \n 8   학습방법         1500 non-null   object \n 9   강의 학습 교재 유형  1500 non-null   object \n 10  학습빈도         1500 non-null   object \n 11  기출문제 공부 횟수   1497 non-null   float64\n 12  취약분야 인지 여부   1500 non-null   object \n 13  토익 모의테스트 횟수  1500 non-null   int64  \n 14  Student ID   1500 non-null   object \ndtypes: float64(1), int64(7), object(7)\nmemory usage: 175.9+ KB\nNone\n\n\n\n\n\n\n기출문제 공부횟수에서 총 3개의 결측치가 확인된다.\n\n\n\nCode\ndata.isna().sum()\n\n\nID             0\nSeq            0\nGender         0\nBirth_Year     0\nLC_Score       0\nRC_Score       0\nTotal Score    0\n학습목표           0\n학습방법           0\n강의 학습 교재 유형    0\n학습빈도           0\n기출문제 공부 횟수     3\n취약분야 인지 여부     0\n토익 모의테스트 횟수    0\nStudent ID     0\ndtype: int64\n\n\n\n\n\n\n\nCode\ndata.describe()\n\n\n\n\n\n\n\n\n\nID\nSeq\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n기출문제 공부 횟수\n토익 모의테스트 횟수\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n1497.000000\n1500.000000\n\n\nmean\n250.500000\n2.000000\n1992.906000\n340.079333\n340.164667\n680.260667\n5.286573\n9.784000\n\n\nstd\n144.385415\n0.816769\n8.218893\n86.807523\n87.143890\n159.110652\n2.797303\n5.324181\n\n\nmin\n1.000000\n1.000000\n1973.000000\n105.000000\n84.000000\n250.000000\n1.000000\n1.000000\n\n\n25%\n125.750000\n1.000000\n1986.750000\n279.000000\n280.000000\n564.000000\n3.000000\n5.000000\n\n\n50%\n250.500000\n2.000000\n1992.500000\n335.000000\n337.000000\n687.000000\n5.000000\n9.000000\n\n\n75%\n375.250000\n3.000000\n2000.000000\n404.000000\n406.000000\n800.000000\n8.000000\n14.000000\n\n\nmax\n500.000000\n3.000000\n2007.000000\n495.000000\n495.000000\n990.000000\n10.000000\n20.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(data.dtypes)\n\n\nID               int64\nSeq              int64\nGender          object\nBirth_Year       int64\nLC_Score         int64\nRC_Score         int64\nTotal Score      int64\n학습목표            object\n학습방법            object\n강의 학습 교재 유형     object\n학습빈도            object\n기출문제 공부 횟수     float64\n취약분야 인지 여부      object\n토익 모의테스트 횟수      int64\nStudent ID      object\ndtype: object\n\n\n\n\n\n\n\nCode\ndata.drop(\"Student ID\",axis=1,inplace=True)\n\n\n\n\nCode\ndata.head()\n\n\n\n\n\n\n\n\n\nID\nSeq\nGender\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n\n\n\n\n0\n1\n1\nM\n1973\n181\n173\n354\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주3-4회\n6.0\n알고 있지 않음\n6\n\n\n1\n1\n2\nM\n1973\n227\n213\n440\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n주1-2회\n3.0\n알고 있음\n5\n\n\n2\n1\n3\nM\n1973\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\n\n\n3\n2\n1\nF\n1982\n330\n290\n620\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n매일(주 7회)\n8.0\n알고 있지 않음\n19\n\n\n4\n2\n2\nF\n1982\n354\n339\n693\n승진\n온라인강의\n영상 교재\n주5-6회\n2.0\n알고 있음\n15\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlen(data.columns)\n\n\n14\n\n\n\n\n\n\n\nCode\ndata[\"기출문제 공부 횟수\"].fillna(0,inplace=True)\n\n\n\n\n\n\n\nCode\ndata[\"기출문제 공부 횟수\"].unique()\n\n\narray([ 6.,  3.,  7.,  8.,  2.,  4.,  9.,  5., 10.,  1.,  0.])\n\n\n\n\n\n\ndf1(개인정보 데이터) features : 'ID', 'Gender', 'Birth_Year'\ndf2(토익시험 학습정보 데이터) features : 'ID','Seq', 'LC_Score', 'RC_Score', 'Total Score', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수'\n\n\n\nCode\ncol_1 = ['ID', 'Gender', 'Birth_Year']\ncol_2 = ['ID','Seq', 'LC_Score', 'RC_Score', 'Total Score',\n         '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도',\n         '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수']\n\ndf1 = data.loc[:, map(lambda x : x  in col_1,data.columns )]\ndf2 = data.loc[:, map(lambda x : x  in col_2,data.columns )]\n\nprint(f\"df1의 컬럼 : {list(df1.columns)}\\n\")\nprint(\"*\"*100+\"\\n\")\nprint(f\"df2의 컬럼 : {list(df2.columns)}\")\n\n\ndf1의 컬럼 : ['ID', 'Gender', 'Birth_Year']\n\n****************************************************************************************************\n\ndf2의 컬럼 : ['ID', 'Seq', 'LC_Score', 'RC_Score', 'Total Score', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수']\n\n\n\n\n\n\n\n\nCode\ndf1 = df1.drop_duplicates()\n\n\n\n\nCode\ndf1.head()\n\n\n\n\n\n\n\n\n\nID\nGender\nBirth_Year\n\n\n\n\n0\n1\nM\n1973\n\n\n3\n2\nF\n1982\n\n\n6\n3\nF\n1995\n\n\n9\n4\nM\n1987\n\n\n12\n5\nM\n1994\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp = df2.loc[map(lambda x : x == 3,df2.Seq), :]\ntemp.Seq.unique()\n\n\narray([3], dtype=int64)\n\n\n\n\nCode\ntemp.head()\n\n\n\n\n\n\n\n\n\nID\nSeq\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n\n\n\n\n2\n1\n3\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\n\n\n5\n2\n3\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n4.0\n알고 있음\n14\n\n\n8\n3\n3\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n4.0\n알고 있음\n4\n\n\n11\n4\n3\n495\n397\n892\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주3-4회\n9.0\n알고 있음\n8\n\n\n14\n5\n3\n398\n437\n835\n자기계발\n온라인강의\n영상 교재\n주3-4회\n6.0\n알고 있음\n4\n\n\n\n\n\n\n\n\n\n\n\nLC_Score, RC_Score, Total Score를 각각 ‘3st_LC_Score’, ‘3st_RC_Score’, ’3st_Total_Score’로 변경하고 확인해주세요.\n\n\n\nCode\ntemp = temp.rename(columns = {\"LC_Score\" : \"3st_LC_SCcore\",\n                        \"RC_Score\" : \"3st_RC_SCcore\",\n                        \"Total Score\" : \"3st_Total_SCcore\",\n                        })\ntemp.head()\n\n\n\n\n\n\n\n\n\nID\nSeq\n3st_LC_SCcore\n3st_RC_SCcore\n3st_Total_SCcore\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n\n\n\n\n2\n1\n3\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\n\n\n5\n2\n3\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n4.0\n알고 있음\n14\n\n\n8\n3\n3\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n4.0\n알고 있음\n4\n\n\n11\n4\n3\n495\n397\n892\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주3-4회\n9.0\n알고 있음\n8\n\n\n14\n5\n3\n398\n437\n835\n자기계발\n온라인강의\n영상 교재\n주3-4회\n6.0\n알고 있음\n4\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp1 = df2.loc[map(lambda x : x == 1,df2.Seq), :]\ntemp1.Seq.unique()\n\n\narray([1], dtype=int64)\n\n\n\n\n\n\n\nCode\ntemp1 = temp1.loc[:,['ID','LC_Score','RC_Score','Total Score']]\n\n\n\n\n\n\nLC_Score, RC_Score, Total Score를 각각 ‘1st_LC_Score’, ‘1st_RC_Score’, ’1st_Total_Score’로 변경하고 확인해주세요.\n\n\n\nCode\ntemp1 = temp1.rename(columns = {\"LC_Score\" : \"1st_LC_SCcore\",\n                        \"RC_Score\" : \"1st_RC_SCcore\",\n                        \"Total Score\" : \"1st_Total_SCcore\",\n                        })\ntemp1.head()\n\n\n\n\n\n\n\n\n\nID\n1st_LC_SCcore\n1st_RC_SCcore\n1st_Total_SCcore\n\n\n\n\n0\n1\n181\n173\n354\n\n\n3\n2\n330\n290\n620\n\n\n6\n3\n367\n309\n676\n\n\n9\n4\n470\n285\n755\n\n\n12\n5\n273\n372\n645\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp2 = df2.loc[map(lambda x : x == 2,df2.Seq), :]\ntemp2.Seq.unique()\n\n\narray([2], dtype=int64)\n\n\n\n\n\n\n\nCode\ntemp2 =  temp2.loc[:,['ID','LC_Score','RC_Score','Total Score']]\n\n\n\n\n\n\n\nCode\ntemp2 = temp2.rename(columns = {\"LC_Score\" : \"2st_LC_SCcore\",\n                        \"RC_Score\" : \"2st_RC_SCcore\",\n                        \"Total Score\" : \"2st_Total_SCcore\",\n                        })\ntemp2.head()\n\n\n\n\n\n\n\n\n\nID\n2st_LC_SCcore\n2st_RC_SCcore\n2st_Total_SCcore\n\n\n\n\n1\n1\n227\n213\n440\n\n\n4\n2\n354\n339\n693\n\n\n7\n3\n396\n365\n761\n\n\n10\n4\n495\n341\n836\n\n\n13\n5\n314\n426\n740\n\n\n\n\n\n\n\n\n\n\n- 합친 후 ’score_merged_data1’에 할당\n\n\nCode\nscore_merged_data1 = pd.merge(temp,temp1)\n\n\n\n\n\n\n\nCode\nscore_merged_data2 = pd.merge(score_merged_data1,temp2)\n\n\n\n\n\n\n\nCode\nprint(score_merged_data2.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 500 entries, 0 to 499\nData columns (total 18 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                500 non-null    int64  \n 1   Seq               500 non-null    int64  \n 2   3st_LC_SCcore     500 non-null    int64  \n 3   3st_RC_SCcore     500 non-null    int64  \n 4   3st_Total_SCcore  500 non-null    int64  \n 5   학습목표              500 non-null    object \n 6   학습방법              500 non-null    object \n 7   강의 학습 교재 유형       500 non-null    object \n 8   학습빈도              500 non-null    object \n 9   기출문제 공부 횟수        500 non-null    float64\n 10  취약분야 인지 여부        500 non-null    object \n 11  토익 모의테스트 횟수       500 non-null    int64  \n 12  1st_LC_SCcore     500 non-null    int64  \n 13  1st_RC_SCcore     500 non-null    int64  \n 14  1st_Total_SCcore  500 non-null    int64  \n 15  2st_LC_SCcore     500 non-null    int64  \n 16  2st_RC_SCcore     500 non-null    int64  \n 17  2st_Total_SCcore  500 non-null    int64  \ndtypes: float64(1), int64(12), object(5)\nmemory usage: 70.4+ KB\nNone\n\n\n\n\n\n\n- 합친 데이터를 baseline_data에 할당\n\n\nCode\nbaseline_data = pd.merge(df1,score_merged_data2)\n\n\n\n\nCode\nbaseline_data.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 20 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \ndtypes: float64(1), int64(13), object(6)\nmemory usage: 78.6+ KB\n\n\n\n\n\n\n‘Score_diff_total’ = ‘3st_Total_Score’ - ‘2st_Total_Score’\n\n\n\nCode\nbaseline_data[\"Score_diff_total\"] = baseline_data[\"3st_Total_SCcore\"] - baseline_data[\"2st_Total_SCcore\"] \n\n\n\n\n\n\n\nCode\nbaseline_data.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \n 20  Score_diff_total  502 non-null    int64  \ndtypes: float64(1), int64(14), object(6)\nmemory usage: 82.5+ KB\n\n\n\n\n\n\n\n\n\n\n\nCode\nbaseline_data.to_csv(\"data04_baseline.csv\",index=False)\n\n\n\n\n\n\n\nCode\npd.read_csv(\"data04_baseline.csv\").info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \n 20  Score_diff_total  502 non-null    int64  \ndtypes: float64(1), int64(14), object(6)\nmemory usage: 82.5+ KB"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#환경설정",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#환경설정",
    "title": "00. MP (1)",
    "section": "",
    "text": "pandas와 numpy 라라이브러리를 불러오기\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\n\n\n\n\n\n- 데이터를 불러온 후 상위 10개 행 확인\n\n\nCode\nimport openpyxl\ndata = pd.read_excel(\"data04.xlsx\")\ndata.head(10)\n\n\n\n\n\n\n\n\n\nID\nSeq\nGender\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\nStudent ID\n\n\n\n\n0\n1\n1\nM\n1973\n181\n173\n354\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주3-4회\n6.0\n알고 있지 않음\n6\nstudent1\n\n\n1\n1\n2\nM\n1973\n227\n213\n440\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n주1-2회\n3.0\n알고 있음\n5\nstudent1\n\n\n2\n1\n3\nM\n1973\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\nstudent1\n\n\n3\n2\n1\nF\n1982\n330\n290\n620\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n매일(주 7회)\n8.0\n알고 있지 않음\n19\nstudent2\n\n\n4\n2\n2\nF\n1982\n354\n339\n693\n승진\n온라인강의\n영상 교재\n주5-6회\n2.0\n알고 있음\n15\nstudent2\n\n\n5\n2\n3\nF\n1982\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n4.0\n알고 있음\n14\nstudent2\n\n\n6\n3\n1\nF\n1995\n367\n309\n676\n취업\n온라인강의\n영상 교재\n매일(주 7회)\n9.0\n알고 있지 않음\n7\nstudent3\n\n\n7\n3\n2\nF\n1995\n396\n365\n761\n자기계발\n온라인강의\n영상 교재\n주3-4회\n7.0\n알고 있지 않음\n6\nstudent3\n\n\n8\n3\n3\nF\n1995\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n4.0\n알고 있음\n4\nstudent3\n\n\n9\n4\n1\nM\n1987\n470\n285\n755\n자기계발\n온라인강의\n뉴스/이슈 기반 교재\n주1-2회\n7.0\n알고 있지 않음\n4\nstudent4"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터프레임-탐색",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터프레임-탐색",
    "title": "00. MP (1)",
    "section": "",
    "text": "Code\nprint(f\"전체 데이터는 {data.shape[0]}개의 행과 {data.shape[1]}열로 구성되어 있습니다.\")\n\n\n전체 데이터는 1500개의 행과 15열로 구성되어 있습니다.\n\n\n\n\n\n\n\nCode\ndata.tail(5)\n\n\n\n\n\n\n\n\n\nID\nSeq\nGender\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\nStudent ID\n\n\n\n\n1495\n499\n2\nF\n1990\n378\n326\n704\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n6.0\n알고 있지 않음\n12\nstudent499\n\n\n1496\n499\n3\nF\n1990\n422\n370\n792\n자기계발\n오프라인강의\n비즈니스 시뮬레이션(Role Play)\n주3-4회\n4.0\n알고 있음\n7\nstudent499\n\n\n1497\n500\n1\nM\n1984\n169\n188\n357\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주3-4회\n8.0\n알고 있지 않음\n2\nstudent500\n\n\n1498\n500\n2\nM\n1984\n172\n190\n362\n자기계발\n참고서\n뉴스/이슈 기반 교재\n매일(주 7회)\n10.0\n알고 있음\n16\nstudent500\n\n\n1499\n500\n3\nM\n1984\n235\n226\n461\n승진\n오프라인강의\n비즈니스 시뮬레이션(Role Play)\n주5-6회\n7.0\n알고 있음\n15\nstudent500\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(list(data.columns))\n\n\n['ID', 'Seq', 'Gender', 'Birth_Year', 'LC_Score', 'RC_Score', 'Total Score', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수', 'Student ID']\n\n\n\n\n\n\n\nCode\nprint(data.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 15 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   ID           1500 non-null   int64  \n 1   Seq          1500 non-null   int64  \n 2   Gender       1500 non-null   object \n 3   Birth_Year   1500 non-null   int64  \n 4   LC_Score     1500 non-null   int64  \n 5   RC_Score     1500 non-null   int64  \n 6   Total Score  1500 non-null   int64  \n 7   학습목표         1500 non-null   object \n 8   학습방법         1500 non-null   object \n 9   강의 학습 교재 유형  1500 non-null   object \n 10  학습빈도         1500 non-null   object \n 11  기출문제 공부 횟수   1497 non-null   float64\n 12  취약분야 인지 여부   1500 non-null   object \n 13  토익 모의테스트 횟수  1500 non-null   int64  \n 14  Student ID   1500 non-null   object \ndtypes: float64(1), int64(7), object(7)\nmemory usage: 175.9+ KB\nNone\n\n\n\n\n\n\n기출문제 공부횟수에서 총 3개의 결측치가 확인된다.\n\n\n\nCode\ndata.isna().sum()\n\n\nID             0\nSeq            0\nGender         0\nBirth_Year     0\nLC_Score       0\nRC_Score       0\nTotal Score    0\n학습목표           0\n학습방법           0\n강의 학습 교재 유형    0\n학습빈도           0\n기출문제 공부 횟수     3\n취약분야 인지 여부     0\n토익 모의테스트 횟수    0\nStudent ID     0\ndtype: int64\n\n\n\n\n\n\n\nCode\ndata.describe()\n\n\n\n\n\n\n\n\n\nID\nSeq\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n기출문제 공부 횟수\n토익 모의테스트 횟수\n\n\n\n\ncount\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n1500.000000\n1497.000000\n1500.000000\n\n\nmean\n250.500000\n2.000000\n1992.906000\n340.079333\n340.164667\n680.260667\n5.286573\n9.784000\n\n\nstd\n144.385415\n0.816769\n8.218893\n86.807523\n87.143890\n159.110652\n2.797303\n5.324181\n\n\nmin\n1.000000\n1.000000\n1973.000000\n105.000000\n84.000000\n250.000000\n1.000000\n1.000000\n\n\n25%\n125.750000\n1.000000\n1986.750000\n279.000000\n280.000000\n564.000000\n3.000000\n5.000000\n\n\n50%\n250.500000\n2.000000\n1992.500000\n335.000000\n337.000000\n687.000000\n5.000000\n9.000000\n\n\n75%\n375.250000\n3.000000\n2000.000000\n404.000000\n406.000000\n800.000000\n8.000000\n14.000000\n\n\nmax\n500.000000\n3.000000\n2007.000000\n495.000000\n495.000000\n990.000000\n10.000000\n20.000000"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터-전처리-수행",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터-전처리-수행",
    "title": "00. MP (1)",
    "section": "",
    "text": "Code\nprint(data.dtypes)\n\n\nID               int64\nSeq              int64\nGender          object\nBirth_Year       int64\nLC_Score         int64\nRC_Score         int64\nTotal Score      int64\n학습목표            object\n학습방법            object\n강의 학습 교재 유형     object\n학습빈도            object\n기출문제 공부 횟수     float64\n취약분야 인지 여부      object\n토익 모의테스트 횟수      int64\nStudent ID      object\ndtype: object\n\n\n\n\n\n\n\nCode\ndata.drop(\"Student ID\",axis=1,inplace=True)\n\n\n\n\nCode\ndata.head()\n\n\n\n\n\n\n\n\n\nID\nSeq\nGender\nBirth_Year\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n\n\n\n\n0\n1\n1\nM\n1973\n181\n173\n354\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주3-4회\n6.0\n알고 있지 않음\n6\n\n\n1\n1\n2\nM\n1973\n227\n213\n440\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n주1-2회\n3.0\n알고 있음\n5\n\n\n2\n1\n3\nM\n1973\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\n\n\n3\n2\n1\nF\n1982\n330\n290\n620\n자기계발\n오프라인강의\n뉴스/이슈 기반 교재\n매일(주 7회)\n8.0\n알고 있지 않음\n19\n\n\n4\n2\n2\nF\n1982\n354\n339\n693\n승진\n온라인강의\n영상 교재\n주5-6회\n2.0\n알고 있음\n15\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlen(data.columns)\n\n\n14\n\n\n\n\n\n\n\nCode\ndata[\"기출문제 공부 횟수\"].fillna(0,inplace=True)\n\n\n\n\n\n\n\nCode\ndata[\"기출문제 공부 횟수\"].unique()\n\n\narray([ 6.,  3.,  7.,  8.,  2.,  4.,  9.,  5., 10.,  1.,  0.])\n\n\n\n\n\n\ndf1(개인정보 데이터) features : 'ID', 'Gender', 'Birth_Year'\ndf2(토익시험 학습정보 데이터) features : 'ID','Seq', 'LC_Score', 'RC_Score', 'Total Score', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수'\n\n\n\nCode\ncol_1 = ['ID', 'Gender', 'Birth_Year']\ncol_2 = ['ID','Seq', 'LC_Score', 'RC_Score', 'Total Score',\n         '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도',\n         '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수']\n\ndf1 = data.loc[:, map(lambda x : x  in col_1,data.columns )]\ndf2 = data.loc[:, map(lambda x : x  in col_2,data.columns )]\n\nprint(f\"df1의 컬럼 : {list(df1.columns)}\\n\")\nprint(\"*\"*100+\"\\n\")\nprint(f\"df2의 컬럼 : {list(df2.columns)}\")\n\n\ndf1의 컬럼 : ['ID', 'Gender', 'Birth_Year']\n\n****************************************************************************************************\n\ndf2의 컬럼 : ['ID', 'Seq', 'LC_Score', 'RC_Score', 'Total Score', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수', '취약분야 인지 여부', '토익 모의테스트 횟수']\n\n\n\n\n\n\n\n\nCode\ndf1 = df1.drop_duplicates()\n\n\n\n\nCode\ndf1.head()\n\n\n\n\n\n\n\n\n\nID\nGender\nBirth_Year\n\n\n\n\n0\n1\nM\n1973\n\n\n3\n2\nF\n1982\n\n\n6\n3\nF\n1995\n\n\n9\n4\nM\n1987\n\n\n12\n5\nM\n1994\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp = df2.loc[map(lambda x : x == 3,df2.Seq), :]\ntemp.Seq.unique()\n\n\narray([3], dtype=int64)\n\n\n\n\nCode\ntemp.head()\n\n\n\n\n\n\n\n\n\nID\nSeq\nLC_Score\nRC_Score\nTotal Score\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n\n\n\n\n2\n1\n3\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\n\n\n5\n2\n3\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n4.0\n알고 있음\n14\n\n\n8\n3\n3\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n4.0\n알고 있음\n4\n\n\n11\n4\n3\n495\n397\n892\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주3-4회\n9.0\n알고 있음\n8\n\n\n14\n5\n3\n398\n437\n835\n자기계발\n온라인강의\n영상 교재\n주3-4회\n6.0\n알고 있음\n4\n\n\n\n\n\n\n\n\n\n\n\nLC_Score, RC_Score, Total Score를 각각 ‘3st_LC_Score’, ‘3st_RC_Score’, ’3st_Total_Score’로 변경하고 확인해주세요.\n\n\n\nCode\ntemp = temp.rename(columns = {\"LC_Score\" : \"3st_LC_SCcore\",\n                        \"RC_Score\" : \"3st_RC_SCcore\",\n                        \"Total Score\" : \"3st_Total_SCcore\",\n                        })\ntemp.head()\n\n\n\n\n\n\n\n\n\nID\nSeq\n3st_LC_SCcore\n3st_RC_SCcore\n3st_Total_SCcore\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n\n\n\n\n2\n1\n3\n345\n336\n681\n승진\n온라인강의\n영상 교재\n주5-6회\n7.0\n알고 있음\n10\n\n\n5\n2\n3\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n4.0\n알고 있음\n14\n\n\n8\n3\n3\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n4.0\n알고 있음\n4\n\n\n11\n4\n3\n495\n397\n892\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주3-4회\n9.0\n알고 있음\n8\n\n\n14\n5\n3\n398\n437\n835\n자기계발\n온라인강의\n영상 교재\n주3-4회\n6.0\n알고 있음\n4\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp1 = df2.loc[map(lambda x : x == 1,df2.Seq), :]\ntemp1.Seq.unique()\n\n\narray([1], dtype=int64)\n\n\n\n\n\n\n\nCode\ntemp1 = temp1.loc[:,['ID','LC_Score','RC_Score','Total Score']]\n\n\n\n\n\n\nLC_Score, RC_Score, Total Score를 각각 ‘1st_LC_Score’, ‘1st_RC_Score’, ’1st_Total_Score’로 변경하고 확인해주세요.\n\n\n\nCode\ntemp1 = temp1.rename(columns = {\"LC_Score\" : \"1st_LC_SCcore\",\n                        \"RC_Score\" : \"1st_RC_SCcore\",\n                        \"Total Score\" : \"1st_Total_SCcore\",\n                        })\ntemp1.head()\n\n\n\n\n\n\n\n\n\nID\n1st_LC_SCcore\n1st_RC_SCcore\n1st_Total_SCcore\n\n\n\n\n0\n1\n181\n173\n354\n\n\n3\n2\n330\n290\n620\n\n\n6\n3\n367\n309\n676\n\n\n9\n4\n470\n285\n755\n\n\n12\n5\n273\n372\n645\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntemp2 = df2.loc[map(lambda x : x == 2,df2.Seq), :]\ntemp2.Seq.unique()\n\n\narray([2], dtype=int64)\n\n\n\n\n\n\n\nCode\ntemp2 =  temp2.loc[:,['ID','LC_Score','RC_Score','Total Score']]\n\n\n\n\n\n\n\nCode\ntemp2 = temp2.rename(columns = {\"LC_Score\" : \"2st_LC_SCcore\",\n                        \"RC_Score\" : \"2st_RC_SCcore\",\n                        \"Total Score\" : \"2st_Total_SCcore\",\n                        })\ntemp2.head()\n\n\n\n\n\n\n\n\n\nID\n2st_LC_SCcore\n2st_RC_SCcore\n2st_Total_SCcore\n\n\n\n\n1\n1\n227\n213\n440\n\n\n4\n2\n354\n339\n693\n\n\n7\n3\n396\n365\n761\n\n\n10\n4\n495\n341\n836\n\n\n13\n5\n314\n426\n740\n\n\n\n\n\n\n\n\n\n\n- 합친 후 ’score_merged_data1’에 할당\n\n\nCode\nscore_merged_data1 = pd.merge(temp,temp1)\n\n\n\n\n\n\n\nCode\nscore_merged_data2 = pd.merge(score_merged_data1,temp2)\n\n\n\n\n\n\n\nCode\nprint(score_merged_data2.info())\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 500 entries, 0 to 499\nData columns (total 18 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                500 non-null    int64  \n 1   Seq               500 non-null    int64  \n 2   3st_LC_SCcore     500 non-null    int64  \n 3   3st_RC_SCcore     500 non-null    int64  \n 4   3st_Total_SCcore  500 non-null    int64  \n 5   학습목표              500 non-null    object \n 6   학습방법              500 non-null    object \n 7   강의 학습 교재 유형       500 non-null    object \n 8   학습빈도              500 non-null    object \n 9   기출문제 공부 횟수        500 non-null    float64\n 10  취약분야 인지 여부        500 non-null    object \n 11  토익 모의테스트 횟수       500 non-null    int64  \n 12  1st_LC_SCcore     500 non-null    int64  \n 13  1st_RC_SCcore     500 non-null    int64  \n 14  1st_Total_SCcore  500 non-null    int64  \n 15  2st_LC_SCcore     500 non-null    int64  \n 16  2st_RC_SCcore     500 non-null    int64  \n 17  2st_Total_SCcore  500 non-null    int64  \ndtypes: float64(1), int64(12), object(5)\nmemory usage: 70.4+ KB\nNone\n\n\n\n\n\n\n- 합친 데이터를 baseline_data에 할당\n\n\nCode\nbaseline_data = pd.merge(df1,score_merged_data2)\n\n\n\n\nCode\nbaseline_data.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 20 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \ndtypes: float64(1), int64(13), object(6)\nmemory usage: 78.6+ KB\n\n\n\n\n\n\n‘Score_diff_total’ = ‘3st_Total_Score’ - ‘2st_Total_Score’\n\n\n\nCode\nbaseline_data[\"Score_diff_total\"] = baseline_data[\"3st_Total_SCcore\"] - baseline_data[\"2st_Total_SCcore\"] \n\n\n\n\n\n\n\nCode\nbaseline_data.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \n 20  Score_diff_total  502 non-null    int64  \ndtypes: float64(1), int64(14), object(6)\nmemory usage: 82.5+ KB"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터셋-저장하기",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터셋-저장하기",
    "title": "00. MP (1)",
    "section": "",
    "text": "Code\nbaseline_data.to_csv(\"data04_baseline.csv\",index=False)\n\n\n\n\n\n\n\nCode\npd.read_csv(\"data04_baseline.csv\").info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \n 20  Score_diff_total  502 non-null    int64  \ndtypes: float64(1), int64(14), object(6)\nmemory usage: 82.5+ KB"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#환경설정-1",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#환경설정-1",
    "title": "00. MP (1)",
    "section": "1. 환경설정",
    "text": "1. 환경설정\n\n(1) 폰트설치\n\n\nCode\n!pip install matplotlib\n!pip install --upgrade matplotlib\n\nimport matplotlib.pyplot as plt\n\n\nRequirement already satisfied: matplotlib in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (3.7.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (1.1.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (4.42.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: numpy&gt;=1.20 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (1.25.2)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (23.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (10.0.0)\nRequirement already satisfied: pyparsing&lt;3.1,&gt;=2.3.1 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil&gt;=2.7 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\nRequirement already satisfied: matplotlib in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (3.7.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (1.1.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (4.42.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: numpy&gt;=1.20 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (1.25.2)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (23.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (10.0.0)\nRequirement already satisfied: pyparsing&lt;3.1,&gt;=2.3.1 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil&gt;=2.7 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\n\n\n\n\n(2) 라이브러리 불러오기\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.rc('font', family='Malgun Gothic')\n\n\n\n\n(3)-1. 데이터 불러오기\n\n\nCode\ndata = pd.read_csv(\"data04_baseline.csv\")\n\n\n\n\n(3)-2 데이터 확인\n\n\nCode\ndata.head()\n\n\n\n\n\n\n\n\n\nID\nGender\nBirth_Year\nSeq\n3st_LC_SCcore\n3st_RC_SCcore\n3st_Total_SCcore\n학습목표\n학습방법\n강의 학습 교재 유형\n...\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n1st_LC_SCcore\n1st_RC_SCcore\n1st_Total_SCcore\n2st_LC_SCcore\n2st_RC_SCcore\n2st_Total_SCcore\nScore_diff_total\n\n\n\n\n0\n1\nM\n1973\n3\n345\n336\n681\n승진\n온라인강의\n영상 교재\n...\n7.0\n알고 있음\n10\n181\n173\n354\n227\n213\n440\n241\n\n\n1\n2\nF\n1982\n3\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n...\n4.0\n알고 있음\n14\n330\n290\n620\n354\n339\n693\n55\n\n\n2\n3\nF\n1995\n3\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n...\n4.0\n알고 있음\n4\n367\n309\n676\n396\n365\n761\n37\n\n\n3\n4\nM\n1987\n3\n495\n397\n892\n승진\n온라인강의\n뉴스/이슈 기반 교재\n...\n9.0\n알고 있음\n8\n470\n285\n755\n495\n341\n836\n56\n\n\n4\n5\nM\n1994\n3\n398\n437\n835\n자기계발\n온라인강의\n영상 교재\n...\n6.0\n알고 있음\n4\n273\n372\n645\n314\n426\n740\n95\n\n\n\n\n5 rows × 21 columns\n\n\n\n\n\n(3)-3. 열과 행확인\n\n\nCode\ndata.shape\n\n\n(502, 21)\n\n\n\n\n(3)-4. 데이터의 자료구조(Row, Colu,n, Not-null, type)을 확인\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    object \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    object \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \n 20  Score_diff_total  502 non-null    int64  \ndtypes: float64(1), int64(14), object(6)\nmemory usage: 82.5+ KB\n\n\n\n\n(3)-5. 인덱스 확인\n\n\nCode\ndata.index\n\n\nRangeIndex(start=0, stop=502, step=1)\n\n\n\n\n(3)-6. 컬럼명을 확인\n\n\nCode\ndata.columns\n\n\nIndex(['ID', 'Gender', 'Birth_Year', 'Seq', '3st_LC_SCcore', '3st_RC_SCcore',\n       '3st_Total_SCcore', '학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '기출문제 공부 횟수',\n       '취약분야 인지 여부', '토익 모의테스트 횟수', '1st_LC_SCcore', '1st_RC_SCcore',\n       '1st_Total_SCcore', '2st_LC_SCcore', '2st_RC_SCcore',\n       '2st_Total_SCcore', 'Score_diff_total'],\n      dtype='object')\n\n\n\n\n(3)-7. 상단 5행을 확인\n\n\nCode\ndata.head(5)\n\n\n\n\n\n\n\n\n\nID\nGender\nBirth_Year\nSeq\n3st_LC_SCcore\n3st_RC_SCcore\n3st_Total_SCcore\n학습목표\n학습방법\n강의 학습 교재 유형\n...\n기출문제 공부 횟수\n취약분야 인지 여부\n토익 모의테스트 횟수\n1st_LC_SCcore\n1st_RC_SCcore\n1st_Total_SCcore\n2st_LC_SCcore\n2st_RC_SCcore\n2st_Total_SCcore\nScore_diff_total\n\n\n\n\n0\n1\nM\n1973\n3\n345\n336\n681\n승진\n온라인강의\n영상 교재\n...\n7.0\n알고 있음\n10\n181\n173\n354\n227\n213\n440\n241\n\n\n1\n2\nF\n1982\n3\n380\n368\n748\n승진\n온라인강의\n뉴스/이슈 기반 교재\n...\n4.0\n알고 있음\n14\n330\n290\n620\n354\n339\n693\n55\n\n\n2\n3\nF\n1995\n3\n416\n382\n798\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n...\n4.0\n알고 있음\n4\n367\n309\n676\n396\n365\n761\n37\n\n\n3\n4\nM\n1987\n3\n495\n397\n892\n승진\n온라인강의\n뉴스/이슈 기반 교재\n...\n9.0\n알고 있음\n8\n470\n285\n755\n495\n341\n836\n56\n\n\n4\n5\nM\n1994\n3\n398\n437\n835\n자기계발\n온라인강의\n영상 교재\n...\n6.0\n알고 있음\n4\n273\n372\n645\n314\n426\n740\n95\n\n\n\n\n5 rows × 21 columns"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터프레임-탐색-개별-변수-분석",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터프레임-탐색-개별-변수-분석",
    "title": "00. MP (1)",
    "section": "2. 데이터프레임 탐색 : 개별 변수 분석",
    "text": "2. 데이터프레임 탐색 : 개별 변수 분석\n\n(1)-1 : 열별 누락값 확인\n\n\nCode\ndata.isna().sum()\n\n\nID                  0\nGender              0\nBirth_Year          0\nSeq                 0\n3st_LC_SCcore       0\n3st_RC_SCcore       0\n3st_Total_SCcore    0\n학습목표                0\n학습방법                0\n강의 학습 교재 유형         0\n학습빈도                0\n기출문제 공부 횟수          0\n취약분야 인지 여부          0\n토익 모의테스트 횟수         0\n1st_LC_SCcore       0\n1st_RC_SCcore       0\n1st_Total_SCcore    0\n2st_LC_SCcore       0\n2st_RC_SCcore       0\n2st_Total_SCcore    0\nScore_diff_total    0\ndtype: int64\n\n\n\n\n(1)-2. 열별 통계량 요약하여 출력\n\n\nCode\ndata.describe()\n\n\n\n\n\n\n\n\n\nID\nBirth_Year\nSeq\n3st_LC_SCcore\n3st_RC_SCcore\n3st_Total_SCcore\n기출문제 공부 횟수\n토익 모의테스트 횟수\n1st_LC_SCcore\n1st_RC_SCcore\n1st_Total_SCcore\n2st_LC_SCcore\n2st_RC_SCcore\n2st_Total_SCcore\nScore_diff_total\n\n\n\n\ncount\n502.000000\n502.000000\n502.0\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n502.000000\n\n\nmean\n250.587649\n1992.948207\n3.0\n368.023904\n369.318725\n737.382470\n5.087649\n9.452191\n313.697211\n312.798805\n626.496016\n337.868526\n338.045817\n675.924303\n61.458167\n\n\nstd\n144.199862\n8.236603\n0.0\n82.052339\n81.659228\n155.752174\n2.790826\n4.952137\n85.483105\n86.522443\n148.318758\n84.141542\n83.817809\n152.986694\n39.684902\n\n\nmin\n1.000000\n1973.000000\n3.0\n141.000000\n135.000000\n280.000000\n0.000000\n1.000000\n105.000000\n84.000000\n250.000000\n120.000000\n129.000000\n260.000000\n0.000000\n\n\n25%\n126.250000\n1987.000000\n3.0\n295.000000\n295.000000\n591.250000\n3.000000\n5.000000\n259.250000\n250.000000\n519.000000\n279.000000\n280.500000\n558.750000\n30.000000\n\n\n50%\n251.500000\n1993.000000\n3.0\n372.000000\n375.000000\n760.000000\n5.000000\n8.000000\n308.000000\n311.500000\n641.000000\n332.500000\n335.000000\n690.500000\n63.000000\n\n\n75%\n374.750000\n2000.000000\n3.0\n434.000000\n437.000000\n860.000000\n7.000000\n13.000000\n369.000000\n377.750000\n734.750000\n395.000000\n400.000000\n790.000000\n83.000000\n\n\nmax\n500.000000\n2007.000000\n3.0\n495.000000\n495.000000\n990.000000\n10.000000\n20.000000\n495.000000\n491.000000\n970.000000\n495.000000\n495.000000\n990.000000\n281.000000\n\n\n\n\n\n\n\n\n\n(1)-3. 출력한 요약통계량을 행과 열을 바꿔서 출력\n\n\nCode\ndata.describe().T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nID\n502.0\n250.587649\n144.199862\n1.0\n126.25\n251.5\n374.75\n500.0\n\n\nBirth_Year\n502.0\n1992.948207\n8.236603\n1973.0\n1987.00\n1993.0\n2000.00\n2007.0\n\n\nSeq\n502.0\n3.000000\n0.000000\n3.0\n3.00\n3.0\n3.00\n3.0\n\n\n3st_LC_SCcore\n502.0\n368.023904\n82.052339\n141.0\n295.00\n372.0\n434.00\n495.0\n\n\n3st_RC_SCcore\n502.0\n369.318725\n81.659228\n135.0\n295.00\n375.0\n437.00\n495.0\n\n\n3st_Total_SCcore\n502.0\n737.382470\n155.752174\n280.0\n591.25\n760.0\n860.00\n990.0\n\n\n기출문제 공부 횟수\n502.0\n5.087649\n2.790826\n0.0\n3.00\n5.0\n7.00\n10.0\n\n\n토익 모의테스트 횟수\n502.0\n9.452191\n4.952137\n1.0\n5.00\n8.0\n13.00\n20.0\n\n\n1st_LC_SCcore\n502.0\n313.697211\n85.483105\n105.0\n259.25\n308.0\n369.00\n495.0\n\n\n1st_RC_SCcore\n502.0\n312.798805\n86.522443\n84.0\n250.00\n311.5\n377.75\n491.0\n\n\n1st_Total_SCcore\n502.0\n626.496016\n148.318758\n250.0\n519.00\n641.0\n734.75\n970.0\n\n\n2st_LC_SCcore\n502.0\n337.868526\n84.141542\n120.0\n279.00\n332.5\n395.00\n495.0\n\n\n2st_RC_SCcore\n502.0\n338.045817\n83.817809\n129.0\n280.50\n335.0\n400.00\n495.0\n\n\n2st_Total_SCcore\n502.0\n675.924303\n152.986694\n260.0\n558.75\n690.5\n790.00\n990.0\n\n\nScore_diff_total\n502.0\n61.458167\n39.684902\n0.0\n30.00\n63.0\n83.00\n281.0\n\n\n\n\n\n\n\n\n\n(1)-4. Gender 컬럼의 값 별 개수를 확인\n\n\nCode\ndata.Gender.value_counts()\n\n\nGender\nM    251\nF    251\nName: count, dtype: int64\n\n\n\n\n(1)-5. Gender 컬럼의 [‘M’, ‘F’] –&gt; [1,2]로 변경\n\n\nCode\ndata.Gender = [1 if i ==\"M\" else 2 for i in data.Gender]\n\n\n\n\nCode\ndata.Gender.unique()\n\n\narray([1, 2], dtype=int64)\n\n\n\n\n(1)-6. Gender 컬럼의 값 별 개수를 다시 확인해주세요.\n\n\nCode\ndata.Gender.value_counts()\n\n\nGender\n1    251\n2    251\nName: count, dtype: int64\n\n\n\n\n(1)-7. Gender컬럼 타입을 int로 변경\n- 리스트 컴프리헨션을 통해 위에서 수행\n\n\n(1)-8. 데이터 프레임의 Null 데이터가 있는지 확인\n\n\nCode\ndata.isnull().sum()\n\n\nID                  0\nGender              0\nBirth_Year          0\nSeq                 0\n3st_LC_SCcore       0\n3st_RC_SCcore       0\n3st_Total_SCcore    0\n학습목표                0\n학습방법                0\n강의 학습 교재 유형         0\n학습빈도                0\n기출문제 공부 횟수          0\n취약분야 인지 여부          0\n토익 모의테스트 횟수         0\n1st_LC_SCcore       0\n1st_RC_SCcore       0\n1st_Total_SCcore    0\n2st_LC_SCcore       0\n2st_RC_SCcore       0\n2st_Total_SCcore    0\nScore_diff_total    0\ndtype: int64\n\n\n\n\n\n(2)-1. 변수 sdt 문자열 “Score_diff_total”을 할당\n\n\nCode\nsdt  =\"Score_diff_total\"\n\n\n\n\n(2)-2. Score_diff_total에 대한 기술 통계 정보를 데이터 프레임의 형태로 출력\n\n\nCode\ndata[[sdt]].describe()\n\n\n\n\n\n\n\n\n\nScore_diff_total\n\n\n\n\ncount\n502.000000\n\n\nmean\n61.458167\n\n\nstd\n39.684902\n\n\nmin\n0.000000\n\n\n25%\n30.000000\n\n\n50%\n63.000000\n\n\n75%\n83.000000\n\n\nmax\n281.000000\n\n\n\n\n\n\n\n\n\n(2)-3. 위의 결과를 행과 열을 변환하여 출력\n\n\nCode\ndata[[sdt]].describe().T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nScore_diff_total\n502.0\n61.458167\n39.684902\n0.0\n30.0\n63.0\n83.0\n281.0\n\n\n\n\n\n\n\n\n\n(2)-4. 변수 BY에 문자열 ’Birth_Year’을 할당\n\n\nCode\nBY = \"Birth_Year\"\n\n\n\n\n(2)-5. ’Birth_Year’열에 대한 기술 통계 정보를 행과열을 변환해 출력\n\n\nCode\ndata[[BY]].describe().T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nBirth_Year\n502.0\n1992.948207\n8.236603\n1973.0\n1987.0\n1993.0\n2000.0\n2007.0\n\n\n\n\n\n\n\n\n\n(2)-6. ‘data’ 데이터프레임의 ‘Birth_Year’ 컬럼의 연도별 개수를 Bar 차트로 그리세요.\n\n\nCode\ndata[BY]\n\n\n0      1973\n1      1982\n2      1995\n3      1987\n4      1994\n       ... \n497    2006\n498    1988\n499    2006\n500    1990\n501    1984\nName: Birth_Year, Length: 502, dtype: int64\n\n\n\n\nCode\ndata.groupby(BY)[[BY]].count().\\\n                    rename(columns = {\"Birth_Year\" : \"Count\"}).\\\n                    reset_index().plot(kind= \"bar\",x=\"Birth_Year\",y=\"Count\",title=  \"Count of Birth_Year\")\n\n\n&lt;Axes: title={'center': 'Count of Birth_Year'}, xlabel='Birth_Year'&gt;\n\n\n\n\n\n\n\n(2)-7. 데이터 타입이 object인 컬럼만 추출\n\n\nCode\ndata.select_dtypes(\"O\")\n\n\n\n\n\n\n\n\n\n학습목표\n학습방법\n강의 학습 교재 유형\n학습빈도\n취약분야 인지 여부\n\n\n\n\n0\n승진\n온라인강의\n영상 교재\n주5-6회\n알고 있음\n\n\n1\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주5-6회\n알고 있음\n\n\n2\n자기계발\n참고서\n일반적인 영어 텍스트 기반 교재\n주1-2회\n알고 있음\n\n\n3\n승진\n온라인강의\n뉴스/이슈 기반 교재\n주3-4회\n알고 있음\n\n\n4\n자기계발\n온라인강의\n영상 교재\n주3-4회\n알고 있음\n\n\n...\n...\n...\n...\n...\n...\n\n\n497\n자기계발\n온라인강의\n일반적인 영어 텍스트 기반 교재\n매일(주 7회)\n알고 있음\n\n\n498\n승진\n온라인강의\n비즈니스 시뮬레이션(Role Play)\n매일(주 7회)\n알고 있음\n\n\n499\n자기계발\n오프라인강의\n일반적인 영어 텍스트 기반 교재\n주1-2회\n알고 있음\n\n\n500\n자기계발\n오프라인강의\n비즈니스 시뮬레이션(Role Play)\n주3-4회\n알고 있음\n\n\n501\n승진\n오프라인강의\n비즈니스 시뮬레이션(Role Play)\n주5-6회\n알고 있음\n\n\n\n\n502 rows × 5 columns\n\n\n\n\n\n(2)-8. 데이터 타입이 Object 형태인 컬럼의 컬럼명만 추출해서 출력\n\n\nCode\ndata.select_dtypes(\"O\").columns.values\n\n\narray(['학습목표', '학습방법', '강의 학습 교재 유형', '학습빈도', '취약분야 인지 여부'], dtype=object)\n\n\n\n\n(2)-9. 학습목표의 값들의 빈도수를 계산하여 출력\n\n\nCode\ndata.select_dtypes(\"O\")[[\"학습목표\"]].value_counts().reset_index()\n\n\n\n\n\n\n\n\n\n학습목표\ncount\n\n\n\n\n0\n자기계발\n331\n\n\n1\n승진\n155\n\n\n2\n취업\n16\n\n\n\n\n\n\n\n\n\n(2)-10. data 데이터 프레임의 전체 열과 행 개수를 출력\n\n\nCode\nr,c = data.shape\n\n\n\n\nCode\nprint(f\"전체 행의 수 : {r}, 전체 열의 수 : {c}\")\n\n\n전체 행의 수 : 502, 전체 열의 수 : 21\n\n\n\n\n(2)-10. 변수 ’학습목표’의 값들의 빈도수를 전체 데이터의 개수로 나누어서 해당 값들이 전체 데이터에서 차지하는 비율을 구하기\n\n\nCode\ntemp = data.select_dtypes(\"O\")[[\"학습목표\"]].value_counts().reset_index()\n\n\n\n\nCode\ntemp[\"비율(%)\"] = round(temp[\"count\"]/r*100,2)\n\n\n\n\nCode\ntemp\n\n\n\n\n\n\n\n\n\n학습목표\ncount\n비율(%)\n\n\n\n\n0\n자기계발\n331\n65.94\n\n\n1\n승진\n155\n30.88\n\n\n2\n취업\n16\n3.19\n\n\n\n\n\n\n\n\n\n(2)-11. 학습목표 열에 대한 Bar 차트를 확인\n\n\nCode\ntemp.plot(kind= \"bar\", x= \"학습목표\",y=\"비율(%)\", title =\"토익 학습 목표 비율\")\n\n\n&lt;Axes: title={'center': '토익 학습 목표 비율'}, xlabel='학습목표'&gt;\n\n\n\n\n\n\n\n(2)-12. data 데이터 프레임에서 숫자형 컬럼에 대하여 검색\n\n\nCode\n#data.info()\n\n\n\n\nCode\ndata.select_dtypes(include= [\"float64\", \"int64\"])\n\n\n\n\n\n\n\n\n\nID\nGender\nBirth_Year\nSeq\n3st_LC_SCcore\n3st_RC_SCcore\n3st_Total_SCcore\n기출문제 공부 횟수\n토익 모의테스트 횟수\n1st_LC_SCcore\n1st_RC_SCcore\n1st_Total_SCcore\n2st_LC_SCcore\n2st_RC_SCcore\n2st_Total_SCcore\nScore_diff_total\n\n\n\n\n0\n1\n1\n1973\n3\n345\n336\n681\n7.0\n10\n181\n173\n354\n227\n213\n440\n241\n\n\n1\n2\n2\n1982\n3\n380\n368\n748\n4.0\n14\n330\n290\n620\n354\n339\n693\n55\n\n\n2\n3\n2\n1995\n3\n416\n382\n798\n4.0\n4\n367\n309\n676\n396\n365\n761\n37\n\n\n3\n4\n1\n1987\n3\n495\n397\n892\n9.0\n8\n470\n285\n755\n495\n341\n836\n56\n\n\n4\n5\n1\n1994\n3\n398\n437\n835\n6.0\n4\n273\n372\n645\n314\n426\n740\n95\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n497\n496\n1\n2006\n3\n364\n336\n700\n10.0\n13\n347\n315\n662\n349\n321\n670\n30\n\n\n498\n497\n2\n1988\n3\n187\n252\n439\n9.0\n17\n112\n250\n362\n120\n251\n371\n68\n\n\n499\n498\n1\n2006\n3\n255\n167\n422\n0.0\n4\n252\n150\n402\n254\n158\n412\n10\n\n\n500\n499\n2\n1990\n3\n422\n370\n792\n4.0\n7\n371\n324\n695\n378\n326\n704\n88\n\n\n501\n500\n1\n1984\n3\n235\n226\n461\n7.0\n15\n169\n188\n357\n172\n190\n362\n99\n\n\n\n\n502 rows × 16 columns\n\n\n\n\n\n(2)-13. 변수 ’강의 학습 교재 유형’의 값들의 빈도수, 비율을 계산해서 출력\n\n\nCode\ntemp2 = data[[\"강의 학습 교재 유형\"]].value_counts().reset_index()\n\n\n\n\nCode\ntemp2[\"비율(%)\"] = temp2[\"count\"]/r\n\n\n\n\nCode\ntemp2\n\n\n\n\n\n\n\n\n\n강의 학습 교재 유형\ncount\n비율(%)\n\n\n\n\n0\n일반적인 영어 텍스트 기반 교재\n137\n0.272908\n\n\n1\n영상 교재\n129\n0.256972\n\n\n2\n뉴스/이슈 기반 교재\n122\n0.243028\n\n\n3\n비즈니스 시뮬레이션(Role Play)\n114\n0.227092\n\n\n\n\n\n\n\n\n\n(2)-14. 취약분야 인지 여부 문자열의 값을 알고 있음은 1, 알고 있지 않음은 0으로 변경\n\n\nCode\ndata[\"취약분야 인지 여부\"].replace(\"알고 있음\",\"1\").replace(\"알고 있지 않음\",\"0\").unique()\n\n\narray(['1', '0'], dtype=object)\n\n\n\n\nCode\ndata[\"취약분야 인지 여부\"] = data[\"취약분야 인지 여부\"].replace(\"알고 있음\",\"1\").replace(\"알고 있지 않음\",\"0\")"
  },
  {
    "objectID": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터-저장",
    "href": "posts/DX/MP/2023-08-24-00. MP (1).html#데이터-저장",
    "title": "00. MP (1)",
    "section": "3. 데이터 저장",
    "text": "3. 데이터 저장\n\n\nCode\ndata.to_csv(\"data04_featured.csv\",index=False)\n\n\n\n\nCode\npd.read_csv(\"data04_featured.csv\").info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 502 entries, 0 to 501\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   ID                502 non-null    int64  \n 1   Gender            502 non-null    int64  \n 2   Birth_Year        502 non-null    int64  \n 3   Seq               502 non-null    int64  \n 4   3st_LC_SCcore     502 non-null    int64  \n 5   3st_RC_SCcore     502 non-null    int64  \n 6   3st_Total_SCcore  502 non-null    int64  \n 7   학습목표              502 non-null    object \n 8   학습방법              502 non-null    object \n 9   강의 학습 교재 유형       502 non-null    object \n 10  학습빈도              502 non-null    object \n 11  기출문제 공부 횟수        502 non-null    float64\n 12  취약분야 인지 여부        502 non-null    int64  \n 13  토익 모의테스트 횟수       502 non-null    int64  \n 14  1st_LC_SCcore     502 non-null    int64  \n 15  1st_RC_SCcore     502 non-null    int64  \n 16  1st_Total_SCcore  502 non-null    int64  \n 17  2st_LC_SCcore     502 non-null    int64  \n 18  2st_RC_SCcore     502 non-null    int64  \n 19  2st_Total_SCcore  502 non-null    int64  \n 20  Score_diff_total  502 non-null    int64  \ndtypes: float64(1), int64(16), object(4)\nmemory usage: 82.5+ KB"
  },
  {
    "objectID": "posts/DX/2023-07-31-00.intro.html",
    "href": "posts/DX/2023-07-31-00.intro.html",
    "title": "00. Intro & setting",
    "section": "",
    "text": "- 어… 일단 평소에도 quarto를 이용해서 웹사이트를 관리했지만… 뭔가 처음 깃허브를 접하구 하시는 분들은 이 플랫폼을 사용할 때 되게 난항이 있을것 같다… (내가 그랬다…)\n- 그리고 원래 만들어 놓았던 사이트는 뭔가 좀 지저분한 느낌이 들어서….\n- 에이블스쿨 하면서 배운것들 기록할 때는 뭔가 깔끔한 공간에 하고 싶기도 하다.\n- 이참에 절차를 확실히 내가 적어두자!\n\n\n- quarto download link : 여기서 quarto를 다운받자!\n\n\n\n- Terminal을 켠다음에 아래와 같은 명령어를 입력한다!\n(그.. 명령어 입력할 때 현재 자기 주피터 킬때 켜지는 폴더로 옮긴 다음에 수행하자… 골치 아프다ㅜㅜ)\nquarto create project website gcsite\n- 그러면 다음과 같은 이미지가 보인다\n\n- 저기 open with 어찌고 보이는데 d버튼 누르면 (don’t open)으로 넘어가니 그걸 선택한 후 엔터를 눌러준다!\n- 그러면 아래 이미지처럼 맨 밑에 gcsite라는 폴더가 생긴 것을 볼 수 있다.\n\n\n\n\n- git bash 쓰는 사람들 많던데 난 github desktop이 훨씬 편하다.\n- git 알못이기 때문에 많은 것을 알기 위해 괴롭고 싶지 않다.\n- 뭐 여튼 깃허브 데스크탑을 킨다.\n- 상단 메뉴바 \\(\\to\\) File \\(\\to\\) Add local repository\n- 그러면 아래와 같은 경고문이 뜬다.\n\n- local하고 연결하고 싶은데 깃허브에는 gcsite가 없으니 대충 만들어 달라는 것임 “create a repository” 를 눌러주자.\n\n- 무시, 걍 create repository ㄱㄱ\n- 그러면 깃허브 데스크탑에서 너 방금 만든거 너꺼 깃허브에 Publish 할거냐고 물어봄\n\n- Publish repository 눌러주면 끝~~ (단, publish할 때 private 체크박스는 해제하구 하자!)\n- 그 다음 내가 생성산 gcsite 저장소 setting으로 넘어가서 pages를 클릭!\n- 아래와 같이 branch를 수정 후 save 버튼 눌러주자\n\n\n\n\n- quarto 원리 : 작성한 ipynb파일 html파일로 출력해서 그 html파일들로 웹사이트를 구성하는 것1\n- step1. posts와 docs라는 폴더를 만들자\n\nposts는 내가 작성하는 ipynb파일들이 들어갈거고, docs에는 html파일이 들어갈 것이다.\n\n- step2. index 파일 수정\n\nindex파일은 뭐랄까 네비게이터 역할이랄까 아래와 같이 바꿔주자\n\n---\ntitle: \"GC site\"\nlisting:\n  contents: posts\n  sort: [date desc, title]\n  type: table\n  categories: true\n  sort-ui: true\n  filter-ui: true\npage-layout: full\ntitle-block-banner: true\n---\n- step3. _quarto.uml 파일 수정 \\(\\to\\) 템플릿이랑 디자인 이쁜거 많으니 본인 입맛에 맞게 수정하면 됩니당\nproject:\n  type: website\n  output-dir : docs  \nwebsite:\n  title: \"GC site\"\n  page-navigation: true\n  navbar:\n    right:\n      - icon : github\n        href : https://github.com/gangcheol/\n  sidebar:\n    style: \"docked\"\n    search: True\n    contents: auto\n    \nformat:\n  html:\n    css: styles.css\n    toc: true\n    code-fold : False\n    code-line-numbers : True\n    code-copy : True\n\ntheme :\n  light : flatly\n  \neditor : visual\n- step4. 앞서 만든 posts폴더에 아무 파일이나 만들어보자\n\n- step5. 그 후 다시 터미널에서 내가 생성한 폴더로 이동\n필자의 경우는 cd gcsite\n- step6. quarto render 입력\n- step7. github desktop보면 난리가 났을 것이다. 막 일을 좀 많이 했음.\n\n로컬하고 연결되어 있으니 로컬이 하고 있는 걸 다적어서 그럼\n\n\n\n저기 내가 밑에 이러한 기록을 init이라고 써놨다. 저건 내가 로컬에서 한 행동을 내 깃허브 로컬에 저장할 건데, 그 행동을 init이라고 쓴거\n이제 저 Commit to main 버튼을 눌러주고 가운데 화면에 뜨는 push origin을 눌러주자!\n\n- 마지막!! 아까 깃허브 로컬 셋팅에서 pases란에 잠시 후에 들어가보면 다음과 같은 것을 볼 수 있다.\n\n- 저 링크로 들어가면 내가 만든 웹사이트 초안을 볼 수 있다.\n- 링크"
  },
  {
    "objectID": "posts/DX/2023-07-31-00.intro.html#install",
    "href": "posts/DX/2023-07-31-00.intro.html#install",
    "title": "00. Intro & setting",
    "section": "",
    "text": "- quarto download link : 여기서 quarto를 다운받자!"
  },
  {
    "objectID": "posts/DX/2023-07-31-00.intro.html#website-생성",
    "href": "posts/DX/2023-07-31-00.intro.html#website-생성",
    "title": "00. Intro & setting",
    "section": "",
    "text": "- Terminal을 켠다음에 아래와 같은 명령어를 입력한다!\n(그.. 명령어 입력할 때 현재 자기 주피터 킬때 켜지는 폴더로 옮긴 다음에 수행하자… 골치 아프다ㅜㅜ)\nquarto create project website gcsite\n- 그러면 다음과 같은 이미지가 보인다\n\n- 저기 open with 어찌고 보이는데 d버튼 누르면 (don’t open)으로 넘어가니 그걸 선택한 후 엔터를 눌러준다!\n- 그러면 아래 이미지처럼 맨 밑에 gcsite라는 폴더가 생긴 것을 볼 수 있다."
  },
  {
    "objectID": "posts/DX/2023-07-31-00.intro.html#깃허브-로컬-연결",
    "href": "posts/DX/2023-07-31-00.intro.html#깃허브-로컬-연결",
    "title": "00. Intro & setting",
    "section": "",
    "text": "- git bash 쓰는 사람들 많던데 난 github desktop이 훨씬 편하다.\n- git 알못이기 때문에 많은 것을 알기 위해 괴롭고 싶지 않다.\n- 뭐 여튼 깃허브 데스크탑을 킨다.\n- 상단 메뉴바 \\(\\to\\) File \\(\\to\\) Add local repository\n- 그러면 아래와 같은 경고문이 뜬다.\n\n- local하고 연결하고 싶은데 깃허브에는 gcsite가 없으니 대충 만들어 달라는 것임 “create a repository” 를 눌러주자.\n\n- 무시, 걍 create repository ㄱㄱ\n- 그러면 깃허브 데스크탑에서 너 방금 만든거 너꺼 깃허브에 Publish 할거냐고 물어봄\n\n- Publish repository 눌러주면 끝~~ (단, publish할 때 private 체크박스는 해제하구 하자!)\n- 그 다음 내가 생성산 gcsite 저장소 setting으로 넘어가서 pages를 클릭!\n- 아래와 같이 branch를 수정 후 save 버튼 눌러주자"
  },
  {
    "objectID": "posts/DX/2023-07-31-00.intro.html#문서-생성",
    "href": "posts/DX/2023-07-31-00.intro.html#문서-생성",
    "title": "00. Intro & setting",
    "section": "",
    "text": "- quarto 원리 : 작성한 ipynb파일 html파일로 출력해서 그 html파일들로 웹사이트를 구성하는 것1\n- step1. posts와 docs라는 폴더를 만들자\n\nposts는 내가 작성하는 ipynb파일들이 들어갈거고, docs에는 html파일이 들어갈 것이다.\n\n- step2. index 파일 수정\n\nindex파일은 뭐랄까 네비게이터 역할이랄까 아래와 같이 바꿔주자\n\n---\ntitle: \"GC site\"\nlisting:\n  contents: posts\n  sort: [date desc, title]\n  type: table\n  categories: true\n  sort-ui: true\n  filter-ui: true\npage-layout: full\ntitle-block-banner: true\n---\n- step3. _quarto.uml 파일 수정 \\(\\to\\) 템플릿이랑 디자인 이쁜거 많으니 본인 입맛에 맞게 수정하면 됩니당\nproject:\n  type: website\n  output-dir : docs  \nwebsite:\n  title: \"GC site\"\n  page-navigation: true\n  navbar:\n    right:\n      - icon : github\n        href : https://github.com/gangcheol/\n  sidebar:\n    style: \"docked\"\n    search: True\n    contents: auto\n    \nformat:\n  html:\n    css: styles.css\n    toc: true\n    code-fold : False\n    code-line-numbers : True\n    code-copy : True\n\ntheme :\n  light : flatly\n  \neditor : visual\n- step4. 앞서 만든 posts폴더에 아무 파일이나 만들어보자\n\n- step5. 그 후 다시 터미널에서 내가 생성한 폴더로 이동\n필자의 경우는 cd gcsite\n- step6. quarto render 입력\n- step7. github desktop보면 난리가 났을 것이다. 막 일을 좀 많이 했음.\n\n로컬하고 연결되어 있으니 로컬이 하고 있는 걸 다적어서 그럼\n\n\n\n저기 내가 밑에 이러한 기록을 init이라고 써놨다. 저건 내가 로컬에서 한 행동을 내 깃허브 로컬에 저장할 건데, 그 행동을 init이라고 쓴거\n이제 저 Commit to main 버튼을 눌러주고 가운데 화면에 뜨는 push origin을 눌러주자!\n\n- 마지막!! 아까 깃허브 로컬 셋팅에서 pases란에 잠시 후에 들어가보면 다음과 같은 것을 볼 수 있다.\n\n- 저 링크로 들어가면 내가 만든 웹사이트 초안을 볼 수 있다.\n- 링크"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html",
    "title": "08. summary (1)",
    "section": "",
    "text": "- knn의 경우 필요하다면 스케일링 단계가 필요\n- 이산형 변수, 즉 범주형 변수를 모델의 예측변수로 사용할 경우 더미변수로 변환해주어야한다.\npd.get_dummies(data, columns = 더미화할컬럼리스트, dtype = (int or float))\n- 결측치 처리 : 히스토그램, boxplot, 시계열 데이터인 경우 등등을 고려하여 각 case에 맞게 적절히 결측치를 처리해준다.\n\nmisforest, EM 알고리즘을 통한 결측치 처리를 한다지만, 개인적인 생각으로는 좀 과한 결측치 처리가 아닌지 싶음\n이유는 즉슨, 결측치를 처리하기위해 결측치 처리 단계에서 모델링을 한번 더 수행하는데 이 때 시간이 생각보다 오래 걸림\n\n\n\n\n- 아래와 같이 여러개의 모델을 생성한다음 cross-validation 통해 최적의 모델을 선택하였다.\n\nexample\n\n\n# 1. knn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.cv = cross_val_score(knn, x_train_s, y_train, cv = 5)\n\nknn.cv_m = knn.cv.mean()\n\n# 2. tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\n\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\n\ntree.cv_m = tree.cv.mean()\n\n# 3. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\n\nlogit.cv_m = logit.cv.mean()\n\n# 4. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\n\nrf.cv = cross_val_score(rf, x_train,y_train)\n\nrf.cv_m = rf.cv.mean()\n\n# 5. XGBoost\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\n\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\n\nxgb.cv_m  = xgb.cv.mean()\n\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(max_depth = 5, random_state = 1,verbose = -100) \n\nlgbm.cv = cross_val_score(lgbm, x_train, y_train, cv = 5)\n\nlgbm.cv_m = lgbm.cv.mean()\n\n\n\n- 그 후 선택한 최종 모델을 튜닝해 최종 모델을 select\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring='r2')\n\n\n\n\n\n\n\n- 아래 링크를 참조해서 까먹을때 마다 보자~~\n- ISLP2023-00.Linear Regression\n\n\n\n- 이것두 아래 링크를 참조하자.\n- ISLP2023-01. Classification\n\n\n\n- 학습을 안함, 그냥 그 근처 K개의 녀석들을 보고 값을 할당\n\\[P(y= j | X = x_0) = \\frac {1}{K}  \\sum_{i\\in N_0} I(y_i = j)\\]\n\\[N_0  : x_0\\text {와 가장 가까운  K개의 자료의 집합}\\]\n- \\(k\\)가 작을수록 모델은 복잡해지고, 클수록 단순해짐\n\n솔직히 와닿지 않지만, 내 방식대로 이해해보자.\n이전에 선형회귀분석에서 모델 복잡도를 생각해보자, 모델을 일직선으로 예측한 경우 단순선형회귀분석이다.\n즉, 모델 하나하나의 포인트를 고려하지 않고 전체 평균적인 선형회귀식을 하나 구한 것이다.\n이를 다시 KNN예제로 생각해 \\(K\\)가 클경우 생각해보변, 주변 녀석들의 하나하나 개인적은 특성을 고려하기보단 전체적인 특성에 기반하여 주어진\\(x_0\\)에 대한 \\(y\\)를 예측하는 것이다.\n따라서, \\(k\\)가 작을수록 주변 녀석들의 특징을 하나하나 잘 고려해서 모델이 복잡한 것이고, \\(k\\)가 크면 전체적인 평균을 고려한 것이기 때문에 모델이 단순해진다… \\(\\to\\) 사실 이것도 그렇게 와닿지 않음 나중에 더 찾아보자…\n\n\n\n\n\n나무모형은 간단하고 해석상에 장점이 있으나 다른 방법들에 비해 좋은 성능을 보이지 못하는 경우가 있음\n\n\n\n1 설명변수들의 가능한 조합을 이용하여 예측공간을 \\(J\\)개의 겹치지 않는(non-overlaping)구역으로 분할\n2 각 관측값은 \\(R_j\\) 구역에 포함되며, \\(R_j\\) 구역에 포함된 training data의 반응변수 (\\(y\\))의 평균 (분류문제에선 voting방식)을 이용하여 예측\n\\[\\hat {y}_{R_j} = \\frac {1}{n_j} \\sum_{k\\in R_J} y_k \\]\n3 목표 : 다음의 RSS를 최소화 하는 구역 \\(R_1,R_2, R_J\\)를 찾는 것\n\\[RSS = \\sum_{j=1}^{J} \\sum_{i \\in R_j} (y_i - \\hat {y}_{R_{j}})^2\\]\n4 모든 조합을 확인하는 것은 불가능…(사실 가능하다. tree를 무한정 쪼개면)\n\n근데 tree를 무한정 쪼갤경우 과적합문제가 무조건 발생\n\n5 정지규칙 (stopping rule)\n\n모든 자료가 한 범주에 속할 때\n노드에 속하는 자료가 일정 수 이하일 떄\nMSE의 감소량이 아주 작을 떄\n뿌리마디로부터의 깊이가 일정 수 이상일 떄 등 (max_depth)\n\n6 가지치기 : 과적합을 막기위한 방법\n\n사실 정지규칙도 이에 포함됨, 따라서 위에거 + 빠진 내용을 적겠음\nmin_samples_leaf(default = 1) : leaf노드가 되기 위한 최소한의 샘플 수\nmin_samples_split(default = 20 : 노드를 분할하기 위한 최소한의 샘플 수 (값을 적게 설정할수록 계순 분할되어, 과적합 발생 위험 증가)\nmax_feature : 최선의 분할을 위해 고려할 변수(feature) 개수\n\nsqrt : 전체 변수 개수의 루트\nauto : sqrt와 같은 의미\nlog : \\(\\log_{2}\\) (전체 변수의 수)\n\nmax_leaf_node : 리프 노드의 최대 개수 \\(\\to\\) \\(\\text{Cost complexity Pruning}\\)\n\n\\(|T|\\)는 터미널도드로 리프노드의 개수를 뜻한다.\n\\(R_{\\alpha}(T)\\)는 변하지 않는 비용함수로 \\(R(T)\\)는 우리가 알고 있는 \\(RSS\\)와 같다.\n아래식이 뜻하는 바는 리프노드의 개수가 클수록 \\(R(T)\\) 훈련 데이터 셋에대한 \\(RSS\\)가 작아져 과적합 문제가 발생할 수 있기 때문에 적절한 리프노드의 개수를 설정해야한다는 의미이다.\n\\(\\alpha\\)는 \\(\\text {tuning parameter}\\)로 복잡도를 조절한다. 만약 \\(\\alpha\\)가 0이라면 기존의 비용함수와 같고 1에 가까워질수록 \\(R(T)\\)값이 작아진다.\n따라서 우리는 적절한 \\(\\alpha\\)값과 \\(|T|\\)값을 교차검증 기법을 통해 찾아내어 가지치기를 수행하여야한다.\n\n\n\\[\\begin {align}R_{\\alpha}(T) &= \\sum R(T) + \\alpha |T|  \\\\ \\\\\n                                                          &= \\sum_{m=1}^{|T|} \\sum_{x_i \\in R_m} (y_i - \\hat {y}_{R_m})^2 +  \\alpha |T|  \\end {align}\\]\n7 비용함수\n\n지니 지수 (Gini Index)\n\n\\[Gini (D) = 1- \\sum_{k=1}^{K}p_{k}^2 = \\sum_{k=1}^{K} p_k(1-p_k)\\]\n\\[p_k : \\text{Node D에서 k번째 범주에 속하는 관측 비율}\\]\n\n\n\n\n순수하게 분류되면 값은 0이다.\n만약 분리규칙 \\(A\\)에 의해서 Node D가 \\(D_1, D_2\\)로 분리된다면, 분리규칙 \\(A\\)에서 Ginin지수는 다음과 같다.\n\n\\[Gini_A(D) =\\frac {|D_1|}{|D|}Gini(D_1) +\\frac {|D_2|}{|D|}Gini(D_2) \\]\n\n위에 근거하여 분리규칙 A에서 발생한 불순도 감소량은 다음과 같이 정의할 수 있다.\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n따라서, \\(Gini_{A}(D)\\)를 가장 작게 하거나 \\(\\Delta Gini(A)\\)를 가장 크게 하는 분리 규칙을 선택!\n\n\n\n엔트로피(Entropy)\n\n\\[\\text {Entropy}  = -\\sum_{i=1}^m p_i\\log_{2} p_i\\]\n\n순수하게 분류되면 0\n\n\n정보 이득\n\n\n엔트로피와 지니지수는 단지 속성의 불순도를 표현한다.\n우리가 알고 싶은 것은 “어떠한 속성이 얼마나 많은 정보를 제공하는가!” 이다.\n\n\\[\\text {Gain}(T,X)= \\text{Entropy}(T)-\\text{Entropy}(T,X)\\]\n\n위 식을 살펴보니 지니지수에서 했던 불순도 감소량과 비슷하지 않은가?\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n\n\n\n\n앞서 언급한 tree는 과대적합의 위험이 큰 모형임 \\(\\to\\) max_depth를 무작정 깊게 하면 과대적합이 발생하므로\n앙상블의 아이디어 : 이러한 test데이터 셋에 예측력이 약한 모델을 결합해서 성능이 좋은 모델을 만들자!\n\n\n\n- 여러 모델들의 예측결과를 투표를 통해 최종 예측결과를 결정\n\n하드 보팅 : 다수 모델이 예측한 값이 최종 결과값\n소프트 보팅 : 모든 모델이 예측한 레이블 값의 결정 확률 평균을 구한 뒤 가장 확률이 높은 값을 최종 선택\n\n\n\n\n- Boostrap Aggregating\n- 아이디어 : 모형의 분산을 줄여 과적합을 방지하자.\n\n만약, 모집단으로부터 여러개의 훈련자료를 얻을 수 있고 이로부터 여러개의 모형 \\(\\hat{f}_1(x)\\dots \\hat{f}_b(x)\\)를 얻을 수 있다면, 다음과 같이 분산을 줄일 수 있다.\n\n\\[\\hat{f}_{avg}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}_b(x)\\]\n\n보통은 한 set의 자료만이 주어지게 되므로 위 방식은 직접 적용이 불가능\n그래서 우리는 복원추출을 기반으로 같은 size의 표본을 추출해 각각의 모델링을 수행한다. (Bootstrap sample)\n\n\\[X_1^{*}\\dots X_B^{*}\\]\n\\[\\hat{f}_{\\text{bag}}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}^{*}_b(x)\\]\n\n보팅과 다른점은 보팅은 여러개의 예측모델, 배깅은 동일한 예측모델 여러개를 앙상블하는 것임!\n대표적인 모델 : Randoms Forest\n\n\n\n- 여러 tree모델이 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링\n\n모델들이 개별적으로 학습을 수행한 뒤 모든 결과를 집계하여 최종 결과를 결정\n\n# 불러오기\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n- Out-of-Bag은 생략 (ISLP 교재참고)\n- RF 모델의 변수 선택\n\n하나의 트리를 형성하는 과정에서, 각 노드에서 전체 \\(p\\)개의 설명변수 중 \\(m\\)개만을 임의로 추출하여 분리 규칙을 생성한다.\n\n일반적으로 \\(m \\approx \\sqrt {p}\\)\n\n\nRandomForestClassifier( max_features='sqrt') ## default\n- 변수 중요도 (Variable Importance measur)\n\n사실 여러 형태의 나무를 결합하여 산출된 모델은…. 해석이 거의 불가능해진다.\n대안적으로, 나무들을 생성할 떄 어떠한 변수들이 RSS 혹은 Gini index 등에 큰 감소를 가져왔는지를 요약한 값으로 변수의 중요도를 파악할 수 있음.\n\\(B\\)개의 모형에 대한 평균적인 기여 정도로 변수의 중요도를 평가하게 된다!\nscikit-learn 참고링크\n\n\n\n\n\n\n\n\n\n\n같은 유형의 약한 예측 모형을 결합하여 매우 정확한 예측 모형을 만드는 방법\n예측 모형을 순차적으로(Sequentially) 학습하여 먼저 학습된 모형의 결과가 다음 모형의 학습 시 정보를 제공\n즉, 이전 모형의 약점(잔차)를 학습하여 보완한다.\n\n\n\n\n\n배깅에 비해 성능이 좋지만, 속도가 느리고 과적합 발생 가능성이 있음.\n대표적인 부스팅 알고리즘 : XGBoost, LightGBM\n\n- Boosting의 원리 (ISLP 기준)\n\n초기값 셋팅 \\(\\hat{f}(x) = 0, r_1 = y_1\\)\nFor \\(b = 1, 2\\dots B , repaet\\) :\n\n\\[\\hat {f}(x)_{i+1} = \\hat {f}(x)_{i} + \\lambda \\hat {f}^{b}(x)\\]\n\nupdate the residual,\n\n\\[r_{i+1} = r_{i}- \\lambda \\hat{f}^{b} (x) \\]\n\n초기 셋팅된 \\(\\hat {f}_1 = 0\\) 이므로\n\n\\[\\hat {f}(x)_{\\text{final}} = \\sum_{i=1}^{B} \\lambda \\hat {f}^{b}(x)\\]\n- 위 같은 방식의 문제점 \\(\\to\\) 과적합발생… 당연하다. 예측 모형을 순차적으로 학습한다는 것은 모형간 자기 상관성이 존재하고 모형의 분산이 증가하기 때문에 과적합이 발생할 수 밖에 없다…\n- 이를 막기위해 나온 모델이 XGBoost!\n\n\n- Extreme Gradient Boost\n\nreview : 방금 정리했던 Boosting기법과 같이 기본 학습기를 의사결정나무로 하며, 잔차를 이용해 이전 모형의 약점을 보완하는 방식으로 학습한다.\n+\\(\\alpha\\) : 기존의 Graident Tree Boosting에 과적합 방지를 위한 파라미터\\((\\lambda, \\gamma)\\)가 추가된 알고리즘이다.\n\n\n\n0 parameter\n\n\\(L\\) : 손실함수\n\\(M\\) : 개별 모형의 최대 개수\n\\(l\\) : 학습률\n\\(\\gamma, \\lambda\\) : 과적합 방지를 위한 파라미터\n\n1. 초기 모형은 상수로 설정하며 다음과 같이 손실함수를 최소화 하는 모형으로 설정한다.\n\n초기 모형(상수값)을 아무렇게나 설정해도 된다고 하지만… 최적화 관점에서 아래처럼 잡아주는게 적절한 듯 하다.\n\n\\[F_{0}(x) = \\underset {c}{\\text{arg min}}  \\sum_{i=1}^{n} L(y_i,c)  \\]\n2 \\(m = 1,\\dots M\\)에 대하여 다음을 반복\n\n\nGradient \\(g_i\\)와 Hessian \\(h_i\\)를 계산\n\n\n\\[g_i = \\left[ \\frac {\\partial L(y_i, F(x_i))}{\\partial  F(x_i)}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\\[h_i = \\left[ \\frac {\\partial^2 L(y_i, F(x_i))}{\\partial  F(x_i)^2}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\n\n회귀나무 \\(\\phi_m\\)을 다음과 같이 적합\n\n\n\\[l = \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\\[\\phi_m = \\underset {\\phi} {\\text{arg min}} \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\n여기서 \\(T\\)는 \\(\\phi\\)의 끝마디 개수, \\(||\\phi||^2 = \\sum_{j=1}^{T} w_j^2\\) 이며 \\(w_j\\)는 \\(j\\)번째 끝마디에서의 출력값이다.\n\n잘 살펴보면 릿지회귀분석에 L2 penalty와 비슷한데, L1 penalty 방식도 지원하는 것 같다.\n\n\n다음과 같이 업데이트 한다.\n\n\n\\[ F_{m}(x) = F_{m-1}(x) + l\\cdot \\phi_m(x)\\]\n3 최종모형은?\n\\[F_M(x) =  \\sum_{m=0}^{M} F_m(x)\\]\n4 summary\n\nXGBoost는 기존 Gradient Boosting기법에 문제인 과적합문제를 해결하기 위해 \\(\\gamma, \\lambda\\) 파라미터를 사용한다.(규제)\n손실함수를 살펴보면 터미널 노드(끝마디 노드)의 수와 끝마디에서의 출력값에 대한 패널티 파라미터가 들어가있다,\n의사결정나무에 가지치기 과정에서 터미널 노드의 개수에 따라 panelty를 부여하는 방식을 생각해보면 비슷한 방식이다.\n또한, 내장된 교차 검증? (이거는 이론적으로 구현되어있다기보단 사이킷런에서 내부적으로 동작하게 만든것 같음)\n\n여튼 여기서 조기 중단을 가능하게끔 지원해준다.\n\n결측치 자체 처리 : 알아서 결측치를 고려해서 학습을 한다.(결측치 여부를 노드 분기를 위한 질문에 포함시킴)\n\n이것도 사이킷런에서 내부적으로 구현한듯\n그래도 명시적으로 결측치에 대한 처리를 진행하기를 권고…\n\n\n5 실습 코드\n# 불러오기\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# 선언하기\nmodel = XGBRegressor(max_depth=5, n_estimators=100, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(mean_absolute_error(y_test, y_pred))\nprint(r2_score(y_test, y_pred))\n6 주요 파라미터\n\nlearning_rate : 학습률(default = 0.1)\nn_estimators : 나무의 개수 (default = 100)\nmid_child_weight : 트리에서 추가적으로 분할할 지를 결정하기 위해 필요한 데이터들의 weight(\\(w_i\\))들의 총함 (default = 1)\ngamma : 트리에서 추가적으로 분할할지를 결정하기 위한 값 \\(\\gamma T\\) (default = 0)\nmax_depth : 나무의 깊이 (default = 6)\nsub_sample : weak learner가 학습에 사용되는 데이터 샘플링 비율\n\n과적합이 염려되는 경우 1보다 작은 값으로 설정, (default = 1)\n\ncolsample_bytree : 트리 생성에 필요한 변수 선택 비율\n\n변수가 많은 경우 과적합을 조절하기 위해서 사용, 기본값 = 1\n\nreg_lambda : L2규제 적용값 (\\(\\lambda \\sum_{j=1}^{T} w_j^2\\), 기본값 \\(\\lambda = 1\\))\nreg_alpha : L1규제 적용값 (\\(\\alpha \\sum_{j=1}^{T} |w|\\), 기본값 \\(\\alpha = 0\\))\nearly_stopping_rounds : n_estimators만큼 학습을 반복하지 않더라도 조기 종료 가능(default = 10, 10번 동안 성능 향상이 없으면 학습 중단.)\n\n\n\n\n\n\n\n- 기본 아이디어 : 두 클래스 사이에 가장 넓은 도로를 내는 것\n- 용어 정리\n\n결정 경계 (Decision Boundary) or 초평면\n\n클래스를 구분하는 경계선\n결정 경계가 바로 모델 (Hyper plane)이라고 부름\n\n벡터 : 모든 데이터 포인트\n서포트 벡터 : 결정경계와 가끼운 데이터 포인트\n\n마진의 크기와 결정경계에 영향을 미침\n\n마진(margin) : 서포트 벡터와 결정경계 사이의 거리\n\n폭이 가장 넓은 도로를 찾는 것이 SVM의 목표\n마진이 클수록 새로운 데이터에 대해 안정적인 분류가 가능해지는 것임\n\n잘 생각해보면 마진의 크기가 좁을수록 정확한 분류가 일어나나 과적합 문제가 발생하므로\n마진의 크기와 오류에 대한 허용 정도는 Trade-off 관계에 있는 것을 알 수 있다.\n이것을 조절하는 파라미터 \\(\\to\\) 비용(C)\n\n- 이를 이해하기 위해서!\n\nSupport vector classifier의 decision boundary는 다음과 같은 최적화 문제의 해로 정의된다.\n\n\n만약, label = {1,-1}이라 하면 초평면은 다음과 같은 성질을 가진다.\n\n\\[\\text {Hyper plane}=  \\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} = 0\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &gt; 0, \\quad \\text{if }  y_i=1\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &lt; 0, \\quad \\text{if }  y_i=-1\\]\n\n이는 다음과 같이 간단히 표현할 수 있다.\n\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; 0\\]\n\n아래의 두 식은 관측치가 초평면을 중심으로 두 class를 정확히 구분되고, 관측치와 초평면사이의 직교거리가 최소 \\(M\\)이상이 되도록 보장해 주는 조건이다.\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M} \\]\n\\[ \\sum_{i=1}^{p} \\beta_j^2 =  1\\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M\\]\n\n그러나 실제로 관측치는 두 개의 class로 정확히 구분되지 않은 경우가 더 많으며 한 두개의 관측치에 큰 영향을 받을 수 있다,(Not robust)\n\n\n관측치에 영향을 받아 초평면이 영향을 받은 예시\n\n\n\n\n\n이를 해결하기 위해 \\(C&gt;0\\), tuning parameter와 \\(\\epsilon_i\\)(slack bariable)를 사용\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M}, \\sum_{i=1}^{p} \\beta_j^2 =  1 \\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M(1-\\epsilon_i) \\quad  (\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C)\\]\n\n\\(C\\)가 커질수록 margin이 넓어짐\n\\(C\\)를 작게하면 현 데이터의 정확한 분류에 더 집중하게 되므로 자료 적합성이 좋아짐, 즉 bias는 감소하고 variance는 증가\nmargin 위 혹은 안쪽에 위치한 관측치들을 일컬어 support vector라고 한다.\n\n\nC값에 따른 margin 변화\n\n\n\n\n\n여기에서 \\(C\\)값이 가장 큰 것은 왼쪽 맨위 그림이다. \\(\\to\\) 직관적으로 \\(C\\)는 허용한계이므로 \\(M\\)즉, 마진의 넓이를 넓힌다고 생각하자.\n잠깐 생각해야될 문제\n\n\n\n\n\n우리는 여태껏 직선의 경우인 Support vector classifier를 생각했다. 근데 위에 처럼 생긴다면….\n\n- 그래서 고안된 방법이 본격적인 SVM(support vector machine)이다.\n\n고차원의 decision boundary를 고려함. \\(\\to\\) 예를 들어, 2차항까지 고려한 최적화 문제의 해로써 decision boundary를 정의할 수 있음…\n\n\\[\\underset{\\beta_0,\\beta_{11},\\dots,\\beta_{p1},\\beta_{12},\\dots,\\beta_{p2},\\varepsilon_1,\\dots ,\\varepsilon_n,M} {\\text {maximize}}M\\]\n\\[\\sum_{i=1}^{p}\\sum_{k=1}^2 \\beta_{jk}^2 = 1\\]\n\\[y_i \\left( \\beta_0 + \\sum_{j=1}^{p} \\beta_{j1}x_{ij} + \\sum_{j=1}^{p}\\beta_{i2}x_{ij}^2\\right) &gt; M(1-\\varepsilon_i)\\]\n\\[\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C\\]\n- 단순히 확장한 것에 불과하지 않은가???\n\nsupport vector classifier을 찾기 위해서는 관측치들간의 내적(inner product)을 계산하는 것으로 충분함이 알려져 있음\n이러한 내적을 여러 방면으로 일반화하여 표현할 수 있는데 이를 규정해 주는 함수를 kernel 이라 한다. (이 부분은 설명 생략!)\n\n- kernel 종류\n\npoly(다항), rbf(Radial Basis Function), sigmoid, linear\n\n\n\n- 걍 넘어가려고 했는데 안되겠음 \\(\\to\\) ㅅㅂ… 결과를 납득할 수 없다. 진짜 다시보자\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import svm\n\n# we create 40 separable points\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n\n# figure number\nfignum = 1\n\n# fit the model\nfor name, penalty in ((\"unreg\", 1), (\"reg\", 0.05)):\n    clf = svm.SVC(kernel=\"linear\", C=penalty)\n    clf.fit(X, Y)\n\n    # get the separating hyperplane\n    w = clf.coef_[0]\n    a = -w[0] / w[1]\n    xx = np.linspace(-5, 5)\n    yy = a * xx - (clf.intercept_[0]) / w[1]\n\n    # plot the parallels to the separating hyperplane that pass through the\n    # support vectors (margin away from hyperplane in direction\n    # perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in\n    # 2-d.\n    margin = 1 / np.sqrt(np.sum(clf.coef_**2))\n    yy_down = yy - np.sqrt(1 + a**2) * margin\n    yy_up = yy + np.sqrt(1 + a**2) * margin\n\n    # plot the line, the points, and the nearest vectors to the plane\n    plt.figure(fignum, figsize=(4, 3))\n    plt.clf()\n    plt.plot(xx, yy, \"k-\")\n    plt.plot(xx, yy_down, \"k--\")\n    plt.plot(xx, yy_up, \"k--\")\n    plt.title(f\"C={penalty}\")\n    plt.scatter(\n        clf.support_vectors_[:, 0],\n        clf.support_vectors_[:, 1],\n        s=80,\n        facecolors=\"none\",\n        zorder=10,\n        edgecolors=\"k\",\n    )\n    plt.scatter(\n        X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.get_cmap(\"RdBu\"), edgecolors=\"k\"\n    )\n\n    plt.axis(\"tight\")\n    x_min = -4.8\n    x_max = 4.2\n    y_min = -6\n    y_max = 6\n\n    YY, XX = np.meshgrid(yy, xx)\n    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n    Z = clf.decision_function(xy).reshape(XX.shape)\n\n    # Put the result into a contour plot\n    plt.contourf(XX, YY, Z, cmap=plt.get_cmap(\"RdBu\"), alpha=0.5, linestyles=[\"-\"])\n\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    fignum = fignum + 1\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n- 우리가 기존의 하던 방식\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 2023)\n- 단점\n\n랜덤하게 자료를 분할하기 때문에 분할결과에 따라 추정의 변동성이 크다….\n특히 자료위 크기가 작거나 이상/영향치들이 포함되어 있는 경우에 더더욱 그러함.\n또한, 원 자료의 크기 보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음.\n\n\n이러한 방법을 \\(\\text {Validation set Approach}\\)라고 한다….\n\n- K-fold Cross Validation 방식\n\n\n\n\n전체 자료를 \\(k\\)개의 집합으로 분할한 후그 중 하나의 집합 (\\(i\\))번째 집합을 평가자료롤 설정(위 그림의 경우 \\(i=1,2 \\dots 5\\))\n그 후 각 정확도를 평균냄 (교제에서는 \\(MSE\\)를 평균 냈는데, 이번 강의에서는 정확도를 평균내더라…)\n\n\\[\\text {CV}_{5} = \\frac {1}{5} \\sum_{i=1}^{5} \\text{Accuracy}_{i}\\]\n# 1단계: 불러오기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 2단계: 선언하기\nmodel = DecisionTreeClassifier(max_depth=3)\n\n# 3단계: 검증하기\ncv_score = cross_val_score(model, x_train, y_train, cv=10)\n\n# 확인\nprint(cv_score)\nprint(cv_score.mean())\n= 장점\n\n모든 데이터가 학습과 평가에 사용됨\n데이터가 부족해서 발생하는 과소적합 문제을 방지할 수 있음\n 좀 더 일반화된 모델 을 만들 수 있음\ntest error의 과대추정을 방지\n\n- 단점\n\n반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요\n\n\n\n\n\n\n\n- 일단, 튜닝 시 모델들의 각 파라미터들에 값을 어떻게 하느냐에 따라 성능이 달라지는 것을 확인할 수 있었음\n- grid search의 아이디어는 가능한 파라미터 값 범위를 지정해 해당 범위에서의 값을 모두 사용하는 것이다.\n\n당연히 정확도는 높으나….시간이 오래 걸리겠지라는 생각을 해볼 수 있다.\n\n\n요런느낌\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10), 'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n\n# Grid Search 선언\nmodel = GridSearchCV(knn_model, param, cv=3)\n\n\n\n- 그리드 서치처럼 파라미터 범위를 지정하는 것은 동일\n- 설정한 파라미터 값 범위에서 몇 개를 선택할지를 정하여 Random Search 모델 선언 후 학습\n- 학습 데이터에 대해 가장 좋은 성능을 보인 파라미터 값으로 자동 학습함.\n\n참고로 Grid Search, Random Search를 사용할 때 내부적으로 K-Fold Cross Validation을 위해 cv값을 지정하므로!\n실제 수행되는 횟수는  파라미터 조합 수 x CV값이 된다.\n\n\ncode\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10),\n'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n# Random Search 선언\nmodel = RandomizedSearchCV(knn_model, \n                                                       param, cv=3, # (default = 5)\n                                                           n_iter=20) ### 전체 파라미터 범위에서 몇 개를 뽑을 것인지 (default = 10)\n\n또한, 두 가지 기법을 섞어서 사용할 수 있음! (강의자료 참고)\n\n\n\n\n\n\n- 머신러닝 알고리즘은 데이터가 클래스 간에 균형 있게 분포되어 있다고 가정함\n\nexample : 생존자와 사망자 수가 거의 같을 것이다~~\n\n- 클래스 불균형으로 인한 재현율이 형편없어지는 경우는 아래 링크를 참고!\n\n재현율\n\n\n\n- under sampling\n\n다수 클래스 데이터를 소수 클래스 수 만큼 랜덤 샘플링\n\n- over sampling\n\n소수의 클래스 데이터를 다수 클래스 수 만큼 랜덤 샘플링\n\n# pip install imbalanced-learn\n# 불러오기\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Under Sampling\nunder_sample = RandomUnderSampler()\nu_x_train, u_y_train = under_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(u_y_train))\n\n# 불러오기\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Over Sampling\nover_sample = RandomOverSampler()\no_x_train, o_y_train = over_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(o_y_train))\n- over sampling (2)\n# 불러오기\nfrom imblearn.over_sampling import SMOTE\n\n# Over Sampling\nsmote = SMOTE()\ns_x_train, s_y_train = smote.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(s_y_train))\n\n\n\n- resampling 없이 클래스에 가중치를 부여하여 클래스 불균형 문제를 해결해줌\n\n학습하는 동안 알고리즘의 비용함수에서 소수 클래스에 더 많은 가중치를 부여하여 소수 클래스에 더 높은 패널티를 제공함으로써, 소수 클래스에 대한 오류를 줄이게 됨\nsklearn에서 제공하는 알고리즘 대부분 class_weight라는 하이퍼 파라미터를 제공한다.\n\nclass_weight = ‘None’ : 기본값\nclass_weight = ‘balanced’: y_train의 class 비율을 역으로 적용\nclass_weight={0:0.2, 1:0.8}: 비율 지정, 단 비율의 합은 1\n\n주의! \\(\\to\\) 전반적인 성능을 높이기 위한 작업이 아니라, 소수 클래스 성능을 높이기 위한 작업임!\n\n\n\n\n\n\n\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n# 데이터 불러오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/airline_satisfaction_small.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\ndeparture/arrival_time_convenient\nease_of_online_booking\n...\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\ndeparture_delay_in_minutes\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\n70172\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n4\n3\n...\n5\n4\n3\n4\n4\n5\n5\n25\n18.0\n0\n\n\n1\n5047\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n2\n3\n...\n1\n1\n5\n3\n1\n4\n1\n1\n6.0\n0\n\n\n2\n110028\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n2\n...\n5\n4\n3\n4\n4\n4\n5\n0\n0.0\n1\n\n\n3\n24026\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n5\n...\n2\n2\n5\n3\n1\n4\n2\n11\n9.0\n0\n\n\n4\n119299\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n3\n...\n3\n3\n4\n4\n3\n3\n3\n0\n0.0\n1\n\n\n\n\n5 rows × 24 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2580 entries, 0 to 2579\nData columns (total 24 columns):\n #   Column                             Non-Null Count  Dtype  \n---  ------                             --------------  -----  \n 0   id                                 2580 non-null   int64  \n 1   gender                             2580 non-null   object \n 2   customer_type                      2580 non-null   object \n 3   age                                2580 non-null   int64  \n 4   type_of_travel                     2580 non-null   object \n 5   class                              2580 non-null   object \n 6   flight_distance                    2580 non-null   int64  \n 7   inflight_wifi_service              2580 non-null   int64  \n 8   departure/arrival_time_convenient  2580 non-null   int64  \n 9   ease_of_online_booking             2580 non-null   int64  \n 10  gate_location                      2580 non-null   int64  \n 11  food_and_drink                     2580 non-null   int64  \n 12  online_boarding                    2580 non-null   int64  \n 13  seat_comfort                       2580 non-null   int64  \n 14  inflight_entertainment             2580 non-null   int64  \n 15  on-board_service                   2580 non-null   int64  \n 16  leg_room_service                   2580 non-null   int64  \n 17  baggage_handling                   2580 non-null   int64  \n 18  checkin_service                    2580 non-null   int64  \n 19  inflight_service                   2580 non-null   int64  \n 20  cleanliness                        2580 non-null   int64  \n 21  departure_delay_in_minutes         2580 non-null   int64  \n 22  arrival_delay_in_minutes           2574 non-null   float64\n 23  satisfaction                       2580 non-null   int64  \ndtypes: float64(1), int64(19), object(4)\nmemory usage: 483.9+ KB\n\n\n- 쓸모없는 변수 제거\n\n# 변수 제거\nd_cols = [\"id\", \"departure/arrival_time_convenient\", \"gate_location\", \"departure_delay_in_minutes\"]\n\n\ndata.drop(d_cols,axis=1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n0\n\n\n1\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n0\n\n\n2\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n1\n\n\n3\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0\n\n\n4\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1\n\n\n\n\n\n\n\n- 결측치 확인\n\nprint(data.columns[data.isna().sum() !=0])\n\nIndex(['arrival_delay_in_minutes'], dtype='object')\n\n\n\ndata.arrival_delay_in_minutes.isna().sum()\n\n6\n\n\n- 현재 arrival_delay_in_minutes의 6개 결측치가 확인된다.\n\n결측치 제거를 위해 해당 변수의 분포를 확인하자.\n\n\ndata.plot(x=\"arrival_delay_in_minutes\",  kind = \"hist\", backend  = \"plotly\",\n                  width = 1000, height = 400,nbins=100)\n\n\n                                                \n\n\n- 대부분의 값들이 0값 근처에 몰려있으니 결측값을 0으로 대체하자.\n\ndata.arrival_delay_in_minutes.fillna(0, inplace = True)\nprint(data.columns[data.isna().sum() !=0])\n\nIndex([], dtype='object')\n\n\n- x, y 분리\n\ntarget = \"satisfaction\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd = [\"gender\", \"customer_type\", \"type_of_travel\", \"class\"]\n\nx = pd.get_dummies(x, columns = d, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nage\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\ngender_Male\ncustomer_type_disloyal Customer\ntype_of_travel_Personal Travel\nclass_Eco\nclass_Eco Plus\n\n\n\n\n0\n13\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n1.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n25\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n1.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n26\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n25\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n61\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습, 평가용 데이터 분리\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n\n\n\n\n\nCode\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n# 1. tree\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\ntree.cv_m = tree.cv.mean()\n\n# 2. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\nlogit.cv_m = logit.cv.mean()\n\n# 3. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\nrf.cv = cross_val_score(rf, x_train,y_train)\nrf.cv_m = rf.cv.mean()\n\n# 4. XGBoost\n\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\nxgb.cv_m  = xgb.cv.mean()\n\n\n\nresult = [tree.cv_m, logit.cv_m, rf.cv_m,  xgb.cv_m]\nmodel = [\"tree\",\"logit\", \"rf\", \"xgb\"]\n\nfig = pd.DataFrame({\"model\" : model, \"result\" : result}).\\\n            sort_values(\"result\", ascending = False).plot(x = \"result\", y = \"model\", kind = \"bar\", backend = \"plotly\",color = \"model\")\n\nfig.update_xaxes(range = [0.7, 1.0])\n\n\n                                                \n\n\n- cv를 기준으로 XGB 모델이 최적의 모델인 것 같다.\n\ngrid search기법을 이용하여 모델 튜닝\n\n\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring=\"accuracy\")\n\n\nmodel.fit(x_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')estimator: XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)\n\n\n\ny_pred = model.predict(x_test)\n\n\n# 예측 결과 확인\nprint(model.best_params_)\nprint(model.best_score_)\n\n{'max_depth': 3}\n0.9363202277283789\n\n\n\nfig = pd.DataFrame([model.best_estimator_.feature_names_in_,model.best_estimator_.feature_importances_]).T.\\\n        rename(columns = {0 : \"feature\", 1 : \"importance\"}).sort_values(\"importance\", ascending = False).\\\n            plot(y = \"feature\", x=  \"importance\", kind = \"barh\",\n                    backend = \"plotly\",color = \"feature\")\n\nfig.update_layout(showlegend = False)\n\n\n                                                \n\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmeasure = [\"accuracy\", \"precision\", \"reacll\", \"f1-score\"]\n\nacc = accuracy_score(y_test, y_pred)\npre = precision_score(y_test, y_pred)\nre = recall_score(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred)\n\n\npd.DataFrame({\"measure\" : measure, \"score\" : [acc, pre, re, f1_score]})\n\n\n\n\n\n\n\n\nmeasure\nscore\n\n\n\n\n0\naccuracy\n0.931525\n\n\n1\nprecision\n0.949102\n\n\n2\nreacll\n0.898017\n\n\n3\nf1-score\n0.922853"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#모델링-단계",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#모델링-단계",
    "title": "08. summary (1)",
    "section": "",
    "text": "- knn의 경우 필요하다면 스케일링 단계가 필요\n- 이산형 변수, 즉 범주형 변수를 모델의 예측변수로 사용할 경우 더미변수로 변환해주어야한다.\npd.get_dummies(data, columns = 더미화할컬럼리스트, dtype = (int or float))\n- 결측치 처리 : 히스토그램, boxplot, 시계열 데이터인 경우 등등을 고려하여 각 case에 맞게 적절히 결측치를 처리해준다.\n\nmisforest, EM 알고리즘을 통한 결측치 처리를 한다지만, 개인적인 생각으로는 좀 과한 결측치 처리가 아닌지 싶음\n이유는 즉슨, 결측치를 처리하기위해 결측치 처리 단계에서 모델링을 한번 더 수행하는데 이 때 시간이 생각보다 오래 걸림\n\n\n\n\n- 아래와 같이 여러개의 모델을 생성한다음 cross-validation 통해 최적의 모델을 선택하였다.\n\nexample\n\n\n# 1. knn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.cv = cross_val_score(knn, x_train_s, y_train, cv = 5)\n\nknn.cv_m = knn.cv.mean()\n\n# 2. tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\n\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\n\ntree.cv_m = tree.cv.mean()\n\n# 3. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\n\nlogit.cv_m = logit.cv.mean()\n\n# 4. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\n\nrf.cv = cross_val_score(rf, x_train,y_train)\n\nrf.cv_m = rf.cv.mean()\n\n# 5. XGBoost\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\n\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\n\nxgb.cv_m  = xgb.cv.mean()\n\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(max_depth = 5, random_state = 1,verbose = -100) \n\nlgbm.cv = cross_val_score(lgbm, x_train, y_train, cv = 5)\n\nlgbm.cv_m = lgbm.cv.mean()\n\n\n\n- 그 후 선택한 최종 모델을 튜닝해 최종 모델을 select\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring='r2')"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#각-모델-소개",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#각-모델-소개",
    "title": "08. summary (1)",
    "section": "",
    "text": "- 아래 링크를 참조해서 까먹을때 마다 보자~~\n- ISLP2023-00.Linear Regression\n\n\n\n- 이것두 아래 링크를 참조하자.\n- ISLP2023-01. Classification\n\n\n\n- 학습을 안함, 그냥 그 근처 K개의 녀석들을 보고 값을 할당\n\\[P(y= j | X = x_0) = \\frac {1}{K}  \\sum_{i\\in N_0} I(y_i = j)\\]\n\\[N_0  : x_0\\text {와 가장 가까운  K개의 자료의 집합}\\]\n- \\(k\\)가 작을수록 모델은 복잡해지고, 클수록 단순해짐\n\n솔직히 와닿지 않지만, 내 방식대로 이해해보자.\n이전에 선형회귀분석에서 모델 복잡도를 생각해보자, 모델을 일직선으로 예측한 경우 단순선형회귀분석이다.\n즉, 모델 하나하나의 포인트를 고려하지 않고 전체 평균적인 선형회귀식을 하나 구한 것이다.\n이를 다시 KNN예제로 생각해 \\(K\\)가 클경우 생각해보변, 주변 녀석들의 하나하나 개인적은 특성을 고려하기보단 전체적인 특성에 기반하여 주어진\\(x_0\\)에 대한 \\(y\\)를 예측하는 것이다.\n따라서, \\(k\\)가 작을수록 주변 녀석들의 특징을 하나하나 잘 고려해서 모델이 복잡한 것이고, \\(k\\)가 크면 전체적인 평균을 고려한 것이기 때문에 모델이 단순해진다… \\(\\to\\) 사실 이것도 그렇게 와닿지 않음 나중에 더 찾아보자…\n\n\n\n\n\n나무모형은 간단하고 해석상에 장점이 있으나 다른 방법들에 비해 좋은 성능을 보이지 못하는 경우가 있음\n\n\n\n1 설명변수들의 가능한 조합을 이용하여 예측공간을 \\(J\\)개의 겹치지 않는(non-overlaping)구역으로 분할\n2 각 관측값은 \\(R_j\\) 구역에 포함되며, \\(R_j\\) 구역에 포함된 training data의 반응변수 (\\(y\\))의 평균 (분류문제에선 voting방식)을 이용하여 예측\n\\[\\hat {y}_{R_j} = \\frac {1}{n_j} \\sum_{k\\in R_J} y_k \\]\n3 목표 : 다음의 RSS를 최소화 하는 구역 \\(R_1,R_2, R_J\\)를 찾는 것\n\\[RSS = \\sum_{j=1}^{J} \\sum_{i \\in R_j} (y_i - \\hat {y}_{R_{j}})^2\\]\n4 모든 조합을 확인하는 것은 불가능…(사실 가능하다. tree를 무한정 쪼개면)\n\n근데 tree를 무한정 쪼갤경우 과적합문제가 무조건 발생\n\n5 정지규칙 (stopping rule)\n\n모든 자료가 한 범주에 속할 때\n노드에 속하는 자료가 일정 수 이하일 떄\nMSE의 감소량이 아주 작을 떄\n뿌리마디로부터의 깊이가 일정 수 이상일 떄 등 (max_depth)\n\n6 가지치기 : 과적합을 막기위한 방법\n\n사실 정지규칙도 이에 포함됨, 따라서 위에거 + 빠진 내용을 적겠음\nmin_samples_leaf(default = 1) : leaf노드가 되기 위한 최소한의 샘플 수\nmin_samples_split(default = 20 : 노드를 분할하기 위한 최소한의 샘플 수 (값을 적게 설정할수록 계순 분할되어, 과적합 발생 위험 증가)\nmax_feature : 최선의 분할을 위해 고려할 변수(feature) 개수\n\nsqrt : 전체 변수 개수의 루트\nauto : sqrt와 같은 의미\nlog : \\(\\log_{2}\\) (전체 변수의 수)\n\nmax_leaf_node : 리프 노드의 최대 개수 \\(\\to\\) \\(\\text{Cost complexity Pruning}\\)\n\n\\(|T|\\)는 터미널도드로 리프노드의 개수를 뜻한다.\n\\(R_{\\alpha}(T)\\)는 변하지 않는 비용함수로 \\(R(T)\\)는 우리가 알고 있는 \\(RSS\\)와 같다.\n아래식이 뜻하는 바는 리프노드의 개수가 클수록 \\(R(T)\\) 훈련 데이터 셋에대한 \\(RSS\\)가 작아져 과적합 문제가 발생할 수 있기 때문에 적절한 리프노드의 개수를 설정해야한다는 의미이다.\n\\(\\alpha\\)는 \\(\\text {tuning parameter}\\)로 복잡도를 조절한다. 만약 \\(\\alpha\\)가 0이라면 기존의 비용함수와 같고 1에 가까워질수록 \\(R(T)\\)값이 작아진다.\n따라서 우리는 적절한 \\(\\alpha\\)값과 \\(|T|\\)값을 교차검증 기법을 통해 찾아내어 가지치기를 수행하여야한다.\n\n\n\\[\\begin {align}R_{\\alpha}(T) &= \\sum R(T) + \\alpha |T|  \\\\ \\\\\n                                                          &= \\sum_{m=1}^{|T|} \\sum_{x_i \\in R_m} (y_i - \\hat {y}_{R_m})^2 +  \\alpha |T|  \\end {align}\\]\n7 비용함수\n\n지니 지수 (Gini Index)\n\n\\[Gini (D) = 1- \\sum_{k=1}^{K}p_{k}^2 = \\sum_{k=1}^{K} p_k(1-p_k)\\]\n\\[p_k : \\text{Node D에서 k번째 범주에 속하는 관측 비율}\\]\n\n\n\n\n순수하게 분류되면 값은 0이다.\n만약 분리규칙 \\(A\\)에 의해서 Node D가 \\(D_1, D_2\\)로 분리된다면, 분리규칙 \\(A\\)에서 Ginin지수는 다음과 같다.\n\n\\[Gini_A(D) =\\frac {|D_1|}{|D|}Gini(D_1) +\\frac {|D_2|}{|D|}Gini(D_2) \\]\n\n위에 근거하여 분리규칙 A에서 발생한 불순도 감소량은 다음과 같이 정의할 수 있다.\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n따라서, \\(Gini_{A}(D)\\)를 가장 작게 하거나 \\(\\Delta Gini(A)\\)를 가장 크게 하는 분리 규칙을 선택!\n\n\n\n엔트로피(Entropy)\n\n\\[\\text {Entropy}  = -\\sum_{i=1}^m p_i\\log_{2} p_i\\]\n\n순수하게 분류되면 0\n\n\n정보 이득\n\n\n엔트로피와 지니지수는 단지 속성의 불순도를 표현한다.\n우리가 알고 싶은 것은 “어떠한 속성이 얼마나 많은 정보를 제공하는가!” 이다.\n\n\\[\\text {Gain}(T,X)= \\text{Entropy}(T)-\\text{Entropy}(T,X)\\]\n\n위 식을 살펴보니 지니지수에서 했던 불순도 감소량과 비슷하지 않은가?\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n\n\n\n\n앞서 언급한 tree는 과대적합의 위험이 큰 모형임 \\(\\to\\) max_depth를 무작정 깊게 하면 과대적합이 발생하므로\n앙상블의 아이디어 : 이러한 test데이터 셋에 예측력이 약한 모델을 결합해서 성능이 좋은 모델을 만들자!\n\n\n\n- 여러 모델들의 예측결과를 투표를 통해 최종 예측결과를 결정\n\n하드 보팅 : 다수 모델이 예측한 값이 최종 결과값\n소프트 보팅 : 모든 모델이 예측한 레이블 값의 결정 확률 평균을 구한 뒤 가장 확률이 높은 값을 최종 선택\n\n\n\n\n- Boostrap Aggregating\n- 아이디어 : 모형의 분산을 줄여 과적합을 방지하자.\n\n만약, 모집단으로부터 여러개의 훈련자료를 얻을 수 있고 이로부터 여러개의 모형 \\(\\hat{f}_1(x)\\dots \\hat{f}_b(x)\\)를 얻을 수 있다면, 다음과 같이 분산을 줄일 수 있다.\n\n\\[\\hat{f}_{avg}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}_b(x)\\]\n\n보통은 한 set의 자료만이 주어지게 되므로 위 방식은 직접 적용이 불가능\n그래서 우리는 복원추출을 기반으로 같은 size의 표본을 추출해 각각의 모델링을 수행한다. (Bootstrap sample)\n\n\\[X_1^{*}\\dots X_B^{*}\\]\n\\[\\hat{f}_{\\text{bag}}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}^{*}_b(x)\\]\n\n보팅과 다른점은 보팅은 여러개의 예측모델, 배깅은 동일한 예측모델 여러개를 앙상블하는 것임!\n대표적인 모델 : Randoms Forest\n\n\n\n- 여러 tree모델이 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링\n\n모델들이 개별적으로 학습을 수행한 뒤 모든 결과를 집계하여 최종 결과를 결정\n\n# 불러오기\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n- Out-of-Bag은 생략 (ISLP 교재참고)\n- RF 모델의 변수 선택\n\n하나의 트리를 형성하는 과정에서, 각 노드에서 전체 \\(p\\)개의 설명변수 중 \\(m\\)개만을 임의로 추출하여 분리 규칙을 생성한다.\n\n일반적으로 \\(m \\approx \\sqrt {p}\\)\n\n\nRandomForestClassifier( max_features='sqrt') ## default\n- 변수 중요도 (Variable Importance measur)\n\n사실 여러 형태의 나무를 결합하여 산출된 모델은…. 해석이 거의 불가능해진다.\n대안적으로, 나무들을 생성할 떄 어떠한 변수들이 RSS 혹은 Gini index 등에 큰 감소를 가져왔는지를 요약한 값으로 변수의 중요도를 파악할 수 있음.\n\\(B\\)개의 모형에 대한 평균적인 기여 정도로 변수의 중요도를 평가하게 된다!\nscikit-learn 참고링크\n\n\n\n\n\n\n\n\n\n\n같은 유형의 약한 예측 모형을 결합하여 매우 정확한 예측 모형을 만드는 방법\n예측 모형을 순차적으로(Sequentially) 학습하여 먼저 학습된 모형의 결과가 다음 모형의 학습 시 정보를 제공\n즉, 이전 모형의 약점(잔차)를 학습하여 보완한다.\n\n\n\n\n\n배깅에 비해 성능이 좋지만, 속도가 느리고 과적합 발생 가능성이 있음.\n대표적인 부스팅 알고리즘 : XGBoost, LightGBM\n\n- Boosting의 원리 (ISLP 기준)\n\n초기값 셋팅 \\(\\hat{f}(x) = 0, r_1 = y_1\\)\nFor \\(b = 1, 2\\dots B , repaet\\) :\n\n\\[\\hat {f}(x)_{i+1} = \\hat {f}(x)_{i} + \\lambda \\hat {f}^{b}(x)\\]\n\nupdate the residual,\n\n\\[r_{i+1} = r_{i}- \\lambda \\hat{f}^{b} (x) \\]\n\n초기 셋팅된 \\(\\hat {f}_1 = 0\\) 이므로\n\n\\[\\hat {f}(x)_{\\text{final}} = \\sum_{i=1}^{B} \\lambda \\hat {f}^{b}(x)\\]\n- 위 같은 방식의 문제점 \\(\\to\\) 과적합발생… 당연하다. 예측 모형을 순차적으로 학습한다는 것은 모형간 자기 상관성이 존재하고 모형의 분산이 증가하기 때문에 과적합이 발생할 수 밖에 없다…\n- 이를 막기위해 나온 모델이 XGBoost!\n\n\n- Extreme Gradient Boost\n\nreview : 방금 정리했던 Boosting기법과 같이 기본 학습기를 의사결정나무로 하며, 잔차를 이용해 이전 모형의 약점을 보완하는 방식으로 학습한다.\n+\\(\\alpha\\) : 기존의 Graident Tree Boosting에 과적합 방지를 위한 파라미터\\((\\lambda, \\gamma)\\)가 추가된 알고리즘이다.\n\n\n\n0 parameter\n\n\\(L\\) : 손실함수\n\\(M\\) : 개별 모형의 최대 개수\n\\(l\\) : 학습률\n\\(\\gamma, \\lambda\\) : 과적합 방지를 위한 파라미터\n\n1. 초기 모형은 상수로 설정하며 다음과 같이 손실함수를 최소화 하는 모형으로 설정한다.\n\n초기 모형(상수값)을 아무렇게나 설정해도 된다고 하지만… 최적화 관점에서 아래처럼 잡아주는게 적절한 듯 하다.\n\n\\[F_{0}(x) = \\underset {c}{\\text{arg min}}  \\sum_{i=1}^{n} L(y_i,c)  \\]\n2 \\(m = 1,\\dots M\\)에 대하여 다음을 반복\n\n\nGradient \\(g_i\\)와 Hessian \\(h_i\\)를 계산\n\n\n\\[g_i = \\left[ \\frac {\\partial L(y_i, F(x_i))}{\\partial  F(x_i)}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\\[h_i = \\left[ \\frac {\\partial^2 L(y_i, F(x_i))}{\\partial  F(x_i)^2}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\n\n회귀나무 \\(\\phi_m\\)을 다음과 같이 적합\n\n\n\\[l = \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\\[\\phi_m = \\underset {\\phi} {\\text{arg min}} \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\n여기서 \\(T\\)는 \\(\\phi\\)의 끝마디 개수, \\(||\\phi||^2 = \\sum_{j=1}^{T} w_j^2\\) 이며 \\(w_j\\)는 \\(j\\)번째 끝마디에서의 출력값이다.\n\n잘 살펴보면 릿지회귀분석에 L2 penalty와 비슷한데, L1 penalty 방식도 지원하는 것 같다.\n\n\n다음과 같이 업데이트 한다.\n\n\n\\[ F_{m}(x) = F_{m-1}(x) + l\\cdot \\phi_m(x)\\]\n3 최종모형은?\n\\[F_M(x) =  \\sum_{m=0}^{M} F_m(x)\\]\n4 summary\n\nXGBoost는 기존 Gradient Boosting기법에 문제인 과적합문제를 해결하기 위해 \\(\\gamma, \\lambda\\) 파라미터를 사용한다.(규제)\n손실함수를 살펴보면 터미널 노드(끝마디 노드)의 수와 끝마디에서의 출력값에 대한 패널티 파라미터가 들어가있다,\n의사결정나무에 가지치기 과정에서 터미널 노드의 개수에 따라 panelty를 부여하는 방식을 생각해보면 비슷한 방식이다.\n또한, 내장된 교차 검증? (이거는 이론적으로 구현되어있다기보단 사이킷런에서 내부적으로 동작하게 만든것 같음)\n\n여튼 여기서 조기 중단을 가능하게끔 지원해준다.\n\n결측치 자체 처리 : 알아서 결측치를 고려해서 학습을 한다.(결측치 여부를 노드 분기를 위한 질문에 포함시킴)\n\n이것도 사이킷런에서 내부적으로 구현한듯\n그래도 명시적으로 결측치에 대한 처리를 진행하기를 권고…\n\n\n5 실습 코드\n# 불러오기\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# 선언하기\nmodel = XGBRegressor(max_depth=5, n_estimators=100, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(mean_absolute_error(y_test, y_pred))\nprint(r2_score(y_test, y_pred))\n6 주요 파라미터\n\nlearning_rate : 학습률(default = 0.1)\nn_estimators : 나무의 개수 (default = 100)\nmid_child_weight : 트리에서 추가적으로 분할할 지를 결정하기 위해 필요한 데이터들의 weight(\\(w_i\\))들의 총함 (default = 1)\ngamma : 트리에서 추가적으로 분할할지를 결정하기 위한 값 \\(\\gamma T\\) (default = 0)\nmax_depth : 나무의 깊이 (default = 6)\nsub_sample : weak learner가 학습에 사용되는 데이터 샘플링 비율\n\n과적합이 염려되는 경우 1보다 작은 값으로 설정, (default = 1)\n\ncolsample_bytree : 트리 생성에 필요한 변수 선택 비율\n\n변수가 많은 경우 과적합을 조절하기 위해서 사용, 기본값 = 1\n\nreg_lambda : L2규제 적용값 (\\(\\lambda \\sum_{j=1}^{T} w_j^2\\), 기본값 \\(\\lambda = 1\\))\nreg_alpha : L1규제 적용값 (\\(\\alpha \\sum_{j=1}^{T} |w|\\), 기본값 \\(\\alpha = 0\\))\nearly_stopping_rounds : n_estimators만큼 학습을 반복하지 않더라도 조기 종료 가능(default = 10, 10번 동안 성능 향상이 없으면 학습 중단.)\n\n\n\n\n\n\n\n- 기본 아이디어 : 두 클래스 사이에 가장 넓은 도로를 내는 것\n- 용어 정리\n\n결정 경계 (Decision Boundary) or 초평면\n\n클래스를 구분하는 경계선\n결정 경계가 바로 모델 (Hyper plane)이라고 부름\n\n벡터 : 모든 데이터 포인트\n서포트 벡터 : 결정경계와 가끼운 데이터 포인트\n\n마진의 크기와 결정경계에 영향을 미침\n\n마진(margin) : 서포트 벡터와 결정경계 사이의 거리\n\n폭이 가장 넓은 도로를 찾는 것이 SVM의 목표\n마진이 클수록 새로운 데이터에 대해 안정적인 분류가 가능해지는 것임\n\n잘 생각해보면 마진의 크기가 좁을수록 정확한 분류가 일어나나 과적합 문제가 발생하므로\n마진의 크기와 오류에 대한 허용 정도는 Trade-off 관계에 있는 것을 알 수 있다.\n이것을 조절하는 파라미터 \\(\\to\\) 비용(C)\n\n- 이를 이해하기 위해서!\n\nSupport vector classifier의 decision boundary는 다음과 같은 최적화 문제의 해로 정의된다.\n\n\n만약, label = {1,-1}이라 하면 초평면은 다음과 같은 성질을 가진다.\n\n\\[\\text {Hyper plane}=  \\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} = 0\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &gt; 0, \\quad \\text{if }  y_i=1\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &lt; 0, \\quad \\text{if }  y_i=-1\\]\n\n이는 다음과 같이 간단히 표현할 수 있다.\n\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; 0\\]\n\n아래의 두 식은 관측치가 초평면을 중심으로 두 class를 정확히 구분되고, 관측치와 초평면사이의 직교거리가 최소 \\(M\\)이상이 되도록 보장해 주는 조건이다.\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M} \\]\n\\[ \\sum_{i=1}^{p} \\beta_j^2 =  1\\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M\\]\n\n그러나 실제로 관측치는 두 개의 class로 정확히 구분되지 않은 경우가 더 많으며 한 두개의 관측치에 큰 영향을 받을 수 있다,(Not robust)\n\n\n관측치에 영향을 받아 초평면이 영향을 받은 예시\n\n\n\n\n\n이를 해결하기 위해 \\(C&gt;0\\), tuning parameter와 \\(\\epsilon_i\\)(slack bariable)를 사용\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M}, \\sum_{i=1}^{p} \\beta_j^2 =  1 \\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M(1-\\epsilon_i) \\quad  (\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C)\\]\n\n\\(C\\)가 커질수록 margin이 넓어짐\n\\(C\\)를 작게하면 현 데이터의 정확한 분류에 더 집중하게 되므로 자료 적합성이 좋아짐, 즉 bias는 감소하고 variance는 증가\nmargin 위 혹은 안쪽에 위치한 관측치들을 일컬어 support vector라고 한다.\n\n\nC값에 따른 margin 변화\n\n\n\n\n\n여기에서 \\(C\\)값이 가장 큰 것은 왼쪽 맨위 그림이다. \\(\\to\\) 직관적으로 \\(C\\)는 허용한계이므로 \\(M\\)즉, 마진의 넓이를 넓힌다고 생각하자.\n잠깐 생각해야될 문제\n\n\n\n\n\n우리는 여태껏 직선의 경우인 Support vector classifier를 생각했다. 근데 위에 처럼 생긴다면….\n\n- 그래서 고안된 방법이 본격적인 SVM(support vector machine)이다.\n\n고차원의 decision boundary를 고려함. \\(\\to\\) 예를 들어, 2차항까지 고려한 최적화 문제의 해로써 decision boundary를 정의할 수 있음…\n\n\\[\\underset{\\beta_0,\\beta_{11},\\dots,\\beta_{p1},\\beta_{12},\\dots,\\beta_{p2},\\varepsilon_1,\\dots ,\\varepsilon_n,M} {\\text {maximize}}M\\]\n\\[\\sum_{i=1}^{p}\\sum_{k=1}^2 \\beta_{jk}^2 = 1\\]\n\\[y_i \\left( \\beta_0 + \\sum_{j=1}^{p} \\beta_{j1}x_{ij} + \\sum_{j=1}^{p}\\beta_{i2}x_{ij}^2\\right) &gt; M(1-\\varepsilon_i)\\]\n\\[\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C\\]\n- 단순히 확장한 것에 불과하지 않은가???\n\nsupport vector classifier을 찾기 위해서는 관측치들간의 내적(inner product)을 계산하는 것으로 충분함이 알려져 있음\n이러한 내적을 여러 방면으로 일반화하여 표현할 수 있는데 이를 규정해 주는 함수를 kernel 이라 한다. (이 부분은 설명 생략!)\n\n- kernel 종류\n\npoly(다항), rbf(Radial Basis Function), sigmoid, linear\n\n\n\n- 걍 넘어가려고 했는데 안되겠음 \\(\\to\\) ㅅㅂ… 결과를 납득할 수 없다. 진짜 다시보자\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import svm\n\n# we create 40 separable points\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n\n# figure number\nfignum = 1\n\n# fit the model\nfor name, penalty in ((\"unreg\", 1), (\"reg\", 0.05)):\n    clf = svm.SVC(kernel=\"linear\", C=penalty)\n    clf.fit(X, Y)\n\n    # get the separating hyperplane\n    w = clf.coef_[0]\n    a = -w[0] / w[1]\n    xx = np.linspace(-5, 5)\n    yy = a * xx - (clf.intercept_[0]) / w[1]\n\n    # plot the parallels to the separating hyperplane that pass through the\n    # support vectors (margin away from hyperplane in direction\n    # perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in\n    # 2-d.\n    margin = 1 / np.sqrt(np.sum(clf.coef_**2))\n    yy_down = yy - np.sqrt(1 + a**2) * margin\n    yy_up = yy + np.sqrt(1 + a**2) * margin\n\n    # plot the line, the points, and the nearest vectors to the plane\n    plt.figure(fignum, figsize=(4, 3))\n    plt.clf()\n    plt.plot(xx, yy, \"k-\")\n    plt.plot(xx, yy_down, \"k--\")\n    plt.plot(xx, yy_up, \"k--\")\n    plt.title(f\"C={penalty}\")\n    plt.scatter(\n        clf.support_vectors_[:, 0],\n        clf.support_vectors_[:, 1],\n        s=80,\n        facecolors=\"none\",\n        zorder=10,\n        edgecolors=\"k\",\n    )\n    plt.scatter(\n        X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.get_cmap(\"RdBu\"), edgecolors=\"k\"\n    )\n\n    plt.axis(\"tight\")\n    x_min = -4.8\n    x_max = 4.2\n    y_min = -6\n    y_max = 6\n\n    YY, XX = np.meshgrid(yy, xx)\n    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n    Z = clf.decision_function(xy).reshape(XX.shape)\n\n    # Put the result into a contour plot\n    plt.contourf(XX, YY, Z, cmap=plt.get_cmap(\"RdBu\"), alpha=0.5, linestyles=[\"-\"])\n\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    fignum = fignum + 1\n\nplt.show()"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#k-fold-cross-validation",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#k-fold-cross-validation",
    "title": "08. summary (1)",
    "section": "",
    "text": "- 우리가 기존의 하던 방식\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 2023)\n- 단점\n\n랜덤하게 자료를 분할하기 때문에 분할결과에 따라 추정의 변동성이 크다….\n특히 자료위 크기가 작거나 이상/영향치들이 포함되어 있는 경우에 더더욱 그러함.\n또한, 원 자료의 크기 보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음.\n\n\n이러한 방법을 \\(\\text {Validation set Approach}\\)라고 한다….\n\n- K-fold Cross Validation 방식\n\n\n\n\n전체 자료를 \\(k\\)개의 집합으로 분할한 후그 중 하나의 집합 (\\(i\\))번째 집합을 평가자료롤 설정(위 그림의 경우 \\(i=1,2 \\dots 5\\))\n그 후 각 정확도를 평균냄 (교제에서는 \\(MSE\\)를 평균 냈는데, 이번 강의에서는 정확도를 평균내더라…)\n\n\\[\\text {CV}_{5} = \\frac {1}{5} \\sum_{i=1}^{5} \\text{Accuracy}_{i}\\]\n# 1단계: 불러오기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 2단계: 선언하기\nmodel = DecisionTreeClassifier(max_depth=3)\n\n# 3단계: 검증하기\ncv_score = cross_val_score(model, x_train, y_train, cv=10)\n\n# 확인\nprint(cv_score)\nprint(cv_score.mean())\n= 장점\n\n모든 데이터가 학습과 평가에 사용됨\n데이터가 부족해서 발생하는 과소적합 문제을 방지할 수 있음\n 좀 더 일반화된 모델 을 만들 수 있음\ntest error의 과대추정을 방지\n\n- 단점\n\n반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#search",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#search",
    "title": "08. summary (1)",
    "section": "",
    "text": "- 일단, 튜닝 시 모델들의 각 파라미터들에 값을 어떻게 하느냐에 따라 성능이 달라지는 것을 확인할 수 있었음\n- grid search의 아이디어는 가능한 파라미터 값 범위를 지정해 해당 범위에서의 값을 모두 사용하는 것이다.\n\n당연히 정확도는 높으나….시간이 오래 걸리겠지라는 생각을 해볼 수 있다.\n\n\n요런느낌\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10), 'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n\n# Grid Search 선언\nmodel = GridSearchCV(knn_model, param, cv=3)\n\n\n\n- 그리드 서치처럼 파라미터 범위를 지정하는 것은 동일\n- 설정한 파라미터 값 범위에서 몇 개를 선택할지를 정하여 Random Search 모델 선언 후 학습\n- 학습 데이터에 대해 가장 좋은 성능을 보인 파라미터 값으로 자동 학습함.\n\n참고로 Grid Search, Random Search를 사용할 때 내부적으로 K-Fold Cross Validation을 위해 cv값을 지정하므로!\n실제 수행되는 횟수는  파라미터 조합 수 x CV값이 된다.\n\n\ncode\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10),\n'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n# Random Search 선언\nmodel = RandomizedSearchCV(knn_model, \n                                                       param, cv=3, # (default = 5)\n                                                           n_iter=20) ### 전체 파라미터 범위에서 몇 개를 뽑을 것인지 (default = 10)\n\n또한, 두 가지 기법을 섞어서 사용할 수 있음! (강의자료 참고)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#클래스-불균형",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#클래스-불균형",
    "title": "08. summary (1)",
    "section": "",
    "text": "- 머신러닝 알고리즘은 데이터가 클래스 간에 균형 있게 분포되어 있다고 가정함\n\nexample : 생존자와 사망자 수가 거의 같을 것이다~~\n\n- 클래스 불균형으로 인한 재현율이 형편없어지는 경우는 아래 링크를 참고!\n\n재현율\n\n\n\n- under sampling\n\n다수 클래스 데이터를 소수 클래스 수 만큼 랜덤 샘플링\n\n- over sampling\n\n소수의 클래스 데이터를 다수 클래스 수 만큼 랜덤 샘플링\n\n# pip install imbalanced-learn\n# 불러오기\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Under Sampling\nunder_sample = RandomUnderSampler()\nu_x_train, u_y_train = under_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(u_y_train))\n\n# 불러오기\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Over Sampling\nover_sample = RandomOverSampler()\no_x_train, o_y_train = over_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(o_y_train))\n- over sampling (2)\n# 불러오기\nfrom imblearn.over_sampling import SMOTE\n\n# Over Sampling\nsmote = SMOTE()\ns_x_train, s_y_train = smote.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(s_y_train))\n\n\n\n- resampling 없이 클래스에 가중치를 부여하여 클래스 불균형 문제를 해결해줌\n\n학습하는 동안 알고리즘의 비용함수에서 소수 클래스에 더 많은 가중치를 부여하여 소수 클래스에 더 높은 패널티를 제공함으로써, 소수 클래스에 대한 오류를 줄이게 됨\nsklearn에서 제공하는 알고리즘 대부분 class_weight라는 하이퍼 파라미터를 제공한다.\n\nclass_weight = ‘None’ : 기본값\nclass_weight = ‘balanced’: y_train의 class 비율을 역으로 적용\nclass_weight={0:0.2, 1:0.8}: 비율 지정, 단 비율의 합은 1\n\n주의! \\(\\to\\) 전반적인 성능을 높이기 위한 작업이 아니라, 소수 클래스 성능을 높이기 위한 작업임!"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#excersise",
    "href": "posts/DX/04. 머신러닝/2023-09-28-08. summary (1).html#excersise",
    "title": "08. summary (1)",
    "section": "",
    "text": "# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n# 데이터 불러오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/airline_satisfaction_small.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\ndeparture/arrival_time_convenient\nease_of_online_booking\n...\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\ndeparture_delay_in_minutes\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\n70172\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n4\n3\n...\n5\n4\n3\n4\n4\n5\n5\n25\n18.0\n0\n\n\n1\n5047\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n2\n3\n...\n1\n1\n5\n3\n1\n4\n1\n1\n6.0\n0\n\n\n2\n110028\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n2\n...\n5\n4\n3\n4\n4\n4\n5\n0\n0.0\n1\n\n\n3\n24026\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n5\n...\n2\n2\n5\n3\n1\n4\n2\n11\n9.0\n0\n\n\n4\n119299\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n3\n...\n3\n3\n4\n4\n3\n3\n3\n0\n0.0\n1\n\n\n\n\n5 rows × 24 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2580 entries, 0 to 2579\nData columns (total 24 columns):\n #   Column                             Non-Null Count  Dtype  \n---  ------                             --------------  -----  \n 0   id                                 2580 non-null   int64  \n 1   gender                             2580 non-null   object \n 2   customer_type                      2580 non-null   object \n 3   age                                2580 non-null   int64  \n 4   type_of_travel                     2580 non-null   object \n 5   class                              2580 non-null   object \n 6   flight_distance                    2580 non-null   int64  \n 7   inflight_wifi_service              2580 non-null   int64  \n 8   departure/arrival_time_convenient  2580 non-null   int64  \n 9   ease_of_online_booking             2580 non-null   int64  \n 10  gate_location                      2580 non-null   int64  \n 11  food_and_drink                     2580 non-null   int64  \n 12  online_boarding                    2580 non-null   int64  \n 13  seat_comfort                       2580 non-null   int64  \n 14  inflight_entertainment             2580 non-null   int64  \n 15  on-board_service                   2580 non-null   int64  \n 16  leg_room_service                   2580 non-null   int64  \n 17  baggage_handling                   2580 non-null   int64  \n 18  checkin_service                    2580 non-null   int64  \n 19  inflight_service                   2580 non-null   int64  \n 20  cleanliness                        2580 non-null   int64  \n 21  departure_delay_in_minutes         2580 non-null   int64  \n 22  arrival_delay_in_minutes           2574 non-null   float64\n 23  satisfaction                       2580 non-null   int64  \ndtypes: float64(1), int64(19), object(4)\nmemory usage: 483.9+ KB\n\n\n- 쓸모없는 변수 제거\n\n# 변수 제거\nd_cols = [\"id\", \"departure/arrival_time_convenient\", \"gate_location\", \"departure_delay_in_minutes\"]\n\n\ndata.drop(d_cols,axis=1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n0\n\n\n1\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n0\n\n\n2\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n1\n\n\n3\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0\n\n\n4\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1\n\n\n\n\n\n\n\n- 결측치 확인\n\nprint(data.columns[data.isna().sum() !=0])\n\nIndex(['arrival_delay_in_minutes'], dtype='object')\n\n\n\ndata.arrival_delay_in_minutes.isna().sum()\n\n6\n\n\n- 현재 arrival_delay_in_minutes의 6개 결측치가 확인된다.\n\n결측치 제거를 위해 해당 변수의 분포를 확인하자.\n\n\ndata.plot(x=\"arrival_delay_in_minutes\",  kind = \"hist\", backend  = \"plotly\",\n                  width = 1000, height = 400,nbins=100)\n\n\n                                                \n\n\n- 대부분의 값들이 0값 근처에 몰려있으니 결측값을 0으로 대체하자.\n\ndata.arrival_delay_in_minutes.fillna(0, inplace = True)\nprint(data.columns[data.isna().sum() !=0])\n\nIndex([], dtype='object')\n\n\n- x, y 분리\n\ntarget = \"satisfaction\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd = [\"gender\", \"customer_type\", \"type_of_travel\", \"class\"]\n\nx = pd.get_dummies(x, columns = d, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nage\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\ngender_Male\ncustomer_type_disloyal Customer\ntype_of_travel_Personal Travel\nclass_Eco\nclass_Eco Plus\n\n\n\n\n0\n13\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n1.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n25\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n1.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n26\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n25\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n61\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습, 평가용 데이터 분리\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n\n\n\n\n\nCode\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n# 1. tree\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\ntree.cv_m = tree.cv.mean()\n\n# 2. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\nlogit.cv_m = logit.cv.mean()\n\n# 3. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\nrf.cv = cross_val_score(rf, x_train,y_train)\nrf.cv_m = rf.cv.mean()\n\n# 4. XGBoost\n\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\nxgb.cv_m  = xgb.cv.mean()\n\n\n\nresult = [tree.cv_m, logit.cv_m, rf.cv_m,  xgb.cv_m]\nmodel = [\"tree\",\"logit\", \"rf\", \"xgb\"]\n\nfig = pd.DataFrame({\"model\" : model, \"result\" : result}).\\\n            sort_values(\"result\", ascending = False).plot(x = \"result\", y = \"model\", kind = \"bar\", backend = \"plotly\",color = \"model\")\n\nfig.update_xaxes(range = [0.7, 1.0])\n\n\n                                                \n\n\n- cv를 기준으로 XGB 모델이 최적의 모델인 것 같다.\n\ngrid search기법을 이용하여 모델 튜닝\n\n\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring=\"accuracy\")\n\n\nmodel.fit(x_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')estimator: XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)\n\n\n\ny_pred = model.predict(x_test)\n\n\n# 예측 결과 확인\nprint(model.best_params_)\nprint(model.best_score_)\n\n{'max_depth': 3}\n0.9363202277283789\n\n\n\nfig = pd.DataFrame([model.best_estimator_.feature_names_in_,model.best_estimator_.feature_importances_]).T.\\\n        rename(columns = {0 : \"feature\", 1 : \"importance\"}).sort_values(\"importance\", ascending = False).\\\n            plot(y = \"feature\", x=  \"importance\", kind = \"barh\",\n                    backend = \"plotly\",color = \"feature\")\n\nfig.update_layout(showlegend = False)\n\n\n                                                \n\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmeasure = [\"accuracy\", \"precision\", \"reacll\", \"f1-score\"]\n\nacc = accuracy_score(y_test, y_pred)\npre = precision_score(y_test, y_pred)\nre = recall_score(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred)\n\n\npd.DataFrame({\"measure\" : measure, \"score\" : [acc, pre, re, f1_score]})\n\n\n\n\n\n\n\n\nmeasure\nscore\n\n\n\n\n0\naccuracy\n0.931525\n\n\n1\nprecision\n0.949102\n\n\n2\nreacll\n0.898017\n\n\n3\nf1-score\n0.922853"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html",
    "title": "06. 머신러닝 (5)",
    "section": "",
    "text": "# 기본 라이브러리 가져오기\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import *\n\nfrom sklearn.datasets import load_breast_cancer, load_digits\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n\n\n\n\n\n\n# breast_cancer 데이터 로딩\ncancer=load_breast_cancer()\nx = cancer.data\ny = cancer.target\n\nx = pd.DataFrame(x, columns=cancer.feature_names)\n\n\nx.head()\n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst radius\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\n\n\n\n\n0\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.3001\n0.14710\n0.2419\n0.07871\n...\n25.38\n17.33\n184.60\n2019.0\n0.1622\n0.6656\n0.7119\n0.2654\n0.4601\n0.11890\n\n\n1\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.0869\n0.07017\n0.1812\n0.05667\n...\n24.99\n23.41\n158.80\n1956.0\n0.1238\n0.1866\n0.2416\n0.1860\n0.2750\n0.08902\n\n\n2\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.1974\n0.12790\n0.2069\n0.05999\n...\n23.57\n25.53\n152.50\n1709.0\n0.1444\n0.4245\n0.4504\n0.2430\n0.3613\n0.08758\n\n\n3\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.2414\n0.10520\n0.2597\n0.09744\n...\n14.91\n26.50\n98.87\n567.7\n0.2098\n0.8663\n0.6869\n0.2575\n0.6638\n0.17300\n\n\n4\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.1980\n0.10430\n0.1809\n0.05883\n...\n22.54\n16.67\n152.20\n1575.0\n0.1374\n0.2050\n0.4000\n0.1625\n0.2364\n0.07678\n\n\n\n\n5 rows × 30 columns\n\n\n\n\n#x.info()\n\n\n#x.describe().T\n\n\n\n\n- 거리계산 기반 차원축소이므로 스케일링이 필요\n\n\n\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .3, random_state = 20)\n\n\n\n\n\n\n\n\nfrom sklearn.decomposition import PCA\n\n\n# feature 수\nx_train.shape[1]\n\n30\n\n\n\n# 주성분을 몇개로 할지 결정(최대값 : 전체 feature 수)\nn = x_train.shape[1] ## 일단 원래 feature의 수만 지정\n\n# 주성분 분석 선언\npca = PCA(n_components=n)\n\n# 만들고, 적용하기\nx_train_pc = pca.fit_transform(x_train)\nx_val_pc = pca.transform(x_val)\n\n- 편리한 사용을 위해 데이터프레임으로 변환\n\n# 칼럼이름 생성\ncolumn_names = [ 'PC'+str(i+1) for i in range(n) ]\ncolumn_names[:5]\n\n['PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n\n\n\n# 데이터프레임으로 변환하기\nx_train_pc = pd.DataFrame(x_train_pc, columns = column_names)\nx_val_pc = pd.DataFrame(x_val_pc, columns = column_names)\nx_train_pc.head()\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\n...\nPC21\nPC22\nPC23\nPC24\nPC25\nPC26\nPC27\nPC28\nPC29\nPC30\n\n\n\n\n0\n-34.932206\n47.067779\n-17.756611\n-7.596006\n1.342721\n-1.956710\n1.710276\n0.641097\n0.120917\n0.139938\n...\n0.000962\n0.010435\n-0.003107\n-0.002029\n0.003974\n-0.000625\n-0.000576\n-0.000446\n0.000679\n0.001145\n\n\n1\n830.092826\n201.450565\n-6.166167\n-2.578986\n-1.794260\n2.619614\n0.284543\n0.366729\n-0.027226\n0.018051\n...\n-0.019489\n0.001261\n0.003305\n-0.011163\n0.005675\n0.001333\n0.001847\n-0.003122\n0.001580\n0.000655\n\n\n2\n-546.384045\n22.139574\n17.780018\n0.887465\n-0.308381\n-0.126655\n-1.450590\n-0.632612\n-0.009378\n-0.606726\n...\n0.002701\n-0.014928\n0.001773\n0.001490\n0.007249\n-0.000604\n-0.001318\n-0.001299\n-0.000982\n-0.000077\n\n\n3\n653.345270\n25.739603\n30.832277\n-7.437820\n2.139092\n3.686376\n-0.111756\n0.191535\n-0.181315\n0.111042\n...\n0.002200\n0.021932\n-0.012297\n0.002943\n0.002366\n-0.005320\n0.000484\n0.000967\n-0.002898\n-0.000765\n\n\n4\n-422.567968\n19.784995\n6.432610\n-10.383670\n-14.675624\n0.098355\n-0.537767\n-0.113981\n0.062963\n0.442519\n...\n0.003790\n-0.012366\n0.004250\n0.005447\n-0.002826\n-0.000611\n-0.000136\n0.000270\n-0.000225\n0.000407\n\n\n\n\n5 rows × 30 columns\n\n\n\n\n\n\n- 주성분을 1,2,3개로 선언하고, x_train을 이용해서 주성분을 추출\n\n# 주성분을 몇개로 할지 결정(최대값 : 전체 feature 수)\nn = [1,2,3]## 일단 원래 feature의 수만 지정\n\n# 주성분 분석 선언\n\nfor i in n : \n     exec(f\"pca{i} = PCA(n_components={i})\")\n     exec(f\"x_train_pc{i} = pca{i}.fit_transform(x_train)\")\n\n\n\n\n\n그래프를 보고 적절한 주성분의 개수를 지정(elbow method!)\nx축 : PC 수\ny축 : 전체 분산크기 - 누적 분산크기\n\n\npca\n\nPCA(n_components=30)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PCAPCA(n_components=30)\n\n\n\nplt.plot(pca.explained_variance_ratio_, marker = '.')\nplt.xlabel('No. of PC')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n- 주성분 중 상위 2개를 뽑아 시각화\n\nsns.scatterplot(x = 'PC1', y = 'PC2', data = x_train_pc, hue = y_train)\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nmodel0 = KNeighborsClassifier()\nmodel0.fit(x_train, y_train)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifierKNeighborsClassifier()\n\n\n\n# 원본데이터 모델의 성능\npred0 = model0.predict(x_val)\n\nprint(confusion_matrix(y_val, pred0))\nprint(accuracy_score(y_val, pred0))\nprint(classification_report(y_val, pred0))\n\n[[ 57   7]\n [  5 102]]\n0.9298245614035088\n              precision    recall  f1-score   support\n\n           0       0.92      0.89      0.90        64\n           1       0.94      0.95      0.94       107\n\n    accuracy                           0.93       171\n   macro avg       0.93      0.92      0.92       171\nweighted avg       0.93      0.93      0.93       171\n\n\n\n\n\n\n\nn = 1 \nx_train_pc_n = x_train_pc[column_names[:n]] \nx_val_pc_n = x_val_pc[column_names[:n]] \n# 뽑은 데이터로 모델링 \nmodel1 = KNeighborsClassifier() \nmodel1.fit(x_train_pc_n, y_train) # 예측 평가 \npred1 = model1.predict(x_val_pc_n) \nprint(accuracy_score(y_val, pred1))\n\n0.8830409356725146\n\n\n\n\n\n\nn = 2 \nx_train_pc_n = x_train_pc[column_names[:n]] \nx_val_pc_n = x_val_pc[column_names[:n]] \n# 뽑은 데이터로 모델링 \nmodel1 = KNeighborsClassifier() \nmodel1.fit(x_train_pc_n, y_train) # 예측 평가 \npred1 = model1.predict(x_val_pc_n) \nprint(accuracy_score(y_val, pred1))\n\n0.9181286549707602\n\n\n\n\n\n\nn = 3\nx_train_pc_n = x_train_pc[column_names[:n]] \nx_val_pc_n = x_val_pc[column_names[:n]] \n# 뽑은 데이터로 모델링 \nmodel1 = KNeighborsClassifier() \nmodel1.fit(x_train_pc_n, y_train) # 예측 평가 \npred1 = model1.predict(x_val_pc_n) \nprint(accuracy_score(y_val, pred1))\n\n0.9181286549707602\n\n\n\n\n\n\n\n1. 원본데이터의 유사도(거리) 맵을 만듬\n2 원본에서의 유사도가 축소한 차원에서도 유지 되었으면 좋겠음\n3 주성분 분석은 선형 축소, t-SNE는 비선형 축소이다.\n\n\n\nfrom sklearn.manifold import TSNE\n\n\n# 2차원으로 축소하기\ntsne = TSNE(n_components = 2, random_state=20)\nx_tsne = tsne.fit_transform(x)\n\n# 사용의 편리함을 위해 DataFrame으로` 변환\nx_tsne = pd.DataFrame(x_tsne, columns = ['T1','T2'])\n\n\nx_tsne.shape\n\n(569, 2)\n\n\n- 시각화\n\nplt.figure(figsize=(6,6))\nsns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)\nplt.grid()\n\n\n\n\n\n\n\n\n\n\ndigits = load_digits()\nx = digits.data\ny = digits.target\n\ny = pd.Categorical(y)\n\n\nx.shape\n\n(1797, 64)\n\n\n- 데이터 살펴보기\n\nprint(x[0].reshape(8,8))\n\n[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n [ 0.  0. 13. 15. 10. 15.  5.  0.]\n [ 0.  3. 15.  2.  0. 11.  8.  0.]\n [ 0.  4. 12.  0.  0.  8.  8.  0.]\n [ 0.  5.  8.  0.  0.  9.  8.  0.]\n [ 0.  4. 11.  0.  1. 12.  7.  0.]\n [ 0.  2. 14.  5. 10. 12.  0.  0.]\n [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n\n\n\n# f, axes = plt.subplots(5, 2, sharey=True, figsize=(16,6))\nplt.figure(figsize=(10, 4))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(x[i,:].reshape([8,8]), cmap='gray');\n\n\n\n\n\n스케일링\n\n\n# 최대, 최소값\nnp.min(x), np.max(x)\n\n(0.0, 16.0)\n\n\n\n# 최대값으로 나누면 Min Max 스케일링이 됩니다.\nx = x / 16\n\n\n\n\n- 주성분 2개로 차원을 축소하고 시각화\n\nn = 2\npca = PCA(n_components = n)\n\nx_pca = pca.fit_transform(x)\nx_pca = pd.DataFrame(x_pca, columns = ['PC1', 'PC2'])\n\n\n# 시각화\nplt.figure(figsize=(12, 4))\nsns.scatterplot(x = 'PC1', y = 'PC2', data = x_pca, hue = y)\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n# 2차원으로 축소하기\ntsne = TSNE(n_components = 2, random_state=20)\nx_tsne = tsne.fit_transform(x)\n\n# 사용의 편리함을 위해 DataFrame으로` 변환\nx_tsne = pd.DataFrame(x_tsne, columns = ['T1','T2'])\n\n\n# 시각화\nplt.figure(figsize=(12, 4))\nsns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#import",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#import",
    "title": "06. 머신러닝 (5)",
    "section": "",
    "text": "# 기본 라이브러리 가져오기\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import *\n\nfrom sklearn.datasets import load_breast_cancer, load_digits\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#데이터-준비",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#데이터-준비",
    "title": "06. 머신러닝 (5)",
    "section": "",
    "text": "# breast_cancer 데이터 로딩\ncancer=load_breast_cancer()\nx = cancer.data\ny = cancer.target\n\nx = pd.DataFrame(x, columns=cancer.feature_names)\n\n\nx.head()\n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst radius\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\n\n\n\n\n0\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.3001\n0.14710\n0.2419\n0.07871\n...\n25.38\n17.33\n184.60\n2019.0\n0.1622\n0.6656\n0.7119\n0.2654\n0.4601\n0.11890\n\n\n1\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.0869\n0.07017\n0.1812\n0.05667\n...\n24.99\n23.41\n158.80\n1956.0\n0.1238\n0.1866\n0.2416\n0.1860\n0.2750\n0.08902\n\n\n2\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.1974\n0.12790\n0.2069\n0.05999\n...\n23.57\n25.53\n152.50\n1709.0\n0.1444\n0.4245\n0.4504\n0.2430\n0.3613\n0.08758\n\n\n3\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.2414\n0.10520\n0.2597\n0.09744\n...\n14.91\n26.50\n98.87\n567.7\n0.2098\n0.8663\n0.6869\n0.2575\n0.6638\n0.17300\n\n\n4\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.1980\n0.10430\n0.1809\n0.05883\n...\n22.54\n16.67\n152.20\n1575.0\n0.1374\n0.2050\n0.4000\n0.1625\n0.2364\n0.07678\n\n\n\n\n5 rows × 30 columns\n\n\n\n\n#x.info()\n\n\n#x.describe().T\n\n\n\n\n- 거리계산 기반 차원축소이므로 스케일링이 필요\n\n\n\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .3, random_state = 20)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#차원-축소-주성분-분석-pca",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#차원-축소-주성분-분석-pca",
    "title": "06. 머신러닝 (5)",
    "section": "",
    "text": "from sklearn.decomposition import PCA\n\n\n# feature 수\nx_train.shape[1]\n\n30\n\n\n\n# 주성분을 몇개로 할지 결정(최대값 : 전체 feature 수)\nn = x_train.shape[1] ## 일단 원래 feature의 수만 지정\n\n# 주성분 분석 선언\npca = PCA(n_components=n)\n\n# 만들고, 적용하기\nx_train_pc = pca.fit_transform(x_train)\nx_val_pc = pca.transform(x_val)\n\n- 편리한 사용을 위해 데이터프레임으로 변환\n\n# 칼럼이름 생성\ncolumn_names = [ 'PC'+str(i+1) for i in range(n) ]\ncolumn_names[:5]\n\n['PC1', 'PC2', 'PC3', 'PC4', 'PC5']\n\n\n\n# 데이터프레임으로 변환하기\nx_train_pc = pd.DataFrame(x_train_pc, columns = column_names)\nx_val_pc = pd.DataFrame(x_val_pc, columns = column_names)\nx_train_pc.head()\n\n\n\n\n\n\n\n\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\nPC9\nPC10\n...\nPC21\nPC22\nPC23\nPC24\nPC25\nPC26\nPC27\nPC28\nPC29\nPC30\n\n\n\n\n0\n-34.932206\n47.067779\n-17.756611\n-7.596006\n1.342721\n-1.956710\n1.710276\n0.641097\n0.120917\n0.139938\n...\n0.000962\n0.010435\n-0.003107\n-0.002029\n0.003974\n-0.000625\n-0.000576\n-0.000446\n0.000679\n0.001145\n\n\n1\n830.092826\n201.450565\n-6.166167\n-2.578986\n-1.794260\n2.619614\n0.284543\n0.366729\n-0.027226\n0.018051\n...\n-0.019489\n0.001261\n0.003305\n-0.011163\n0.005675\n0.001333\n0.001847\n-0.003122\n0.001580\n0.000655\n\n\n2\n-546.384045\n22.139574\n17.780018\n0.887465\n-0.308381\n-0.126655\n-1.450590\n-0.632612\n-0.009378\n-0.606726\n...\n0.002701\n-0.014928\n0.001773\n0.001490\n0.007249\n-0.000604\n-0.001318\n-0.001299\n-0.000982\n-0.000077\n\n\n3\n653.345270\n25.739603\n30.832277\n-7.437820\n2.139092\n3.686376\n-0.111756\n0.191535\n-0.181315\n0.111042\n...\n0.002200\n0.021932\n-0.012297\n0.002943\n0.002366\n-0.005320\n0.000484\n0.000967\n-0.002898\n-0.000765\n\n\n4\n-422.567968\n19.784995\n6.432610\n-10.383670\n-14.675624\n0.098355\n-0.537767\n-0.113981\n0.062963\n0.442519\n...\n0.003790\n-0.012366\n0.004250\n0.005447\n-0.002826\n-0.000611\n-0.000136\n0.000270\n-0.000225\n0.000407\n\n\n\n\n5 rows × 30 columns\n\n\n\n\n\n\n- 주성분을 1,2,3개로 선언하고, x_train을 이용해서 주성분을 추출\n\n# 주성분을 몇개로 할지 결정(최대값 : 전체 feature 수)\nn = [1,2,3]## 일단 원래 feature의 수만 지정\n\n# 주성분 분석 선언\n\nfor i in n : \n     exec(f\"pca{i} = PCA(n_components={i})\")\n     exec(f\"x_train_pc{i} = pca{i}.fit_transform(x_train)\")\n\n\n\n\n\n그래프를 보고 적절한 주성분의 개수를 지정(elbow method!)\nx축 : PC 수\ny축 : 전체 분산크기 - 누적 분산크기\n\n\npca\n\nPCA(n_components=30)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PCAPCA(n_components=30)\n\n\n\nplt.plot(pca.explained_variance_ratio_, marker = '.')\nplt.xlabel('No. of PC')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n- 주성분 중 상위 2개를 뽑아 시각화\n\nsns.scatterplot(x = 'PC1', y = 'PC2', data = x_train_pc, hue = y_train)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#지도학습으로-연계",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#지도학습으로-연계",
    "title": "06. 머신러닝 (5)",
    "section": "",
    "text": "model0 = KNeighborsClassifier()\nmodel0.fit(x_train, y_train)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifierKNeighborsClassifier()\n\n\n\n# 원본데이터 모델의 성능\npred0 = model0.predict(x_val)\n\nprint(confusion_matrix(y_val, pred0))\nprint(accuracy_score(y_val, pred0))\nprint(classification_report(y_val, pred0))\n\n[[ 57   7]\n [  5 102]]\n0.9298245614035088\n              precision    recall  f1-score   support\n\n           0       0.92      0.89      0.90        64\n           1       0.94      0.95      0.94       107\n\n    accuracy                           0.93       171\n   macro avg       0.93      0.92      0.92       171\nweighted avg       0.93      0.93      0.93       171\n\n\n\n\n\n\n\nn = 1 \nx_train_pc_n = x_train_pc[column_names[:n]] \nx_val_pc_n = x_val_pc[column_names[:n]] \n# 뽑은 데이터로 모델링 \nmodel1 = KNeighborsClassifier() \nmodel1.fit(x_train_pc_n, y_train) # 예측 평가 \npred1 = model1.predict(x_val_pc_n) \nprint(accuracy_score(y_val, pred1))\n\n0.8830409356725146\n\n\n\n\n\n\nn = 2 \nx_train_pc_n = x_train_pc[column_names[:n]] \nx_val_pc_n = x_val_pc[column_names[:n]] \n# 뽑은 데이터로 모델링 \nmodel1 = KNeighborsClassifier() \nmodel1.fit(x_train_pc_n, y_train) # 예측 평가 \npred1 = model1.predict(x_val_pc_n) \nprint(accuracy_score(y_val, pred1))\n\n0.9181286549707602\n\n\n\n\n\n\nn = 3\nx_train_pc_n = x_train_pc[column_names[:n]] \nx_val_pc_n = x_val_pc[column_names[:n]] \n# 뽑은 데이터로 모델링 \nmodel1 = KNeighborsClassifier() \nmodel1.fit(x_train_pc_n, y_train) # 예측 평가 \npred1 = model1.predict(x_val_pc_n) \nprint(accuracy_score(y_val, pred1))\n\n0.9181286549707602"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#차원축소-t-sne",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#차원축소-t-sne",
    "title": "06. 머신러닝 (5)",
    "section": "",
    "text": "1. 원본데이터의 유사도(거리) 맵을 만듬\n2 원본에서의 유사도가 축소한 차원에서도 유지 되었으면 좋겠음\n3 주성분 분석은 선형 축소, t-SNE는 비선형 축소이다.\n\n\n\nfrom sklearn.manifold import TSNE\n\n\n# 2차원으로 축소하기\ntsne = TSNE(n_components = 2, random_state=20)\nx_tsne = tsne.fit_transform(x)\n\n# 사용의 편리함을 위해 DataFrame으로` 변환\nx_tsne = pd.DataFrame(x_tsne, columns = ['T1','T2'])\n\n\nx_tsne.shape\n\n(569, 2)\n\n\n- 시각화\n\nplt.figure(figsize=(6,6))\nsns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)\nplt.grid()\n\n\n\n\n\n\n\n\n\n\ndigits = load_digits()\nx = digits.data\ny = digits.target\n\ny = pd.Categorical(y)\n\n\nx.shape\n\n(1797, 64)\n\n\n- 데이터 살펴보기\n\nprint(x[0].reshape(8,8))\n\n[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n [ 0.  0. 13. 15. 10. 15.  5.  0.]\n [ 0.  3. 15.  2.  0. 11.  8.  0.]\n [ 0.  4. 12.  0.  0.  8.  8.  0.]\n [ 0.  5.  8.  0.  0.  9.  8.  0.]\n [ 0.  4. 11.  0.  1. 12.  7.  0.]\n [ 0.  2. 14.  5. 10. 12.  0.  0.]\n [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n\n\n\n# f, axes = plt.subplots(5, 2, sharey=True, figsize=(16,6))\nplt.figure(figsize=(10, 4))\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(x[i,:].reshape([8,8]), cmap='gray');\n\n\n\n\n\n스케일링\n\n\n# 최대, 최소값\nnp.min(x), np.max(x)\n\n(0.0, 16.0)\n\n\n\n# 최대값으로 나누면 Min Max 스케일링이 됩니다.\nx = x / 16\n\n\n\n\n- 주성분 2개로 차원을 축소하고 시각화\n\nn = 2\npca = PCA(n_components = n)\n\nx_pca = pca.fit_transform(x)\nx_pca = pd.DataFrame(x_pca, columns = ['PC1', 'PC2'])\n\n\n# 시각화\nplt.figure(figsize=(12, 4))\nsns.scatterplot(x = 'PC1', y = 'PC2', data = x_pca, hue = y)\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n# 2차원으로 축소하기\ntsne = TSNE(n_components = 2, random_state=20)\nx_tsne = tsne.fit_transform(x)\n\n# 사용의 편리함을 위해 DataFrame으로` 변환\nx_tsne = pd.DataFrame(x_tsne, columns = ['T1','T2'])\n\n\n# 시각화\nplt.figure(figsize=(12, 4))\nsns.scatterplot(x = 'T1', y = 'T2', data = x_tsne, hue = y)\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#k-means",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#k-means",
    "title": "06. 머신러닝 (5)",
    "section": "1. k-means",
    "text": "1. k-means\n\n주어진 데이터를 k개의 클러스터로 묶는 알고리즘, 각 클러스터와 거리 차이의 분산을 최소화 하는 방식으로 동작\n허나 군집의 수, 가중치와 거리 정의가 어려우며, 사전에 주어진 목적이 없으므로 결과 해석이 어려움.\n또한 잡음이나 이상값의 영향을 받으며 초기 군집 수를 결정해야 한다는 단점이 있다.\n\n\nimport\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# 샘플데이터 로딩 함수\nfrom sklearn.datasets import make_blobs, make_moons\n\n# 클러스터링을 위한 함수\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.cluster import KMeans, DBSCAN\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n\n\ndata\n\nx, y = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\nx = pd.DataFrame(x, columns = ['x1', 'x2'])\ny = pd.Series(y, name = 'shape')\n\nplt.figure(figsize = (12,4))\nplt.scatter(x['x1'], x['x2'])\nplt.show()\n\n\n\n\n\n\n모델링\n\n# k means 학습\nmodel = KMeans(n_clusters= 2, n_init = 'auto')\nmodel.fit(x)\n\n# 예측\npred = model.predict(x)\nprint(pred)\n\n[0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1\n 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0\n 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0\n 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0\n 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0\n 0 0 1 0]\n\n\n\n# feature + pred + y 붙여 놓고 비교해 봅시다.\npred = pd.DataFrame(pred, columns = ['predicted'])\nresult = pd.concat([x, pred, y], axis = 1)\nresult.head()\n\n\n\n\n\n\n\n\nx1\nx2\npredicted\nshape\n\n\n\n\n0\n0.836857\n2.136359\n0\n1\n\n\n1\n-1.413658\n7.409623\n1\n3\n\n\n2\n1.155213\n5.099619\n0\n0\n\n\n3\n-1.018616\n7.814915\n1\n3\n\n\n4\n1.271351\n1.892542\n0\n1\n\n\n\n\n\n\n\n\n\n결과 시각화\n\n# k means 모델로 부터 클러스터의 평균 값들을 가져올 수 있습니다.\ncenters = pd.DataFrame(model.cluster_centers_, columns=['x1','x2'])\ncenters\n\n\n\n\n\n\n\n\nx1\nx2\n\n\n\n\n0\n0.452332\n2.681056\n\n\n1\n-1.334654\n7.694427\n\n\n\n\n\n\n\n\nplt.figure(figsize = (8,6))\nplt.scatter(result['x1'], result['x2'], c = result['predicted'], alpha=0.5)\nplt.scatter(centers['x1'], centers['x2'], s=50, marker='D', c='r')\nplt.show()\n\n\n\n\n\n\nk 값에 따라 모델을 생성하고 스래프 그리기\n\ndef k_means_plot(x, y, k) :\n    # 모델 생성\n    model = KMeans(n_clusters= k, n_init = 'auto')\n    model.fit(x)\n    pred = model.predict(x)\n\n    # 군집 결과와 원본 데이터 합치기(concat)\n    pred = pd.DataFrame(pred, columns = ['predicted'])\n    result = pd.concat([x, pred, y], axis = 1)\n\n    # 중앙(평균) 값 뽑기\n    centers = pd.DataFrame(model.cluster_centers_, columns=['x1','x2'])\n\n    # 그래프 그리기\n    plt.figure(figsize = (12,4))\n    plt.scatter(result['x1'],result['x2'],c=result['predicted'],alpha=0.5)\n    plt.scatter(centers['x1'], centers['x2'], s=50,marker='D',c='r')\n    plt.grid()\n    plt.show()\n\n\n\n적절한 k찾기\n- Inertia value : 군집화가 된 후에, 각 중심점에서 군집의 데이터 간의 거리를 합산한 값\n\n# k의 갯수에 따라 각 점과의 거리를 계산하여 적정한 k를 찾아 봅시다.\nkvalues = range(1, 10)\ninertias = []\n\nfor k in kvalues:\n    model = KMeans(n_clusters=k, n_init = 'auto')\n    model.fit(x)\n    inertias.append(model.inertia_)\n\n\n# Plot k vs inertias\nplt.figure(figsize = (12, 4))\nplt.plot(kvalues, inertias, '-o')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.grid()\nplt.show()\n\n\n\n\n- 난 4개의 군집이 좀 적절한 것 같음.\n\n\nkmeans의 한계\n\nx, y = make_moons(n_samples = 300, noise = .08, random_state=2)\nx = pd.DataFrame(x, columns = ['x1', 'x2'])\ny = pd.Series(y, name = 'shape')\n\nplt.figure(figsize = (12,4))\nplt.scatter(x['x1'], x['x2'])\nplt.show()\n\n\n\n\n\n# k의 갯수에 따라 각 점과의 거리를 계산하여 적정한 k를 찾아 봅시다.\nkvalues = range(1, 15)\ninertias = []\n\nfor k in kvalues:\n    model = KMeans(n_clusters=k, n_init = 'auto')\n    model.fit(x)\n    inertias.append(model.inertia_)\n\n\n# Plot k vs inertias\nplt.figure(figsize = (12,4))\nplt.plot(kvalues, inertias, '-o')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.grid()\nplt.show()\n\n\n\n\n\n# 적절한 k값으로 모델을 생성해 봅시다.\nplt.figure(figsize = (12,4))\nk_means_plot(x, y, k = 6)\n\n&lt;Figure size 1200x400 with 0 Axes&gt;\n\n\n\n\n\n\n우리가 기대하는 모델이 생성되지는 앟는다.\nKmeans는 블록한(convex) 덩어리 cluster 구분에서는 괜찮지만, 뭐야 근데 위에 잘 분류된거 아녀? 여튼 저런식에서는 잘 분류가 안된다는 것을 말하고 싶었음"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#dbscan",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#dbscan",
    "title": "06. 머신러닝 (5)",
    "section": "2. DBSCAN",
    "text": "2. DBSCAN\n- DBSCAN모델은 위 kmeans의 한계점을 보완한 모델이다.\n\n임의의 한 점에서 시작\n반경 범위내에 최소 포인트 수가 존재하는지 확인\n존재한다면 각 포인트들을 중심으로 다시 원을 그어 최소 포인트 수를 확인\n2~3을 반복 수행\n존재하지 않으면, 군집에 포함되지 않은 점으로 이동하여 1~4 반복 수행\n어느 군집에도 포함되지 않은점을 이상치로 간주\n\n\nDBSCAN의 주 매개변수\n\nmin_samples : 핵심 포인트를 중심점으로 간주하는 주변 지역의 표본 수\neps : 핵심 포인트를 중심으로 측정되는 유클리디언 거리값\n\n\n\nx, y = make_blobs(n_samples=300, centers=5, cluster_std=1.8, random_state=20)\nx = pd.DataFrame(x, columns = ['x1', 'x2'])\ny = pd.Series(y, name = 'shape')\n\nplt.figure(figsize = (8,6))\nplt.scatter(x['x1'], x['x2'])\nplt.show()\n\n\n\n\n\n# DBSCAN 모델을 만들어 봅시다.\nmodel = DBSCAN(eps=0.1, min_samples=3)\nmodel.fit(x)\n\nDBSCAN(eps=0.1, min_samples=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DBSCANDBSCAN(eps=0.1, min_samples=3)\n\n\n\n# fitting한 후에 모델의 labels_ 값이 찾아낸 군집 종류입니다.\nclusters = model.labels_\n\n\n# 군집 번호 중 -1은 이상치를 의미합니다.(어느 군집에도 포함 안되는 값들!)\nclusters\n\narray([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64)\n\n\n\nplt.figure(figsize = (12, 4))\nplt.scatter(x['x1'], x['x2'], c=clusters, alpha=0.5)\nplt.show()\n\n\n\n\n- eps를 적용하며 모델을 생성하고 그래프 그리기\n\ndef dbscan_plot(x, y, eps) :\n    model = DBSCAN(eps=eps, min_samples=3)\n    model.fit(x)\n    clusters = model.labels_\n    plt.figure(figsize = (12,4))\n    plt.scatter(x['x1'], x['x2'], c=clusters, alpha=0.5)\n    plt.grid()\n    plt.show()\n\n\ndbscan_plot(x,y,1.)\n\n\n\n\n\n적절한 eps 찾기\n\n역시 눈으로 보면서 찾는 것은 실전에서는 거의 불가능\nDBSCAN에도 적절한 값을 찾는 방법\n\n모든 점과 가까운 n개와 평균 거리 계산\n평균 거리순으로 정렬해서, 그래프 그리기\n평균 거리가 급격히 커지기 시작하는 지점 찾기(elbow point)\n\nDBSCAN의 주 매개변수\nmin_samples : 핵심 포인트를 중심점으로 간주하는 주변 지역의 표본 수\neps : 핵심 포인트를 중심으로 측정되는 유클리디언 거리값\n\n\n# 각점과 근처 3개 점과의 평균 거리\n# NearestNeighbors은 거리계산할 때, 자기 자신을 포함하므로 n+1\nn = 3\nknnDist = NearestNeighbors(n_neighbors = n+1).fit(x)\ndistances, _ = knnDist.kneighbors(x)\n\n- 열의 수가 4이다. \\(\\to\\) 0은 자기 자신을 의미하고 나머지 3개의 열은 가장 가까운 3개의 점과의 거리를 의미한다.\n\ndistances.shape\n\n(300, 4)\n\n\n\ndistances[:5]\n\narray([[0.        , 0.49231025, 0.55853535, 0.63526856],\n       [0.        , 0.47383177, 1.47765296, 1.67802678],\n       [0.        , 0.40879685, 0.43381656, 0.6280564 ],\n       [0.        , 0.63087629, 0.72695518, 0.73171997],\n       [0.        , 0.35638603, 0.3886451 , 0.53734417]])\n\n\n- 평균 거리 계산\n\ndist = np.mean(distances[:,1:],axis=1)\ndist = np.sqrt(dist)\n\n- 급격ㅎ; 갈;기 증가하기 시작하는 구간을 찾아 eps값 적용\n\nplt.plot(np.sort(dist))\n\n\n\n\n- 여기서 보니 1.0때가 거리가 급격히 증가하는 것 같다.\n\ndbscan_plot(x, y, eps = 1.0 )"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#실습-1",
    "href": "posts/DX/04. 머신러닝/2023-09-18-06. 머신러닝 (5).html#실습-1",
    "title": "06. 머신러닝 (5)",
    "section": "3. 실습",
    "text": "3. 실습\n\n(1) 데이터 로드\n\npath = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/customer_segmentation.csv'\ndata = pd.read_csv(path)\ndata.head()\n\n\n\n\n\n\n\n\nCustID\nGender\nAge\nIncome\nScore\n\n\n\n\n0\n1\nMale\n19\n15\n39\n\n\n1\n2\nMale\n21\n15\n81\n\n\n2\n3\nFemale\n20\n16\n6\n\n\n3\n4\nFemale\n23\n16\n77\n\n\n4\n5\nFemale\n31\n17\n40\n\n\n\n\n\n\n\n\n\n(2) 데이터 전처리\n\n# 군집화는 아래 변수들만 사용합니다.\nx = data.loc[:, ['Age', 'Income', 'Score']]\n\n\nx.head()\n\n\n\n\n\n\n\n\nAge\nIncome\nScore\n\n\n\n\n0\n19\n15\n39\n\n\n1\n21\n15\n81\n\n\n2\n20\n16\n6\n\n\n3\n23\n16\n77\n\n\n4\n31\n17\n40\n\n\n\n\n\n\n\n\n\n(3) 스케일링\n\nscaler = MinMaxScaler()\nx_s = scaler.fit_transform(x)\n\n\n\n(4) 클러스터링\n\n# k의 갯수에 따라 각 점과의 거리를 계산하여 적정한 k를 찾아 봅시다.\nkvalues = range(1, 10)\ninertias = []\n\nfor k in kvalues:\n    model = KMeans(n_clusters=k, n_init = 'auto')\n    model.fit(x)\n    inertias.append(model.inertia_)\n\n- 적절한 군집의 개수는 5개로 추정된다.\n\nplt.plot(kvalues, inertias)\n\n\n\n\n\n# k means 학습\nmodel = KMeans(n_clusters= 5, n_init = 'auto')\nmodel.fit(x)\n\n# 예측\npred = model.predict(x)\nprint(pred)\n\n[1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 1\n 4 1 4 1 4 1 4 1 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 4 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n 3 3 3 3 3 3 3 3 3 3 3 3 0 2 0 3 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 3 0 2 0 2 0\n 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2\n 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0]\n\n\n\n\n(5) 데이터 군집 결과 정리\n\ndata[\"pred\"] = pred\n\n\ndata.head()\n\n\n\n\n\n\n\n\nCustID\nGender\nAge\nIncome\nScore\npred\n\n\n\n\n0\n1\nMale\n19\n15\n39\n1\n\n\n1\n2\nMale\n21\n15\n81\n4\n\n\n2\n3\nFemale\n20\n16\n6\n1\n\n\n3\n4\nFemale\n23\n16\n77\n4\n\n\n4\n5\nFemale\n31\n17\n40\n1\n\n\n\n\n\n\n\n\n\n(6) 군집별 변수 비교\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n1 Age\n\n\nCode\nfig = data.plot(x=\"Age\", kind =\"hist\",\n                 backend = \"plotly\",color=\"pred\",nbins=50,\n                facet_col = \"pred\",\n                facet_col_wrap = 3,title = \"Age\")\n\nfig.update_layout(\n    title={\n        'text': \"distribution of Age\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()\n\n\n\n                                                \n\n\n2 Income\n\n\nCode\nfig = data.plot(x=\"Income\", kind =\"hist\",\n                 backend = \"plotly\",color=\"pred\",nbins=50,\n                facet_col = \"pred\",\n                facet_col_wrap = 3,title = \"Age\")\n\nfig.update_layout(\n    title={\n        'text': \"distribution of Income\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()\n\n\n\n                                                \n\n\n\n\nCode\nfig = data.plot(x=\"Score\", kind =\"hist\",\n                 backend = \"plotly\",color=\"pred\",nbins=50,\n                facet_col = \"pred\",\n                facet_col_wrap = 3,title = \"Age\")\n\nfig.update_layout(\n    title={\n        'text': \"distribution of Score\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html",
    "title": "04. 머신러닝 (4)",
    "section": "",
    "text": "- 알고리즘을 사영해 모델링을 수행할 때 모델 성능을 최적화하기 위해 조절할 수 있는 매개변수\n\nKNN의 n_neighbors, tree의 max_depth 등\n\n- 모델의 성능 향상을 위해선 최선의 하이퍼파라미터 값을 찾는 다양한 시도를 해야함\n\n\n- 모든 경우의 수를 고려\n\n\n- 1부터 \\(n\\)까지 주변 이웃수를 바꾸어구며 가장 최적의 모델을 찾음 \\(\\to\\) \\(n\\)이 커질수록 엄청난 시간이 소요됨\n\nKNN은 주변의 이웃수인 \\(k\\)값이 작을수록 복잡한 모델, 클수록 단순한 모델이된다.\n보통 데이터 건수의 제곱근으로 결정하는 경우가 종종 있음\n\n- 또한, 거리 계산법에 따라 성능이 달라질 수 있으나. 참고만 해두자\n\n\n\n- max_depth : 트리의 최대 깊이로 작을수록 모형이 단순해짐\n- min_samples_leaf * leaf가 되기 위한 최소한의 샘플 데이터 수 * 이 값이 클 수록 모델이 단순해 짐\n- min_ samples_split : 분리하려면 최소 몇 명은 되어야한다.~~\n\n노드를 분할하기 위한 최소한의 샘플 데이터 수\n해당 값이 클 수록 모델이 단순해 짐\n\n- 위 값을을 적절히 조잘하여 과적합을 막을 수 있다.\n\n\n\n\n- 1부터 n구간의 정수 중 무작위로 \\(m\\)개를 골라 최적의 모델을 선태그\n\n임의의 \\(m\\)개만 골라 수행하니 시간 소모는 적을 것임\n그러나 선택되지 못한 값중에서 더 좋은 성능이 보이는 값이 있을까 걱정됨.\n\n- 근데 우리는 Random Search와 Grid Search를 함께 사용할 수 있음!\n\n일단 random search 수행\n그 다음 산출된 최적의 파라미터 주변 파라미터들에 대해서 grid search를 수행!\n\n\n\n\n\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/boston.csv'\ndata = pd.read_csv(path)\n\n데이터 설명\n\ncrim: 자치시(Town)별 1인당 범죄율\nzn: 25,000 평방피트를 초과하는 거주지역 비율\nindus: 비소매상업지역이 점유하고 있는 토지 비율\nchas: 찰스강에 대한 더미 변수 (= 1 강 경계에 위치; 0 나머지)\nnox: 10ppm당 농축 일산화질소\nrm: 주택 1가구당 평균 방 개수\nage: 1940년 이전에 건축된 소유주택 비율\ndis: 5개 보스턴 직업센터까지 접근성 지수\nrad: 방사형 도로까지의 접근성 지수\ntax: 10,000달러 당 재산세율\nptratio: 자치시(Town)별 학생/교사 비율\nblack: 1000(Bk - 0.63)^2, 여기서 Bk는 자치시별 흑인의 비율을 의미\nlstat: 모집단 하위 계층의 비율(%)\nmedv: 본인 소유 주택가격(중앙값) (단위:$1,000)\n\n\n\n\n\n# target 확인\ntarget = 'medv'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data[target]\n\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 데이터 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\ntree = DecisionTreeRegressor(random_state =1)\n\ncv_tree = cross_val_score(tree, x_train, y_train, cv = 5)\n\n\nprint(cv_tree)\nprint(cv_tree.mean())\n\n[0.65873754 0.49225288 0.78163071 0.80327749 0.82834327]\n0.7128483767547819\n\n\n- 튜닝을 해보자. 먼가 튜닝을 하면 더 괜찮은 분석이 될 것 같다.\n1) 모델 튜닝\n\n성능을 확인할 파라미터를 딕셔너리 형태로 선언합니다.\n기존 모델을 기본으로 RandomizedSearchCV 알고리즘을 사용하는 모델을 선언합니다.\n다음 정보를 최종 모델에 파라미터로 전달합니다.\n\n기본 모델 이름\n파라미터 변수\ncv: K-Fold 분할 개수(기본값=5)\nn_iter: 시도 횟수(기본값=10)\nscoring: 평가 방법\n\n\n- step 1. 일단 Random Search를 수행\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# 파라미터 선언\n  # max_depth: 1~50\nparam = {\"max_depth\" : range(1, 51)}\n\ntree =DecisionTreeRegressor(random_state=1)\n# Random Search 선언\n  # cv=5\n  # n_iter=20\n  # scoring='r2'\ntree_model = RandomizedSearchCV(tree,       ## 기번 모델 이름을 전달\n                                                                param,  ## 설정한 파라미터 범위를 전달\n                                                                   cv = 5,  ## k-fold 개수  \n                                                                     n_iter = 20, ## 전체 파라미터 범위 중에서 몇 개만 뽑을 것인지. \n                                                                           scoring = \"r2\")  \ntree_model.fit(x_train, y_train)\n\nRandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(1, 51)},\n                   scoring='r2')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(1, 51)},\n                   scoring='r2')estimator: DecisionTreeRegressorDecisionTreeRegressor(random_state=1)DecisionTreeRegressorDecisionTreeRegressor(random_state=1)\n\n\n- 중요정보 확인\n\n# 중요 정보 확인\nprint('=' * 80)\nprint(tree_model.cv_results_['mean_test_score'])\nprint('-' * 80)\nprint('최적파라미터:',tree_model.best_params_)\nprint('-' * 80)\nprint('최고성능:', tree_model.best_score_)\nprint('=' * 80)\n\n================================================================================\n[0.71284838 0.70905766 0.67646772 0.7383174  0.72240391 0.71284838\n 0.71284838 0.71284838 0.71278394 0.71250015 0.71284838 0.37077174\n 0.71284838 0.70928798 0.71284838 0.70526236 0.71284838 0.71284838\n 0.71284838 0.71284838]\n--------------------------------------------------------------------------------\n최적파라미터: {'max_depth': 5}\n--------------------------------------------------------------------------------\n최고성능: 0.7383174002807829\n================================================================================\n\n\n- 변수 중요도 확인\n\n# 변수 중요도\nplt.figure(figsize=(5, 5))\nplt.barh(y=list(x), width=tree_model.best_estimator_.feature_importances_)\nplt.show()\n\n\n\n\n\n\n\n\ny_pred = tree_model.predict(x_test)\n\n\nprint(\"MAE : \", mean_absolute_error(y_test, y_pred))\nprint(\"r2 : \", r2_score(y_test, y_pred))\n\nMAE :  3.0965698865596964\nr2 :  0.7389100169622292\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score, precision_score, recall_score\n\n\n\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/mobile.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20000 entries, 0 to 19999\nData columns (total 13 columns):\n #   Column                       Non-Null Count  Dtype \n---  ------                       --------------  ----- \n 0   id                           20000 non-null  int64 \n 1   COLLEGE                      20000 non-null  int64 \n 2   INCOME                       20000 non-null  int64 \n 3   OVERAGE                      20000 non-null  int64 \n 4   LEFTOVER                     20000 non-null  int64 \n 5   HOUSE                        20000 non-null  int64 \n 6   HANDSET_PRICE                20000 non-null  int64 \n 7   OVER_15MINS_CALLS_PER_MONTH  20000 non-null  int64 \n 8   AVERAGE_CALL_DURATION        20000 non-null  int64 \n 9   REPORTED_SATISFACTION        20000 non-null  object\n 10  REPORTED_USAGE_LEVEL         20000 non-null  object\n 11  CONSIDERING_CHANGE_OF_PLAN   20000 non-null  object\n 12  CHURN                        20000 non-null  int64 \ndtypes: int64(10), object(3)\nmemory usage: 2.0+ MB\n\n\n\ndata.isna().sum()\n\nid                             0\nCOLLEGE                        0\nINCOME                         0\nOVERAGE                        0\nLEFTOVER                       0\nHOUSE                          0\nHANDSET_PRICE                  0\nOVER_15MINS_CALLS_PER_MONTH    0\nAVERAGE_CALL_DURATION          0\nREPORTED_SATISFACTION          0\nREPORTED_USAGE_LEVEL           0\nCONSIDERING_CHANGE_OF_PLAN     0\nCHURN                          0\ndtype: int64\n\n\n\n\n\n- 변수 제거\n\ndata.drop(\"id\", axis = 1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\n0\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\n0\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\n0\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\n1\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\n0\n\n\n\n\n\n\n\n- x, y 분리\n\ntarget = \"CHURN\"\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd_cols = [\"REPORTED_SATISFACTION\", \"REPORTED_USAGE_LEVEL\", \"CONSIDERING_CHANGE_OF_PLAN\"]\n\nx = pd.get_dummies(x, columns = d_cols, dtype = float, drop_first = True)\n\n\nx.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION_sat\nREPORTED_SATISFACTION_unsat\nREPORTED_SATISFACTION_very_sat\nREPORTED_SATISFACTION_very_unsat\nREPORTED_USAGE_LEVEL_high\nREPORTED_USAGE_LEVEL_little\nREPORTED_USAGE_LEVEL_very_high\nREPORTED_USAGE_LEVEL_very_little\nCONSIDERING_CHANGE_OF_PLAN_considering\nCONSIDERING_CHANGE_OF_PLAN_never_thought\nCONSIDERING_CHANGE_OF_PLAN_no\nCONSIDERING_CHANGE_OF_PLAN_perhaps\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습용, 평가용 데이터 분리\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)\n\n\n\n\n\n일단 k-fold로 예측\n\n\ntree1 = DecisionTreeClassifier(max_depth = 5)\n\ncv_tree = cross_val_score(tree1, x_train, y_train, cv = 10)\nprint(cv_tree)\nprint(cv_tree.mean())\n\n[0.69928571 0.69214286 0.69857143 0.69285714 0.69428571 0.695\n 0.70857143 0.69142857 0.70428571 0.70285714]\n0.6979285714285715\n\n\n\n\n\n- 선언\n\nparams = {\"max_depth\" : range(3, 31)}\n\ntree =DecisionTreeClassifier(random_state=1)\ncv_tree2 = RandomizedSearchCV(tree,\n                                                           params, cv = 5, n_iter = 20, scoring = \"accuracy\" )\n\n- 모델 학습\n\ncv_tree2.fit(x_train, y_train)\n\nRandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(3, 31)},\n                   scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(3, 31)},\n                   scoring='accuracy')estimator: DecisionTreeClassifierDecisionTreeClassifier(random_state=1)DecisionTreeClassifierDecisionTreeClassifier(random_state=1)\n\n\n\n# 중요 정보 확인\nprint(cv_tree2.cv_results_[\"params\"])\nprint('=' * 80)\nprint(cv_tree2.cv_results_['mean_test_score']) ## 각각의 랜덤서치요소 에서의 cv =5  결과\nprint('-' * 80)\nprint('최적파라미터:',cv_tree2.best_params_)\nprint('-' * 80)\nprint('최고성능:', cv_tree2.best_score_)\nprint('=' * 80)\n\n[{'max_depth': 9}, {'max_depth': 8}, {'max_depth': 4}, {'max_depth': 5}, {'max_depth': 25}, {'max_depth': 21}, {'max_depth': 7}, {'max_depth': 24}, {'max_depth': 23}, {'max_depth': 30}, {'max_depth': 6}, {'max_depth': 11}, {'max_depth': 26}, {'max_depth': 29}, {'max_depth': 3}, {'max_depth': 13}, {'max_depth': 14}, {'max_depth': 28}, {'max_depth': 19}, {'max_depth': 27}]\n================================================================================\n[0.68792857 0.69428571 0.69964286 0.69621429 0.62078571 0.62321429\n 0.69742857 0.61914286 0.61742857 0.61814286 0.69757143 0.67385714\n 0.6205     0.61792857 0.68907143 0.65785714 0.65592857 0.61685714\n 0.63342857 0.6165    ]\n--------------------------------------------------------------------------------\n최적파라미터: {'max_depth': 4}\n--------------------------------------------------------------------------------\n최고성능: 0.6996428571428571\n================================================================================\n\n\n- 변수 중요도 확인\n\n# 변수 중요도\nplt.figure(figsize=(4, 4))\nplt.barh(y=list(x), width=cv_tree2.best_estimator_.feature_importances_)\nplt.show()\n\n\n\n\n- 기존의 튜닝전과 비교\n\nprint(\"튜닝전 : \", cv_tree.mean(), \", 튜닝후 : \", cv_tree2.best_score_)\n\n튜닝전 :  0.6979285714285715 , 튜닝후 :  0.6996428571428571\n\n\n\n\n\n\ny_pred = cv_tree2.predict(x_test)\n\n\nacc, pre, re, f1 = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)\n\n\nscore = [acc, pre, re, f1]\nmeasure = [\"accuracy\", \"precision\", \"recall\", \"F1-score\"]\n\nfig = pd.DataFrame({\"measure\" : measure, \"score\" : score}).\\\n                                sort_values(\"score\", ascending = False).\\\n                                    plot(y = \"measure\",  x= \"score\", color = \"measure\",\n                                            backend = \"plotly\", kind = \"barh\", width = 600, height = 400)\n\nfig.update_xaxes(range = (0.5, 0.8))"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#grid-search",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#grid-search",
    "title": "04. 머신러닝 (4)",
    "section": "",
    "text": "- 모든 경우의 수를 고려\n\n\n- 1부터 \\(n\\)까지 주변 이웃수를 바꾸어구며 가장 최적의 모델을 찾음 \\(\\to\\) \\(n\\)이 커질수록 엄청난 시간이 소요됨\n\nKNN은 주변의 이웃수인 \\(k\\)값이 작을수록 복잡한 모델, 클수록 단순한 모델이된다.\n보통 데이터 건수의 제곱근으로 결정하는 경우가 종종 있음\n\n- 또한, 거리 계산법에 따라 성능이 달라질 수 있으나. 참고만 해두자\n\n\n\n- max_depth : 트리의 최대 깊이로 작을수록 모형이 단순해짐\n- min_samples_leaf * leaf가 되기 위한 최소한의 샘플 데이터 수 * 이 값이 클 수록 모델이 단순해 짐\n- min_ samples_split : 분리하려면 최소 몇 명은 되어야한다.~~\n\n노드를 분할하기 위한 최소한의 샘플 데이터 수\n해당 값이 클 수록 모델이 단순해 짐\n\n- 위 값을을 적절히 조잘하여 과적합을 막을 수 있다."
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#random-search",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#random-search",
    "title": "04. 머신러닝 (4)",
    "section": "",
    "text": "- 1부터 n구간의 정수 중 무작위로 \\(m\\)개를 골라 최적의 모델을 선태그\n\n임의의 \\(m\\)개만 골라 수행하니 시간 소모는 적을 것임\n그러나 선택되지 못한 값중에서 더 좋은 성능이 보이는 값이 있을까 걱정됨.\n\n- 근데 우리는 Random Search와 Grid Search를 함께 사용할 수 있음!\n\n일단 random search 수행\n그 다음 산출된 최적의 파라미터 주변 파라미터들에 대해서 grid search를 수행!"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#실습",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#실습",
    "title": "04. 머신러닝 (4)",
    "section": "",
    "text": "# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/boston.csv'\ndata = pd.read_csv(path)\n\n데이터 설명\n\ncrim: 자치시(Town)별 1인당 범죄율\nzn: 25,000 평방피트를 초과하는 거주지역 비율\nindus: 비소매상업지역이 점유하고 있는 토지 비율\nchas: 찰스강에 대한 더미 변수 (= 1 강 경계에 위치; 0 나머지)\nnox: 10ppm당 농축 일산화질소\nrm: 주택 1가구당 평균 방 개수\nage: 1940년 이전에 건축된 소유주택 비율\ndis: 5개 보스턴 직업센터까지 접근성 지수\nrad: 방사형 도로까지의 접근성 지수\ntax: 10,000달러 당 재산세율\nptratio: 자치시(Town)별 학생/교사 비율\nblack: 1000(Bk - 0.63)^2, 여기서 Bk는 자치시별 흑인의 비율을 의미\nlstat: 모집단 하위 계층의 비율(%)\nmedv: 본인 소유 주택가격(중앙값) (단위:$1,000)\n\n\n\n\n\n# target 확인\ntarget = 'medv'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data[target]\n\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 데이터 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\ntree = DecisionTreeRegressor(random_state =1)\n\ncv_tree = cross_val_score(tree, x_train, y_train, cv = 5)\n\n\nprint(cv_tree)\nprint(cv_tree.mean())\n\n[0.65873754 0.49225288 0.78163071 0.80327749 0.82834327]\n0.7128483767547819\n\n\n- 튜닝을 해보자. 먼가 튜닝을 하면 더 괜찮은 분석이 될 것 같다.\n1) 모델 튜닝\n\n성능을 확인할 파라미터를 딕셔너리 형태로 선언합니다.\n기존 모델을 기본으로 RandomizedSearchCV 알고리즘을 사용하는 모델을 선언합니다.\n다음 정보를 최종 모델에 파라미터로 전달합니다.\n\n기본 모델 이름\n파라미터 변수\ncv: K-Fold 분할 개수(기본값=5)\nn_iter: 시도 횟수(기본값=10)\nscoring: 평가 방법\n\n\n- step 1. 일단 Random Search를 수행\n\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# 파라미터 선언\n  # max_depth: 1~50\nparam = {\"max_depth\" : range(1, 51)}\n\ntree =DecisionTreeRegressor(random_state=1)\n# Random Search 선언\n  # cv=5\n  # n_iter=20\n  # scoring='r2'\ntree_model = RandomizedSearchCV(tree,       ## 기번 모델 이름을 전달\n                                                                param,  ## 설정한 파라미터 범위를 전달\n                                                                   cv = 5,  ## k-fold 개수  \n                                                                     n_iter = 20, ## 전체 파라미터 범위 중에서 몇 개만 뽑을 것인지. \n                                                                           scoring = \"r2\")  \ntree_model.fit(x_train, y_train)\n\nRandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(1, 51)},\n                   scoring='r2')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(1, 51)},\n                   scoring='r2')estimator: DecisionTreeRegressorDecisionTreeRegressor(random_state=1)DecisionTreeRegressorDecisionTreeRegressor(random_state=1)\n\n\n- 중요정보 확인\n\n# 중요 정보 확인\nprint('=' * 80)\nprint(tree_model.cv_results_['mean_test_score'])\nprint('-' * 80)\nprint('최적파라미터:',tree_model.best_params_)\nprint('-' * 80)\nprint('최고성능:', tree_model.best_score_)\nprint('=' * 80)\n\n================================================================================\n[0.71284838 0.70905766 0.67646772 0.7383174  0.72240391 0.71284838\n 0.71284838 0.71284838 0.71278394 0.71250015 0.71284838 0.37077174\n 0.71284838 0.70928798 0.71284838 0.70526236 0.71284838 0.71284838\n 0.71284838 0.71284838]\n--------------------------------------------------------------------------------\n최적파라미터: {'max_depth': 5}\n--------------------------------------------------------------------------------\n최고성능: 0.7383174002807829\n================================================================================\n\n\n- 변수 중요도 확인\n\n# 변수 중요도\nplt.figure(figsize=(5, 5))\nplt.barh(y=list(x), width=tree_model.best_estimator_.feature_importances_)\nplt.show()\n\n\n\n\n\n\n\n\ny_pred = tree_model.predict(x_test)\n\n\nprint(\"MAE : \", mean_absolute_error(y_test, y_pred))\nprint(\"r2 : \", r2_score(y_test, y_pred))\n\nMAE :  3.0965698865596964\nr2 :  0.7389100169622292"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#excercise.-1",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#excercise.-1",
    "title": "04. 머신러닝 (4)",
    "section": "",
    "text": "from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score, precision_score, recall_score\n\n\n\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/mobile.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20000 entries, 0 to 19999\nData columns (total 13 columns):\n #   Column                       Non-Null Count  Dtype \n---  ------                       --------------  ----- \n 0   id                           20000 non-null  int64 \n 1   COLLEGE                      20000 non-null  int64 \n 2   INCOME                       20000 non-null  int64 \n 3   OVERAGE                      20000 non-null  int64 \n 4   LEFTOVER                     20000 non-null  int64 \n 5   HOUSE                        20000 non-null  int64 \n 6   HANDSET_PRICE                20000 non-null  int64 \n 7   OVER_15MINS_CALLS_PER_MONTH  20000 non-null  int64 \n 8   AVERAGE_CALL_DURATION        20000 non-null  int64 \n 9   REPORTED_SATISFACTION        20000 non-null  object\n 10  REPORTED_USAGE_LEVEL         20000 non-null  object\n 11  CONSIDERING_CHANGE_OF_PLAN   20000 non-null  object\n 12  CHURN                        20000 non-null  int64 \ndtypes: int64(10), object(3)\nmemory usage: 2.0+ MB\n\n\n\ndata.isna().sum()\n\nid                             0\nCOLLEGE                        0\nINCOME                         0\nOVERAGE                        0\nLEFTOVER                       0\nHOUSE                          0\nHANDSET_PRICE                  0\nOVER_15MINS_CALLS_PER_MONTH    0\nAVERAGE_CALL_DURATION          0\nREPORTED_SATISFACTION          0\nREPORTED_USAGE_LEVEL           0\nCONSIDERING_CHANGE_OF_PLAN     0\nCHURN                          0\ndtype: int64\n\n\n\n\n\n- 변수 제거\n\ndata.drop(\"id\", axis = 1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\n0\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\n0\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\n0\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\n1\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\n0\n\n\n\n\n\n\n\n- x, y 분리\n\ntarget = \"CHURN\"\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd_cols = [\"REPORTED_SATISFACTION\", \"REPORTED_USAGE_LEVEL\", \"CONSIDERING_CHANGE_OF_PLAN\"]\n\nx = pd.get_dummies(x, columns = d_cols, dtype = float, drop_first = True)\n\n\nx.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION_sat\nREPORTED_SATISFACTION_unsat\nREPORTED_SATISFACTION_very_sat\nREPORTED_SATISFACTION_very_unsat\nREPORTED_USAGE_LEVEL_high\nREPORTED_USAGE_LEVEL_little\nREPORTED_USAGE_LEVEL_very_high\nREPORTED_USAGE_LEVEL_very_little\nCONSIDERING_CHANGE_OF_PLAN_considering\nCONSIDERING_CHANGE_OF_PLAN_never_thought\nCONSIDERING_CHANGE_OF_PLAN_no\nCONSIDERING_CHANGE_OF_PLAN_perhaps\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습용, 평가용 데이터 분리\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)\n\n\n\n\n\n일단 k-fold로 예측\n\n\ntree1 = DecisionTreeClassifier(max_depth = 5)\n\ncv_tree = cross_val_score(tree1, x_train, y_train, cv = 10)\nprint(cv_tree)\nprint(cv_tree.mean())\n\n[0.69928571 0.69214286 0.69857143 0.69285714 0.69428571 0.695\n 0.70857143 0.69142857 0.70428571 0.70285714]\n0.6979285714285715\n\n\n\n\n\n- 선언\n\nparams = {\"max_depth\" : range(3, 31)}\n\ntree =DecisionTreeClassifier(random_state=1)\ncv_tree2 = RandomizedSearchCV(tree,\n                                                           params, cv = 5, n_iter = 20, scoring = \"accuracy\" )\n\n- 모델 학습\n\ncv_tree2.fit(x_train, y_train)\n\nRandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(3, 31)},\n                   scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=1),\n                   n_iter=20, param_distributions={'max_depth': range(3, 31)},\n                   scoring='accuracy')estimator: DecisionTreeClassifierDecisionTreeClassifier(random_state=1)DecisionTreeClassifierDecisionTreeClassifier(random_state=1)\n\n\n\n# 중요 정보 확인\nprint(cv_tree2.cv_results_[\"params\"])\nprint('=' * 80)\nprint(cv_tree2.cv_results_['mean_test_score']) ## 각각의 랜덤서치요소 에서의 cv =5  결과\nprint('-' * 80)\nprint('최적파라미터:',cv_tree2.best_params_)\nprint('-' * 80)\nprint('최고성능:', cv_tree2.best_score_)\nprint('=' * 80)\n\n[{'max_depth': 9}, {'max_depth': 8}, {'max_depth': 4}, {'max_depth': 5}, {'max_depth': 25}, {'max_depth': 21}, {'max_depth': 7}, {'max_depth': 24}, {'max_depth': 23}, {'max_depth': 30}, {'max_depth': 6}, {'max_depth': 11}, {'max_depth': 26}, {'max_depth': 29}, {'max_depth': 3}, {'max_depth': 13}, {'max_depth': 14}, {'max_depth': 28}, {'max_depth': 19}, {'max_depth': 27}]\n================================================================================\n[0.68792857 0.69428571 0.69964286 0.69621429 0.62078571 0.62321429\n 0.69742857 0.61914286 0.61742857 0.61814286 0.69757143 0.67385714\n 0.6205     0.61792857 0.68907143 0.65785714 0.65592857 0.61685714\n 0.63342857 0.6165    ]\n--------------------------------------------------------------------------------\n최적파라미터: {'max_depth': 4}\n--------------------------------------------------------------------------------\n최고성능: 0.6996428571428571\n================================================================================\n\n\n- 변수 중요도 확인\n\n# 변수 중요도\nplt.figure(figsize=(4, 4))\nplt.barh(y=list(x), width=cv_tree2.best_estimator_.feature_importances_)\nplt.show()\n\n\n\n\n- 기존의 튜닝전과 비교\n\nprint(\"튜닝전 : \", cv_tree.mean(), \", 튜닝후 : \", cv_tree2.best_score_)\n\n튜닝전 :  0.6979285714285715 , 튜닝후 :  0.6996428571428571\n\n\n\n\n\n\ny_pred = cv_tree2.predict(x_test)\n\n\nacc, pre, re, f1 = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)\n\n\nscore = [acc, pre, re, f1]\nmeasure = [\"accuracy\", \"precision\", \"recall\", \"F1-score\"]\n\nfig = pd.DataFrame({\"measure\" : measure, \"score\" : score}).\\\n                                sort_values(\"score\", ascending = False).\\\n                                    plot(y = \"measure\",  x= \"score\", color = \"measure\",\n                                            backend = \"plotly\", kind = \"barh\", width = 600, height = 400)\n\nfig.update_xaxes(range = (0.5, 0.8))"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#실습-review",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#실습-review",
    "title": "04. 머신러닝 (4)",
    "section": "실습 : review",
    "text": "실습 : review\n\n# 학습용 데이터 불러오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/insurance_train.csv'\ndata1 = pd.read_csv(path)\n\n\n# 평가용 데이터 불러오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/insurance_test.csv'\ndata2 = pd.read_csv(path)\n\n\n1. 데이터 이해\n- 가변수화\n\n# 가변수화\ndumm_cols = ['sex', 'smoker', 'region']\ndata1 = pd.get_dummies(data1, columns=dumm_cols, drop_first=True)\n\n# 확인\ndata1.head()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\ncharges\nsex_male\nsmoker_yes\nregion_northwest\nregion_southeast\nregion_southwest\n\n\n\n\n0\n41\n31.600\n0\n6186.1270\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n1\n30\n25.460\n0\n3645.0894\nTrue\nFalse\nFalse\nFalse\nFalse\n\n\n2\n18\n30.115\n0\n21344.8467\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\n61\n29.920\n3\n30942.1918\nFalse\nTrue\nFalse\nTrue\nFalse\n\n\n4\n34\n27.500\n1\n5003.8530\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n\n\n\n\n\n- x, y 분리\n\n# x, y 분리\ntarget = 'charges'\nx = data1.drop(target, axis=1)\ny = data1.loc[:, target]\n\n- 학습 및 평가 데이터 분리\n\n# 학습용, 검증용 분리\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=1)\n\n\n\n2. 모델링\n\n\nCode\n# 불러오기\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# 선언하기\nmodel = DecisionTreeRegressor(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_val_pred = model.predict(x_val)\n\n# 평가하기\nprint('MAE:', mean_absolute_error(y_val, y_val_pred))\nprint('R2:', r2_score(y_val, y_val_pred))\n\n\nMAE: 2848.925847322852\nR2: 0.8488510105762039\n\n\n\n\n3. 일반화된 성능을 확인 (K-fold)\n\n# 불러오기\nfrom sklearn.model_selection import cross_val_score\n\n# 성능예측\ncv_score = cross_val_score(model, x_train, y_train, cv=5)\n\n# 결과\nprint(cv_score)\nprint('평균:', cv_score.mean())\n\n[0.80393852 0.87010485 0.80735679 0.84036835 0.81403185]\n평균: 0.8271600698665711\n\n\n\n\n4. 성능 튜닝\n- Grid Search\n\n\nCode\n# 불러오기\nfrom sklearn.model_selection import GridSearchCV\n\n# 기본 모델 선언\nmodel_dt = DecisionTreeRegressor(random_state=1)\n\n# 파라미터 선언\nparams = {'max_depth': range(1, 51)}\n\n# 모델 선언\nmodel = GridSearchCV(model_dt,\n                     params,\n                     cv=5,\n                     scoring='r2')\n\n\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\nGridSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=1),\n             param_grid={'max_depth': range(1, 51)}, scoring='r2')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, estimator=DecisionTreeRegressor(random_state=1),\n             param_grid={'max_depth': range(1, 51)}, scoring='r2')estimator: DecisionTreeRegressorDecisionTreeRegressor(random_state=1)DecisionTreeRegressorDecisionTreeRegressor(random_state=1)\n\n\n\n# 예측 결과 확인\nprint(model.best_params_)\nprint(model.best_score_)\n\n{'max_depth': 4}\n0.83462894168412\n\n\n\n# 성능 검증\ny_val_pred = model.predict(x_val)\nprint(r2_score(y_val, y_val_pred))\n\n0.8577535714634761\n\n\n\n\n5. 최종 평가\n\n# 평가 데이터 확인\ndata2.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n\n\n\n\n\n\n\n\n# 평가 데이터 가변수화\ndumm_cols = ['sex', 'smoker', 'region']\ndata2 = pd.get_dummies(data2, columns=dumm_cols, drop_first=True)\n\n# 확인\ndata2.head()\n\n\n\n\n\n\n\n\nage\nbmi\nchildren\nsex_male\nsmoker_yes\nregion_northwest\nregion_southeast\nregion_southwest\n\n\n\n\n0\n19\n27.900\n0\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n1\n18\n33.770\n1\nTrue\nFalse\nFalse\nTrue\nFalse\n\n\n2\n28\n33.000\n3\nTrue\nFalse\nFalse\nTrue\nFalse\n\n\n3\n33\n22.705\n0\nTrue\nFalse\nTrue\nFalse\nFalse\n\n\n4\n32\n28.880\n0\nTrue\nFalse\nTrue\nFalse\nFalse\n\n\n\n\n\n\n\n\n# 예측하기\nx_test = data2\ny_pred = model.predict(x_test)\n\ndata2[\"charges\"] = y_pred\n\n- 파일 저장\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/insurance_test.csv'\ndata2 = pd.read_csv(path)\ndata2[\"charges\"] = y_pred\n\n\ndata.to_csv?\n\n\ndata2.to_csv(\"insurance_test.csv\", index= False)\n\n- 다시 불러오기\n\npd.read_csv(\"insurance_test.csv\").head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16167.418120\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n6117.634358\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n6117.634358\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n5235.846316\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n5235.846316"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#클래스-불균형",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#클래스-불균형",
    "title": "04. 머신러닝 (4)",
    "section": "클래스 불균형",
    "text": "클래스 불균형\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/Attrition2.csv'\ndata = pd.read_csv(path)\n\n\n1. 데이터 이해\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/Attrition2.csv'\ndata = pd.read_csv(path)\n\n\n# Target 확인\nprint(data['Attrition'].value_counts())\n\n# 시각화\ndata['Attrition'].value_counts().plot(kind='barh')\nplt.show()\n\nAttrition\n0    1050\n1     100\nName: count, dtype: int64\n\n\n\n\n\n\n\n2. 데이터 준비\n\n# 가변수화\ndumm_cols = ['Education', 'Department', 'EducationField', 'Gender', 'JobRole', 'JobSatisfaction',\n             'MaritalStatus', 'RelationshipSatisfaction', 'WorkLifeBalance']\ndata = pd.get_dummies(data, columns=dumm_cols, drop_first=True)\n\n\n# target 확인\ntarget = 'Attrition'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n\n\n3. 모델링\n\n# 학습 데이터 분포 확인\nsns.scatterplot(x='Age', y='MonthlyIncome', hue=y_train, data=x_train)\nplt.show()\n\n\n\n\n\n\nCode\n# 불러오기\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n\n[[317   1]\n [ 26   1]]\n              precision    recall  f1-score   support\n\n           0       0.92      1.00      0.96       318\n           1       0.50      0.04      0.07        27\n\n    accuracy                           0.92       345\n   macro avg       0.71      0.52      0.51       345\nweighted avg       0.89      0.92      0.89       345\n\n\n\n\nAccuracy(정확도)는 높지만 Target 값 1에 대한 Recall(재현율, 민감도)이 매우 낮다.\n전체 데이터 중에서 Target 값이 1인 데이터가 매우 적기 때문!\n이러한 현상을 클래스 불균형 이라고 한다.\n이를 위해 Under Sampling 또는 Over Sampling 을 사용!\n\n\n\n4. Under Sampling\n\n클래스가 많은 비중의 데이터에서 표본을 적게 추출해 비율을 맞춤\n\n\n# pip install imbalanced-learn\n\n\n# 불러오기\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Under Sampling\nunder_sample = RandomUnderSampler()\nu_x_train, u_y_train = under_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(u_y_train))\n\n전: [732  73]\n후: [73 73]\n\n\n- 학습 데이터 분포확인\n\n# 학습 데이터 분포 확인\nsns.scatterplot(x='Age', y='MonthlyIncome', hue=u_y_train, data=u_x_train)\nplt.show()\n\n\n\n\n- 모델 성능 다시 확인\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(u_x_train, u_y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[237  81]\n [ 13  14]]\n              precision    recall  f1-score   support\n\n           0       0.95      0.75      0.83       318\n           1       0.15      0.52      0.23        27\n\n    accuracy                           0.73       345\n   macro avg       0.55      0.63      0.53       345\nweighted avg       0.89      0.73      0.79       345\n\n\n\n\n\n5. Over sampling\n\n# 불러오기\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Over Sampling\nover_sample = RandomOverSampler()\no_x_train, o_y_train = over_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(o_y_train))\n\n전: [732  73]\n후: [732 732]\n\n\n\n# 학습 데이터 분포 확인\nsns.scatterplot(x='Age', y='MonthlyIncome', hue=o_y_train, data=o_x_train, alpha=0.3)\nplt.show()\n\n\n\n\n- 모델 성능 다시 확인\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(o_x_train, o_y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[292  26]\n [ 16  11]]\n              precision    recall  f1-score   support\n\n           0       0.95      0.92      0.93       318\n           1       0.30      0.41      0.34        27\n\n    accuracy                           0.88       345\n   macro avg       0.62      0.66      0.64       345\nweighted avg       0.90      0.88      0.89       345\n\n\n\n\n\n6. Over Sampling #2\n- 클래스가 부족한 표본 사이에 해당 표본을 몇 개 더 추가\n\n# 불러오기\nfrom imblearn.over_sampling import SMOTE\n\n# Over Sampling\nsmote = SMOTE()\ns_x_train, s_y_train = smote.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(s_y_train))\n\n전: [732  73]\n후: [732 732]\n\n\n- 학습 데이터 분포 확인\n\n# 학습 데이터 분포 확인\nsns.scatterplot(x='Age', y='MonthlyIncome', hue=s_y_train, data=s_x_train)\nplt.show()\n\n\n\n\n- 모델 성능 다시 확인\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(s_x_train, s_y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[301  17]\n [ 20   7]]\n              precision    recall  f1-score   support\n\n           0       0.94      0.95      0.94       318\n           1       0.29      0.26      0.27        27\n\n    accuracy                           0.89       345\n   macro avg       0.61      0.60      0.61       345\nweighted avg       0.89      0.89      0.89       345\n\n\n\n\n\n7. Class weight\n- class_weight 하이퍼파라미터를 설정해 모델링한 후 성능을 확인\n\nclass_weight는 자체적으로 불균형 데이터에 대한 균형을 맞춰줌\n\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1, class_weight='balanced')\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[302  16]\n [ 17  10]]\n              precision    recall  f1-score   support\n\n           0       0.95      0.95      0.95       318\n           1       0.38      0.37      0.38        27\n\n    accuracy                           0.90       345\n   macro avg       0.67      0.66      0.66       345\nweighted avg       0.90      0.90      0.90       345"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#voting",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#voting",
    "title": "04. 머신러닝 (4)",
    "section": "1. Voting",
    "text": "1. Voting\n- 여러 모델들의 예측 결과를 투표를 통해 최종 예측 결과를 예측하는 방법 (서로 다른 알고리즘 사용가능)\n\n하드 보팅 : 다수 모델이 예측한 값이 최종 결과값\n소프트 보팅 : 각 모델에서 구한 클래스에 속할 확률의 평균을 구해서 예측 결과 산출"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#배깅bootstrap-aggregation",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#배깅bootstrap-aggregation",
    "title": "04. 머신러닝 (4)",
    "section": "2. 배깅(Bootstrap Aggregation)",
    "text": "2. 배깅(Bootstrap Aggregation)\n- 전체 데이터에서 각각 샘플링을 하여 개별 모델을 생성 (단, 샘플링 방식은 복원추출)\n\n단, 모델은 같은 유형의 알고리즘 기반 모델들을 사용\n범주형 데이터는 Voting 방식으로 결과를 집계\n연속형 데이터는 평균으로 결과를 집계\n대표적인 알고리즘 : Random Forest\n\n\n(1) Random Forest\n\n서로 다른 데이터로 만든 Decision Tree가 개별적으로 학습하여 모든 결과를 집계한 뒤 최종 결과를 결정하는 알고리즘\n\n- Random\n\nRandom하게 데이터를 샘플링 했다. (일부는 중복이 되었지만… 그래도 뭐 인정!)\n개별 모델이 트리를 구성할 때 분할 기준이 되는 변수를 랜덤하게 선정 \\(\\to\\) 무작위로 뽑은 \\(n\\)개의 변수 중에서 가장 Gain이 큰 변수를 기준으로 트리를 분할\n2번의 이유로 개별 모델마다 다른 구조의 트리를 형성할 것임\n\n\n- 파라미터\n\nn_estimatorsr : 트리의 개수\nmax_depth : 트리의 촤대 깊이\nmin_samples_split : 트리와 동일\nmin_samples_leaf : 트리와 동일\nmax_feature : 최선의 분할을 위해 고려할 Feature 수(기본값: auto)\n\n기본값으로 설정하면 모든 Feature를 사용해서 분할 수행\n정수형으로 선언하면 Feature 수, 실수형으로 선언하면 Feature 비율\n’sqrt’로 선언하면 전체 Feature 수의 루트 값\n’auto’로 설정하면 ’sqrt’와 같은 의미\n’log’로 선언하면 log2(전체 Feature 수)\n\n\n\n\n(2) 부스팅(Boosting)\n\n같은 유형의 알고리즘 기반 모델 여러 개에 대해 순차적으로 학습을 수행\n이전 모델이 제대로 예측하지 못한 데이터에 대해서 가중치를 부여하여 다음 모델이 학습과 예측을 진행하는 방법\n계속하여 모델에게 가중치를 부스팅하며 학습을 진행해 부스팅 방식이라 함\n예측 성능이 뛰어나 앙상블 학습을 주도함\n배깅에 비해 성능이 좋지만, 속도가 느리고 과적합 발생 가능성이 있음 → 상황에 맞게 적절히 사용해야 함\n대표적인 부스팅 알고리즘: XGBoost, LightGBM`\n\n- 배깅은 투표 or 평균, 부스팅은 잔차와 가중치를 이용하여 순차적 학습을 진행!!\n\n부스팅은 잔차를 추정한다.\n\n\nGradient Boost (이 부분 다시정리)\n- \\(f_i(x)\\) : \\(i\\) 번째 예측 모델이라고하자\n- \\(e_i\\) : \\(i\\) 번째 예측 모델의 오차\n\n\nXGBoost extreme Gradient Boosting\n- 부스팅을 구현한 대표적인 알고리즘 중 하나가 GBM(Gradient Boost Machine)\n\nGBM 알고리즘을 병렬 학습이 가능하도록 구현한 것이 XGBoost\n회귀, 분류 문제를 모두 지원하며, 성능과 자원 효율이 좋아 많이 사용됨\n\n- 장점\n\n높은 예측 성능\nGBM 대비 빠른 수행 시간 : 병렬 수행 및 다양한 기능으로 GBM에 비해 빠르게 수행됨\n규제 (Regularzaiton) : GBM에 없었던 과적합 규제 기능을 가지고 있\n가지치기(Tree Pruning) : max_depth 등의 하이퍼파라미터로 가지치기를 할 수 있음\n\nTree Pruning 기능으로 성능에 이점이 없는 분할은 가지치기 할 수 있음\n\n내장된 교차 검증 : 반복 수행시마다 내부적으로 학습 데이터와 검증 데이터에 대한 교차 검증을 수행\n\n지정된 반복 횟수가 아닌 교차 검증을 통해 성능을 확인하여 필요시 조기 중단 가능 (검증 데이터에 대한 성능이 떨어질 경우!)\n\n결측치 자체 처리 : 알아서 결측치를 고려해서 학습함(결측치 여부를 노드 분시를 위한 질문에 포함시킴)\n\n하지만 명시적으로 결측치에 대한 처리를 진행하기를 권고한다…..\n\n\n\n\n\n(3) stacking\n- 여러 모델의 예측 값을 최종 모델의 학습 데이터로 사용하여 예측하는 방법 * KNN, Logistic Regression, XGBoost 모델을 사용해 4종류 예측값을 구한 후, 이 예측 값을 최종 모델인 Randomforest 학습 데이터로 사용 * 현실 모델에서 많이 사용되지 않으며, 캐글(Kaggle) 같은 미세한 성능 차이로 승부를 결정하는 대회에서 사용됨 * 기본 모델로 4개 이상 선택해야 좋은 결과를 기대할 수 있음"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#실습-1",
    "href": "posts/DX/04. 머신러닝/2023-09-15-04. 머신러닝 (4).html#실습-1",
    "title": "04. 머신러닝 (4)",
    "section": "실습",
    "text": "실습\n\n(1) 데이터 이해\n\n# 데이터 불러오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/admission_simple.csv'\ndata = pd.read_csv(path)\n\n\n# 데이터 살펴보기\ndata.head()\n\n\n\n\n\n\n\n\nGRE\nTOEFL\nRANK\nSOP\nLOR\nGPA\nRESEARCH\nADMIT\n\n\n\n\n0\n337\n118\n4\n4.5\n4.5\n9.65\n1\n1\n\n\n1\n324\n107\n4\n4.0\n4.5\n8.87\n1\n1\n\n\n2\n316\n104\n3\n3.0\n3.5\n8.00\n1\n0\n\n\n3\n322\n110\n3\n3.5\n2.5\n8.67\n1\n1\n\n\n4\n314\n103\n2\n2.0\n3.0\n8.21\n0\n0\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 500 entries, 0 to 499\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   GRE       500 non-null    int64  \n 1   TOEFL     500 non-null    int64  \n 2   RANK      500 non-null    int64  \n 3   SOP       500 non-null    float64\n 4   LOR       500 non-null    float64\n 5   GPA       500 non-null    float64\n 6   RESEARCH  500 non-null    int64  \n 7   ADMIT     500 non-null    int64  \ndtypes: float64(3), int64(5)\nmemory usage: 31.4 KB\n\n\n\ndata.isna().sum()\n\nGRE         0\nTOEFL       0\nRANK        0\nSOP         0\nLOR         0\nGPA         0\nRESEARCH    0\nADMIT       0\ndtype: int64\n\n\n\n\n(2) 데이터 준비\n\n# target 확인\ntarget = 'ADMIT'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data[target]\n\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n\n# 모듈 불러오기\nfrom sklearn.preprocessing import MinMaxScaler\n\n# 정규화\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n(3) 모델링\n\n# 라이브러리 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import *\n\n\n# xgboost 설치\n#!pip install xgboost\n\n\n# lightgbm 설치\n#!pip install lightgbm\n\n1 Knn\n\n# 선언하기\nmodel = KNeighborsClassifier(n_neighbors=5)\n\n# 학습하기\nmodel.fit(x_train_s, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test_s)\n\n# 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[79  5]\n [15 51]]\n              precision    recall  f1-score   support\n\n           0       0.84      0.94      0.89        84\n           1       0.91      0.77      0.84        66\n\n    accuracy                           0.87       150\n   macro avg       0.88      0.86      0.86       150\nweighted avg       0.87      0.87      0.86       150\n\n\n\n2 tree\n\n# 선언하기\nmodel = DecisionTreeClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 5단계: 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[77  7]\n [13 53]]\n              precision    recall  f1-score   support\n\n           0       0.86      0.92      0.89        84\n           1       0.88      0.80      0.84        66\n\n    accuracy                           0.87       150\n   macro avg       0.87      0.86      0.86       150\nweighted avg       0.87      0.87      0.87       150\n\n\n\n3 logistic\n\n# 선언하기\nmodel = LogisticRegression()\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 5단계: 평가하기\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[75  9]\n [14 52]]\n              precision    recall  f1-score   support\n\n           0       0.84      0.89      0.87        84\n           1       0.85      0.79      0.82        66\n\n    accuracy                           0.85       150\n   macro avg       0.85      0.84      0.84       150\nweighted avg       0.85      0.85      0.85       150\n\n\n\n4 Random Forest\n\nmodel = RandomForestClassifier(max_depth = 5, random_state = 1) ## default tree = 100\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[78  6]\n [13 53]]\n              precision    recall  f1-score   support\n\n           0       0.86      0.93      0.89        84\n           1       0.90      0.80      0.85        66\n\n    accuracy                           0.87       150\n   macro avg       0.88      0.87      0.87       150\nweighted avg       0.88      0.87      0.87       150\n\n\n\n\nprint(list(x))\nprint(model.feature_importances_)\n\n['GRE', 'TOEFL', 'RANK', 'SOP', 'LOR', 'GPA', 'RESEARCH']\n[0.22081595 0.20240024 0.09976925 0.08278875 0.04189168 0.32011405\n 0.0322201 ]\n\n\n5 XGBoost\n\nmodel = XGBClassifier(max_depth = 5, random_state = 1)\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n[[77  7]\n [15 51]]\n              precision    recall  f1-score   support\n\n           0       0.84      0.92      0.88        84\n           1       0.88      0.77      0.82        66\n\n    accuracy                           0.85       150\n   macro avg       0.86      0.84      0.85       150\nweighted avg       0.86      0.85      0.85       150\n\n\n\n\nprint(list(x))\nprint(model.feature_importances_)\n\n['GRE', 'TOEFL', 'RANK', 'SOP', 'LOR', 'GPA', 'RESEARCH']\n[0.10025358 0.10419714 0.07541527 0.09831444 0.07010549 0.43016294\n 0.1215511 ]\n\n\n6 LightGBM\n\n#model = LGBMClassifier(max_depth = 5, random_state = 1) ## 이렇게 하면 먼가 주르륵, 주르륵 뜬다. 그래서  verbose 인자를 넣어줌\n\nmodel = LGBMClassifier(max_depth = 5, random_state = 1,verbose = -100) \nmodel.fit(x_train, y_train) \n\ny_pred = model.predict(x_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\nprint(list(x))\nprint(model.feature_importances_)\n\n[[77  7]\n [14 52]]\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88        84\n           1       0.88      0.79      0.83        66\n\n    accuracy                           0.86       150\n   macro avg       0.86      0.85      0.86       150\nweighted avg       0.86      0.86      0.86       150\n\n['GRE', 'TOEFL', 'RANK', 'SOP', 'LOR', 'GPA', 'RESEARCH']\n[221 190  50 115  63 383  34]\n\n\n- 음 변수 중요도가 뭔가 다른 모델들과 비교해 굉장히 크게 나온다. 척도가 다르구나 하고 넘어가자.\n\n\n(4) 참고 : Early Stopping\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state=1)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=1)\n\n\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nmodel.fit(x_train, y_train,\n                eval_set=[(x_train, y_train), (x_val, y_val)],\n                early_stopping_rounds=10) \n\n[0] validation_0-logloss:0.50189    validation_1-logloss:0.50718\n[1] validation_0-logloss:0.39727    validation_1-logloss:0.41745\n[2] validation_0-logloss:0.32813    validation_1-logloss:0.35767\n[3] validation_0-logloss:0.28005    validation_1-logloss:0.32211\n[4] validation_0-logloss:0.24248    validation_1-logloss:0.30427\n[5] validation_0-logloss:0.21255    validation_1-logloss:0.29216\n[6] validation_0-logloss:0.19052    validation_1-logloss:0.28142\n[7] validation_0-logloss:0.17478    validation_1-logloss:0.26955\n[8] validation_0-logloss:0.16192    validation_1-logloss:0.26525\n[9] validation_0-logloss:0.15309    validation_1-logloss:0.25668\n[10]    validation_0-logloss:0.14571    validation_1-logloss:0.25679\n[11]    validation_0-logloss:0.14029    validation_1-logloss:0.25512\n[12]    validation_0-logloss:0.13597    validation_1-logloss:0.25464\n[13]    validation_0-logloss:0.12819    validation_1-logloss:0.25188\n[14]    validation_0-logloss:0.12105    validation_1-logloss:0.25316\n[15]    validation_0-logloss:0.11541    validation_1-logloss:0.25592\n[16]    validation_0-logloss:0.11220    validation_1-logloss:0.25947\n[17]    validation_0-logloss:0.10689    validation_1-logloss:0.26523\n[18]    validation_0-logloss:0.10236    validation_1-logloss:0.27018\n[19]    validation_0-logloss:0.09768    validation_1-logloss:0.27086\n[20]    validation_0-logloss:0.09465    validation_1-logloss:0.27693\n[21]    validation_0-logloss:0.09172    validation_1-logloss:0.27836\n[22]    validation_0-logloss:0.08943    validation_1-logloss:0.27502\n\n\nXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)\n\n\n- 그 후에 내용은 나중에 코드 참고…\n\nresults = model.evals_result()\n#results\n\nAttributeError: 'LGBMClassifier' object has no attribute 'evals_result'\n\n\n\nplt.plot(results['validation_0'][\"logloss\"],label= \"val0\")\nplt.plot(results['validation_1'][\"logloss\"],label= \"val1\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x2b7b1243850&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html",
    "title": "02. 머신러닝 (2)",
    "section": "",
    "text": "# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format='retina'"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-로드-및-탐색",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-로드-및-탐색",
    "title": "02. 머신러닝 (2)",
    "section": "(1) 데이터 로드 및 탐색",
    "text": "(1) 데이터 로드 및 탐색\n\n# 데이터 읽어오기\npath = 'https://bit.ly/CarsFile'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nspeed\ndist\n\n\n\n\n0\n4\n2\n\n\n1\n4\n10\n\n\n2\n7\n4\n\n\n3\n7\n22\n\n\n4\n8\n16\n\n\n\n\n\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nspeed\ndist\n\n\n\n\ncount\n50.000000\n50.000000\n\n\nmean\n15.400000\n42.980000\n\n\nstd\n5.287644\n25.769377\n\n\nmin\n4.000000\n2.000000\n\n\n25%\n12.000000\n26.000000\n\n\n50%\n15.000000\n36.000000\n\n\n75%\n19.000000\n56.000000\n\n\nmax\n25.000000\n120.000000\n\n\n\n\n\n\n\n\ndata.isnull().sum()\n\nspeed    0\ndist     0\ndtype: int64\n\n\n- \\((x,y)\\) 시각화\n\nplt.figure(figsize = (4, 4))\nplt.plot(data.speed, data.dist, \".r\", label = r\"$(x, y)$\",alpha = 0.3)\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x1c94b19fb90&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#모델링",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#모델링",
    "title": "02. 머신러닝 (2)",
    "section": "(2) 모델링",
    "text": "(2) 모델링\n\n\nCode\ntarget = \"dist\"\n\n## step 1. x,y 부리\nx  = data.drop(target, axis = 1)\ny  = data[target]\n\n## step 2. 훈련 데이터와 평가 데이터 분리\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n## step 3 . 모델 불러오기\nfrom sklearn.linear_model import  LinearRegression\nmodel1 = LinearRegression()\n\n## step 4.  모델 fit\nmodel1.fit(x_train, y_train)\n\n## step 5. 예측\ny_pred = model1.predict(x_test)\n\n\n- 회귀계수 확인\n\nprint(model1.coef_)\nprint(model1.intercept_)\n\n[3.91046344]\n-16.37336414935769\n\n\n- 산출된 회귀식\n\\[\\text{dist} \\approx 3.9 \\times \\text{speed} -16.37\\]\n- 결과 시각화\n\n\nCode\nplt.figure(figsize = (4,4))\nplt.plot(x_test, y_test, \".r\", label =r\"$(x,y)$\", alpha = 0.3)\nplt.plot(x_test, y_pred, label =r\"$(x,\\hat {y})$\", alpha = 0.5)\nplt.axhline(y_train.mean(),linestyle = \"--\", color = \"g\", label = r\"$\\bar {y}_{train}$\")\nplt.axhline(y_test.mean(),linestyle = \"--\", color = \"y\", label = r\"$\\bar {y}_{test}$\")\nplt.legend()\n\n\n&lt;matplotlib.legend.Legend at 0x1c94e0b02d0&gt;\n\n\n\n\n\n- 예측성능확인\n\nfrom sklearn.metrics import *\n\nprint(f\"MAE :  {mean_absolute_error(y_test, y_pred) : .2f}\" )\nprint(f\"R2 : {r2_score(y_test, y_pred) : .2f}\")\n\nMAE :   15.11\nR2 :  0.55\n\n\n- 학습 데이터의 평균 성능은?\n\ny_mean = y_train.mean()\ny_mean = [y_mean]*len(y_pred)\n\nprint(f\"MAE :  {mean_absolute_error(y_test, y_mean) : .2f}\" )\nprint(f\"R2 : {r2_score(y_test, y_mean) : .2f}\")\n\nMAE :   18.34\nR2 : -0.06"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-1",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-1",
    "title": "02. 머신러닝 (2)",
    "section": "excercise. 1",
    "text": "excercise. 1\n\n(1). 데이터 로드 및 전처리\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/income_happy.csv'\ndata = pd.read_csv(path)\n\n\ndata.isna().sum()\n\nincome       0\nhappiness    0\ndtype: int64\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 498 entries, 0 to 497\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   income     498 non-null    float64\n 1   happiness  498 non-null    float64\ndtypes: float64(2)\nmemory usage: 7.9 KB\n\n\n\n\n(2). 모델링\n\n\nCode\n# step 1.  데이터 분리\ntarget = \"income\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, random_state = 1, test_size = 0.3)\n\n# step 2.  model 선언 \nmodel2 = LinearRegression()\n\n# step 3. fit\nmodel2.fit(x_train,y_train)\n\n# step 4. predict\ny_pred = model2.predict(x_test)\n\nr2 = r2_score(y_test, y_pred)\nMAE = mean_absolute_error(y_test, y_pred)\n\nplt.figure(figsize=(4,4))\nplt.plot(x_test, y_test, \".r\", label = r\"$(x,y)$\", alpha = 0.3)\nplt.plot(x_test, y_pred, \".b\", label = r\"$(x,\\hat {y})$\", alpha = 0.3)\nplt.title(r\"$income = 1.03 \\times happiness + 0.963,\\,   R^{2} = 0.75, MAE = 0.69$\",fontsize = 10)\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-2",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-2",
    "title": "02. 머신러닝 (2)",
    "section": "excercise. 2",
    "text": "excercise. 2\n데이터 설명\n\nSales: 각 지역 판매량(단위: 1,000개)\nCompPrice: 경쟁사 가격 (단위: 달러)\nIncome: 지역 평균 소득 (단위: 1,000달러)\nAdvertising: 각 지역, 회사의 광고 예산 (단위: 1,000달러)\nPopulation: 지역 인구 수 (단위: 1,000명)\nPrice: 자사 지역별 판매 가격 (단위: 달러)\nShelveLoc: 진열 상태\nAge: 지역 인구의 평균 연령\nEducation: 각 지역 교육 수준\nUrban: 도심 지역 여부 (Yes,No)\nUS: 매장이 미국에 있는지 여부 (Yes, No)\n\n\n(1) 데이터 탐색 및 전처리\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/Carseats.csv'\ndata = pd.read_csv(path)\n\ndata.isna().sum()\n\nSales          0\nCompPrice      0\nIncome         0\nAdvertising    0\nPopulation     0\nPrice          0\nShelveLoc      0\nAge            0\nEducation      0\nUrban          0\nUS             0\ndtype: int64\n\n\n\ndata.select_dtypes(\"number\").corr()\n\n\n\n\n\n\n\n\nSales\nCompPrice\nIncome\nAdvertising\nPopulation\nPrice\nAge\nEducation\n\n\n\n\nSales\n1.000000\n0.064079\n0.151951\n0.269507\n0.050471\n-0.444951\n-0.231815\n-0.051955\n\n\nCompPrice\n0.064079\n1.000000\n-0.080653\n-0.024199\n-0.094707\n0.584848\n-0.100239\n0.025197\n\n\nIncome\n0.151951\n-0.080653\n1.000000\n0.058995\n-0.007877\n-0.056698\n-0.004670\n-0.056855\n\n\nAdvertising\n0.269507\n-0.024199\n0.058995\n1.000000\n0.265652\n0.044537\n-0.004557\n-0.033594\n\n\nPopulation\n0.050471\n-0.094707\n-0.007877\n0.265652\n1.000000\n-0.012144\n-0.042663\n-0.106378\n\n\nPrice\n-0.444951\n0.584848\n-0.056698\n0.044537\n-0.012144\n1.000000\n-0.102177\n0.011747\n\n\nAge\n-0.231815\n-0.100239\n-0.004670\n-0.004557\n-0.042663\n-0.102177\n1.000000\n0.006488\n\n\nEducation\n-0.051955\n0.025197\n-0.056855\n-0.033594\n-0.106378\n0.011747\n0.006488\n1.000000\n\n\n\n\n\n\n\n- 컬럼 가변수화\n\nd_cols = [\"ShelveLoc\", \"Education\", \"Urban\", \"US\"]\n\n\n_data = pd.get_dummies(data, columns= d_cols, drop_first=True, dtype = \"float\")\n_data.head()\n\n\n\n\n\n\n\n\nSales\nCompPrice\nIncome\nAdvertising\nPopulation\nPrice\nAge\nShelveLoc_Good\nShelveLoc_Medium\nEducation_11\nEducation_12\nEducation_13\nEducation_14\nEducation_15\nEducation_16\nEducation_17\nEducation_18\nUrban_Yes\nUS_Yes\n\n\n\n\n0\n9.50\n138\n73\n11\n276\n120\n42\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n1.0\n\n\n1\n11.22\n111\n48\n16\n260\n83\n65\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n1.0\n\n\n2\n10.06\n113\n35\n10\n269\n80\n59\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n1.0\n\n\n3\n7.40\n117\n100\n4\n466\n97\n55\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n1.0\n\n\n4\n4.15\n141\n64\n3\n340\n128\n38\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\n- 학습용, 평가용 데이터 분리\n\ntarget  = \"Sales\"\nx = _data.drop(target, axis = 1)\ny = _data[target]\n\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n\n\n(2) 모델링\n\n## 1. 모델 선언\nmodel3 = LinearRegression()\n\n## 2. model fit\nmodel3.fit(x_train, y_train)\n\n## 3. predict\ny_pred = model3.predict(x_test)\n\n## 5. 결정계수 및 MAE 값 계산\nr2 = r2_score(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\n\n\n\n(3) 시각화 1 : 회귀계수\n\n\nCode\nx_cols = x_train.columns.values\ncoef = model3.coef_\n\nfig = pd.DataFrame({\"X\" : x_cols,\n                            \"coef\" : coef}).\\\n                                sort_values(\"coef\",ascending=False).\\\n                                                        plot(x=\"coef\", y=\"X\",\n                                                               color= \"X\",kind= \"barh\",\n                                                                backend = \"plotly\",width = 700, height = 450)\nfig.update_layout(showlegend=False)\n\n\n\n                                                \n\n\n\n\n(4) 시각화 2 : 잔차 시각화\n- 잔차를 살펴보니 잔차의 평균으로부터 분포가 일정하다. (회귀선이 안정적으로 추정된 것 같다!)\n\n\nCode\ne = y_test - y_pred\ne_m = e.mean()\n\nplt.figure(figsize=(5,4))\nplt.plot(e,'.',label = r\"$\\varepsilon$\")\nplt.axhline(e_m, linestyle = \"--\", color = \"red\", label = r\"$E(\\varepsilon)$\")\nplt.title(r\"$\\varepsilon \\sim  N(0, \\sigma^2)$\")\nplt.legend()\nplt.ylim(-5,5)\nplt.show()\n\n\n\n\n\n\n\n(4) 시각화 3 : \\((y, \\hat y)\\)\n\nplt.plot(y_test.reset_index(drop=True), \"--r\", label = r\"$y$\",alpha = 0.3)\nplt.plot(y_pred, \"b\", label = r\"$\\hat {y}$\",alpha=0.5)\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x1c94e3cf890&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-로드-및-탐색-1",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-로드-및-탐색-1",
    "title": "02. 머신러닝 (2)",
    "section": "(1) 데이터 로드 및 탐색",
    "text": "(1) 데이터 로드 및 탐색\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/airquality_simple.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n0\n41\n190.0\n7.4\n67\n5\n1\n\n\n1\n36\n118.0\n8.0\n72\n5\n2\n\n\n2\n12\n149.0\n12.6\n74\n5\n3\n\n\n3\n18\n313.0\n11.5\n62\n5\n4\n\n\n4\n19\nNaN\n14.3\n56\n5\n5\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    153 non-null    int64  \n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(2), int64(4)\nmemory usage: 7.3 KB\n\n\n\ndata.isna().sum()\n\nOzone      0\nSolar.R    7\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\ndata.corr()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\nOzone\n1.000000\n0.280068\n-0.605478\n0.683372\n0.174197\n0.004419\n\n\nSolar.R\n0.280068\n1.000000\n-0.056792\n0.275840\n-0.075301\n-0.150275\n\n\nWind\n-0.605478\n-0.056792\n1.000000\n-0.457988\n-0.178293\n0.027181\n\n\nTemp\n0.683372\n0.275840\n-0.457988\n1.000000\n0.420947\n-0.130593\n\n\nMonth\n0.174197\n-0.075301\n-0.178293\n0.420947\n1.000000\n-0.007962\n\n\nDay\n0.004419\n-0.150275\n0.027181\n-0.130593\n-0.007962\n1.000000"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#결측치-처리",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#결측치-처리",
    "title": "02. 머신러닝 (2)",
    "section": "(2) 결측치 처리",
    "text": "(2) 결측치 처리\n- 시계열 데이터이므로 선형보간법으로 채움\n\ndata[\"Solar.R\"].interpolate(method = \"linear\", inplace = True)\n\n\ndata.isna().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#변수-제거",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#변수-제거",
    "title": "02. 머신러닝 (2)",
    "section": "(3) 변수 제거",
    "text": "(3) 변수 제거\n\n#  변수 제거\ndrop_cols = ['Month', 'Day']\ndata.drop(drop_cols, axis=1, inplace=True)\n\n# 확인\ndata.head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\n\n\n\n\n0\n41\n190.000000\n7.4\n67\n\n\n1\n36\n118.000000\n8.0\n72\n\n\n2\n12\n149.000000\n12.6\n74\n\n\n3\n18\n313.000000\n11.5\n62\n\n\n4\n19\n308.333333\n14.3\n56"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#모델링-3",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#모델링-3",
    "title": "02. 머신러닝 (2)",
    "section": "(4) 모델링",
    "text": "(4) 모델링\n\n# target 확인\ntarget = 'Ozone'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 데이터 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n- 스케일링\n\n# 1.  손계산\nx_train = x_train.apply(lambda x : \n                                            (x-min(x))/(max(x)-min(x)),axis=0)\n\nx_test = x_test.apply(lambda x : \n                                            (x-min(x))/(max(x)-min(x)),axis=0)\n\n# 2. 모듈 이용\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n- 모델링 수행\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\nmodel = KNeighborsRegressor()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nprint(f\"MAE : {mean_absolute_error(y_test, y_pred ): .2f}, R2 = {r2_score(y_test, y_pred): .2f} \")\n\nMAE :  13.68, R2 =  0.57"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#결과-시각화",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#결과-시각화",
    "title": "02. 머신러닝 (2)",
    "section": "(5) 결과 시각화",
    "text": "(5) 결과 시각화\n\nplt.figure(figsize = (5,4))\nplt.plot(y_test.reset_index(drop=True),\"--r\",label = r\"$y$\",alpha = .3)\nplt.plot(y_pred,\"--b\",label = r\"$\\hat y$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x1c94e3cfb90&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#exercise.-1",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#exercise.-1",
    "title": "02. 머신러닝 (2)",
    "section": "exercise. 1",
    "text": "exercise. 1\n\n(1) 데이터 탐색 및 전처리\n데이터설명\n피마 인디언 당뇨 데이터셋은 몇 명의 여성 피마 인디언의 진료 자료와 진단 후 5년 내 당뇨 발병 여부로 구성됨\n\nPregnancies: 임신 횟수\nGlucose: 포도당 부하 검사 수치\nBloodPressure: 혈압(mm Hg)\nSkinThickness: 팔 삼두근 뒤쪽의 피하지방 측정값(mm)\nInsulin: 혈청 인슐린(mu U/ml)\nBMI: 체질량지수(체중(kg)/키(m))^2\nDiabetesPedigreeFunction: 당뇨 내력 가중치 값\nAge: 나이\nOutcome: 클래스 결정 값(0 또는 1)\n\ndiabetes\n\n당뇨병(糖尿病, diabetes)은 높은 혈당 수치가 오랜 기간 지속되는 대사 질환이다.\n혈당이 높을 때의 증상으로는 소변이 잦아지고, 갈증과 배고픔이 심해진다.\n이를 치료하지 않으면 다른 합병증을 유발할 수 있다. (출처: 위키백과)\n\n\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/diabetes.csv'\ndata = pd.read_csv(path)\ndata.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n\n\n\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\ndata.Outcome.value_counts()\n\nOutcome\n0    500\n1    268\nName: count, dtype: int64\n\n\n\n\n(2) 모델링\n\n# step 1. 데이터 분리\ntarget = \"Outcome\"\n\nx = data.drop(target, axis=1)\ny = data[target]\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n# step 2.  정규화\n\nscale = lambda  x : (x-min(x)) /(max(x)-min(x))\n\nx_train = x_train.apply(scale, axis=0)\nx_test = x_test.apply(scale, axis=0)\n\n# step 3. 모델 호출 및 예측\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import  accuracy_score, precision_score, recall_score, f1_score\n\nmodel = KNeighborsClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nprint(f\"accuracy : {accuracy_score(y_pred, y_test) : .3}\")\nprint(f\"precision : {precision_score(y_pred, y_test) : .3}\")\nprint(f\"recall : {recall_score(y_pred, y_test) : .3}\")\nprint(f\"F1-score : {f1_score(y_pred, y_test) : .3}\")\n\naccuracy :  0.779\nprecision :  0.506\nrecall :  0.827\nF1-score :  0.628\n\n\n\n\n(3) 결과 시각화 1 : \\((y, \\hat y)\\) 클래스 비교\n\npd.DataFrame({\"y_test\" : y_test.astype(str),\n                             \"y_pred\" : y_pred.astype(str)}).\\\n                                    melt(var_name = \"label\", \n                                     value_name= \"Outcome\").\\\n                                     groupby(\"label\",as_index=False)[[\"Outcome\"]].value_counts().\\\n                                            plot(x = \"label\",y = \"count\", \n                                                    kind =\"bar\", backend = \"plotly\",\n                                                     color = \"label\", facet_col = \"Outcome\",width = 500, height = 400)\n\n\n                                                \n\n\n\n\n(4) 결과 시각화 2 : 평가지표\n\nacc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test)\nrecall = recall_score(y_pred, y_test)\nf1 = f1_score(y_pred, y_test)\n\nresult = [acc, pre, recall, f1]\ncol = [\"accuracy\", \"precision\", \"recall\", \"F1-score\"]\n\npd.DataFrame(result,columns=[\"value\"],index=col).reset_index().\\\n                plot(x=\"index\", y= \"value\",kind=\"bar\",color= \"index\", backend = \"plotly\",\n                        height = 400, width = 600)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-2-불균형-클래스",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-2-불균형-클래스",
    "title": "02. 머신러닝 (2)",
    "section": "excercise. 2 (불균형 클래스)",
    "text": "excercise. 2 (불균형 클래스)\n데이터 설명\n\nAttrition: 이직 여부 (1: 이직, 0: 잔류)\nAge: 나이\nDistanceFromHome: 집-직장 거리 (단위: 마일)\nEmployeeNumber: 사번\nGender: 성별 (Male, Female)\nJobSatisfaction: 직무 만족도(1: Low, 2: Medium, 3: High, 4: Very High)\nMaritalStatus: 결혼 상태 (Single, Married, Divorced)\nMonthlyIncome: 월급 (단위: 달러)\nOverTime: 야근 여부 (Yes, No)\nPercentSalaryHike: 전년 대비 급여 인상율(단위: %)\nTotalWorkingYears: 총 경력 연수\n\n\n(1) 데이터 로드 및 탐색\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/Attrition_simple2.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1196 entries, 0 to 1195\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   Attrition          1196 non-null   int64 \n 1   Age                1196 non-null   int64 \n 2   DistanceFromHome   1196 non-null   int64 \n 3   EmployeeNumber     1196 non-null   int64 \n 4   Gender             1196 non-null   object\n 5   JobSatisfaction    1196 non-null   int64 \n 6   MaritalStatus      1196 non-null   object\n 7   MonthlyIncome      1196 non-null   int64 \n 8   OverTime           1196 non-null   object\n 9   PercentSalaryHike  1196 non-null   int64 \n 10  TotalWorkingYears  1196 non-null   int64 \ndtypes: int64(8), object(3)\nmemory usage: 102.9+ KB\n\n\n\ndata.isna().sum()\n\nAttrition            0\nAge                  0\nDistanceFromHome     0\nEmployeeNumber       0\nGender               0\nJobSatisfaction      0\nMaritalStatus        0\nMonthlyIncome        0\nOverTime             0\nPercentSalaryHike    0\nTotalWorkingYears    0\ndtype: int64\n\n\n\ndata.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nAttrition\n1196.0\n0.163043\n0.369560\n0.0\n0.00\n0.0\n0.00\n1.0\n\n\nAge\n1196.0\n36.943980\n9.092700\n18.0\n30.00\n36.0\n43.00\n60.0\n\n\nDistanceFromHome\n1196.0\n9.258361\n8.166016\n1.0\n2.00\n7.0\n14.00\n29.0\n\n\nEmployeeNumber\n1196.0\n1035.629599\n604.340130\n1.0\n507.75\n1028.0\n1581.25\n2068.0\n\n\nJobSatisfaction\n1196.0\n2.716555\n1.110962\n1.0\n2.00\n3.0\n4.00\n4.0\n\n\nMonthlyIncome\n1196.0\n6520.104515\n4665.902253\n1009.0\n2928.25\n4973.5\n8420.50\n19999.0\n\n\nPercentSalaryHike\n1196.0\n15.251672\n3.625946\n11.0\n12.00\n14.0\n18.00\n25.0\n\n\nTotalWorkingYears\n1196.0\n11.330268\n7.823821\n0.0\n6.00\n10.0\n15.00\n40.0\n\n\n\n\n\n\n\n\ndata.select_dtypes(\"number\").corr()\n\n\n\n\n\n\n\n\nAttrition\nAge\nDistanceFromHome\nEmployeeNumber\nJobSatisfaction\nMonthlyIncome\nPercentSalaryHike\nTotalWorkingYears\n\n\n\n\nAttrition\n1.000000\n-0.167866\n0.081973\n-0.008707\n-0.078936\n-0.163572\n-0.000048\n-0.182162\n\n\nAge\n-0.167866\n1.000000\n-0.010917\n-0.023786\n-0.012425\n0.490107\n-0.008303\n0.674331\n\n\nDistanceFromHome\n0.081973\n-0.010917\n1.000000\n0.054948\n-0.021623\n-0.012803\n0.052348\n0.002606\n\n\nEmployeeNumber\n-0.008707\n-0.023786\n0.054948\n1.000000\n-0.022863\n-0.014032\n-0.009514\n-0.016317\n\n\nJobSatisfaction\n-0.078936\n-0.012425\n-0.021623\n-0.022863\n1.000000\n-0.025082\n0.030811\n-0.039380\n\n\nMonthlyIncome\n-0.163572\n0.490107\n-0.012803\n-0.014032\n-0.025082\n1.000000\n-0.021334\n0.768437\n\n\nPercentSalaryHike\n-0.000048\n-0.008303\n0.052348\n-0.009514\n0.030811\n-0.021334\n1.000000\n-0.021988\n\n\nTotalWorkingYears\n-0.182162\n0.674331\n0.002606\n-0.016317\n-0.039380\n0.768437\n-0.021988\n1.000000\n\n\n\n\n\n\n\n\n\n(2) 데이터 준비\n- 변수 제거\n\ndata.drop(\"EmployeeNumber\", axis=1, inplace =True)\ndata.head()\n\n\n\n\n\n\n\n\nAttrition\nAge\nDistanceFromHome\nGender\nJobSatisfaction\nMaritalStatus\nMonthlyIncome\nOverTime\nPercentSalaryHike\nTotalWorkingYears\n\n\n\n\n0\n0\n33\n7\nMale\n3\nMarried\n11691\nNo\n11\n14\n\n\n1\n0\n35\n18\nMale\n4\nSingle\n9362\nNo\n11\n10\n\n\n2\n0\n42\n6\nMale\n1\nMarried\n13348\nNo\n13\n18\n\n\n3\n0\n46\n2\nFemale\n1\nMarried\n17048\nNo\n23\n28\n\n\n4\n1\n22\n4\nMale\n3\nSingle\n3894\nNo\n16\n4\n\n\n\n\n\n\n\n- x, y 분리\n\ntarget = \"Attrition\"\n\nx = data.drop(target, axis=1)\ny = data[target]\n\n- 가변수화\n\ndum_col = [\"Gender\", \"JobSatisfaction\", \"MaritalStatus\", \"OverTime\"]\n\nx = pd.get_dummies(x, columns = dum_col, drop_first= True, dtype = float)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nAttrition\nAge\nDistanceFromHome\nGender\nJobSatisfaction\nMaritalStatus\nMonthlyIncome\nOverTime\nPercentSalaryHike\nTotalWorkingYears\n\n\n\n\n0\n0\n33\n7\nMale\n3\nMarried\n11691\nNo\n11\n14\n\n\n1\n0\n35\n18\nMale\n4\nSingle\n9362\nNo\n11\n10\n\n\n2\n0\n42\n6\nMale\n1\nMarried\n13348\nNo\n13\n18\n\n\n3\n0\n46\n2\nFemale\n1\nMarried\n17048\nNo\n23\n28\n\n\n4\n1\n22\n4\nMale\n3\nSingle\n3894\nNo\n16\n4\n\n\n\n\n\n\n\n- 학슴용 평가 데이터 분리\n\nx_train, x_test, y_train, y_test = train_test_split(x, y.astype(str), random_state = 1, test_size = 0.3)\n\n- 정규화\n\nscale = lambda  x : (x - min(x))/(max(x)-min(x))\n\nx_train = x_train.apply(scale, axis =  0)\nx_test = x_test.apply(scale, axis =  0)\nx_train.head()\n\n\n\n\n\n\n\n\nAge\nDistanceFromHome\nMonthlyIncome\nPercentSalaryHike\nTotalWorkingYears\nGender_Male\nJobSatisfaction_2\nJobSatisfaction_3\nJobSatisfaction_4\nMaritalStatus_Married\nMaritalStatus_Single\nOverTime_Yes\n\n\n\n\n567\n0.214286\n0.321429\n0.248997\n0.000000\n0.150\n0.0\n0.0\n0.0\n1.0\n1.0\n0.0\n1.0\n\n\n330\n0.547619\n0.071429\n0.416244\n0.000000\n0.350\n1.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n785\n0.285714\n0.071429\n0.084758\n0.000000\n0.200\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n1.0\n\n\n11\n0.357143\n0.500000\n0.662814\n0.071429\n0.375\n1.0\n0.0\n1.0\n0.0\n1.0\n0.0\n1.0\n\n\n885\n0.380952\n0.071429\n0.353863\n0.428571\n0.175\n1.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\n\n\n(3) 모델링\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\nmodel = KNeighborsClassifier()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\n\n\n(4) 결과 시각화 1 : \\((y, \\hat y)\\) 클래스 비교\n\nfig = pd.DataFrame({\"y_test\" : y_test, \"y_pred\" : y_pred}).\\\n                        melt(var_name = \"label\",value_name = \"Attrition\").\\\n                            groupby(\"label\",as_index=False)[[\"Attrition\"]].value_counts().\\\n                                plot(x=\"label\",y= \"count\", backend = \"plotly\",\n                                        facet_col = \"Attrition\", kind=\"bar\",color = \"label\",height = 400, width = 600)\nfig\n\n\n                                                \n\n\n\n\n(5) 결과 시각화 2 : 평가지표\n\nacc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test, pos_label = \"1\")\nrecall = recall_score(y_pred, y_test,pos_label = \"1\")\nf1 = f1_score(y_pred, y_test,pos_label = \"1\")\n\nresult = [acc, pre, recall, f1]\ncol = [\"accuracy\", \"precision\", \"recall\", \"F1-score\"]\n\npd.DataFrame(result,columns=[\"value\"],index=col).reset_index().\\\n                plot(x=\"index\", y= \"value\",kind=\"bar\",color= \"index\", backend = \"plotly\",\n                        height = 400, width = 600)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#실습",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#실습",
    "title": "02. 머신러닝 (2)",
    "section": "실습",
    "text": "실습\n\n(1) 데이터 로드 및 탐색\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/titanic_train.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n\ndata[\"Survived\"].value_counts()\n\nSurvived\n0    549\n1    342\nName: count, dtype: int64\n\n\n\ndata.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\ndata.select_dtypes(\"number\").corr()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\nPassengerId\n1.000000\n-0.005007\n-0.035144\n0.036847\n-0.057527\n-0.001652\n0.012658\n\n\nSurvived\n-0.005007\n1.000000\n-0.338481\n-0.077221\n-0.035322\n0.081629\n0.257307\n\n\nPclass\n-0.035144\n-0.338481\n1.000000\n-0.369226\n0.083081\n0.018443\n-0.549500\n\n\nAge\n0.036847\n-0.077221\n-0.369226\n1.000000\n-0.308247\n-0.189119\n0.096067\n\n\nSibSp\n-0.057527\n-0.035322\n0.083081\n-0.308247\n1.000000\n0.414838\n0.159651\n\n\nParch\n-0.001652\n0.081629\n0.018443\n-0.189119\n0.414838\n1.000000\n0.216225\n\n\nFare\n0.012658\n0.257307\n-0.549500\n0.096067\n0.159651\n0.216225\n1.000000\n\n\n\n\n\n\n\n\n# 제거 대상: PassengerId, Name, Ticket, Cabin\ndrop_cols = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n\n# 변수 제거\ndata.drop(drop_cols, axis=1, inplace=True)\n\n# 확인\ndata.head()\n\n\n\n\n\n\n\n\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nFare\nEmbarked\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\n\n\n\n\n\n\n\n\n# Age 결측치를 중앙값으로 채우기\nage_median = data['Age'].median()\ndata['Age'].fillna(age_median, inplace=True)\n\n\n# Embarked 최빈값으로 채우기\nemb_freq = data['Embarked'].mode()[0]\ndata['Embarked'].fillna(emb_freq, inplace=True)\n\n\n# target 확인\ntarget = 'Survived'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n\n# 가변수화 대상: Pclass, Sex, Embarked\ndumm_cols = ['Pclass', 'Sex', 'Embarked']\n\n# 가변수화\nx = pd.get_dummies(x, columns=dumm_cols, drop_first=True)\n\n# 확인\nx.head()\n\n\n\n\n\n\n\n\nAge\nSibSp\nParch\nFare\nPclass_2\nPclass_3\nSex_male\nEmbarked_Q\nEmbarked_S\n\n\n\n\n0\n22.0\n1\n0\n7.2500\nFalse\nTrue\nTrue\nFalse\nTrue\n\n\n1\n38.0\n1\n0\n71.2833\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\n26.0\n0\n0\n7.9250\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n3\n35.0\n1\n0\n53.1000\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n4\n35.0\n0\n0\n8.0500\nFalse\nTrue\nTrue\nFalse\nTrue\n\n\n\n\n\n\n\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n\n\n(2) 모델링\n\n# step 1.  모듈 로드\nfrom sklearn.tree import DecisionTreeClassifier\n\n# step 2.  선언하기\n\nmodel = DecisionTreeClassifier(max_depth = 5)\n\n# step 3. 학습하기\n\nmodel.fit(x_train, y_train)\n\n# step 4.  예측하기\ny_pred = model.predict(x_test)\n\n# step 5. 평가하기\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nacc = accuracy_score(y_test, y_pred)\npre = precision_score(y_test, y_pred) \nrecall = recall_score(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred)\n\n\n\n(3) 시각화 1 : 평가지표\n\nfig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\nfig.update_yaxes(range = [0.5, 0.85])\n\n\n                                                \n\n\n\n\n(4) 시각화 2 : tree 모델\n\n\nCode\n# 시각화 모듈 불러오기\nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image\n\n# 이미지 파일 만들기\nexport_graphviz(model,                                 # 모델 이름\n                out_file='tree.dot',                   # 파일 이름\n                feature_names=x.columns,               # Feature 이름\n                class_names=['die', 'survived'],       # Target Class 이름\n                rounded=True,                          # 둥근 테두리\n                precision=2,                           # 불순도 소숫점 자리수\n                filled=True,                              # 박스 내부 채우기\n                max_depth=3)                         # 그래프에 표시할 트리의 깊이\n\n# 파일 변환\n!dot tree.dot -Tpng -otree.png -Gdpi=300\n\n# 이미지 파일 표시\nImage(filename='tree.png')\n\n\n\n\n\n\n\n(5) 시각화 3 : 변수 중요도\n\nipt = model.feature_importances_\npd.DataFrame({\"importance\" : ipt, \"var\" : list(x)}).\\\n                            sort_values(\"importance\", ascending = False).\\\n                            plot( x = \"importance\", y= \"var\", \n                                     kind = \"barh\", backend = \"plotly\",\n                                     height = 400, width = 600,color = \"var\")"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-1-1",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-1-1",
    "title": "02. 머신러닝 (2)",
    "section": "excercise. 1",
    "text": "excercise. 1\n\n(1) 데이터 로드 및 탐색\n데이터 설명\n\nCOLLEGE: 대학 졸업여부\nINCOME: 연수입\nOVERAGE: 월평균 초과사용 시간(분)\nLEFTOVER: 월평균 잔여시간비율(%)\nHOUSE: 집값\nHANDSET_PRICE: 스마트폰 가격\nOVER_15MINS_CALLS_PER_MONTH: 월평균 장기통화(15분이상) 횟수\nAVERAGE_CALL_DURATION: 평균 통화 시간\nREPORTED_SATISFACTION: 만족도 설문조사 결과\nREPORTED_USAGE_LEVEL: 사용도 자가진단 결과\nCONSIDERING_CHANGE_OF_PLAN: 향후 변경계획 설문조사 결과\nCHURN: 이탈(번호이동) 여부 (Target 변수)\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/mobile_cust_churn.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 20000 entries, 0 to 19999\nData columns (total 13 columns):\n #   Column                       Non-Null Count  Dtype \n---  ------                       --------------  ----- \n 0   id                           20000 non-null  int64 \n 1   COLLEGE                      20000 non-null  int64 \n 2   INCOME                       20000 non-null  int64 \n 3   OVERAGE                      20000 non-null  int64 \n 4   LEFTOVER                     20000 non-null  int64 \n 5   HOUSE                        20000 non-null  int64 \n 6   HANDSET_PRICE                20000 non-null  int64 \n 7   OVER_15MINS_CALLS_PER_MONTH  20000 non-null  int64 \n 8   AVERAGE_CALL_DURATION        20000 non-null  int64 \n 9   REPORTED_SATISFACTION        20000 non-null  object\n 10  REPORTED_USAGE_LEVEL         20000 non-null  object\n 11  CONSIDERING_CHANGE_OF_PLAN   20000 non-null  object\n 12  CHURN                        20000 non-null  object\ndtypes: int64(9), object(4)\nmemory usage: 2.0+ MB\n\n\n\ndata[\"CHURN\"].value_counts()\n\nCHURN\nSTAY     10148\nLEAVE     9852\nName: count, dtype: int64\n\n\n\ndata.select_dtypes(\"number\").corr()\n\n\n\n\n\n\n\n\nid\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\n\n\n\n\nid\n1.000000\n-0.005557\n0.003686\n-0.006050\n0.006069\n0.011347\n-0.007838\n0.001254\n-0.005830\n\n\nCOLLEGE\n-0.005557\n1.000000\n0.011122\n-0.003091\n-0.003925\n-0.000217\n0.009950\n-0.007205\n-0.001490\n\n\nINCOME\n0.003686\n0.011122\n1.000000\n0.000458\n0.006515\n-0.010964\n0.727200\n0.002136\n-0.007219\n\n\nOVERAGE\n-0.006050\n-0.003091\n0.000458\n1.000000\n-0.003123\n0.002412\n0.000324\n0.770557\n0.000653\n\n\nLEFTOVER\n0.006069\n-0.003925\n0.006515\n-0.003123\n1.000000\n0.006530\n0.004004\n-0.010411\n-0.660285\n\n\nHOUSE\n0.011347\n-0.000217\n-0.010964\n0.002412\n0.006530\n1.000000\n-0.007756\n0.007410\n-0.009359\n\n\nHANDSET_PRICE\n-0.007838\n0.009950\n0.727200\n0.000324\n0.004004\n-0.007756\n1.000000\n0.002680\n-0.005190\n\n\nOVER_15MINS_CALLS_PER_MONTH\n0.001254\n-0.007205\n0.002136\n0.770557\n-0.010411\n0.007410\n0.002680\n1.000000\n0.007769\n\n\nAVERAGE_CALL_DURATION\n-0.005830\n-0.001490\n-0.007219\n0.000653\n-0.660285\n-0.009359\n-0.005190\n0.007769\n1.000000\n\n\n\n\n\n\n\n\ndata.isna().sum()\n\nid                             0\nCOLLEGE                        0\nINCOME                         0\nOVERAGE                        0\nLEFTOVER                       0\nHOUSE                          0\nHANDSET_PRICE                  0\nOVER_15MINS_CALLS_PER_MONTH    0\nAVERAGE_CALL_DURATION          0\nREPORTED_SATISFACTION          0\nREPORTED_USAGE_LEVEL           0\nCONSIDERING_CHANGE_OF_PLAN     0\nCHURN                          0\ndtype: int64\n\n\n\n(a). 데이터 준비\n- 변수 제거\n\n_data = data.drop(\"id\", axis = 1).copy()\n_data.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\nSTAY\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\nSTAY\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\nSTAY\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\nLEAVE\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\nSTAY\n\n\n\n\n\n\n\n= x, y 분리\n\ntarget = \"CHURN\"\n\nx = _data.drop(target, axis = 1)\ny = _data[target]\n\n- 가변수화\n\nd_cols = [\"REPORTED_SATISFACTION\", \"REPORTED_USAGE_LEVEL\", \"CONSIDERING_CHANGE_OF_PLAN\"]\n\nx = pd.get_dummies(x, columns = d_cols, drop_first = True, dtype = float)\n\n- 훈련, 평가 데이터 분리\n\nx_train, x_test, y_train , y_test = train_test_split(x, y, test_size = 0.3, random_state = 1)\n\n\n\n\n(2) 모델링\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# step 1. 모델 선언\nmodel  = DecisionTreeClassifier(max_depth = 5,random_state=1)\n# step 2.  모델 fit\nmodel.fit(x_train,y_train)\n\n# step 3. 모델 pred\ny_pred = model.predict(x_test)\n\n# step 4.  평가지표 산출\nfrom sklearn import metrics\nacc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred, y_test, pos_label = \"LEAVE\")\nrec =  recall_score(y_pred, y_test,  pos_label = \"LEAVE\")\nf1 = metrics.f1_score(y_test,y_pred, pos_label = \"LEAVE\")\n\n\n\n(3) 시각화 1 : 평가지표\n\nfig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\nfig.update_yaxes(range = [0.5, 0.71])\n\n\n                                                \n\n\n\n\n(4) 시각화 2 : tree 모델\n\n\nCode\n# 시각화 모듈 불러오기\nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image\n\n# 이미지 파일 만들기\nexport_graphviz(model,                                 # 모델 이름\n                out_file='tree.dot',                   # 파일 이름\n                feature_names=x.columns,               # Feature 이름\n                class_names=['Leave', 'Stay'],       # Target Class 이름\n                rounded=True,                          # 둥근 테두리\n                precision=2,                           # 불순도 소숫점 자리수\n                filled=True,                              # 박스 내부 채우기\n                max_depth=3)                         # 그래프에 표시할 트리의 깊이\n\n# 파일 변환\n!dot tree.dot -Tpng -otree.png -Gdpi=300\n\n# 이미지 파일 표시\nImage(filename='tree.png')\n\n\n\n\n\n\n\n(5) 시각화 3 : 변수 중요도\n\nipt = model.feature_importances_\nfig = pd.DataFrame({\"importance\" : ipt, \"var\" : list(x)}).\\\n                            sort_values(\"importance\", ascending = False).\\\n                            plot( y = \"importance\", x= \"var\", \n                                     kind = \"bar\", backend = \"plotly\",\n                                     height = 400, width = 600,color = \"var\")\nfig.update_layout(showlegend = False)\nfig.update_xaxes(showticklabels=False)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-2-1",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#excercise.-2-1",
    "title": "02. 머신러닝 (2)",
    "section": "excercise. 2",
    "text": "excercise. 2\n\n(1) 데이터 로드 및 탐색\n데이터설명\n피마 인디언 당뇨 데이터셋은 몇 명의 여성 피마 인디언의 진료 자료와 진단 후 5년 내 당뇨 발병 여부로 구성됨\n\nPregnancies: 임신 횟수\nGlucose: 포도당 부하 검사 수치\nBloodPressure: 혈압(mm Hg)\nSkinThickness: 팔 삼두근 뒤쪽의 피하지방 측정값(mm)\nInsulin: 혈청 인슐린(mu U/ml)\nBMI: 체질량지수(체중(kg)/키(m))^2\nDiabetesPedigreeFunction: 당뇨 내력 가중치 값\nAge: 나이\nOutcome: 클래스 결정 값(0 또는 1)\n\ndiabetes\n\n당뇨병(糖尿病, diabetes)은 높은 혈당 수치가 오랜 기간 지속되는 대사 질환이다.\n혈당이 높을 때의 증상으로는 소변이 잦아지고, 갈증과 배고픔이 심해진다.\n이를 치료하지 않으면 다른 합병증을 유발할 수 있다. (출처: 위키백과)\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/diabetes.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   768 non-null    int64  \n 2   BloodPressure             768 non-null    int64  \n 3   SkinThickness             768 non-null    int64  \n 4   Insulin                   768 non-null    int64  \n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n\n\n\ndata.isna().sum()\n\nPregnancies                 0\nGlucose                     0\nBloodPressure               0\nSkinThickness               0\nInsulin                     0\nBMI                         0\nDiabetesPedigreeFunction    0\nAge                         0\nOutcome                     0\ndtype: int64\n\n\n\ndata.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n\ndata.corr()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\nPregnancies\n1.000000\n0.129459\n0.141282\n-0.081672\n-0.073535\n0.017683\n-0.033523\n0.544341\n0.221898\n\n\nGlucose\n0.129459\n1.000000\n0.152590\n0.057328\n0.331357\n0.221071\n0.137337\n0.263514\n0.466581\n\n\nBloodPressure\n0.141282\n0.152590\n1.000000\n0.207371\n0.088933\n0.281805\n0.041265\n0.239528\n0.065068\n\n\nSkinThickness\n-0.081672\n0.057328\n0.207371\n1.000000\n0.436783\n0.392573\n0.183928\n-0.113970\n0.074752\n\n\nInsulin\n-0.073535\n0.331357\n0.088933\n0.436783\n1.000000\n0.197859\n0.185071\n-0.042163\n0.130548\n\n\nBMI\n0.017683\n0.221071\n0.281805\n0.392573\n0.197859\n1.000000\n0.140647\n0.036242\n0.292695\n\n\nDiabetesPedigreeFunction\n-0.033523\n0.137337\n0.041265\n0.183928\n0.185071\n0.140647\n1.000000\n0.033561\n0.173844\n\n\nAge\n0.544341\n0.263514\n0.239528\n-0.113970\n-0.042163\n0.036242\n0.033561\n1.000000\n0.238356\n\n\nOutcome\n0.221898\n0.466581\n0.065068\n0.074752\n0.130548\n0.292695\n0.173844\n0.238356\n1.000000\n\n\n\n\n\n\n\n\ndata.Outcome.value_counts()\n\nOutcome\n0    500\n1    268\nName: count, dtype: int64\n\n\n\n\n(2) 데이터 분리\n\ntarget = \"Outcome\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y,  random_state = 1, test_size = 0.3)\n\n\n\n(3) 모델링\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(x_train,y_train)\n\ny_pred = model.predict(x_test)\n\nacc, pre, re, f1 = accuracy_score(y_test,y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), metrics.f1_score(y_test, y_pred)\n\n\n\n(4) 시각화 1. 평가지표\n- 걍함수로 만들자…\n\ndef score(range = [0.5, 0.71]) : \n            fig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\n            fig.update_yaxes(range = range)\n            return fig\n\n\nscore()\n\n\n                                                \n\n\n\n\n(5) 시각화 2 : tree 모델\n\n\nCode\n# 시각화 모듈 불러오기\nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image\n\n# 이미지 파일 만들기\nexport_graphviz(model,                                 # 모델 이름\n                out_file='tree.dot',                   # 파일 이름\n                feature_names=x.columns,               # Feature 이름\n                class_names=['0', '1'],       # Target Class 이름\n                rounded=True,                          # 둥근 테두리\n                precision=2,                           # 불순도 소숫점 자리수\n                filled=True,                              # 박스 내부 채우기\n                max_depth=3)                         # 그래프에 표시할 트리의 깊이\n\n# 파일 변환\n!dot tree.dot -Tpng -otree.png -Gdpi=300\n\n# 이미지 파일 표시\nImage(filename='tree.png')\n\n\n\n\n\n\n\n(5) 시각화 3 : 변수 중요도\n\ndef importance(x,model) :\n        ipt = model.feature_importances_\n        fig = pd.DataFrame({\"importance\" : ipt, \"var\" : list(x)}).\\\n                                sort_values(\"importance\", ascending = False).\\\n                                plot( y = \"importance\", x= \"var\", \n                                        kind = \"bar\", backend = \"plotly\",\n                                         height = 400, width = 600,color = \"var\", title=\"\".join([i for i in str(model) if i.isalpha()]))\n        fig.update_layout(showlegend = False)\n        fig.update_xaxes(showticklabels=True)\n        return fig\n\n\nimportance(x,model)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-로드-및-탐색-6",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-로드-및-탐색-6",
    "title": "02. 머신러닝 (2)",
    "section": "(1) 데이터 로드 및 탐색",
    "text": "(1) 데이터 로드 및 탐색\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/admission_simple.csv'\ndata = pd.read_csv(path)\n\n\n# 상위 몇 개 행 확인\ndata.head()\n\n\n\n\n\n\n\n\nGRE\nTOEFL\nRANK\nSOP\nLOR\nGPA\nRESEARCH\nADMIT\n\n\n\n\n0\n337\n118\n4\n4.5\n4.5\n9.65\n1\n1\n\n\n1\n324\n107\n4\n4.0\n4.5\n8.87\n1\n1\n\n\n2\n316\n104\n3\n3.0\n3.5\n8.00\n1\n0\n\n\n3\n322\n110\n3\n3.5\n2.5\n8.67\n1\n1\n\n\n4\n314\n103\n2\n2.0\n3.0\n8.21\n0\n0\n\n\n\n\n\n\n\n\n# 기술통계 확인\ndata.describe()\n\n\n\n\n\n\n\n\nGRE\nTOEFL\nRANK\nSOP\nLOR\nGPA\nRESEARCH\nADMIT\n\n\n\n\ncount\n500.000000\n500.000000\n500.000000\n500.000000\n500.00000\n500.000000\n500.000000\n500.000000\n\n\nmean\n316.472000\n107.192000\n3.114000\n3.374000\n3.48400\n8.576440\n0.560000\n0.436000\n\n\nstd\n11.295148\n6.081868\n1.143512\n0.991004\n0.92545\n0.604813\n0.496884\n0.496384\n\n\nmin\n290.000000\n92.000000\n1.000000\n1.000000\n1.00000\n6.800000\n0.000000\n0.000000\n\n\n25%\n308.000000\n103.000000\n2.000000\n2.500000\n3.00000\n8.127500\n0.000000\n0.000000\n\n\n50%\n317.000000\n107.000000\n3.000000\n3.500000\n3.50000\n8.560000\n1.000000\n0.000000\n\n\n75%\n325.000000\n112.000000\n4.000000\n4.000000\n4.00000\n9.040000\n1.000000\n1.000000\n\n\nmax\n340.000000\n120.000000\n5.000000\n5.000000\n5.00000\n9.920000\n1.000000\n1.000000\n\n\n\n\n\n\n\n\n# 범주값 개수 확인\ndata['ADMIT'].value_counts()\n\nADMIT\n0    282\n1    218\nName: count, dtype: int64\n\n\n\n# 상관관계 확인\ndata.corr()\n\n\n\n\n\n\n\n\nGRE\nTOEFL\nRANK\nSOP\nLOR\nGPA\nRESEARCH\nADMIT\n\n\n\n\nGRE\n1.000000\n0.827200\n0.635376\n0.613498\n0.524679\n0.825878\n0.563398\n0.701671\n\n\nTOEFL\n0.827200\n1.000000\n0.649799\n0.644410\n0.541563\n0.810574\n0.467012\n0.680503\n\n\nRANK\n0.635376\n0.649799\n1.000000\n0.728024\n0.608651\n0.705254\n0.427047\n0.618367\n\n\nSOP\n0.613498\n0.644410\n0.728024\n1.000000\n0.663707\n0.712154\n0.408116\n0.606876\n\n\nLOR\n0.524679\n0.541563\n0.608651\n0.663707\n1.000000\n0.637469\n0.372526\n0.536527\n\n\nGPA\n0.825878\n0.810574\n0.705254\n0.712154\n0.637469\n1.000000\n0.501311\n0.752196\n\n\nRESEARCH\n0.563398\n0.467012\n0.427047\n0.408116\n0.372526\n0.501311\n1.000000\n0.503104\n\n\nADMIT\n0.701671\n0.680503\n0.618367\n0.606876\n0.536527\n0.752196\n0.503104\n1.000000"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-준비-1",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#데이터-준비-1",
    "title": "02. 머신러닝 (2)",
    "section": "(2) 데이터 준비",
    "text": "(2) 데이터 준비\n\n# target 확인\ntarget = 'ADMIT'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#모델링-9",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#모델링-9",
    "title": "02. 머신러닝 (2)",
    "section": "(3) 모델링",
    "text": "(3) 모델링\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\n# step1. model 선언\nmodel  = LogisticRegression()\n\n# step2. fit\nmodel.fit(x_train, y_train)\n\n# step3 . 얘측\ny_pred = model.predict(x_test)\n\n# step 4. 성능 지표 산출\nacc, pre, recall, f1_score = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)\n\n\nscore(range = [0.7, 0.87])"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#extra-확률값-구한-후-결과-계산",
    "href": "posts/DX/04. 머신러닝/2023-09-13-02. 머신러닝 (2).html#extra-확률값-구한-후-결과-계산",
    "title": "02. 머신러닝 (2)",
    "section": "(4) extra : 확률값 구한 후 결과 계산",
    "text": "(4) extra : 확률값 구한 후 결과 계산\n\np = model.predict_proba(x_test)\n\nmy_pred = [1 if x &gt; 0.5 else 0 for x in p[:,1]]"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html",
    "href": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html",
    "title": "00. Intro",
    "section": "",
    "text": "- AirQuality 데이터를 대상으로 모델링을 수행 후 오존 농도를 예측해보자\n\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n\n- 데이터의 정보 및 EDA 수행\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/airquality_simple.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n0\n41\n190.0\n7.4\n67\n5\n1\n\n\n1\n36\n118.0\n8.0\n72\n5\n2\n\n\n2\n12\n149.0\n12.6\n74\n5\n3\n\n\n3\n18\n313.0\n11.5\n62\n5\n4\n\n\n4\n19\nNaN\n14.3\n56\n5\n5\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    153 non-null    int64  \n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(2), int64(4)\nmemory usage: 7.3 KB\n\n\n- 기술통계 확인\n\ndata.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nOzone\n153.0\n42.052288\n30.156127\n1.0\n20.00\n34.0\n59.00\n168.0\n\n\nSolar.R\n146.0\n185.931507\n90.058422\n7.0\n115.75\n205.0\n258.75\n334.0\n\n\nWind\n153.0\n9.957516\n3.523001\n1.7\n7.40\n9.7\n11.50\n20.7\n\n\nTemp\n153.0\n77.882353\n9.465270\n56.0\n72.00\n79.0\n85.00\n97.0\n\n\nMonth\n153.0\n6.993464\n1.416522\n5.0\n6.00\n7.0\n8.00\n9.0\n\n\nDay\n153.0\n15.803922\n8.864520\n1.0\n8.00\n16.0\n23.00\n31.0\n\n\n\n\n\n\n\n- 상관관계 확인\n\ndata.corr()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\nOzone\n1.000000\n0.280068\n-0.605478\n0.683372\n0.174197\n0.004419\n\n\nSolar.R\n0.280068\n1.000000\n-0.056792\n0.275840\n-0.075301\n-0.150275\n\n\nWind\n-0.605478\n-0.056792\n1.000000\n-0.457988\n-0.178293\n0.027181\n\n\nTemp\n0.683372\n0.275840\n-0.457988\n1.000000\n0.420947\n-0.130593\n\n\nMonth\n0.174197\n-0.075301\n-0.178293\n0.420947\n1.000000\n-0.007962\n\n\nDay\n0.004419\n-0.150275\n0.027181\n-0.130593\n-0.007962\n1.000000\n\n\n\n\n\n\n\n\nsns.heatmap(data.corr(),\n                   fmt = \".3f\",\n                    annot = True,\n                   square =True,\n                    cbar = False,\n                   annot_kws = {\"size\"  : 8})\n\n&lt;Axes: &gt;\n\n\n\n\n\n- temp \\(\\to\\) ozone의 관계\n\nplt.figure(figsize=(4,4))\nplt.scatter(data.Temp, data.Ozone,alpha=0.3)\n\n&lt;matplotlib.collections.PathCollection at 0x1c510169b10&gt;\n\n\n\n\n\n\n\n\n\n\n\n\ndata.isna().sum()\n\nOzone      0\nSolar.R    7\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\ndata.fillna(method= \"ffill\",inplace=True)\n\n\ndata.isna().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\n\n\n\nd_cols = data.columns.drop([\"Month\", \"Day\"])\n\n_data = data[d_cols].copy()\n\n\n_data\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\n\n\n\n\n0\n41\n190.0\n7.4\n67\n\n\n1\n36\n118.0\n8.0\n72\n\n\n2\n12\n149.0\n12.6\n74\n\n\n3\n18\n313.0\n11.5\n62\n\n\n4\n19\n313.0\n14.3\n56\n\n\n...\n...\n...\n...\n...\n\n\n148\n30\n193.0\n6.9\n70\n\n\n149\n23\n145.0\n13.2\n77\n\n\n150\n14\n191.0\n14.3\n75\n\n\n151\n18\n131.0\n8.0\n76\n\n\n152\n20\n223.0\n11.5\n68\n\n\n\n\n153 rows × 4 columns\n\n\n\n\n\n\n\nx = _data.iloc[:,1:]\ny = _data[\"Ozone\"]\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=7)\nx_train.head()\n\n\n\n\n\n\n\n\nSolar.R\nWind\nTemp\n\n\n\n\n62\n248.0\n9.2\n85\n\n\n51\n150.0\n6.3\n77\n\n\n141\n238.0\n10.3\n68\n\n\n118\n153.0\n5.7\n88\n\n\n74\n291.0\n14.9\n91\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error \n\n\n\n\n\nmodel = LinearRegression()\n\n\n\n\n\nmodel.fit(x_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n\n\ny_pred = model.predict(x_test)\n\n\n\n\n\nmean_absolute_error(y_pred,y_test)\n\n12.930971421482479\n\n\n- 시각화\n\nplt.plot(y_pred)\nplt.plot(y_test.values)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#import",
    "href": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#import",
    "title": "00. Intro",
    "section": "",
    "text": "# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#데이터-이해",
    "href": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#데이터-이해",
    "title": "00. Intro",
    "section": "",
    "text": "- 데이터의 정보 및 EDA 수행\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/airquality_simple.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n0\n41\n190.0\n7.4\n67\n5\n1\n\n\n1\n36\n118.0\n8.0\n72\n5\n2\n\n\n2\n12\n149.0\n12.6\n74\n5\n3\n\n\n3\n18\n313.0\n11.5\n62\n5\n4\n\n\n4\n19\nNaN\n14.3\n56\n5\n5\n\n\n\n\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    153 non-null    int64  \n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(2), int64(4)\nmemory usage: 7.3 KB\n\n\n- 기술통계 확인\n\ndata.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nOzone\n153.0\n42.052288\n30.156127\n1.0\n20.00\n34.0\n59.00\n168.0\n\n\nSolar.R\n146.0\n185.931507\n90.058422\n7.0\n115.75\n205.0\n258.75\n334.0\n\n\nWind\n153.0\n9.957516\n3.523001\n1.7\n7.40\n9.7\n11.50\n20.7\n\n\nTemp\n153.0\n77.882353\n9.465270\n56.0\n72.00\n79.0\n85.00\n97.0\n\n\nMonth\n153.0\n6.993464\n1.416522\n5.0\n6.00\n7.0\n8.00\n9.0\n\n\nDay\n153.0\n15.803922\n8.864520\n1.0\n8.00\n16.0\n23.00\n31.0\n\n\n\n\n\n\n\n- 상관관계 확인\n\ndata.corr()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\nOzone\n1.000000\n0.280068\n-0.605478\n0.683372\n0.174197\n0.004419\n\n\nSolar.R\n0.280068\n1.000000\n-0.056792\n0.275840\n-0.075301\n-0.150275\n\n\nWind\n-0.605478\n-0.056792\n1.000000\n-0.457988\n-0.178293\n0.027181\n\n\nTemp\n0.683372\n0.275840\n-0.457988\n1.000000\n0.420947\n-0.130593\n\n\nMonth\n0.174197\n-0.075301\n-0.178293\n0.420947\n1.000000\n-0.007962\n\n\nDay\n0.004419\n-0.150275\n0.027181\n-0.130593\n-0.007962\n1.000000\n\n\n\n\n\n\n\n\nsns.heatmap(data.corr(),\n                   fmt = \".3f\",\n                    annot = True,\n                   square =True,\n                    cbar = False,\n                   annot_kws = {\"size\"  : 8})\n\n&lt;Axes: &gt;\n\n\n\n\n\n- temp \\(\\to\\) ozone의 관계\n\nplt.figure(figsize=(4,4))\nplt.scatter(data.Temp, data.Ozone,alpha=0.3)\n\n&lt;matplotlib.collections.PathCollection at 0x1c510169b10&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#데이터-준비",
    "href": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#데이터-준비",
    "title": "00. Intro",
    "section": "",
    "text": "data.isna().sum()\n\nOzone      0\nSolar.R    7\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\ndata.fillna(method= \"ffill\",inplace=True)\n\n\ndata.isna().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\n\n\n\nd_cols = data.columns.drop([\"Month\", \"Day\"])\n\n_data = data[d_cols].copy()\n\n\n_data\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\n\n\n\n\n0\n41\n190.0\n7.4\n67\n\n\n1\n36\n118.0\n8.0\n72\n\n\n2\n12\n149.0\n12.6\n74\n\n\n3\n18\n313.0\n11.5\n62\n\n\n4\n19\n313.0\n14.3\n56\n\n\n...\n...\n...\n...\n...\n\n\n148\n30\n193.0\n6.9\n70\n\n\n149\n23\n145.0\n13.2\n77\n\n\n150\n14\n191.0\n14.3\n75\n\n\n151\n18\n131.0\n8.0\n76\n\n\n152\n20\n223.0\n11.5\n68\n\n\n\n\n153 rows × 4 columns\n\n\n\n\n\n\n\nx = _data.iloc[:,1:]\ny = _data[\"Ozone\"]\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=7)\nx_train.head()\n\n\n\n\n\n\n\n\nSolar.R\nWind\nTemp\n\n\n\n\n62\n248.0\n9.2\n85\n\n\n51\n150.0\n6.3\n77\n\n\n141\n238.0\n10.3\n68\n\n\n118\n153.0\n5.7\n88\n\n\n74\n291.0\n14.9\n91"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#모델링",
    "href": "posts/DX/04. 머신러닝/2023-09-11-00. intro.html#모델링",
    "title": "00. Intro",
    "section": "",
    "text": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error \n\n\n\n\n\nmodel = LinearRegression()\n\n\n\n\n\nmodel.fit(x_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\n\n\ny_pred = model.predict(x_test)\n\n\n\n\n\nmean_absolute_error(y_pred,y_test)\n\n12.930971421482479\n\n\n- 시각화\n\nplt.plot(y_pred)\nplt.plot(y_test.values)"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "a = 1\n\nb,c = 2,3\n\nd = e = 4\n\n\n%whos\n\nVariable   Type    Data/Info\n----------------------------\na          int     1\nb          int     2\nc          int     3\nd          int     4\ne          int     4\n\n\n- 생성한 변수 reset\n\n%reset\n\nOnce deleted, variables cannot be recovered. Proceed (y/[n])?  y\n\n\n\n%whos\n\nInteractive namespace is empty.\n\n\n\n\n\n- 기본 : int, float, bool, str\n\na,b,c,d = -3,1.2,True, \"py\"\n%whos\n\nVariable   Type     Data/Info\n-----------------------------\na          int      -3\nb          float    1.2\nc          bool     True\nd          str      py\n\n\n- 컬렉션 : list, tuple, dict, set \\(\\to\\) 변수 1개가 여러 개의 데이터를 가지고 있는 형태\n\n데이터를 다룰 때 중요 개념 : create, read, update, delete (CRUD)\n\n1 create\n\nd5, d6, d7 = [1, 2, \"A\", \"B\"], (1, 2, \"A\", \"B\"), {\"A\" : 1, 2 : \"B\"}\n%whos\n\nVariable   Type     Data/Info\n-----------------------------\na          int      -3\nb          float    1.2\nc          bool     True\nd          str      py\nd5         list     n=4\nd6         tuple    n=4\nd7         dict     n=2\n\n\n2 read : masking 문법(:)\n\nd5[2] ## data[idx]\n\n'A'\n\n\n\nd7[\"A\"] ## data[key]\n\n1\n\n\n\nd5[1:3] ## slice\n\n[2, 'A']\n\n\n\nd5[::2] ## stride\n\n[1, 'A']\n\n\n3 update : 데이터 선택 = 수정할 데이터\n\nd5[2] = \"C\" \nd5\n\n[1, 2, 'C', 'B']\n\n\n4 delete : del 데이터 선택\n\ndel d5[2]\n\nd5\n\n[1, 2, 'B']\n\n\n\n\n\n\nd1, d2 = [1, 2, 3], (1, 2, 4)\n\n\nprint(d1,d2)\n\n[1, 2, 3] (1, 2, 4)\n\n\n\nprint(type(d1),type(d2)) ## type 출력\n\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\n\n\n\nprint(id(d1),id(d2)) ## 주소값 출력\n\n2444525537280 2444526172864\n\n\n\nimport sys\n\n- 수정할 필요가 없는 데이터는 리스트보다 튜플이 메모리 효율적으로 좋다.\n\nprint(sys.getsizeof(d1),sys.getsizeof(d2))\n\n88 64\n\n\n\n\n\n- 산술 : (+, -) &lt; (*, /, //, %) &lt;&lt; **\n- 비교 : ==, !=, &gt;, &lt;, &gt;=, &lt;= : 조건 1개\n- 논리 : not, and, or\n\n\n\n\nfor _ in range(3) : \n    print(\"py\")\n\npy\npy\npy\n\n\n\n%whos\n\nVariable   Type      Data/Info\n------------------------------\na          int       -3\nb          float     1.2\nc          bool      True\nd          str       py\nd1         list      n=3\nd2         tuple     n=3\nd5         list      n=3\nd6         tuple     n=4\nd7         dict      n=2\nsys        module    &lt;module 'sys' (built-in)&gt;\n\n\n\n\n\n\n\n\ndef plus(a = 1, b = 2) :\n    print(a + b)\n\n- data type이 function이다.\n\n%whos\n\nVariable   Type        Data/Info\n--------------------------------\na          int         -3\nb          float       1.2\nc          bool        True\nd          str         py\nd1         list        n=3\nd2         tuple       n=3\nd5         list        n=3\nd6         tuple       n=4\nd7         dict        n=2\nplus       function    &lt;function plus at 0x00000239291E2B60&gt;\nsys        module      &lt;module 'sys' (built-in)&gt;\n\n\n\n\n\n\nplus() ## 디퐅트값\nplus(1,3) ## 값을 전달\n\n3\n4\n\n\n\n\n\n\nreturn을 추가하지 않아 아래처럼 None으로 결과를 뱉는다.\n\n\ndef plus(a,b = 1, c = 2) :\n    print(a + b + c)\n    \nresult = plus(1, c = 50)\nprint(\"result\", result)\n\n52\nresult None\n\n\n\ndef plus(a,b = 1, c = 2) :\n    return(a + b + c)\n    \nresult = plus(1, c = 50)\nprint(\"result\", result)\n\nresult 52\n\n\n\n\n\n\n함수를 작성한 사람이, 함수를 어떻게 사용하면 되는지 남겨둔 것!\n\n\n?print\n\n\nSignature: print(*args, sep=' ', end='\\n', file=None, flush=False)\nDocstring:\nPrints the values to a stream, or to sys.stdout by default.\nsep\n  string inserted between values, default a space.\nend\n  string appended after the last value, default a newline.\nfile\n  a file-like object (stream); defaults to the current sys.stdout.\nflush\n  whether to forcibly flush the stream.\nType:      builtin_function_or_method\n\n\n\n\nprint(\"A\",\"B\")\nprint(\"C\")\n\nA B\nC\n\n\n\nprint(\"A\",\"B\",sep=\",\", end = \":\")\nprint(\"C\")\n\nA,B:C\n\n\n\n\n\n\n\n- 변수, 함수를 묶어서 코드 작성 실행\n- 객체 지향 문법을 구현한 방법 : 실제 세계를 모델링하여 프로그램을 개발하는 방법론 (사전적 의미)\n\n교수님 생각 : 클래스는 복제, 변형, 재생산을 용이하게 하기 위해 만들어진 확장가능한 프로그램이 코드 단위(extensible program-code-template)이다.\n\n- 사용법 : 클래스 선언 (코드 작성) -&gt; 객체 생성(메모리에 탑재(사용)) -&gt; 메소드 호출 (코드 실행)\n- 클래스 식별자 컨벤션 : PascalCase(O), snake_case(X)\n\n\n\nclass Marine : \n    health, ap = 40, 5\n    def attack(self, target) :\n        target.health -=self.ap\n\n\n\n\n\nm1, m2 = Marine(), Marine()\nm1.health, m1.ap, m2.health, m2.ap\n\n(40, 5, 40, 5)\n\n\n- dir() : 객체에 저장되어 있는 변수(함수포함) 출력\n\ndir(m1)[-3 : ]\n\n['ap', 'attack', 'health']\n\n\n- 값 변경\n\nm2.health, m2.ap =  60, 7\n\nm2.health, m2.ap\n\n(60, 7)\n\n\n\n\n\n\nm2.attack(m1)\n\n\nm1.health\n\n33\n\n\n- m1의 피가 깍여버린 원리\nclass Marine : \n    health, ap = 40, 5\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n\n\n- 스페셜 메서드 중 하나 (__init__())\n\nclass Marine : \n    #health, ap = 40, 5\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n\nm1, m2 = Marine(), Marine()\n\n- 객체는 생성이 되었으나 피와 공격력이 없어서 메소드 호출 시 에러가 발생한다.\n\n'Marine' object has no attribute 'health'\n\n\nm2.attack(m1)\n\nAttributeError: 'Marine' object has no attribute 'health'\n\n\n- 위를 방지하는 방법 중 하나가 생성자 메소드이다.\n\n제품을 만들 때, 메소드에서 사용하는 변수들이 있는지 한번 다 확인하는 것!\n\n\nclass Marine : \n    #health, ap = 40, 5\n    def __init__(self,health,ap) : ## 생성자 작성\n        self.health, self.ap = health, ap\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n- 이제 메서드가 제대로 실행된다.\n\nm1, m2 = Marine(40,5), Marine(40,5)\nm2.attack(m1)\nm2.health, m1.health\n\n(40, 35)\n\n\n- 요약 : 생성자는 객체 생성시 변수의 초기값을 검사 및 설정한다.\n\n디폴트 값도 사용가능\n\n\nclass Marine : \n    #health, ap = 40, 5\n    def __init__(self,health,ap = 5) : ## 생성자 작성\n        self.health, self.ap = health, ap\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n\nm1, m2 = Marine(40,5), Marine(40)\nm2.attack(m1)\nm2.health, m1.health\n\n(40, 35)\n\n\n\n\n\n\nimport pandas as pd \ndf = pd.DataFrame({\"kospi\" : [3, 4, 5], \"usd\" : [9, 2, 1]})\ndf\n\n\n\n\n\n\n\n\nkospi\nusd\n\n\n\n\n0\n3\n9\n\n\n1\n4\n2\n\n\n2\n5\n1\n\n\n\n\n\n\n\n1 아래 코드는 다른사람이 만든 클래스(모듈) 코드를 우리가 불러오는 것!\nimport pandas as pd \n2 생성자 메서드를 이용하여 초기값을 설정하는 것! (메모리가 사용됨)\ndf = pd.DataFrame({\"kospi\" : [3, 4, 5], \"usd\" : [9, 2, 1]})\n3 객체(df) 안에는 pandas안에 작성된 다양한 메서드들이 존재하며 다음과 같이 사용할 수 있다.\n\ndf.corr()\n\n\n\n\n\n\n\n\nkospi\nusd\n\n\n\n\nkospi\n1.000000\n-0.917663\n\n\nusd\n-0.917663\n1.000000\n\n\n\n\n\n\n\n4. 가장 중요 : dir을 통해 객체안에서 쓸 수 있는 method를 잘 살펴보자!\n5 클래스는 데이터 타입이다!! (\\(\\star\\star\\))\n\nm1 객체는 우리가 만든 marine이라는 클래스의 객체이다.\n\n커스터마이징, 즉, 클래스는 사용자 정의 데이터 타입이다.\n\n\n\nm1 = Marine(40)\ntype(m1)\n\n__main__.Marine\n\n\n6 d1, d2 객체에서 사용가능한 변수와 메서드는 str, list 클래스, 정의되어 있다.\n\n파이썬 문법으로 만들어진 내장 클래스는 앞글자를 소문자로 쓴다.\n\n\nd1 = \"python\"\nd2 = [1, 3, 2]\n\n\ntype(d1), type(d2)\n\n(str, list)\n\n\n7 최종 결론\n\n사실 우리가 하는 변수 생성은 객체를 생성, 즉 클래스 객체를 생성한 것이다.\n따라서, 데이터 타입에 따라서 변수에서 사용가능한 변수, 메서드가 다르다."
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#변수-선언-및-삭제",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#변수-선언-및-삭제",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "a = 1\n\nb,c = 2,3\n\nd = e = 4\n\n\n%whos\n\nVariable   Type    Data/Info\n----------------------------\na          int     1\nb          int     2\nc          int     3\nd          int     4\ne          int     4\n\n\n- 생성한 변수 reset\n\n%reset\n\nOnce deleted, variables cannot be recovered. Proceed (y/[n])?  y\n\n\n\n%whos\n\nInteractive namespace is empty."
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#데이터-타입",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#데이터-타입",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "- 기본 : int, float, bool, str\n\na,b,c,d = -3,1.2,True, \"py\"\n%whos\n\nVariable   Type     Data/Info\n-----------------------------\na          int      -3\nb          float    1.2\nc          bool     True\nd          str      py\n\n\n- 컬렉션 : list, tuple, dict, set \\(\\to\\) 변수 1개가 여러 개의 데이터를 가지고 있는 형태\n\n데이터를 다룰 때 중요 개념 : create, read, update, delete (CRUD)\n\n1 create\n\nd5, d6, d7 = [1, 2, \"A\", \"B\"], (1, 2, \"A\", \"B\"), {\"A\" : 1, 2 : \"B\"}\n%whos\n\nVariable   Type     Data/Info\n-----------------------------\na          int      -3\nb          float    1.2\nc          bool     True\nd          str      py\nd5         list     n=4\nd6         tuple    n=4\nd7         dict     n=2\n\n\n2 read : masking 문법(:)\n\nd5[2] ## data[idx]\n\n'A'\n\n\n\nd7[\"A\"] ## data[key]\n\n1\n\n\n\nd5[1:3] ## slice\n\n[2, 'A']\n\n\n\nd5[::2] ## stride\n\n[1, 'A']\n\n\n3 update : 데이터 선택 = 수정할 데이터\n\nd5[2] = \"C\" \nd5\n\n[1, 2, 'C', 'B']\n\n\n4 delete : del 데이터 선택\n\ndel d5[2]\n\nd5\n\n[1, 2, 'B']"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#변수-속성값-함수",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#변수-속성값-함수",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "d1, d2 = [1, 2, 3], (1, 2, 4)\n\n\nprint(d1,d2)\n\n[1, 2, 3] (1, 2, 4)\n\n\n\nprint(type(d1),type(d2)) ## type 출력\n\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\n\n\n\nprint(id(d1),id(d2)) ## 주소값 출력\n\n2444525537280 2444526172864\n\n\n\nimport sys\n\n- 수정할 필요가 없는 데이터는 리스트보다 튜플이 메모리 효율적으로 좋다.\n\nprint(sys.getsizeof(d1),sys.getsizeof(d2))\n\n88 64"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#연산자",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#연산자",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "- 산술 : (+, -) &lt; (*, /, //, %) &lt;&lt; **\n- 비교 : ==, !=, &gt;, &lt;, &gt;=, &lt;= : 조건 1개\n- 논리 : not, and, or"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#row-dash-변수를-사용하지-않음",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#row-dash-변수를-사용하지-않음",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "for _ in range(3) : \n    print(\"py\")\n\npy\npy\npy\n\n\n\n%whos\n\nVariable   Type      Data/Info\n------------------------------\na          int       -3\nb          float     1.2\nc          bool      True\nd          str       py\nd1         list      n=3\nd2         tuple     n=3\nd5         list      n=3\nd6         tuple     n=4\nd7         dict      n=2\nsys        module    &lt;module 'sys' (built-in)&gt;"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#함수-코드-작성의-효율을-높임",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#함수-코드-작성의-효율을-높임",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "def plus(a = 1, b = 2) :\n    print(a + b)\n\n- data type이 function이다.\n\n%whos\n\nVariable   Type        Data/Info\n--------------------------------\na          int         -3\nb          float       1.2\nc          bool        True\nd          str         py\nd1         list        n=3\nd2         tuple       n=3\nd5         list        n=3\nd6         tuple       n=4\nd7         dict        n=2\nplus       function    &lt;function plus at 0x00000239291E2B60&gt;\nsys        module      &lt;module 'sys' (built-in)&gt;\n\n\n\n\n\n\nplus() ## 디퐅트값\nplus(1,3) ## 값을 전달\n\n3\n4\n\n\n\n\n\n\nreturn을 추가하지 않아 아래처럼 None으로 결과를 뱉는다.\n\n\ndef plus(a,b = 1, c = 2) :\n    print(a + b + c)\n    \nresult = plus(1, c = 50)\nprint(\"result\", result)\n\n52\nresult None\n\n\n\ndef plus(a,b = 1, c = 2) :\n    return(a + b + c)\n    \nresult = plus(1, c = 50)\nprint(\"result\", result)\n\nresult 52\n\n\n\n\n\n\n함수를 작성한 사람이, 함수를 어떻게 사용하면 되는지 남겨둔 것!\n\n\n?print\n\n\nSignature: print(*args, sep=' ', end='\\n', file=None, flush=False)\nDocstring:\nPrints the values to a stream, or to sys.stdout by default.\nsep\n  string inserted between values, default a space.\nend\n  string appended after the last value, default a newline.\nfile\n  a file-like object (stream); defaults to the current sys.stdout.\nflush\n  whether to forcibly flush the stream.\nType:      builtin_function_or_method\n\n\n\n\nprint(\"A\",\"B\")\nprint(\"C\")\n\nA B\nC\n\n\n\nprint(\"A\",\"B\",sep=\",\", end = \":\")\nprint(\"C\")\n\nA,B:C"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#클래스",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#클래스",
    "title": "00. 데이터 수집 (1)",
    "section": "",
    "text": "- 변수, 함수를 묶어서 코드 작성 실행\n- 객체 지향 문법을 구현한 방법 : 실제 세계를 모델링하여 프로그램을 개발하는 방법론 (사전적 의미)\n\n교수님 생각 : 클래스는 복제, 변형, 재생산을 용이하게 하기 위해 만들어진 확장가능한 프로그램이 코드 단위(extensible program-code-template)이다.\n\n- 사용법 : 클래스 선언 (코드 작성) -&gt; 객체 생성(메모리에 탑재(사용)) -&gt; 메소드 호출 (코드 실행)\n- 클래스 식별자 컨벤션 : PascalCase(O), snake_case(X)\n\n\n\nclass Marine : \n    health, ap = 40, 5\n    def attack(self, target) :\n        target.health -=self.ap\n\n\n\n\n\nm1, m2 = Marine(), Marine()\nm1.health, m1.ap, m2.health, m2.ap\n\n(40, 5, 40, 5)\n\n\n- dir() : 객체에 저장되어 있는 변수(함수포함) 출력\n\ndir(m1)[-3 : ]\n\n['ap', 'attack', 'health']\n\n\n- 값 변경\n\nm2.health, m2.ap =  60, 7\n\nm2.health, m2.ap\n\n(60, 7)\n\n\n\n\n\n\nm2.attack(m1)\n\n\nm1.health\n\n33\n\n\n- m1의 피가 깍여버린 원리\nclass Marine : \n    health, ap = 40, 5\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n\n\n- 스페셜 메서드 중 하나 (__init__())\n\nclass Marine : \n    #health, ap = 40, 5\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n\nm1, m2 = Marine(), Marine()\n\n- 객체는 생성이 되었으나 피와 공격력이 없어서 메소드 호출 시 에러가 발생한다.\n\n'Marine' object has no attribute 'health'\n\n\nm2.attack(m1)\n\nAttributeError: 'Marine' object has no attribute 'health'\n\n\n- 위를 방지하는 방법 중 하나가 생성자 메소드이다.\n\n제품을 만들 때, 메소드에서 사용하는 변수들이 있는지 한번 다 확인하는 것!\n\n\nclass Marine : \n    #health, ap = 40, 5\n    def __init__(self,health,ap) : ## 생성자 작성\n        self.health, self.ap = health, ap\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n- 이제 메서드가 제대로 실행된다.\n\nm1, m2 = Marine(40,5), Marine(40,5)\nm2.attack(m1)\nm2.health, m1.health\n\n(40, 35)\n\n\n- 요약 : 생성자는 객체 생성시 변수의 초기값을 검사 및 설정한다.\n\n디폴트 값도 사용가능\n\n\nclass Marine : \n    #health, ap = 40, 5\n    def __init__(self,health,ap = 5) : ## 생성자 작성\n        self.health, self.ap = health, ap\n    def attack(self, target) : ## self : 생성된 객체 자신\n        target.health -=self.ap ## 여기에서 target이 공격당한 대상이 m1, 따라서 m2의 공격력 7만큼 감소\n\n\nm1, m2 = Marine(40,5), Marine(40)\nm2.attack(m1)\nm2.health, m1.health\n\n(40, 35)\n\n\n\n\n\n\nimport pandas as pd \ndf = pd.DataFrame({\"kospi\" : [3, 4, 5], \"usd\" : [9, 2, 1]})\ndf\n\n\n\n\n\n\n\n\nkospi\nusd\n\n\n\n\n0\n3\n9\n\n\n1\n4\n2\n\n\n2\n5\n1\n\n\n\n\n\n\n\n1 아래 코드는 다른사람이 만든 클래스(모듈) 코드를 우리가 불러오는 것!\nimport pandas as pd \n2 생성자 메서드를 이용하여 초기값을 설정하는 것! (메모리가 사용됨)\ndf = pd.DataFrame({\"kospi\" : [3, 4, 5], \"usd\" : [9, 2, 1]})\n3 객체(df) 안에는 pandas안에 작성된 다양한 메서드들이 존재하며 다음과 같이 사용할 수 있다.\n\ndf.corr()\n\n\n\n\n\n\n\n\nkospi\nusd\n\n\n\n\nkospi\n1.000000\n-0.917663\n\n\nusd\n-0.917663\n1.000000\n\n\n\n\n\n\n\n4. 가장 중요 : dir을 통해 객체안에서 쓸 수 있는 method를 잘 살펴보자!\n5 클래스는 데이터 타입이다!! (\\(\\star\\star\\))\n\nm1 객체는 우리가 만든 marine이라는 클래스의 객체이다.\n\n커스터마이징, 즉, 클래스는 사용자 정의 데이터 타입이다.\n\n\n\nm1 = Marine(40)\ntype(m1)\n\n__main__.Marine\n\n\n6 d1, d2 객체에서 사용가능한 변수와 메서드는 str, list 클래스, 정의되어 있다.\n\n파이썬 문법으로 만들어진 내장 클래스는 앞글자를 소문자로 쓴다.\n\n\nd1 = \"python\"\nd2 = [1, 3, 2]\n\n\ntype(d1), type(d2)\n\n(str, list)\n\n\n7 최종 결론\n\n사실 우리가 하는 변수 생성은 객체를 생성, 즉 클래스 객체를 생성한 것이다.\n따라서, 데이터 타입에 따라서 변수에서 사용가능한 변수, 메서드가 다르다."
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#종류",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#종류",
    "title": "00. 데이터 수집 (1)",
    "section": "종류",
    "text": "종류\n- 동적 페이지 : 웹 브라우저에서 이벤트가 발생하면 서버에서 데이터를 가져와 화면을 변경하는 페이지 (url 변경 x)\n\n동적 페이지는 데이터를 가져올 때 json 포맷에서 데이터를 가져온다.\n\n위 경우는 리스트나 딕셔너리로 가져오기 편함\n데이터를 가져오기 위해 추가적인 request, response가 발생함.\n이 때, json 포맷의 데이터를 가져온다!!\n이말은 우리가 파이썬 코드로 해당 url을 요청했을 때 json포맷에 데이터를 가져오는 것이다!\n\n\n- 정적 페이지 : url이 바뀌어야만 화면이 바뀌는 페이지\n\n정적 페이지는 html 포맷에서 데이터를 가져옴\n\n이 경우는 리스트나 딕셔너리로 가져오기 어려움\nrequest, response 시 html 포맷의 데이터를 가져옴\n파이썬 코드로 데이터 수집 시 해당 이벤트의 url을 찾고 requset, response를 한다!\n\n\n\\(\\divideontimes\\) 즉, 페이지 방식에 따라 url 접근 방식이 달라지고, 이에 따라 format이 달라져 크롤링 방식이 달라진다."
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#import",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#import",
    "title": "00. 데이터 수집 (1)",
    "section": "import",
    "text": "import\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport requests ## 크롤링을 위한 모듈"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-1.-url-찾기-to-웹-페이지-분석",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-1.-url-찾기-to-웹-페이지-분석",
    "title": "00. 데이터 수집 (1)",
    "section": "step 1. url 찾기 \\(\\to\\) 웹 페이지 분석",
    "text": "step 1. url 찾기 \\(\\to\\) 웹 페이지 분석\n- 크롬 개발자 도구를 이용하여 url을 찾기\n1 네이버의 코스피 주가데이터를 크롤링 (크롤링 할때는 모바일을 이용하자!)\n네이버 코스피 주가 데이터 : 해당 페이지는 동적 페이지\n\npage, pagesize = 1, 20 \nurl = f'https://m.stock.naver.com/api/index/KOSPI/price?pageSize={pagesize}&page={page}' \nprint(url)\n\nhttps://m.stock.naver.com/api/index/KOSPI/price?pageSize=20&page=1"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-2.-response",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-2.-response",
    "title": "00. 데이터 수집 (1)",
    "section": "step 2. response",
    "text": "step 2. response\n2 response\n\nresponse = requests.get(url)\nresponse\n\n&lt;Response [200]&gt;\n\n\n\nresponse.text[:200]\n\n'[{\"localTradedAt\":\"2023-09-04\",\"closePrice\":\"2,579.39\",\"compareToPreviousClosePrice\":\"15.68\",\"compareToPreviousPrice\":{\"code\":\"2\",\"text\":\"상승\",\"name\":\"RISING\"},\"fluctuationsRatio\":\"0.61\",\"openPrice\":\"2'\n\n\n\ntype(response)\n\nrequests.models.Response"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-3.-데이터-파싱",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-3.-데이터-파싱",
    "title": "00. 데이터 수집 (1)",
    "section": "step 3. 데이터 파싱",
    "text": "step 3. 데이터 파싱\n3. data(json(str)) \\(\\to\\) list,dict \\(\\to\\) dataframe : 파싱을 수행\n\ntype(response.text), type(response.json())\n\n(str, list)\n\n\n\ndata = response.json()\n\nkospi = pd.DataFrame(data)[[\"localTradedAt\",\"closePrice\"]]\nkospi.head()\n\n\n\n\n\n\n\n\nlocalTradedAt\nclosePrice\n\n\n\n\n0\n2023-09-04\n2,579.39\n\n\n1\n2023-09-01\n2,563.71\n\n\n2\n2023-08-31\n2,556.27\n\n\n3\n2023-08-30\n2,561.22\n\n\n4\n2023-08-29\n2,552.16"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-4.-위-과정을-함수로-작성",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-4.-위-과정을-함수로-작성",
    "title": "00. 데이터 수집 (1)",
    "section": "step 4. 위 과정을 함수로 작성",
    "text": "step 4. 위 과정을 함수로 작성\n\ndef stock_crawling(page=1, pagesize=60) :\n    url = f'https://m.stock.naver.com/api/index/KOSPI/price?pageSize={pagesize}&page={page}'\n    response = requests.get(url)\n    data = response.json()\n    kospi = pd.DataFrame(data)[[\"localTradedAt\",\"closePrice\"]]\n    return kospi\n\n\nkospi = stock_crawling()"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#extra-코스닥-데이터-가져오기",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#extra-코스닥-데이터-가져오기",
    "title": "00. 데이터 수집 (1)",
    "section": "Extra : 코스닥 데이터 가져오기",
    "text": "Extra : 코스닥 데이터 가져오기\n\ndef stock_crawling2(code = \"KOSPI\",page=1, pagesize=60) :\n    url = f'https://m.stock.naver.com/api/index/{code}/price?pageSize={pagesize}&page={page}'\n    response = requests.get(url)\n    data = response.json()\n    kospi = pd.DataFrame(data)[[\"localTradedAt\",\"closePrice\"]]\n    return kospi\n\n\nkosdaq = stock_crawling2(code = \"KOSDAQ\")"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-5.-원달러-환율-데이터-수집하기",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-5.-원달러-환율-데이터-수집하기",
    "title": "00. 데이터 수집 (1)",
    "section": "step 5. 원달러 환율 데이터 수집하기",
    "text": "step 5. 원달러 환율 데이터 수집하기\n- 뼈대\n\npage = 1\nurl = f\"https://m.stock.naver.com/front-api/v1/marketIndex/prices?page={page}&category=exchange&reutersCode=FX_USDKRW\"\n\nresponse = requests.get(url)\n\nusd = pd.DataFrame(response.json()[\"result\"])[[\"localTradedAt\",\"closePrice\"]]\nusd.tail()\n\n\n\n\n\n\n\n\nlocalTradedAt\nclosePrice\n\n\n\n\n5\n2023-08-28\n1,326.00\n\n\n6\n2023-08-25\n1,327.00\n\n\n7\n2023-08-24\n1,325.00\n\n\n8\n2023-08-23\n1,335.00\n\n\n9\n2023-08-22\n1,339.50\n\n\n\n\n\n\n\n- pagesize = 60 설정\n\npage = 1\npagesize = 60\nurl = f\"https://m.stock.naver.com/front-api/v1/marketIndex/prices?page={page}&category=exchange&reutersCode=FX_USDKRW&pageSize={pagesize}\"\n\nresponse = requests.get(url)\n\nusd = pd.DataFrame(response.json()[\"result\"])[[\"localTradedAt\",\"closePrice\"]]\nusd.tail()\n\n\n\n\n\n\n\n\nlocalTradedAt\nclosePrice\n\n\n\n\n55\n2023-06-16\n1,280.00\n\n\n56\n2023-06-15\n1,277.00\n\n\n57\n2023-06-14\n1,275.00\n\n\n58\n2023-06-13\n1,272.00\n\n\n59\n2023-06-12\n1,290.00"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-6.-시각화",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-6.-시각화",
    "title": "00. 데이터 수집 (1)",
    "section": "step 6. 시각화",
    "text": "step 6. 시각화\n\n(1) 데이터 전처리\n\ndf = kospi.copy()\ndf.columns = [\"date\",\"kospi\"]\ndf[\"kosdaq\"] = kosdaq[\"closePrice\"]\ndf[\"usd\"] = usd[\"closePrice\"]\ndf.head()\n\n\n\n\n\n\n\n\ndate\nkospi\nkosdaq\nusd\n\n\n\n\n0\n2023-09-04\n2,584.55\n919.16\n1,320.50\n\n\n1\n2023-09-01\n2,563.71\n919.74\n1,321.50\n\n\n2\n2023-08-31\n2,556.27\n928.40\n1,325.00\n\n\n3\n2023-08-30\n2,561.22\n923.81\n1,322.00\n\n\n4\n2023-08-29\n2,552.16\n916.24\n1,325.00\n\n\n\n\n\n\n\n\ntemp = df.iloc[:,1:].applymap(lambda x : float(x.replace(\",\",\"\")))\n_df = pd.concat([df[\"date\"],temp],axis=1)\n_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 60 entries, 0 to 59\nData columns (total 4 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   date    60 non-null     object \n 1   kospi   60 non-null     float64\n 2   kosdaq  60 non-null     float64\n 3   usd     60 non-null     float64\ndtypes: float64(3), object(1)\nmemory usage: 2.0+ KB\n\n\n\n_df.head()\n\n\n\n\n\n\n\n\ndate\nkospi\nkosdaq\nusd\n\n\n\n\n0\n2023-09-04\n2584.55\n919.16\n1320.5\n\n\n1\n2023-09-01\n2563.71\n919.74\n1321.5\n\n\n2\n2023-08-31\n2556.27\n928.40\n1325.0\n\n\n3\n2023-08-30\n2561.22\n923.81\n1322.0\n\n\n4\n2023-08-29\n2552.16\n916.24\n1325.0\n\n\n\n\n\n\n\n\n\n(2) 시각화\n\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(14,5))\nplt.plot(_df[\"date\"], _df.kospi)\nplt.plot(_df[\"date\"], _df.kosdaq)\nplt.plot(_df[\"date\"], _df.usd)\nplt.xticks(_df[\"date\"].values[::5])\nplt.show()\n\n\n\n\n\n\n(3) 데이터 스케일링 + 시각화\n\nfrom sklearn.preprocessing import minmax_scale\n\n\nplt.figure(figsize=(14,5))\nplt.plot(_df[\"date\"], minmax_scale(_df.kospi))\nplt.plot(_df[\"date\"], minmax_scale(_df.kosdaq))\nplt.plot(_df[\"date\"], minmax_scale(_df.usd))\nplt.xticks(_df[\"date\"].values[::5])\nplt.show()"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-7.-상관분석",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#step-7.-상관분석",
    "title": "00. 데이터 수집 (1)",
    "section": "step 7. 상관분석",
    "text": "step 7. 상관분석\n\n_df.corr()\n\n\n\n\n\n\n\n\nkospi\nkosdaq\nusd\n\n\n\n\nkospi\n1.000000\n0.435544\n-0.777496\n\n\nkosdaq\n0.435544\n1.000000\n-0.163426\n\n\nusd\n-0.777496\n-0.163426\n1.000000"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#다음-환율-조사",
    "href": "posts/DX/03. 데이터 수집/2023-09-04-00. 데이터 수집 (1).html#다음-환율-조사",
    "title": "00. 데이터 수집 (1)",
    "section": "다음 환율 조사",
    "text": "다음 환율 조사\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport requests\n\n\n1. 웹서비스 분석 : URL 찾기\n\nurl = \"https://finance.daum.net/api/exchanges/summaries\"\n\n\n\n2. response\n- 403 error가 뜬다? 현재 user-agent가 python으로 찍혀서 그럼\nresponse = requests.get(url) response\n- User-Agent를 같이 보내주어야 한다! (크롤링 소스를 잘보자….)\n- 근데도 403 error가 뜬다….\n\nheaders = {\n\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\\\n                Chrome/116.0.0.0 Safari/537.36\",}\n\nresponse = requests.get(url, headers = headers)\nresponse\n\n&lt;Response [403]&gt;\n\n\n- Referer도 추가해야한다. 근데 이런 방법을 알려면 노가다로 다 넣어서 찾아야한다.\n\nheaders = {\n\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\\\n                Chrome/116.0.0.0 Safari/537.36\",\n\"Referer\" : \"https://finance.daum.net/exchanges\" }\n\nresponse = requests.get(url, headers = headers)\nresponse\n\n&lt;Response [200]&gt;\n\n\n- 드디어 성공 !\n\nresponse.text[:500]\n\n'{\"data\":[{\"symbolCode\":\"FRX.KRWUSD\",\"date\":\"2023-09-04 16:53:55\",\"currencyCode\":\"USD\",\"currencyName\":\"달러\",\"currencyUnit\":1,\"country\":\"미국\",\"region\":{\"korName\":\"아메리카\",\"engName\":\"America\"},\"name\":\"미국 (USD/KRW)\",\"recurrenceCount\":372,\"basePrice\":1320.5,\"change\":\"FALL\",\"changePrice\":1.0,\"changeRate\":0.0007567159,\"cashBuyingPrice\":1343.6,\"cashSellingPrice\":1297.4,\"ttBuyingPrice\":1307.6,\"ttSellingPrice\":1333.4,\"tcBuyingPrice\":null,\"fcSellingPrice\":null,\"exchangeCommission\":7.1789,\"usDollarRate\":1.0,\"ch'\n\n\n\n\n3. 데이터 파싱\n\ndf = pd.DataFrame(response.json()[\"data\"])[[\"symbolCode\",\"currencyCode\",\"basePrice\"]]\ndf.head()\n\n\n\n\n\n\n\n\nsymbolCode\ncurrencyCode\nbasePrice\n\n\n\n\n0\nFRX.KRWUSD\nUSD\n1320.50\n\n\n1\nFRX.KRWJPY\nJPY\n901.70\n\n\n2\nFRX.KRWCNY\nCNY\n181.52\n\n\n3\nFRX.KRWEUR\nEUR\n1426.14\n\n\n4\nFRX.KRWGBP\nGBP\n1667.00"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html",
    "title": "01. 데이터 분석 (2)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'Malgun Gothic'\nplt.rcParams['axes.unicode_minus'] = False\n\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport scipy.stats as spst"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#pairplot좋아하는-plot은-아님",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#pairplot좋아하는-plot은-아님",
    "title": "01. 데이터 분석 (2)",
    "section": "pairplot(좋아하는 plot은 아님)",
    "text": "pairplot(좋아하는 plot은 아님)\n\nsns.pairplot(air, kind='reg' )\nplt.show()\n\nC:\\Users\\rkdcj\\anaconda3\\envs\\dx\\Lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning:\n\nThe figure layout has changed to tight"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#joinplot",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#joinplot",
    "title": "01. 데이터 분석 (2)",
    "section": "joinplot",
    "text": "joinplot\n\nsns.jointplot(x='Temp', y='Ozone', data = air)\nplt.show()\n\n\n\n\n\nsns.jointplot(x='Wind', y='Ozone', data = air)\nplt.show()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#regplot",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#regplot",
    "title": "01. 데이터 분석 (2)",
    "section": "regplot",
    "text": "regplot\n\nsns.regplot(x='Solar.R', y='Ozone', data = air)\nplt.show()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#상관계수-계산",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#상관계수-계산",
    "title": "01. 데이터 분석 (2)",
    "section": "상관계수 계산",
    "text": "상관계수 계산\n\nimport scipy.stats as spst\n\n\nspst.pearsonr(air.Temp,air.Ozone)\n\nPearsonRResult(statistic=0.6833717861490115, pvalue=2.197769800200287e-22)\n\n\n\nspst.pearsonr(air.Wind,air.Ozone)\n\nPearsonRResult(statistic=-0.6054782354684076, pvalue=1.1255146087637929e-16)\n\n\n\nair.corr()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nDate\n\n\n\n\nOzone\n1.000000\n0.280068\n-0.605478\n0.683372\n0.170271\n\n\nSolar.R\n0.280068\n1.000000\n-0.056792\n0.275840\n-0.104682\n\n\nWind\n-0.605478\n-0.056792\n1.000000\n-0.457988\n-0.168683\n\n\nTemp\n0.683372\n0.275840\n-0.457988\n1.000000\n0.385605\n\n\nDate\n0.170271\n-0.104682\n-0.168683\n0.385605\n1.000000"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#heatmap",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#heatmap",
    "title": "01. 데이터 분석 (2)",
    "section": "heatmap",
    "text": "heatmap\n\nplt.figure(figsize = (4, 4))\nsns.heatmap(air.corr(),\n            annot = True,            # 숫자(상관계수) 표기 여부\n            fmt = '.3f',             # 숫자 포멧 : 소수점 3자리까지 표기\n            cmap = 'RdYlBu_r',       # 칼라맵\n            vmin = -1, vmax = 1)     # 값의 최소, 최대값\nplt.show()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#import-1",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#import-1",
    "title": "01. 데이터 분석 (2)",
    "section": "import",
    "text": "import\n\nimport pandas as pd\nimport numpy as np\nimport random as rd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport scipy.stats as spst"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#분산과-표준편차",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#분산과-표준편차",
    "title": "01. 데이터 분석 (2)",
    "section": "분산과 표준편차",
    "text": "분산과 표준편차\n\n값들이 평균으로부터 얼마나 벗어나 있느지를 나타내는 값.\n위 값들은 집단간 평균 비교시 사용되는 값들이다."
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#표준오차",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#표준오차",
    "title": "01. 데이터 분석 (2)",
    "section": "표준오차",
    "text": "표준오차\n\\[\\text{표준오차} = \\frac{s}{\\sqrt n},\\quad \\text{표본분산}=  s^2 = \\frac{\\sum (x-\\bar x )^2}{n-1}\\]\n- 표본의 분산을 \\(n-1\\)로 나누는 이유"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#신뢰구간",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#신뢰구간",
    "title": "01. 데이터 분석 (2)",
    "section": "95%신뢰구간",
    "text": "95%신뢰구간\n\nrd.normalvariate?\n\n1 평균이 172, 표준편차가 1인 표본을 800,000개 추출\n\npop = [round(rd.normalvariate(172, 7),1) for i in range(800000)]\n\n\nsns.histplot(pop, bins = 100)\nplt.axvline(np.mean(pop), color = 'r')\nplt.text(np.mean(pop)+1, 30000, f'pop mean : {np.mean(pop).round(3)}', color = 'r')\nplt.show()\n\n\n\n\n2 . 50개씩 데이터를 추출 후 표본 평균을 계산\n\nx_mean = []\nfor i in range(100):\n    s1 = rd.sample(pop, 50)\n    s1 = pd.Series(s1)\n    x_mean.append(round(s1.mean(),3))\n\n\nplt.figure(figsize=(10,6))\nsns.kdeplot(x_mean)\nplt.axvline(np.mean(x_mean), color = 'r')\nplt.text(np.mean(x_mean)+1, 0.1, f'pop mean : {round(np.mean(x_mean),3)}', color = 'r')\n\nText(172.92226, 0.1, 'pop mean : 171.922')"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#중심극한-정리",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#중심극한-정리",
    "title": "01. 데이터 분석 (2)",
    "section": "중심극한 정리",
    "text": "중심극한 정리\n- \\(n\\)의 크기가 충분히 크면 표본평균의 분포는 정규분포로 수렴한다.\n\n조건 1 : 데이터의 수가 충분히 커야함\n조건 2 : 추출된 표본들은 서로 독립이어야 한다.\n\n\n표본평균의 분포\n\npop = [round(rd.expovariate(.3)+165,2) for i in range(10001)]\n\n\n# 표본의 크기\nn = 100\n\n# 표본의 갯수\nm = 200\n\nsample_mean = [np.mean(rd.sample(pop,n)) for i in range(m)]\n\nplt.figure(figsize=(10,6))\nsns.kdeplot(sample_mean)\n\nplt.axvline(x=np.mean(sample_mean), color = 'red') #표본평균들의 평균\nplt.axvline(x=np.mean(pop), color = 'grey') # 모평균\n\nplt.text(np.mean(sample_mean)-.2, 0.02, round(np.mean(sample_mean),3), color = 'red') #표본평균들의 평균\nplt.text(np.mean(pop)+.1,0.02, round(np.mean(pop),3), color = 'grey') #모평균\n\nText(168.4570502949705, 0.02, '168.357')\n\n\n\n\n\n\n\n모집단의 분포\n\nplt.figure(figsize=(10,6)) #설정\nsns.histplot(pop, bins = 100)\nplt.axvline(x=np.mean(pop), color = 'grey') # 모평균\nplt.text(np.mean(pop)+.5, 800, round(np.mean(pop),2), color = 'grey')\nplt.show()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#데이터-로드",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#데이터-로드",
    "title": "01. 데이터 분석 (2)",
    "section": "1. 데이터 로드",
    "text": "1. 데이터 로드\n\ntitanic = pd.read_csv('https://raw.githubusercontent.com/DA4BAM/dataset/master/titanic.1.csv')"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#교차표-생성",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#교차표-생성",
    "title": "01. 데이터 분석 (2)",
    "section": "2. 교차표 생성",
    "text": "2. 교차표 생성\n- 생존과 성별 변수로 교차표를 생성\n\n# 두 범주별 빈도수를 교차표로 만들어 봅시다.\npd.crosstab(titanic['Survived'], titanic['Sex'])\n\n\n\n\n\n\n\nSex\nfemale\nmale\n\n\nSurvived\n\n\n\n\n\n\n0\n81\n468\n\n\n1\n233\n109\n\n\n\n\n\n\n\n- 열별 비율\n\npd.crosstab(titanic['Survived'], titanic['Sex'], normalize = 'columns')\n\n\n\n\n\n\n\nSex\nfemale\nmale\n\n\nSurvived\n\n\n\n\n\n\n0\n0.257962\n0.811092\n\n\n1\n0.742038\n0.188908\n\n\n\n\n\n\n\n- index별 비율\n\npd.crosstab(titanic['Survived'], titanic['Sex'], normalize = 'index')\n\n\n\n\n\n\n\nSex\nfemale\nmale\n\n\nSurvived\n\n\n\n\n\n\n0\n0.147541\n0.852459\n\n\n1\n0.681287\n0.318713\n\n\n\n\n\n\n\n- (행,열)별 전체 비율\n\npd.crosstab(titanic['Survived'], titanic['Embarked'], normalize = 'all')\n\n\n\n\n\n\n\nEmbarked\nC\nQ\nS\n\n\nSurvived\n\n\n\n\n\n\n\n0\n0.084175\n0.05275\n0.479237\n\n\n1\n0.104377\n0.03367\n0.245791\n\n\n\n\n\n\n\n\nx축의 길이는 각 객실 등급별 승객 비율을 표시\ny축의 길이는 각 객실 등급별 사망 및 생존 비율을 의미한다.\n\n\n# Pclass별 생존여부를 mosaic plot으로 그려 봅시다.\nmosaic(titanic, [ 'Pclass','Survived'])\nplt.axhline(1- titanic['Survived'].mean(), color = 'r')\n\n&lt;matplotlib.lines.Line2D at 0x2c073331350&gt;\n\n\n\n\n\n\ntemp = pd.crosstab(titanic['Pclass'], titanic['Survived'], normalize = 'index')\nprint(temp)\ntemp.plot.bar(stacked=True)\nplt.axhline(1-titanic['Survived'].mean(), color = 'r')\n\nSurvived         0         1\nPclass                      \n1         0.370370  0.629630\n2         0.527174  0.472826\n3         0.757637  0.242363\n\n\n&lt;matplotlib.lines.Line2D at 0x2c0729818d0&gt;"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#카이제곱검정",
    "href": "posts/DX/02. 데이터 분석/2023-08-29-01. 데이터 분석 (2).html#카이제곱검정",
    "title": "01. 데이터 분석 (2)",
    "section": "3. 카이제곱검정",
    "text": "3. 카이제곱검정\n- A와 B라는 두 개의 범주형 변수가 존재할 때\n\n두 변수들 사이의 관계가 독립인지 아닌지 검정\n\n\\[H_0 : \\text{두 변수는 독립이다.}\\quad H_1 : \\text{두 변수는 독립이 아니다.}\\]\n\\[\\text {카이제곱 통계량} : \\chi^2 [(p-1)(q-1),\\alpha]= \\sum_{p=1}^P\\sum_{q=1}^Q\\frac {(\\text{관측빈도-기대빈도)}^2}{기대빈도}\\]\n\\[p,q  = \\text {각 범주의 클래스의 수}\\]\n\\[n=(p-1)(q-1)\\to \\text{자유도}\\]\n\\[\\text{기대빈도}= \\frac{\\text{sum}(p=i) \\times \\text{sum}(q=i)}{\\text{total sum}}\\]\n\n카이제곱통계량 계산(손계산)\n1. 기대빈도 계산\n\ntem = titanic.groupby([\"Pclass\",\"Survived\"],as_index=False)[[\"Pclass\"]].value_counts()\ntem.rename(columns = {\"count\": \"관측빈도\"},inplace=True)\n\n\ntem\n\n\n\n\n\n\n\n\nPclass\nSurvived\n관측빈도\n\n\n\n\n0\n1\n0\n80\n\n\n1\n1\n1\n136\n\n\n2\n2\n0\n97\n\n\n3\n2\n1\n87\n\n\n4\n3\n0\n372\n\n\n5\n3\n1\n119\n\n\n\n\n\n\n\n\ntem1  = tem.groupby([\"Pclass\"],as_index=False)[[\"관측빈도\"]].sum().rename(columns ={\"관측빈도\" : \"P_total\"})\ntem2  = tem.groupby([\"Survived\"],as_index=False)[[\"관측빈도\"]].sum().rename(columns ={\"관측빈도\" : \"S_total\"})\n\n\ntotal = pd.merge(pd.merge(tem,tem1),tem2)\n\n\ntotal[\"total\"] =sum(total.S_total.unique())\n\n\ntotal[\"기대빈도\"] = total.P_total*total.S_total/total.total\n\n\ntotal\n\n\n\n\n\n\n\n\nPclass\nSurvived\n관측빈도\nP_total\nS_total\ntotal\n기대빈도\n\n\n\n\n0\n1\n0\n80\n216\n549\n891\n133.090909\n\n\n1\n2\n0\n97\n184\n549\n891\n113.373737\n\n\n2\n3\n0\n372\n491\n549\n891\n302.535354\n\n\n3\n1\n1\n136\n216\n342\n891\n82.909091\n\n\n4\n2\n1\n87\n184\n342\n891\n70.626263\n\n\n5\n3\n1\n119\n491\n342\n891\n188.464646\n\n\n\n\n\n\n\n2. 카이제곱 통계량 계산\n\npd.crosstab(titanic['Survived'], titanic['Pclass'])\n\n\n\n\n\n\n\nPclass\n1\n2\n3\n\n\nSurvived\n\n\n\n\n\n\n\n0\n80\n97\n372\n\n\n1\n136\n87\n119\n\n\n\n\n\n\n\n\nchi_s = sum(((total[\"관측빈도\"] - total[\"기대빈도\"])**2)/total[\"기대빈도\"])\nchi_s\n\n102.88898875696056\n\n\n\nalpha = 0.05 ## 유의수준\n\n\na2 = spst.chi2.ppf(1-alpha/2,2) ## 기각영역1\na1 = spst.chi2.ppf(alpha/2,2) ## 기각영역 2\n\n(a1,a2)\n\n(0.05063561596857975, 7.377758908227871)\n\n\n\nx = np.linspace(0,110,10000) ## 임의의 x생성\ns = spst.chi2.pdf(x,2) ## x에 따른 카이제곱 분포 생성\n\n\n\nCode\nplt.plot(x,s,\".r\",alpha=0.2)\nplt.plot(x[(x&gt;a1) & (x&lt;a2)],s[(x&gt;a1) & (x&lt;a2)],\".b\",alpha=0.3)\nplt.axvline(x=chi_s,color=\"b\",linestyle = \":\")\nplt.text(chi_s-15,.4, r\"계산된 $\\chi$ 의 위치 \"+\" \\n = \"+str(round(chi_s,2)))\nplt.legend([\"빨강(기각영역)\",\"파랑(신뢰구간)\"])\n\n\n&lt;matplotlib.legend.Legend at 0x2c072976190&gt;\n\n\n\n\n\n\n\n카이제곱통계량 계산(함수이용)\n\ntable = pd.crosstab(titanic['Survived'], titanic['Pclass'])\nprint(table)\nprint(\"\\n\",'-' * 50)\n\n# 2) 카이제곱검정\nspst.chi2_contingency(table)\n\nPclass      1   2    3\nSurvived              \n0          80  97  372\n1         136  87  119\n\n --------------------------------------------------\n\n\nChi2ContingencyResult(statistic=102.88898875696056, pvalue=4.549251711298793e-23, dof=2, expected_freq=array([[133.09090909, 113.37373737, 302.53535354],\n       [ 82.90909091,  70.62626263, 188.46464646]]))"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html",
    "title": "04. numpy & pandas (5)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#데이터-프레임-합치기-axis1",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#데이터-프레임-합치기-axis1",
    "title": "04. numpy & pandas (5)",
    "section": "데이터 프레임 합치기 (axis=1)",
    "text": "데이터 프레임 합치기 (axis=1)\n- axis=1 \\(\\to\\) 옆으로 붙임\n\n_df = pd.concat([pop1,pop2],axis=1,join=\"outer\")\n\n\n_df.head()\n\n\n\n\n\n\n\n\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n1981\n4160\n4191\nNaN\nNaN\n\n\n1982\n4160\n4191\nNaN\nNaN\n\n\n1983\n4160\n4191\nNaN\nNaN\n\n\n1984\n4160\n4191\nNaN\nNaN\n\n\n1985\n4160\n4191\n7.0\n6.0\n\n\n\n\n\n\n\n- 데이터를 합친 결과 : pop02 에는 1981~1984년 데이터가 없어 결측치가 생긴다.\n\njoin = \"inner\"옵션을 주면 매핑이 되지 않은 데이터는 제거해서 보여준다.\n\n\n_df = pd.concat([pop1,pop2],axis=1,join=\"inner\")\n\n\n_df.head()\n\n\n\n\n\n\n\n\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n1985\n4160\n4191\n7\n6\n\n\n1986\n4899\n4888\n7\n5\n\n\n1987\n5000\n4979\n6\n5\n\n\n1988\n5156\n5120\n5\n5\n\n\n1989\n5305\n5261\n6\n5"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#데이터-프레임-합치기-axis0",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#데이터-프레임-합치기-axis0",
    "title": "04. numpy & pandas (5)",
    "section": "데이터 프레임 합치기 (axis=0)",
    "text": "데이터 프레임 합치기 (axis=0)\n- axis = 0은 생략가능하다. \\(\\to\\) 세로로 합치기\n\n# 서울 인구정보 읽어오기 #1\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/seoul_pop_v01.csv'\npop1 = pd.read_csv(path)\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/seoul_pop_v02.csv'\npop2 = pd.read_csv(path)\n\n\npop1.head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1985\n4788\n4838\n7\n6\n\n\n1\n1986\n4899\n4888\n7\n5\n\n\n2\n1987\n5000\n4979\n6\n5\n\n\n3\n1988\n5156\n5120\n5\n5\n\n\n4\n1989\n5305\n5261\n6\n5\n\n\n\n\n\n\n\n\npop2.head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n2001\n5142\n5122\n34\n34\n\n\n1\n2002\n5109\n5098\n36\n37\n\n\n2\n2003\n5085\n5089\n49\n54\n\n\n3\n2004\n5075\n5098\n54\n61\n\n\n4\n2005\n5062\n5105\n61\n68\n\n\n\n\n\n\n\n\n pd.concat([pop1,pop2],axis=0,join=\"outer\").head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1985\n4788\n4838\n7\n6\n\n\n1\n1986\n4899\n4888\n7\n5\n\n\n2\n1987\n5000\n4979\n6\n5\n\n\n3\n1988\n5156\n5120\n5\n5\n\n\n4\n1989\n5305\n5261\n6\n5\n\n\n\n\n\n\n\n\n pd.concat([pop1,pop2],axis=0,join=\"inner\").head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1985\n4788\n4838\n7\n6\n\n\n1\n1986\n4899\n4888\n7\n5\n\n\n2\n1987\n5000\n4979\n6\n5\n\n\n3\n1988\n5156\n5120\n5\n5\n\n\n4\n1989\n5305\n5261\n6\n5"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#inner-join",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#inner-join",
    "title": "04. numpy & pandas (5)",
    "section": "inner join",
    "text": "inner join\n\n같은 이름의 열이 있으면 on옵션을 지정하지 않아도 해당 열을 기준으로 합침\nhow=\"inner\" 옵션은 디폴트 옵션!\n\n\npop = pd.merge(pop1,pop2, on =\"year\",how = \"inner\")\n\n\npop.head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1985\n4160\n4191\n7\n6\n\n\n1\n1986\n4899\n4888\n7\n5\n\n\n2\n1987\n5000\n4979\n6\n5\n\n\n3\n1988\n5156\n5120\n5\n5\n\n\n4\n1989\n5305\n5261\n6\n5"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#outer-join",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#outer-join",
    "title": "04. numpy & pandas (5)",
    "section": "outer join",
    "text": "outer join\n\nhow=\"outer\" 와 how=\"left\"의 조인 결과는 동일하다.\n\n\npop = pd.merge(pop1,pop2, on =\"year\",how = \"outer\")\n\n\npop.head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1981\n4160\n4191\nNaN\nNaN\n\n\n1\n1982\n4160\n4191\nNaN\nNaN\n\n\n2\n1983\n4160\n4191\nNaN\nNaN\n\n\n3\n1984\n4160\n4191\nNaN\nNaN\n\n\n4\n1985\n4160\n4191\n7.0\n6.0\n\n\n\n\n\n\n\n\npop = pd.merge(pop1,pop2, on =\"year\",how = \"left\")\n\n\npop.head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1981\n4160\n4191\nNaN\nNaN\n\n\n1\n1982\n4160\n4191\nNaN\nNaN\n\n\n2\n1983\n4160\n4191\nNaN\nNaN\n\n\n3\n1984\n4160\n4191\nNaN\nNaN\n\n\n4\n1985\n4160\n4191\n7.0\n6.0"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#join의-또-다른-방법",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#join의-또-다른-방법",
    "title": "04. numpy & pandas (5)",
    "section": "join의 또 다른 방법",
    "text": "join의 또 다른 방법\n\npop1.join(pop2.set_index(\"year\"),on=\"year\",how=\"outer\").head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n0\n1981\n4160\n4191\nNaN\nNaN\n\n\n1\n1982\n4160\n4191\nNaN\nNaN\n\n\n2\n1983\n4160\n4191\nNaN\nNaN\n\n\n3\n1984\n4160\n4191\nNaN\nNaN\n\n\n4\n1985\n4160\n4191\n7.0\n6.0\n\n\n\n\n\n\n\n\npop1.join(pop2.set_index(\"year\"),on=\"year\",how=\"inner\").head()\n\n\n\n\n\n\n\n\nyear\nk_male\nk_female\nf_male\nf_female\n\n\n\n\n4\n1985\n4160\n4191\n7\n6\n\n\n5\n1986\n4899\n4888\n7\n5\n\n\n6\n1987\n5000\n4979\n6\n5\n\n\n7\n1988\n5156\n5120\n5\n5\n\n\n8\n1989\n5305\n5261\n6\n5"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#setting",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#setting",
    "title": "04. numpy & pandas (5)",
    "section": "setting",
    "text": "setting\n\n# 폰트설정\nplt.rcParams['font.family'] = 'Malgun Gothic'\nplt.rcParams['axes.unicode_minus'] = False"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#test",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-23-04. numpy & pandas (5).html#test",
    "title": "04. numpy & pandas (5)",
    "section": "test",
    "text": "test\n\nx = [1,2,3,4]\ny = [1,2,4,4]\n\n\nplt.plot(x,y)\nplt.xlabel(\"x축\")\nplt.ylabel(\"y축\")\n\nText(0, 0.5, 'y축')"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html",
    "title": "02. numpy & pandas (3)",
    "section": "",
    "text": "import plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#plotly-test",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#plotly-test",
    "title": "02. numpy & pandas (3)",
    "section": "plotly test",
    "text": "plotly test\n\ntip.plot.box(backend = \"plotly\",\n            x = \"time\",\n            y = \"tip\", color = \"sex\")"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#열-조회",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#열-조회",
    "title": "02. numpy & pandas (3)",
    "section": "열 조회",
    "text": "열 조회\n\ntip.loc[:,[\"total_bill\"]].head()\n\n\n\n\n\n\n\n\ntotal_bill\n\n\n\n\n0\n16.99\n\n\n1\n10.34\n\n\n2\n21.01\n\n\n3\n23.68\n\n\n4\n24.59\n\n\n\n\n\n\n\n\ntip.loc[:,[\"tip\",\"total_bill\"]].head()\n\n\n\n\n\n\n\n\ntip\ntotal_bill\n\n\n\n\n0\n1.01\n16.99\n\n\n1\n1.66\n10.34\n\n\n2\n3.50\n21.01\n\n\n3\n3.31\n23.68\n\n\n4\n3.61\n24.59\n\n\n\n\n\n\n\n\ntip.loc[:,[\"tip\",\"day\",\"total_bill\"]].sort_values(\"tip\",ascending=False)\n\n\n\n\n\n\n\n\ntip\nday\ntotal_bill\n\n\n\n\n170\n10.00\nSat\n50.81\n\n\n212\n9.00\nSat\n48.33\n\n\n23\n7.58\nSat\n39.42\n\n\n59\n6.73\nSat\n48.27\n\n\n141\n6.70\nThur\n34.30\n\n\n...\n...\n...\n...\n\n\n0\n1.01\nSun\n16.99\n\n\n236\n1.00\nSat\n12.60\n\n\n111\n1.00\nSat\n7.25\n\n\n67\n1.00\nSat\n3.07\n\n\n92\n1.00\nFri\n5.75\n\n\n\n\n244 rows × 3 columns\n\n\n\n- 인덱스 제거\n\ntip.loc[:,[\"tip\",\"day\",\"total_bill\"]].\\\n        sort_values(\"tip\",ascending=False).\\\n            reset_index(drop=True)\n\n\n\n\n\n\n\n\ntip\nday\ntotal_bill\n\n\n\n\n0\n10.00\nSat\n50.81\n\n\n1\n9.00\nSat\n48.33\n\n\n2\n7.58\nSat\n39.42\n\n\n3\n6.73\nSat\n48.27\n\n\n4\n6.70\nThur\n34.30\n\n\n...\n...\n...\n...\n\n\n239\n1.01\nSun\n16.99\n\n\n240\n1.00\nSat\n12.60\n\n\n241\n1.00\nSat\n7.25\n\n\n242\n1.00\nSat\n3.07\n\n\n243\n1.00\nFri\n5.75\n\n\n\n\n244 rows × 3 columns\n\n\n\n- 열 범위 조회\n\ntip.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\ntip.loc[:,\"tip\":\"day\"].head()\n\n\n\n\n\n\n\n\ntip\nsex\nsmoker\nday\n\n\n\n\n0\n1.01\nFemale\nNo\nSun\n\n\n1\n1.66\nMale\nNo\nSun\n\n\n2\n3.50\nMale\nNo\nSun\n\n\n3\n3.31\nMale\nNo\nSun\n\n\n4\n3.61\nFemale\nNo\nSun"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#행-조회",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#행-조회",
    "title": "02. numpy & pandas (3)",
    "section": "행 조회",
    "text": "행 조회\n\n단일 조건 조회\n\ntip.loc[tip.tip&gt;6.0,:]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n141\n34.30\n6.70\nMale\nNo\nThur\nLunch\n6\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n183\n23.17\n6.50\nMale\nYes\nSun\nDinner\n4\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n\n\n\n\n\n\n\n\ntip.loc[map(lambda x : x &gt;6.0,tip.tip),:]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n141\n34.30\n6.70\nMale\nNo\nThur\nLunch\n6\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n183\n23.17\n6.50\nMale\nYes\nSun\nDinner\n4\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n\n\n\n\n\n\n\n\n\n여러 조건 조회\n- map(lambda)를 사용하지 않고 데이터 프레임을 필터링 할 때는 and 대신 &연산자를 사용해야함.\n\nor 도 | 으로 사용해야 한다.\n\n\ntip.loc[(tip.tip&gt;6.0) & (tip.day == \"Sat\"),:]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n\n\n\n\n\n\n\n\ntip.loc[(tip.tip&gt;6.0) & (tip.day == \"Sat\")]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n\n\n\n\n\n\n\n\ntip.loc[(tip.tip&gt;6.0) | (tip.day == \"Sat\")]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n\n\n20\n17.92\n4.08\nMale\nNo\nSat\nDinner\n2\n\n\n21\n20.29\n2.75\nFemale\nNo\nSat\nDinner\n2\n\n\n22\n15.77\n2.23\nFemale\nNo\nSat\nDinner\n2\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n\n\n89 rows × 7 columns\n\n\n\n\ntip.loc[map(lambda x,y : (x&gt;6.0) and (y == \"Sat\"),tip.tip, tip.day)]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n214\n28.17\n6.50\nFemale\nYes\nSat\nDinner\n3\n\n\n\n\n\n\n\n\ntip.loc[map(lambda x,y : (x&gt;6.0) or (y == \"Sat\"),tip.tip, tip.day)]\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n19\n20.65\n3.35\nMale\nNo\nSat\nDinner\n3\n\n\n20\n17.92\n4.08\nMale\nNo\nSat\nDinner\n2\n\n\n21\n20.29\n2.75\nFemale\nNo\nSat\nDinner\n2\n\n\n22\n15.77\n2.23\nFemale\nNo\nSat\nDinner\n2\n\n\n23\n39.42\n7.58\nMale\nNo\nSat\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n238\n35.83\n4.67\nFemale\nNo\nSat\nDinner\n3\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n\n\n89 rows × 7 columns\n\n\n\n\n\nisin(),between()\n\ntip.loc[tip.day.isin([\"Sat\",\"Sun\"]), :].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n- between(\\(x_1,x_2\\)) \\(\\to x_1 \\leq X \\leq x_2\\)\n\ntip.loc[tip.tip.between(1,2)].head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n6\n8.77\n2.00\nMale\nNo\nSun\nDinner\n2\n\n\n8\n15.04\n1.96\nMale\nNo\nSun\nDinner\n2\n\n\n10\n10.27\n1.71\nMale\nNo\nSun\nDinner\n2"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#특정-열의-합-구하기",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#특정-열의-합-구하기",
    "title": "02. numpy & pandas (3)",
    "section": "특정 열의 합 구하기",
    "text": "특정 열의 합 구하기\n- total_bill의 합계 구하기\n\ntip.total_bill.sum()\n\n4827.77\n\n\n- 두 열의 합계\n\ntip[[\"total_bill\",\"tip\"]].sum()\n\ntotal_bill    4827.77\ntip            731.58\ndtype: float64"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#특정-범주형-변수를-기준으로-합을-구하기",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#특정-범주형-변수를-기준으로-합을-구하기",
    "title": "02. numpy & pandas (3)",
    "section": "특정 범주형 변수를 기준으로 합을 구하기",
    "text": "특정 범주형 변수를 기준으로 합을 구하기\n- 방법 1\n\nas_index =True \\(\\to\\) 집계 기준이 되는 열이 인덱스로 설정됨\n\n\ntip.groupby(\"day\",as_index = True)[\"tip\"].sum()\n\nday\nFri      51.96\nSat     260.40\nSun     247.39\nThur    171.83\nName: tip, dtype: float64\n\n\n- 방법 2\n\ntip.groupby(\"day\",as_index = False)[\"tip\"].sum()\n\n\n\n\n\n\n\n\nday\ntip\n\n\n\n\n0\nFri\n51.96\n\n\n1\nSat\n260.40\n\n\n2\nSun\n247.39\n\n\n3\nThur\n171.83\n\n\n\n\n\n\n\n- 방법 3\n\ntip.groupby(\"day\").agg({\"tip\" : sum}).reset_index()\n\n\n\n\n\n\n\n\nday\ntip\n\n\n\n\n0\nFri\n51.96\n\n\n1\nSat\n260.40\n\n\n2\nSun\n247.39\n\n\n3\nThur\n171.83\n\n\n\n\n\n\n\n\n데이터 프레임으로 선언\n\ntip_sum = tip.groupby(\"day\").agg({\"tip\" : sum}).reset_index()\n\n\ntip_sum\n\n\n\n\n\n\n\n\nday\ntip\n\n\n\n\n0\nFri\n51.96\n\n\n1\nSat\n260.40\n\n\n2\nSun\n247.39\n\n\n3\nThur\n171.83\n\n\n\n\n\n\n\n\n\n집계 결과 시각화\n\nplt.figure(figsize=(4,2))\nplt.bar(x=tip_sum.day, height =tip_sum.tip)\nplt.title(\"Tips by day\",size =15,fontweight=\"bold\")\nplt.xlabel(\"Day\")\nplt.ylabel(\"tip\")\nplt.grid(axis=\"y\")\n\n\n\n\n- 가로 막대\n\nplt.figure(figsize=(4,2))\nplt.barh(y=tip_sum.day, width =tip_sum.tip)\nplt.title(\"Tips by day\",size =15,fontweight=\"bold\")\nplt.xlabel(\"Day\")\nplt.ylabel(\"tip\")\nplt.grid(axis=\"y\")\n\n\n\n\n- 색상 변경\n\nplt.figure(figsize=(4,2))\nplt.barh(y=tip_sum.day, width =tip_sum.tip,color= \"tab:orange\")\nplt.title(\"Tips by day\",size =15,fontweight=\"bold\")\nplt.xlabel(\"Day\")\nplt.ylabel(\"tip\")\n\nText(0, 0.5, 'tip')\n\n\n\n\n\n\n\nlineplot\n\nfig, axes =plt.subplots(1,2,figsize=(4,2))\n\nax1,ax2=axes\nax1.plot(tip.tip)\nax2.plot(tip[[\"total_bill\",\"tip\"]])\nax1.legend([\"tip\",\"tip & total_bill\"],loc=\"upper left\")\nax2.legend([\"tip\",\"tip & total_bill\"],loc=\"upper left\")\nfig.tight_layout()\n\n\n\n\n\n\nhist\n\nplt.figure(figsize=(4,2))\nplt.hist(tip.tip,alpha=0.3,bins=20)\nplt.title(\"hist of tip\")\nplt.axvline(tip.tip.median(),color=\"r\")\nplt.text(tip.tip.median()+1,30,tip.tip.median(),color=\"r\")\n\nText(3.9, 30, '2.9')"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#여러-열-집계",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-21-02. numpy & pandas (3).html#여러-열-집계",
    "title": "02. numpy & pandas (3)",
    "section": "여러 열 집계",
    "text": "여러 열 집계\n1. 특정 열을 지정 후 집계\n\n_ts = tip.groupby(\"day\").agg({\"total_bill\":sum,\n                         \"tip\" : sum  }).reset_index()\n_ts\n\n\n\n\n\n\n\n\nday\ntotal_bill\ntip\n\n\n\n\n0\nFri\n325.88\n51.96\n\n\n1\nSat\n1778.40\n260.40\n\n\n2\nSun\n1627.16\n247.39\n\n\n3\nThur\n1096.33\n171.83\n\n\n\n\n\n\n\n2 컬럼이 numeric인 열만 집계\n\ntip.groupby(\"day\",as_index= False).sum(numeric_only=True)\n\n\n\n\n\n\n\n\nday\ntotal_bill\ntip\nsize\n\n\n\n\n0\nFri\n325.88\n51.96\n40\n\n\n1\nSat\n1778.40\n260.40\n219\n\n\n2\nSun\n1627.16\n247.39\n216\n\n\n3\nThur\n1096.33\n171.83\n152\n\n\n\n\n\n\n\n3 일별, 흡연 여부를 포함하여 집계\n\n_ts = tip.groupby([\"day\",\"smoker\"],as_index=False).sum(numeric_only=True)\n_ts\n\n\n\n\n\n\n\n\nday\nsmoker\ntotal_bill\ntip\nsize\n\n\n\n\n0\nFri\nNo\n73.68\n11.25\n9\n\n\n1\nFri\nYes\n252.20\n40.71\n31\n\n\n2\nSat\nNo\n884.78\n139.63\n115\n\n\n3\nSat\nYes\n893.62\n120.77\n104\n\n\n4\nSun\nNo\n1168.88\n180.57\n167\n\n\n5\nSun\nYes\n458.28\n66.82\n49\n\n\n6\nThur\nNo\n770.09\n120.32\n112\n\n\n7\nThur\nYes\n326.24\n51.51\n40\n\n\n\n\n\n\n\n4 요일별 팁의 평균\n\ntip.groupby([\"day\"],as_index=False).agg({\"tip\" : np.mean})\n\n\n\n\n\n\n\n\nday\ntip\n\n\n\n\n0\nFri\n2.734737\n\n\n1\nSat\n2.993103\n\n\n2\nSun\n3.255132\n\n\n3\nThur\n2.771452\n\n\n\n\n\n\n\n5 day, sex별 모든 숫자 열의 평균\n\ntip.groupby([\"day\",\"sex\"],as_index=False).mean(numeric_only=True)\n\n\n\n\n\n\n\n\nday\nsex\ntotal_bill\ntip\nsize\n\n\n\n\n0\nFri\nFemale\n14.145556\n2.781111\n2.111111\n\n\n1\nFri\nMale\n19.857000\n2.693000\n2.100000\n\n\n2\nSat\nFemale\n19.680357\n2.801786\n2.250000\n\n\n3\nSat\nMale\n20.802542\n3.083898\n2.644068\n\n\n4\nSun\nFemale\n19.872222\n3.367222\n2.944444\n\n\n5\nSun\nMale\n21.887241\n3.220345\n2.810345\n\n\n6\nThur\nFemale\n16.715312\n2.575625\n2.468750\n\n\n7\nThur\nMale\n18.714667\n2.980333\n2.433333\n\n\n\n\n\n\n\n6 요일별 tip의 최대값 구하기\n\ntip.groupby([\"day\"],as_index=False).tip.max()\n\n\n\n\n\n\n\n\nday\ntip\n\n\n\n\n0\nFri\n4.73\n\n\n1\nSat\n10.00\n\n\n2\nSun\n6.50\n\n\n3\nThur\n6.70"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html",
    "title": "00. numpy & pandas (1)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#차원-배열의-선언",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#차원-배열의-선언",
    "title": "00. numpy & pandas (1)",
    "section": "(1) 1차원 배열의 선언",
    "text": "(1) 1차원 배열의 선언\n- 튜플\n\nnp.array((1,2,3))\n\narray([1, 2, 3])\n\n\n- 리스트\n\nnp.array([1,2,3])\n\narray([1, 2, 3])\n\n\n- range\n\nnp.array(range(10))\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\n알아두면 좋은 1차원 배열 선언\n\nnp.zeros(3)\n\narray([0., 0., 0.])\n\n\n\nnp.ones(3)\n\narray([1., 1., 1.])\n\n\n- np.linspace(2,8,4) : 2~8까지, 4개의 원소를 생성\n\nnp.linspace(2,8,4)\n\narray([2., 4., 6., 8.])\n\n\n- np.arange(start,end) : nump버전 range라고 생각하자!\n\nnp.arange(5), np.arange(1,6)\n\n(array([0, 1, 2, 3, 4]), array([1, 2, 3, 4, 5]))\n\n\n\n\n주의 1. 배열의 자료형\n- 숫자 \\(\\to\\) 문자\n\na = np.array([1,\"A\",3.0])\na\n\narray(['1', 'A', '3'], dtype='&lt;U11')\n\n\n- 정수 \\(\\to\\) 실수\n\na = np.array([1,2,3.0])\na\n\narray([1., 2., 3.])"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#차원-배열의-선언-1",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#차원-배열의-선언-1",
    "title": "00. numpy & pandas (1)",
    "section": "(2) 2차원 배열의 선언",
    "text": "(2) 2차원 배열의 선언\n\nlist\n\na1 = [[1,2,3],\n     [4,5,6]]\n\nnp.array(a1)\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\n\nstack\n\na1 = np.random.randint(0,9,3)\na2 = np.random.randint(0,9,3)\n\nA1 = np.stack([a1,a2],axis=0) \nA1, A1.shape\n\n(array([[0, 4, 2],\n        [3, 2, 3]]),\n (2, 3))\n\n\n\nA2 = np.stack([a1,a2],axis=1) \nA2, A2.shape\n\n(array([[0, 3],\n        [4, 2],\n        [2, 3]]),\n (3, 2))"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#차원-배열의-선언-2",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#차원-배열의-선언-2",
    "title": "00. numpy & pandas (1)",
    "section": "(3) 3차원 배열의 선언",
    "text": "(3) 3차원 배열의 선언\n\nlist\n\na = [[[1,2],[3,4]],[[5,6],[7,8]]]\nnp.array(a), np.array(a).shape\n\n(array([[[1, 2],\n         [3, 4]],\n \n        [[5, 6],\n         [7, 8]]]),\n (2, 2, 2))\n\n\n\n\nstack + reshape\n\na1 = np.random.randint(0,9,4)\na2 = np.random.randint(0,9,4)\na3 = np.random.randint(0,9,4)\n\nA1 = np.stack([a1,a2,a3],axis=0).reshape(2,3,2)\nA1, A1.shape\n\n(array([[[8, 8],\n         [4, 0],\n         [6, 8]],\n \n        [[8, 4],\n         [0, 1],\n         [1, 6]]]),\n (2, 3, 2))\n\n\n\nA1.dtype\n\ndtype('int32')"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#행-조회",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#행-조회",
    "title": "00. numpy & pandas (1)",
    "section": "행 조회",
    "text": "행 조회\n\nA1[0:2,]\n\narray([[8, 8, 7],\n       [3, 1, 1]])\n\n\n\nA1[[0,1,2]]\n\narray([[8, 8, 7],\n       [3, 1, 1],\n       [3, 5, 7]])\n\n\n\nA1[[0,1,2], : ]\n\narray([[8, 8, 7],\n       [3, 1, 1],\n       [3, 5, 7]])"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#열-조회",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#열-조회",
    "title": "00. numpy & pandas (1)",
    "section": "열 조회",
    "text": "열 조회\n\nA1[:,0:2]\n\narray([[8, 8],\n       [3, 1],\n       [3, 5],\n       [7, 8]])\n\n\n\nA1[:,[0,1,2]]\n\narray([[8, 8, 7],\n       [3, 1, 1],\n       [3, 5, 7],\n       [7, 8, 6]])"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#행열-조회",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#행열-조회",
    "title": "00. numpy & pandas (1)",
    "section": "행,열 조회",
    "text": "행,열 조회\n\nA1[0:2,0:2]\n\narray([[8, 8],\n       [3, 1]])"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#stride-start-end-interval",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#stride-start-end-interval",
    "title": "00. numpy & pandas (1)",
    "section": "stride( start :end : interval)",
    "text": "stride( start :end : interval)\n\nA1\n\narray([[8, 8, 7],\n       [3, 1, 1],\n       [3, 5, 7],\n       [7, 8, 6]])\n\n\n\nA1[::2, ::2]\n\narray([[8, 7],\n       [3, 7]])"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#특정값을-지정하여-접근",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#특정값을-지정하여-접근",
    "title": "00. numpy & pandas (1)",
    "section": "특정값을 지정하여 접근",
    "text": "특정값을 지정하여 접근\n\nA1\n\narray([[8, 8, 7],\n       [3, 1, 1],\n       [3, 5, 7],\n       [7, 8, 6]])\n\n\n\nA1[A1==1]\n\narray([1, 1])\n\n\n\nA1[A1==7]\n\narray([7, 7, 7])"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#기본-연산",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#기본-연산",
    "title": "00. numpy & pandas (1)",
    "section": "기본 연산",
    "text": "기본 연산\n\na = np.array([1,2,3])\n\n\n\nCode\nprint(f'''\n1. 사칙연산 \n\na + 1 = {a+1}\na - 2 = {a-2}\na x 2 = {a*2}\na / 2 = {a/2}\na // 2 = {a//2}\na % 2 = {a % 2}\n\n=======================================\n\n2. 거듭제곱, 로그, 지수, 삼각함수\n\na^2 = {a**2}\nsqrt(a) = {np.round(np.sqrt(a),2)}\nlog(a) = {np.round(np.log(a),2)}\nexp(a) = {np.round(np.exp(a),2)}\nsin(a),cos(a) = {np.round(np.sin(a),2),np.round(np.cos(a),2)}\n''')\n\n\n\n1. 사칙연산 \n\na + 1 = [2 3 4]\na - 2 = [-1  0  1]\na x 2 = [2 4 6]\na / 2 = [0.5 1.  1.5]\na // 2 = [0 1 1]\na % 2 = [1 0 1]\n\n=======================================\n\n2. 거듭제곱, 로그, 지수, 삼각함수\n\na^2 = [1 4 9]\nsqrt(a) = [1.   1.41 1.73]\nlog(a) = [0.   0.69 1.1 ]\nexp(a) = [ 2.72  7.39 20.09]\nsin(a),cos(a) = (array([0.84, 0.91, 0.14]), array([ 0.54, -0.42, -0.99]))"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#기타-연산전치행렬역행렬",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-00. numpy & pandas (1).html#기타-연산전치행렬역행렬",
    "title": "00. numpy & pandas (1)",
    "section": "기타 연산(전치행렬,역행렬)",
    "text": "기타 연산(전치행렬,역행렬)\n\na1 = np.random.randint(0,9,3)\na2 = np.random.randint(0,9,3)\na3 = np.random.randint(0,9,3)\n\nA1 = np.stack([a1,a2,a3],axis=0) \nA1\n\narray([[8, 1, 1],\n       [2, 1, 4],\n       [4, 4, 1]])\n\n\n- 전치행렬\n\nA1.T\n\narray([[8, 2, 4],\n       [1, 1, 4],\n       [1, 4, 1]])\n\n\n- 역행렬\n\nnp.linalg.inv(A1)\n\narray([[ 0.14705882, -0.02941176, -0.02941176],\n       [-0.1372549 , -0.03921569,  0.29411765],\n       [-0.03921569,  0.2745098 , -0.05882353]])\n\n\n- 행렬연산\n\\[\\bf A^{-1} \\times A = {I}\\]\n\\[\\bf {I} = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\\n                                                     0 & 1 & \\dots & 0 \\\\\n                                                     \\dots &\\dots &\\dots &\\dots \\\\\n                                                     0 & 0 & \\dots & 1\n                                                        \\end{bmatrix}\\]\n\nnp.round(A1 @ np.linalg.inv(A1),2)\n\narray([[ 1.,  0.,  0.],\n       [ 0.,  1., -0.],\n       [ 0.,  0.,  1.]])"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#모티블-클래스를-매번-수정하기-불편해",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#모티블-클래스를-매번-수정하기-불편해",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "모티블 : 클래스를 매번 수정하기 불편해",
    "text": "모티블 : 클래스를 매번 수정하기 불편해"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#upjump---ver1",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#upjump---ver1",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "UPjump - Ver1",
    "text": "UPjump - Ver1\n\nclass UpJump:\n    def __init__(self):\n        self.value = 0\n    def up(self):\n        self.value = self.value + 1  \n    def jump(self,jump_size):\n        self.value = self.value + jump_size\n    def __repr__(self):\n        return str(self.value)        \n\n\na = UpJump()\na.jump(2)\n\n\na\n\n2"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#upjump---ver2",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#upjump---ver2",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "Upjump - Ver2",
    "text": "Upjump - Ver2\n\nclass UpJump_Ver2(UpJump):\n    def jump(self,jump_size):\n        self.value = self.value + jump_size\n\n\na = UpJump_Ver2()\n\n\na.jump(2)\n\n\na\n\n2"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#tip",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#tip",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "tip",
    "text": "tip\n- 클래스를 조금 수정하고 싶을때, 아래와 같은 문법을 이용하면 편리하다.\nclass 새로운 클래스(수정할 클래스):\n    def 수정 및 추가할 함수(self,parameter):\n        return ...\n- 사용에시\n\nclass temp(UpJump) :\n      def __repr__(self) :\n        return f\"현재 value는 {self.value}입니다.\"\n\n\na = temp()\n\n\na.jump(50)\n\n\na\n\n현재 value는 50입니다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "motive",
    "text": "motive\n\n클래스를 배우기 전 : int 자료형의 +는 “정수의 덧셈”을 의미하고 list자료형의 +는 “자료의 추가” 를 의미한다.\n클래스를 배운 후 : 아마 int, list 클래스의 + 라는 연산을 정의하는 숨겨진 메소드가 있을 것이다.\n\n\na,b= 1,2\n\n- int\n\nprint(f\"a = {a}, b = {b}, a+b = {a+b}\")\nprint(f\"a = {a}, b = {b}, a.__add__(b) = {a.__add__(b)}\")\n\na = 1, b = 2, a+b = 3\na = 1, b = 2, a.__add__(b) = 3\n\n\n- list\n\na,b = [1,2],[3,4]\n\n\nprint(f\"a = {a}, b = {b}, a+b = {a+b}\")\nprint(f\"a = {a}, b = {b}, a.__add__(b) = {a.__add__(b)}\")\n\na = [1, 2], b = [3, 4], a+b = [1, 2, 3, 4]\na = [1, 2], b = [3, 4], a.__add__(b) = [1, 2, 3, 4]\n\n\n- 확인 : a+b는 사실 내부적으로 a.__add__(b)의 축약구문이다.\n- 추측 : 따라서 만약 : a.__add__(b)의 기능을 재정의 하면 a+b의 기능도 바뀔것이다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1.-__add__",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1.-__add__",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex1. __add__()",
    "text": "ex1. __add__()\n- 클래스 선언\n\n한 학기를 등록할 때마다. 학생의 나이가 0.5, 학기가 1 증가하는 __add__ 함수를 클래스 내부에 구현\n\n\nclass s:\n    def __init__(self, age=20.0, semester=0): \n        self.age = age\n        self.semester = semester\n        print(f\"입학을 축하합니다. 당신의 나이는 {self.age}이고 현재 학기는 {self.semester}학기 입니다.\")\n    def __add__(self,registration_status):  \n        if registration_status=='휴학': \n            self.age=self.age+0.5 \n        elif registration_status=='등록':\n            self.age=self.age+0.5 \n            self.semester= self.semester+1\n    def _repr_html_(self): ## 코드 출력 정의\n        html_str = \"\"\"\n        나이: {} &lt;br/&gt;\n        학기: {} &lt;br/&gt;\n        \"\"\"\n        return html_str.format(self.age,self.semester)\n\n\ngc = s()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기 입니다.\n\n\n\ngc + \"등록\"\n\n\ngc\n\n\n        나이: 20.5 \n        학기: 1 \n        \n\n\n\ngc + \"휴학\"\n\n\ngc\n\n\n        나이: 21.0 \n        학기: 1"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2.-__add__-return",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2.-__add__-return",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex2. __add__ + return",
    "text": "ex2. __add__ + return\n- 잘못된 사용\n\ngc + '등록'+ '휴학' + '등록' + '휴학'\n\nTypeError: unsupported operand type(s) for +: 'NoneType' and 'str'\n\n\n- Ver 1\n\nclass s:\n    def __init__(self, age=20.0, semester=0): \n        self.age = age\n        self.semester = semester\n        print(f\"입학을 축하합니다. 당신의 나이는 {self.age}이고 현재 학기는 {self.semester}학기 입니다.\")\n    def __add__(self,registration_status):  \n        if registration_status=='휴학': \n            self.age=self.age+0.5 \n        elif registration_status=='등록':\n            self.age=self.age+0.5 \n            self.semester= self.semester+1 \n        return self  ## return 추가\n    def _repr_html_(self): ## 코드 출력 정의\n        html_str = \"\"\"\n        나이: {} &lt;br/&gt;\n        학기: {} &lt;br/&gt;\n        \"\"\"\n        return html_str.format(self.age,self.semester)\n\n\ngc = s()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기 입니다.\n\n\n\ngc + '등록'+ '휴학' + '등록' + '휴학'\n\n\n        나이: 22.0 \n        학기: 2 \n        \n\n\n- Ver2"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2.-__add__-super",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2.-__add__-super",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex2. __add__ + super",
    "text": "ex2. __add__ + super\n\nclass s_2(s):\n    def __add__(self,registration_status): \n        if registration_status=='휴학': \n            self.age = self.age+0.5\n        elif registration_status=='등록':\n            self.age = self.age+0.5 \n            self.semester = self.semester+1 \n        return self\n\n\ngc = s_2()\n\n입학을 축하합니다. 당신의 나이는 20.0이고 현재 학기는 0학기 입니다.\n\n\n\ngc + '등록'+ '휴학' + '등록' + '휴학'\n\n\n        나이: 22.0 \n        학기: 2"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive-1",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive-1",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "motive",
    "text": "motive\n\na = [1,2,3]\na\n\n[1, 2, 3]\n\n\n\na[0]\n\n1\n\n\n\na.__getitem__(0)\n\n1"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1.-rps가위바위보",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1.-rps가위바위보",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex1. RPS(가위바위보)",
    "text": "ex1. RPS(가위바위보)\n\nclass RPS:\n    def __init__(self,candidate):\n        self.candidate = candidate\n        self.actions = list() \n    def pick(self):\n        self.actions.append(np.random.choice(self.candidate))        \n    def _repr_html_(self):\n        html_str = \"\"\"\n        낼 수 있는 패: {} &lt;br/&gt;\n        기록: {}\n        \"\"\"        \n        return html_str.format(self.candidate,self.actions)\n\n\na = RPS([\"가위\",\"바위\",\"보\"])\n\n\na.pick()\na.pick()\n\n\na.actions\n\n['바위', '보']\n\n\n\na[0], a[1]\n\nTypeError: 'RPS' object is not subscriptable\n\n\n- 위를 에러가 나지않고 리스트처럼 인덱싱 했으면 좋겠음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2.-리스트-인덱싱-기능-추가",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2.-리스트-인덱싱-기능-추가",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex2. 리스트 인덱싱 기능 추가",
    "text": "ex2. 리스트 인덱싱 기능 추가\n\nclass RPS_Ver2(RPS):\n    def __getitem__(self,item):\n        return self.actions[item]\n\n\na = RPS_Ver2(['가위','바위','보'])\n\n\na.pick()\na.pick()\na.pick()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['가위', '가위', '가위']\n        \n\n\n\na[0]\n\n'가위'"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive-2",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive-2",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "motive",
    "text": "motive\n\na = RPS_Ver2(['가위','바위'])\na\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        기록: []\n        \n\n\n\na.pick()\na.pick()\na\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        기록: ['가위', '바위']\n        \n\n\n\na[0]\n\n'가위'\n\n\n\na[0] = '보' \n\nTypeError: 'RPS_Ver2' object does not support item assignment\n\n\n- 만약 실수로 기록할 때와 같은 경우가 있을경우 위처럼 수정이 필요할 수도 있겠다.\n- 리스트 예제 관찰\n\nl = [1,2]\nl\n\n[1, 2]\n\n\n\nl[0]=2\n\n\nl\n\n[2, 2]\n\n\n\nl.__setitem__(0,1)\n\n\nl\n\n[1, 2]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1.-값을-수정하는-메소드-구현",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1.-값을-수정하는-메소드-구현",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex1. 값을 수정하는 메소드 구현",
    "text": "ex1. 값을 수정하는 메소드 구현\n\nclass RPS_Ver3(RPS_Ver2):\n    def __setitem__(self,index,val):\n        self.actions[index] = val\n\n\na=RPS_Ver3(['가위','바위','보'])\n\n\na.pick()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['보']\n        \n\n\n\na[0] = \"가위\"\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['가위']"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive1",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive1",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "motive1",
    "text": "motive1\n\n가위===가위이면 True가 나왔으면 좋겠음.\n\n\n관찰 : __eq__\n\na = 1\na\n\n1\n\n\n\na==1\n\nTrue\n\n\n\na.__eq__(1)\n\nTrue\n\n\n\na==1은 a.__eq__(1)의 축약버전이다.\n\n\n\n구현 : __eq__\n\nclass RPS_Ver5(RPS_Ver4):\n    def __eq__(self,other):\n        return self[-1] == other[-1]\n\n\na = RPS_Ver5(['가위','바위'])\nb = RPS_Ver5(['가위','바위'])\n\n- 1회 대결\n\na.pick()\nb.pick()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        기록: ['가위']\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        기록: ['바위']\n        \n\n\n\na == b\n\nFalse\n\n\n- 2회 대결\n\na.pick()\nb.pick()\n\n\na == b\n\nFalse\n\n\n- 3회 대결\n\na.pick()\nb.pick()\n\n\na == b\n\nTrue"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive2",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive2",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "motive2",
    "text": "motive2\n\na[-1], b[-1]\n\n('가위', '가위')\n\n\n\na &gt; b\n\nTypeError: '&gt;' not supported between instances of 'RPS_Ver5' and 'RPS_Ver5'\n\n\n- 목표 : False가 나왔으면 좋겠음\n\n관찰 : __gt__\n\na = 1\nb = 2\n\n\na&gt;1, a.__gt__(1), b&gt;1, b.__gt__(1)\n\n(False, False, True, True)\n\n\n\na.__gt__(1)\n\nFalse\n\n\n\n\n예비학습\n\na = RPS_Ver5(['가위','바위'])\nb = RPS_Ver5(['가위','바위'])\n\n\nfor i in range(3) :\n    a.pick()\n    b.pick()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        기록: ['가위', '바위', '바위']\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위'] \n        기록: ['가위', '가위', '바위']\n        \n\n\n\na[-1], b[-1]\n\n('바위', '바위')\n\n\n- 이기는 요소를 각 리스트 원소에 왼쪽에 배치\n\n[a[-1],b[-1]] in [['가위','보'],['바위','가위'],['보','바위']]\n\nFalse\n\n\n\n\n구현 : __gt__\n\nclass RPS_Ver6(RPS_Ver5):\n    def __gt__(self,other):\n        return [self[-1],other[-1]] in [['가위','보'],['바위','가위'],['보','바위']]\n\n\na = RPS_Ver6(['가위','바위','보'])\nb = RPS_Ver6(['가위','바위','보'])\n\n- 1회 대결\n\na.pick()\nb.pick()\n\n\na[-1],b[-1]\n\n('바위', '가위')\n\n\n\na&gt;b\n\nTrue\n\n\n- 2회 대결\n\na.pick()\nb.pick()\n\n\na[-1],b[-1]\n\n('바위', '바위')\n\n\n\na&gt;b\n\nFalse"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive3",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#motive3",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "motive3",
    "text": "motive3\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['바위', '바위']\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['가위', '바위']\n        \n\n\n- True로 나왔으면 좋겠음\n\na&gt;=b\n\nTypeError: '&gt;=' not supported between instances of 'RPS_Ver6' and 'RPS_Ver6'\n\n\n\n구현\n- 비교 연산자 정리\n\n\n\n특수 메소드\n의미\n\n\n\n\n__eq__\nself == other\n\n\n__gt__\nself &gt; other\n\n\n__lt__\nself &lt; other\n\n\n__ge__\nself &gt;= other\n\n\n__le__\nself &lt;= other\n\n\n\n\nclass RPS_Ver7(RPS_Ver6):\n    def __ge__(self,other):\n        return (self == other) or (self &gt; other)\n    def __lt__(self,other):\n        return not (self &gt;= other)\n    def __le__(self,other):\n        return (self == other) or (self &lt; other)\n\n\na = RPS_Ver7(['가위','바위','보'])\nb = RPS_Ver7(['가위','바위','보'])\n\n\na.pick()\nb.pick()\n\n\na\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['가위']\n        \n\n\n\nb\n\n\n        낼 수 있는 패: ['가위', '바위', '보'] \n        기록: ['가위']\n        \n\n\n\na==b, a&gt;b, a&lt;b, a&gt;=b, a&lt;=b \n\n(True, False, False, True, True)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#함수",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#함수",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "함수",
    "text": "함수\n\ndef f() :\n    return \"test\"\n\n\nf()\n\n'test'\n\n\n\n?f\n\n\nSignature: f()\nDocstring: &lt;no docstring&gt;\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_12160\\3092864090.py\nType:      function\n\n\n\n- 함수 f의 type은 function이다.\n- 즉, 우리가 만든 f는 function이라는 클래스의 오브젝트에 불과하다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1-x-a2",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex1-x-a2",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex1) \\((x-a)^2\\)",
    "text": "ex1) \\((x-a)^2\\)\n\n풀이 1. 중첩\n\ndef f(a) :\n    def _f(x) :\n        return (x-a)**2\n    return _f\n\n\ng = f(10)\n\n\ng(2)\n\n64\n\n\n\n\n풀이 2. lambda\n\ndef f(a) :\n    _f = lambda x : (x-a)**2\n    return _f\n\n\ng = f(10)\n\n\ng(2)\n\n64"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2-fprimex",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex2-fprimex",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex2) \\(f\\prime(x)\\)",
    "text": "ex2) \\(f\\prime(x)\\)\n\n풀이 1. 기본 함수\n\ndef f(x): \n    return x**2 \n\n\ndef d(f,x): \n    h=0.000000000001\n    return (f(x+h)-f(x))/h \n\n\nd(f,4) # f'(4) = 2*4 = 8\n\n8.000711204658728\n\n\n\n\n풀이 2. 함수 중첩\n\ndef f(x): \n    return x**2 \n\n\ndef d(f): \n    def df(x):  \n        h=0.000000000001\n        return (f(x+h)-f(x))/h \n    return df\n\n\nff = d(f)\n\n\nff(4)\n\n8.000711204658728\n\n\n\n\n풀이3. lambda\n\ndef f(x): \n    return x**2 \n\n\ndef dl(f) :\n    h=0.000000000001\n    return lambda x :  (f(x+h)-f(x))/h\n\n\ndd = dl(f)\n\n\ndd(4)\n\n8.000711204658728\n\n\n\n\n시각화\n\nx = np.linspace(-1,1,100)\n\n\nplt.plot(x,f(x),label = r\"$f(x)=x^2$\")\nplt.plot(x,ff(x),label = r\"$f^{\\,\\prime}(x)=2x$\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x1e2d16cbdd0&gt;"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex3-함수들의-리스트",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#ex3-함수들의-리스트",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "ex3) 함수들의 리스트",
    "text": "ex3) 함수들의 리스트\n\nflst = [lambda x: x, lambda x: x**2, lambda x: x**3] \nflst\n\n[&lt;function __main__.&lt;lambda&gt;(x)&gt;,\n &lt;function __main__.&lt;lambda&gt;(x)&gt;,\n &lt;function __main__.&lt;lambda&gt;(x)&gt;]\n\n\n\nfor f in flst : \n    print(f(2))\n\n2\n4\n8\n\n\n\nfor f in flst : \n    plt.plot(x,f(x),\"--\")"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#call__",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#call__",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "__call__",
    "text": "__call__\n\nf = lambda x : x+1\n\n\nf(3)\n\n4\n\n\n\nf.__call__(3)\n\n4\n\n\n\nf(3)은 f__call__(3)의 축약버전이다.\n\n\n관찰\n- 함수처럼 쓸 수없는 인스턴스는 단지 __call__이 없을뿐이다. \\(\\to\\) ‘A’ object is not callable\n\nclass A():\n    def __init__(self) :\n        self.n = \"강철\"\n\n\na = A()\n\n\na()\n\nTypeError: 'A' object is not callable\n\n\n- 위 코드 수정\n\nclass A2(A):\n    def __call__(self) :\n        print(self.n)\n\n\na = A2()\n\n\na()\n\n강철"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#구현-self.상수-상수",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#구현-self.상수-상수",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "구현 : self.상수 + 상수",
    "text": "구현 : self.상수 + 상수\n\nclass add1:\n    def __init__(self,c) :\n        self.c = c\n    def __call__(self,x) :\n        return self.c + x\n\n\na = add1(3)\n\n\na(5)\n\n8\n\n\n\na(10)\n\n13"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#관찰-1.-iter",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#관찰-1.-iter",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "관찰 1. iter",
    "text": "관찰 1. iter\n- 아래 ???의 자리에 올수 있는것은 dir(?)하여 set(dir(lst)) & {'__iter__'} 가 있는 오브젝트이다\nfor i in ???:\n    print(i)\n\nlst = [1,2,3]\n\n\nlst = [1,2,3]\nset(dir(lst)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\ntpl = 1,2,3\nset(dir(tpl)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\nstring = '123'\nset(dir(string)) & {'__iter__'}\n\n{'__iter__'}\n\n\n\na = 5\nset(dir(a)) & {'__iter__'}\n\nset()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#관찰2.-next",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#관찰2.-next",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "관찰2. next",
    "text": "관찰2. next\n\n__next__의 기능은 \\(\\to\\) iterable 객체들의 원소들을 차례대로 꺼내준다\n더이상 꺼낼 원소가 없으면 Stopiteration Error를 발생시킴\n\n\nlst = [1,2,3].__iter__()\n\n\nnext(lst)\n\n1\n\n\n\nnext(lst)\n\n2\n\n\n\nnext(lst)\n\n3\n\n\n- 원소가 3개이기 때문에 3번이상 명령어 입력시 에러 발생\n\nnext(lst)\n\nStopIteration:"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#관찰-3.-데이터-프레임",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#관찰-3.-데이터-프레임",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "관찰 3. 데이터 프레임",
    "text": "관찰 3. 데이터 프레임\n\ndf = pd.DataFrame({'x':[1,2,3],'y':[2,3,4]})\ndf\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n2\n\n\n1\n2\n3\n\n\n2\n3\n4\n\n\n\n\n\n\n\n\nset(dir(df)) & {'__iter__'}\n\n{'__iter__'}\n\n\n- 데이터 프레임의 경우는 루프문 수행 시 컬럼 네임을 출력해준다.\n\nfor i in df :\n    print(i)\n\nx\ny\n\n\n- next 함수 적용\n\n_df = iter(df)\n\n\nnext(_df)\n\n'x'\n\n\n\nnext(_df)\n\n'y'\n\n\n- 컬럼이 2개 밖에 없어 에러 발생\n\nnext(_df)\n\nStopIteration:"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#구현-1",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#구현-1",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "구현",
    "text": "구현\n- 가찌를 내는 순간 for문이 멈추도록 하는 이터레이터를 만들자\n\nclass RPS_ITERATOR: # 찌를 내는순간 for문이 멈추도록 하는 이터레이터를 만들자\n    def __init__(self): \n        self.candidate = [\"묵\",\"찌\",\"빠\"] \n    def __iter__(self):\n        return self \n    def __next__(self):\n        action = np.random.choice(self.candidate) ## 묵찌빠에서 랜덤 선택\n        if action == \"찌\":\n            print(\"찌가 나와서 for문을 멈춥니다\")\n            raise StopIteration\n        else:\n            return action\n\n\na = RPS_ITERATOR()\n\n\nnext(a)\n\n찌가 나와서 for문을 멈춥니다\n\n\nStopIteration: \n\n\n\nnext(a)\n\n'묵'\n\n\n\nnext(a)\n\n'빠'\n\n\n\nfor i in a :\n    print (i)\n\n묵\n빠\n빠\n빠\n찌가 나와서 for문을 멈춥니다"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#range-생략",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#range-생략",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "range (생략)",
    "text": "range (생략)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#zip",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#zip",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "zip",
    "text": "zip\n- 이터레이터엔 개념을 알면 for문에 대한 이해도가 대폭 상승한다.\n\n관찰 1. zip?\n- 일단 zip으로 만든 객체가 iterable object인지 확인하자\n\ntemp = zip([1,2,3],\"abc\")\n\n\ntemp\n\n&lt;zip at 0x1e2d53d2f00&gt;\n\n\n\nset(dir(temp)) & {\"__iter__\",\"__next__\"}\n\n{'__iter__', '__next__'}\n\n\n- 오 2가지 다있는 것을 보니 temp는 iterable 오브젝트이다.\n\nnext(temp)\n\n(1, 'a')\n\n\n\nnext(temp)\n\n(2, 'b')\n\n\n\nnext(temp)\n\n(3, 'c')\n\n\n- 훗, 무슨 느낌인지 알겠음\n\nnext(temp)\n\nStopIteration: \n\n\n\n\n관찰 2. 그래서 뭐하는 문법인가?\n\nzip?\n\n\nInit signature: zip(self, /, *args, **kwargs)\nDocstring:     \nzip(*iterables, strict=False) --&gt; Yield tuples until an input is exhausted.\n   &gt;&gt;&gt; list(zip('abcdefg', range(3), range(4)))\n   [('a', 0, 0), ('b', 1, 1), ('c', 2, 2)]\nThe zip object yields n-length tuples, where n is the number of iterables\npassed as positional arguments to zip().  The i-th element in every tuple\ncomes from the i-th iterable argument to zip().  This continues until the\nshortest argument is exhausted.\nIf strict is true and one of the arguments is exhausted before the others,\nraise a ValueError.\nType:           type\nSubclasses:     \n\n\n\n- 음, 위에 나온 예제를 싱행해보니 무슨 느낌인지 알겠음\n\nlist(zip('abcdefg', range(3), range(4)))\n\n[('a', 0, 0), ('b', 1, 1), ('c', 2, 2)]\n\n\n\n\n관찰 3. enumerate\n- 이녀석도 이터러블 객체이다.\n\nset(dir(enumerate('abc'))) & {'__iter__', '__next__'}\n\n{'__iter__', '__next__'}\n\n\n- enumerate는 원소와 인덱스를 반환해준다.\n\nfor i in enumerate(list(\"abc\")) :\n    print(i)\n\n(0, 'a')\n(1, 'b')\n(2, 'c')"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#summary",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-14-Extra 03. 클래스 탐구 (2).html#summary",
    "title": "Extra 03. 클래스 탐구 (2)",
    "section": "summary",
    "text": "summary\n- for문을 사용하려면 “iterable object” 여야만 한다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html",
    "title": "Extra 01. 클래스",
    "section": "",
    "text": "from IPython.core.display import HTML\n\n\n\n\nclass jkm :\n     pass\n\n\ntest = jkm()\ntest\n\n&lt;__main__.jkm at 0x18dda40e3d0&gt;\n\n\n\n\n\n\ntest.title = \"중요한건 꺽이지 않는 마음\"\n\ntest.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\ntest.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\ntest.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\ntest.h1 = \"마음\"\n\ntest.html_str =  '''\n&lt;style&gt;\n    .title {{\n        font-family: \"Times New Roman\", serif;\n        font-size: 30px;\n        font-weight: 900;\n    }}\n    .text {{\n        font-family: \"Arial\", sans-serif;\n        font-size: 20px;\n        font-style: italic;\n    }}\n    .highlight {{\n        font-family: \"Montserrat\", monospace;\n        font-size: 35px;\n        font-weight: 900;\n        text-decoration: underline; ## 밑줄\n        font-style: normal;\n        color: darkblue;\n        background-color: #FFFF00;\n    }}\n&lt;/style&gt;\n\n&lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n&lt;img src={url} width=\"600\"&gt;\n&lt;p&gt; \\n &lt;/p&gt;\n&lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n&lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n&lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n'''\n\n\n\n\n\ndef show(test):\n    _str = test.html_str.format(\n        tt1 = test.title,\n        url = test.url,\n        Q = test.Q,\n        A = test.A,\n        h1 = test.h1\n    )\n    display(HTML(_str))\n\n\nshow(test)\n\n\n\n\n중요한건 꺽이지 않는 마음\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#단계-도화지-생성",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#단계-도화지-생성",
    "title": "Extra 01. 클래스",
    "section": "",
    "text": "class jkm :\n     pass\n\n\ntest = jkm()\ntest\n\n&lt;__main__.jkm at 0x18dda40e3d0&gt;"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#단계-뼈대-생성",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#단계-뼈대-생성",
    "title": "Extra 01. 클래스",
    "section": "",
    "text": "test.title = \"중요한건 꺽이지 않는 마음\"\n\ntest.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\ntest.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\ntest.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\ntest.h1 = \"마음\"\n\ntest.html_str =  '''\n&lt;style&gt;\n    .title {{\n        font-family: \"Times New Roman\", serif;\n        font-size: 30px;\n        font-weight: 900;\n    }}\n    .text {{\n        font-family: \"Arial\", sans-serif;\n        font-size: 20px;\n        font-style: italic;\n    }}\n    .highlight {{\n        font-family: \"Montserrat\", monospace;\n        font-size: 35px;\n        font-weight: 900;\n        text-decoration: underline; ## 밑줄\n        font-style: normal;\n        color: darkblue;\n        background-color: #FFFF00;\n    }}\n&lt;/style&gt;\n\n&lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n&lt;img src={url} width=\"600\"&gt;\n&lt;p&gt; \\n &lt;/p&gt;\n&lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n&lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n&lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n'''"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#단계-show-함수-작성",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#단계-show-함수-작성",
    "title": "Extra 01. 클래스",
    "section": "",
    "text": "def show(test):\n    _str = test.html_str.format(\n        tt1 = test.title,\n        url = test.url,\n        Q = test.Q,\n        A = test.A,\n        h1 = test.h1\n    )\n    display(HTML(_str))\n\n\nshow(test)\n\n\n\n\n중요한건 꺽이지 않는 마음\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#self",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#self",
    "title": "Extra 01. 클래스",
    "section": "self",
    "text": "self\n- self는 밈 클래스에서 생성할 인스턴스의 이름을 대신한다.\n- jkm이라는 클래스에 다음과 같이 show함수를 종속 시키자\n\nclass jkm:\n    def show(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        display(HTML(_str))\n\n\ntest  = jkm()\n\n\ntest.title = \"중요한건 꺽이지 않는 마음\"\n\ntest.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\ntest.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\ntest.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\ntest.h1 = \"마음\"\n\ntest.html_str =  '''\n&lt;style&gt;\n    .title {{\n        font-family: \"Times New Roman\", serif;\n        font-size: 30px;\n        font-weight: 900;\n    }}\n    .text {{\n        font-family: \"Arial\", sans-serif;\n        font-size: 20px;\n        font-style: italic;\n    }}\n    .highlight {{\n        font-family: \"Montserrat\", monospace;\n        font-size: 35px;\n        font-weight: 900;\n        text-decoration: underline; ## 밑줄\n        font-style: normal;\n        color: darkblue;\n        background-color: #FFFF00;\n    }}\n&lt;/style&gt;\n\n&lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n&lt;img src={url} width=\"600\"&gt;\n&lt;p&gt; \\n &lt;/p&gt;\n&lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n&lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n&lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n'''\n\n\ntest.show()\n\n\n\n\n중요한건 꺽이지 않는 마음\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#init",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#init",
    "title": "Extra 01. 클래스",
    "section": "init",
    "text": "init\n\n모티브\n- 인스턴스를 생성할 떄마다 변수를 선언하는 것이 귀찮음….\n- 초기값을 정의하는 함수 또한 클래스안에 정의해주자\n\n\n뼈대 작성\n\nclass jkm:\n    def __init__(self) :\n        self.title = \"중요한건 꺽이지 않는 마음\"\n\n        self.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\n        self.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\n        self.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\n        self.h1 = \"마음\"\n\n        self.html_str =  '''\n                    &lt;style&gt;\n                        .title {{\n                            font-family: \"Times New Roman\", serif;\n                            font-size: 30px;\n                            font-weight: 900;\n                        }}\n                        .text {{\n                            font-family: \"Arial\", sans-serif;\n                            font-size: 20px;\n                            font-style: italic;\n                        }}\n                        .highlight {{\n                            font-family: \"Montserrat\", monospace;\n                            font-size: 35px;\n                            font-weight: 900;\n                            text-decoration: underline; ## 밑줄\n                            font-style: normal;\n                            color: darkblue;\n                            background-color: #FFFF00;\n                        }}\n                    &lt;/style&gt;\n\n                    &lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n                    &lt;img src={url} width=\"600\"&gt;\n                    &lt;p&gt; \\n &lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    &lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n                    '''\n        \n    def show(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        display(HTML(_str))\n\n\ntest = jkm()\n\n\n\nSHOW\n\ntest.show()\n\n\n                    \n\n                    중요한건 꺽이지 않는 마음\n                    \n                     \n \n                     Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n                     A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex1.클래스-내에-hello라는-메소드를-정의하고-출력하라",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex1.클래스-내에-hello라는-메소드를-정의하고-출력하라",
    "title": "Extra 01. 클래스",
    "section": "ex1.클래스 내에 hello라는 메소드를 정의하고 출력하라",
    "text": "ex1.클래스 내에 hello라는 메소드를 정의하고 출력하라\n\nclass ex1 :\n    def hello(self):\n        print(\"안녕하세요\")\n        \nex1 = ex1()\n\n\nex1.hello()\n\n안녕하세요"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex2.-아래의-조건에-맞는-클래스를-구현",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex2.-아래의-조건에-맞는-클래스를-구현",
    "title": "Extra 01. 클래스",
    "section": "ex2. 아래의 조건에 맞는 클래스를 구현",
    "text": "ex2. 아래의 조건에 맞는 클래스를 구현\n1 “클래스 \\(\\to\\) 인스턴스”의 과정에서 변수 a가 True로 초기설정된다.\n2 클래스에는 show()라는 메소드가 정의되어 있으며, show()의 기능은 a의 값을 print하는 기능을 한다.\n\nclass ex2 :\n     def __init__(self) :\n            self.a = True\n     def show(self) :\n         print(self.a)\n\n\nex2 = ex2()\n\n\nex2.show()\n\nTrue"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex3.-아래에-조건에-맞는-클래스를-구현하라.",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex3.-아래에-조건에-맞는-클래스를-구현하라.",
    "title": "Extra 01. 클래스",
    "section": "ex3. 아래에 조건에 맞는 클래스를 구현하라.",
    "text": "ex3. 아래에 조건에 맞는 클래스를 구현하라.\n1 “클래스 \\(\\to\\)인스턴스”의 과정에서 변수 a가 True 로 초기설정된다.\n2. 클래스에는 toggle() 이라는 메소드가 정의되어 있다. 이 기능은 변수 a의 값이 True 이면 False 로, False 이면 True 로 바꾸는 역할을 한다.\n3. 클래스에는 show()라는 메소드가 정의되어 있다. 이 기능은 a의 값을 print 하는 기능을 한다.\n\nclass ex3: \n    def __init__(self) :\n        self.a = True\n    def toggle(self):\n        self.a = not self.a\n    def show(self) :\n        print(self.a)\n\n\ntest = ex3()\n\n\ntest.a\n\nTrue\n\n\n\ntest.toggle()\n\n\ntest.a\n\nFalse\n\n\n\ntest.show()\n\nFalse"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex4.-아래-조건에-맞는-클래스를-구현",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex4.-아래-조건에-맞는-클래스를-구현",
    "title": "Extra 01. 클래스",
    "section": "ex4. 아래 조건에 맞는 클래스를 구현",
    "text": "ex4. 아래 조건에 맞는 클래스를 구현\n1 “클래스 \\(\\to\\) 인스턴스”의 과정에서 변수 a가 0으로 초기설정된다.\n2 클래스에는 up()이라는 메소드가 정의되어 있따. up()의 기능은 a의 값을 1증가 시키는 기능을 한다.\n3 클래스에는 show()라는 메소드가 정의되어 있다. show()의 기능은 a의값을 print하다.\n\nclass ex4: \n    def __init__(self) :\n        self.a = 1\n    def up(self):\n        self.a += 1\n    def show(self) :\n        print(self.a)\n\n\nex4 = ex4()\n\n\nex4.up()\n\n\nex4.a\n\n2\n\n\n\nex4.show()\n\n1"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex5.-아래-조건에-맞는-클래스를-구현하라.",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex5.-아래-조건에-맞는-클래스를-구현하라.",
    "title": "Extra 01. 클래스",
    "section": "ex5. 아래 조건에 맞는 클래스를 구현하라.",
    "text": "ex5. 아래 조건에 맞는 클래스를 구현하라.\n1 클래스 \\(\\to\\) 인스턴스” 과정에서 변수 a의 값이 사용자가 입력한 값으로 초기 설정된다.\n2 클래스에는 show()라는 메소드가 정의되어 있다. show()의 기능은 a의 값을 print한다.\n\nclass ex5 :\n    def __init__(self,value):\n         self.a = value\n    def show(self) :\n         print(self.a)\n\n\nex5 = ex5(1)\n\n\nex5.show()\n\n1"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex6.-다음-조건을-만족하는-클래스를-구현하라.",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex6.-다음-조건을-만족하는-클래스를-구현하라.",
    "title": "Extra 01. 클래스",
    "section": "ex6. 다음 조건을 만족하는 클래스를 구현하라.",
    "text": "ex6. 다음 조건을 만족하는 클래스를 구현하라.\n\n“클래스 인스턴스”의 과정에서 변수 a가 0으로 초기설정된다.\n클래스에는 up()라는 메소드가 정의되어 있다. up()의 기능은 a의 값을 1증가시키는 기능을 한다.\n클래스에는 jump()라는 메소드가 정의되어 있다. jump()는 jump_size 를 입력으로 받으며 a의 값을 jump_size 만큼 증가시키는 기능을 한다.\n클래스에는 show()라는 메소드가 정의되어 있다. show()의 기능은 a의 값을 print 하는 기능을 한다.\n\n\nclass ex6:\n    def __init__(self):\n        self.a = 0\n    def up(self):\n        self.a += 1\n    def jump(self,js) :\n        self.a += js\n    def show(self) :\n        print(self.a)\n\n\nex6 = ex6()\n\n\nex6.up()\n\n\nex6.a\n\n1\n\n\n\nex6.jump(100)\n\n\nex6.a\n\n101\n\n\n\nex6.show()\n\n101"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex7.-아래-조건에-맞는-클래스를-구현",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex7.-아래-조건에-맞는-클래스를-구현",
    "title": "Extra 01. 클래스",
    "section": "ex7. 아래 조건에 맞는 클래스를 구현",
    "text": "ex7. 아래 조건에 맞는 클래스를 구현\n\n“클래스 인스턴스”의 과정에서 변수 a가 0으로 초기설정된다.\n클래스에는 up()라는 메소드가 정의되어 있다. up()의 기능은 a의 값을 1증가시키는 기능을 한다.\n클래스에는 jump()라는 메소드가 정의되어 있다. jump()는 jump_size 를 입력으로 받으며 a의 값을 jump_size 만큼 증가시키는 기능을 한다.\n클래스에는 reset()이라는 메소드가 정의되어 있다. reset()는 a의 값을 0으로 초기화하는 역할을 한다.\n클래스에는 show()라는 메소드가 정의되어 있다. show()의 기능은 a의 값을 print 하는 기능을 한다.\n\n\nclass ex7:\n    def __init__(self):\n        self.a = 0\n    def up(self):\n        self.a += 1\n    def jump(self,js) :\n        self.a += js\n    def reset(self) :\n        self.a = 0\n    def show(self) :\n        print(self.a)\n\n\nex7 = ex7()\n\n\nex7.up()\n\n\nex7.a\n\n1\n\n\n\nex7.reset()\n\n\nex7.a\n\n0"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex8.-이미지-출력",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex8.-이미지-출력",
    "title": "Extra 01. 클래스",
    "section": "ex8. 이미지 출력",
    "text": "ex8. 이미지 출력\n\nurl = 'https://github.com/guebin/PP2023/blob/main/posts/03_Class/burgerking.png?raw=true'\nhtml_str = '&lt;img src={url} width=\"600\"&gt;'.format(url=url)\ndisplay(HTML(html_str))\n\n\n\n\n\n“클래스 \\(\\to\\) 인스턴스”의 과정에서 변수 url이 위에서 제시된 값으로 초기화된다.\n클래스에는 show()라는 함수가 있어서 url에 해당하는 이미지를 출력해주는 기능을 가진다.\n\n\nclass ex8:\n    def __init_(self) :\n        self.url = 'https://github.com/guebin/PP2023/blob/main/posts/03_Class/burgerking.png?raw=true'\n    def show(self):\n        self.html_str = '&lt;img src={url} width=\"600\"&gt;'.format(url=url)\n        display(HTML(self.html_str))\n\n\nex8= ex8()\n\n\nex8.show()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex9.-이미지-출력-횟수기록",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex9.-이미지-출력-횟수기록",
    "title": "Extra 01. 클래스",
    "section": "ex9. 이미지 출력 + 횟수기록",
    "text": "ex9. 이미지 출력 + 횟수기록\n\n“클래스 \\(\\to\\)인스턴스”의 과정에서 변수 url이 위에서 제시된 값으로 초기화된다.\n클래스에는 show()라는 함수가 있어서 (1) url에 해당하는 이미지를 출력하고 (2) “당신은 이 그림을 \\(n\\)번 보았습니다” 를 출력하는 기능을 한다. 여기에서 \\(n\\)은 그림을 본 횟수\n\n\nclass ex9:\n    def __init__(self) :\n        self.n = 0\n        self.url = 'https://github.com/guebin/PP2023/blob/main/posts/03_Class/burgerking.png?raw=true'\n    def show(self):\n        self.html_str = '&lt;img src={url} width=\"600\"&gt;'.format(url=self.url)\n        display(HTML(self.html_str))\n        self.n += 1\n        print(\"당신은 이 그림을 {}번 보았습니다.\".format(self.n))\n\n\nex9 = ex9()\n\n\nex9.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex10.-예제-9에서-만든-클래스를-이용하여-아래의-url에-해당하는-이미지를-출려가하라.",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex10.-예제-9에서-만든-클래스를-이용하여-아래의-url에-해당하는-이미지를-출려가하라.",
    "title": "Extra 01. 클래스",
    "section": "ex10. 예제 9에서 만든 클래스를 이용하여 아래의 url에 해당하는 이미지를 출려가하라.",
    "text": "ex10. 예제 9에서 만든 클래스를 이용하여 아래의 url에 해당하는 이미지를 출려가하라.\n\ni1 =  ex9()\ni2 =  ex9()\n\n\ni2.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\n\ni1.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다.\n\n\n\ni2.show()\n\n\n\n\n당신은 이 그림을 1번 보았습니다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex11.-stock-이라는-이름의-클래스를-만들고-아래의-기능을-넣어라",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex11.-stock-이라는-이름의-클래스를-만들고-아래의-기능을-넣어라",
    "title": "Extra 01. 클래스",
    "section": "ex11. Stock 이라는 이름의 클래스를 만들고 아래의 기능을 넣어라",
    "text": "ex11. Stock 이라는 이름의 클래스를 만들고 아래의 기능을 넣어라\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\n(1) crawling 메소드: crawling 메소드는 start_date, end_date, code 를 입력으로 받는 함수이며, code 에 대응하는 주식의 주가를 크롤링하는 기능을 가진다. 크롤링된 주식의 가격은 numpy array 형태로 저장되어 있다.\nhint\n\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-02\"\ncode = \"005930.KS\"\ny = yf.download(code, start=start_date, end=end_date)['Adj Close'].to_numpy()\n\n[*********************100%***********************]  1 of 1 completed\n\n\n(2) smoothing 메소드 : smoothing는 크롤링된 주가를 아래의 수식을 통하여 \\(n\\)회 변환하는 기능을 한다.\n\n\\(\\overset{\\sim}{y_1} : \\frac 14(3y_1 + y_2)\\)\n\\(\\overset{\\sim}{y_i} : \\frac 14(y_{i-1} + 2y_i + y_{i+1})\\quad i=2,3 \\dots, n-1\\)\n\\(\\overset{\\sim}{y_n} : \\frac 14(y_{n-1} + 3y_n)\\)\n\nhint\n\nT = len(y)\nM = (np.eye(T) + np.array([abs(i-j)&lt;2 for i in range(T) for j in range(T)]).reshape(T,T))/4\nM[0,0] = 3/4; M[-1,-1]= 3/4 \n#np.linalg.matrix_power(M,50)@y\n\n\n풀이\n\nclass stock :\n    def __init__(self) :\n        self.y = None\n        self.sy = None\n    def crawling(self,code, start_date,end_date):\n        self.y = yf.download(code, start_date,end_date)['Adj Close'].to_numpy()\n    def smoothing(self,n):\n        T = len(self.y)\n        self.n = n\n        M = (np.eye(T) + np.array([abs(i-j)&lt;2 for i in range(T) for j in range(T)]).reshape(T,T))/4\n        M[0,0] = 3/4; M[-1,-1]= 3/4\n        self.sy = np.linalg.matrix_power(M,50)@self.y\n    def plot(self) : \n        plt.plot(self.y,label=r\"$y$\")\n        plt.plot(self.sy,\"--\",label =f\"$M^{self.n}@y$\")\n        plt.legend()\n\n\nex11 = stock()\n\n\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-02\"\ncode = \"005930.KS\"\nex11.crawling(code, start_date,end_date)\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nex11.smoothing(50)\n\n\nex11.plot()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex12.-ex11에서-만든-stock-클래스에서-kakao-인스턴스를-생성하라.-생성된-kakao-인스턴스에서-crawling-메소드를-이용하여-아래의-조건에-맞는-주식을-긁어오라.",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex12.-ex11에서-만든-stock-클래스에서-kakao-인스턴스를-생성하라.-생성된-kakao-인스턴스에서-crawling-메소드를-이용하여-아래의-조건에-맞는-주식을-긁어오라.",
    "title": "Extra 01. 클래스",
    "section": "ex12. ex11에서 만든 Stock 클래스에서 kakao 인스턴스를 생성하라. 생성된 kakao 인스턴스에서 crawling 메소드를 이용하여 아래의 조건에 맞는 주식을 긁어오라.",
    "text": "ex12. ex11에서 만든 Stock 클래스에서 kakao 인스턴스를 생성하라. 생성된 kakao 인스턴스에서 crawling 메소드를 이용하여 아래의 조건에 맞는 주식을 긁어오라.\n\ncode: ‘035720.KS’ (카카오)\nstart_date = “2023-01-01”\nend_date = “2023-05-26”\n\n이후 .smoothing 메소드를 이용하여 \\(n=50\\)회 스무딩하고 .plot 메소드를 이용하여 결과를 시각화하라.\n\n풀이\n\nkakao = stock()\n\n\ncode = \"035720.KS\"\nstart_date = \"2023-01-01\"\nend_date = \"2023-05-26\"\n\n\nkakao.crawling(code,start_date, end_date)\n\n[*********************100%***********************]  1 of 1 completed\n\n\n\nkakao.smoothing(50)\n\n\nkakao.plot()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex13.-linearregression이라는-이름의-클래스를-만들고-아래의-기능을-넣어라",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex13.-linearregression이라는-이름의-클래스를-만들고-아래의-기능을-넣어라",
    "title": "Extra 01. 클래스",
    "section": "ex13. LinearRegression이라는 이름의 클래스를 만들고 아래의 기능을 넣어라",
    "text": "ex13. LinearRegression이라는 이름의 클래스를 만들고 아래의 기능을 넣어라\n(1) “클래스 \\(\\to\\) 인스턴스” 인 시점에 길이가 \\(n\\)인 numpy array \\(\\bf{x} = (x_1\\dots, x_n),\\bf{y} = (y_1\\dots, y_n)\\) 을 입력으로 받아 내부에 저장한다.\n(2) fit 메소드 : fit은 내부에 저장된 \\(\\bf{x,y}\\)를 이용하여 아래의 수식을 계산한다.\n\\[\\bf{\\hat{y}} = X(X^{T}X)^{-1}X^{T}y,\\quad X = \\begin{bmatrix}1 & x_1 \\\\ \\dots & \\dots \\\\ 1 & x_n \\end{bmatrix}\\]\n(3) plot 메소드 작성\n\n풀이\n\nclass LinearRegression:\n        def __init__(self,x,y):\n            self.x = x\n            self.y = y\n        def fit(self):\n            n = len(self.x)\n            self.X = np.stack([np.ones(n),self.x],axis=1)\n            self.yhat = self.X@np.linalg.inv(self.X.T@self.X)@self.X.T@self.y     \n        \n        def plot(self) :\n            plt.plot(self.x,self.y,\"o\",label = r\"$(x,y)$\")\n            plt.plot(self.x,self.yhat,\"--\",label = r\"$(x,\\hat y)$\")\n            plt.legend()\n\n\n\nCode\nx =  np.array([0.00983, 0.01098, 0.02951, 0.0384 , 0.03973, 0.04178, 0.0533 ,\n               0.058  , 0.09454, 0.1103 , 0.1328 , 0.1412 , 0.1497 , 0.1664 ,\n               0.1906 , 0.1923 , 0.198  , 0.2141 , 0.2393 , 0.2433 , 0.3157 ,\n               0.3228 , 0.3418 , 0.3552 , 0.3918 , 0.3962 , 0.4    , 0.4482 ,\n               0.496  , 0.507  , 0.53   , 0.5654 , 0.582  , 0.5854 , 0.5854 ,\n               0.6606 , 0.7007 , 0.723  , 0.7305 , 0.7383 , 0.7656 , 0.7725 ,\n               0.831  , 0.8896 , 0.9053 , 0.914  , 0.949  , 0.952  , 0.9727 ,\n               0.982  ])\ny =  np.array([0.7381, 0.7043, 0.3937, 0.1365, 0.3784, 0.3028, 0.1037, 0.3846,\n               0.706 , 0.7572, 0.2421, 0.232 , 0.9855, 1.162 , 0.4653, 0.6791,\n               0.6905, 0.6865, 0.9757, 0.7665, 0.9522, 0.4641, 0.5498, 1.1509,\n               0.5288, 1.1195, 1.1659, 1.4341, 1.2779, 1.1648, 1.4002, 0.7472,\n               0.9142, 0.9658, 1.0707, 1.4501, 1.6758, 0.8778, 1.3384, 0.7476,\n               1.3086, 1.7537, 1.5559, 1.2928, 1.3832, 1.3115, 1.3382, 1.536 ,           \n               1.9177, 1.2069])\n\n\n\nex13 = LinearRegression(x,y)\n\n\nex13.fit()\n\n\nex13.plot()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex14.-ex13에서-작성한-클래스를-이용하여-아래의-자료를-분석하고-시각화해라.",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-09-Extra 01. 클래스.html#ex14.-ex13에서-작성한-클래스를-이용하여-아래의-자료를-분석하고-시각화해라.",
    "title": "Extra 01. 클래스",
    "section": "ex14. ex13에서 작성한 클래스를 이용하여 아래의 자료를 분석하고 시각화해라.",
    "text": "ex14. ex13에서 작성한 클래스를 이용하여 아래의 자료를 분석하고 시각화해라.\n\n\nCode\nx = np.array(\n    [0.007, 0.008, 0.008, 0.011, 0.037, 0.047, 0.059, 0.07 , 0.072,\n     0.075, 0.078, 0.08 , 0.082, 0.11 , 0.114, 0.117, 0.133, 0.15 ,\n     0.161, 0.163, 0.172, 0.208, 0.209, 0.221, 0.229, 0.231, 0.234,\n     0.235, 0.249, 0.251, 0.256, 0.269, 0.269, 0.273, 0.275, 0.298,\n     0.305, 0.309, 0.34 , 0.362, 0.371, 0.374, 0.382, 0.387, 0.388,\n     0.394, 0.395, 0.397, 0.401, 0.404, 0.419, 0.433, 0.436, 0.466,\n     0.481, 0.492, 0.495, 0.508, 0.511, 0.512, 0.554, 0.57 , 0.574,\n     0.575, 0.584, 0.6  , 0.601, 0.615, 0.618, 0.623, 0.629, 0.633,\n     0.646, 0.65 , 0.654, 0.662, 0.673, 0.686, 0.702, 0.744, 0.754,\n     0.766, 0.772, 0.781, 0.798, 0.8  , 0.807, 0.836, 0.837, 0.871,\n     0.873, 0.877, 0.879, 0.889, 0.891, 0.902, 0.904, 0.923, 0.952,\n     0.981]\n)\n\n\ny = np.array(\n    [4.004, 4.189, 5.483, 4.902, 5.174, 4.468, 4.95 , 4.463, 5.476,\n     4.446, 4.764, 5.244, 4.357, 4.796, 5.464, 4.196, 5.244, 4.868,\n     5.358, 4.493, 4.831, 4.716, 4.929, 4.588, 4.718, 4.389, 4.985,\n     4.266, 4.291, 3.697, 4.248, 4.88 , 5.126, 4.563, 4.131, 4.728,\n     4.168, 4.584, 3.953, 4.747, 3.592, 5.023, 4.601, 3.904, 4.092,\n     4.37 , 3.922, 4.145, 4.576, 4.25 , 4.051, 3.616, 4.634, 3.496,\n     4.631, 4.025, 4.197, 4.226, 4.808, 3.676, 3.834, 3.197, 4.36 ,\n     3.547, 3.956, 3.522, 4.26 , 3.443, 3.97 , 4.068, 4.186, 3.262,\n     3.452, 3.946, 3.875, 3.444, 3.501, 3.959, 3.843, 2.679, 3.266,\n     3.506, 2.916, 3.714, 4.007, 2.795, 3.329, 2.756, 3.72 , 2.381,\n     2.798, 3.035, 3.492, 3.22 , 3.073, 3.85 , 3.233, 3.396, 3.264,\n     2.986]\n)    \n\n\n\nex14 = LinearRegression(x,y)\nex14.fit()\nex14.plot()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "- 홈 디렉토리를 불러오는 명령어\n\nfrom pathlib import Path\nprint(Path.home())\n\nC:\\Users\\user\n\n\n- 현재 작업 디렉토리 확인\n\nprint(Path.cwd())\n\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\n\n\n\nPath.cwd().glob() \\(\\to\\) 해당 경로안에 있는 파일들의 목록을 확인\n\n\nfrom pathlib import Path\n\nfiles = Path.cwd().glob('*')\n\nfor f in files:\n     print(f)\n\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\.ipynb_checkpoints\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-09-00. Python Basic (1).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-10-01. Python Basic (2) .ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-11-02. Python Basic (3) .ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-14-03. Python Basic (4).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-16-04. Python Basic (5).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-17-05. Python Basic (6).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\extra\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\repr.png\n\n\n\n\n\n\n\nf = open(\"gc.txt\", \"w\")\n\nf.write(\"gc test\\n\")\n\nf.close()\n\n- 파일 생성 확인\n\n- 디렉토리 만들기\n\nexist_ok = True : 아래와 같이 Files이라는 폴더가 존재하면 있는 폴더를 쓰고 없을 경우 만들어서 씀\n\n\nPath(\"Files\").mkdir(exist_ok = True)\n\n- 에러문 확인!\n\nPath(\"Files\").mkdir(exist_ok = False)\n\nFileExistsError: [WinError 183] 파일이 이미 있으므로 만들 수 없습니다: 'Files'\n\n\n- 생성한 디렉토리에 파일을 쓰기\n\nf = open(\"Files/gc.txt\", \"w\")\n\nf.write(\"gc test\\n\")\n\nf.close()\n\n\n\n\n\nf = open(\"Files/gc.txt\",\"r\")\n\nprint(f.read())\n\nf.close()\n\ngc test\n\n\n\n\n\n\n- 지정한 파일이 없으면 새로운 파일을 생성한다.\n\nf = open(\"Files/gc.txt\",\"a\")\n\nf.write(\"test를 확인 중입니다.\")\n\nf.close()\n\n\nf = open('Files/gc.txt', 'r')\nprint(f.read())\nf.close()\n\ngc test\ntest를 확인 중입니다.\n\n\n\n\n\n- [Errno 17] File exists: ‘Files/gc.txt’\n\nf = open('Files/gc.txt', 'x')\n\nFileExistsError: [Errno 17] File exists: 'Files/gc.txt'\n\n\n\n\n\ntry : \n    f = open('Files/gc.txt', 'x')\nexcept FileExistsError :\n    print(\"이미 파일이 존재합니다.\")\nelse : \n    print (\"파일 쓰기 성공!\")\n\n이미 파일이 존재합니다.\n\n\n\n\n\n\n\n\n\nf = open(\"test.txt\",\"w\")\nf.close()\n\n\n\n\n\n\nf = open(\"test.txt\",\"a\")\n\nf.write(\"이름 : 이강철\\n 나이 : 28세\")\n\nf.close()\n\n\n\n\n\nf = open(\"test.txt\",\"r\")\n\nprint(f.read())\n\n이름 : 이강철\n 나이 : 28세\n\n\n\n\n\n\n\n\nl = [\"이강철\\n\",\"28세\\n\", \"통계학 전공\\n\"]\n\nf = open(\"test2.txt\",\"w\")\n\nf.writelines(l)\nf.close()\n\n\nf = open(\"test2.txt\",\"r\")\nprint(f.read())\n\n이강철\n28세\n통계학 전공\n\n\n\n\n\n\n\nf = open(\"test2.txt\",\"r\")\nresult = f.readlines() \nprint(result)\n\n['이강철\\n', '28세\\n', '통계학 전공\\n']\n\n\n\nfor txt in result:\n    print(txt,end=\"\")\n\n이강철\n28세\n통계학 전공\n\n\n\n\n\n\nf = open(\"test2.txt\",\"r\")\n\nresult = f.readline()\nwhile result : \n    print(result,end=\"\")\n    result = f.readline()\nf.close()\n\n이강철\n28세\n통계학 전공"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#경로-설정",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#경로-설정",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "- 홈 디렉토리를 불러오는 명령어\n\nfrom pathlib import Path\nprint(Path.home())\n\nC:\\Users\\user\n\n\n- 현재 작업 디렉토리 확인\n\nprint(Path.cwd())\n\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\n\n\n\nPath.cwd().glob() \\(\\to\\) 해당 경로안에 있는 파일들의 목록을 확인\n\n\nfrom pathlib import Path\n\nfiles = Path.cwd().glob('*')\n\nfor f in files:\n     print(f)\n\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\.ipynb_checkpoints\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-09-00. Python Basic (1).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-10-01. Python Basic (2) .ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-11-02. Python Basic (3) .ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-14-03. Python Basic (4).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-16-04. Python Basic (5).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\2023-08-17-05. Python Basic (6).ipynb\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\extra\nC:\\projects\\mysite2\\posts\\DX\\0. 데이터 다루기\\repr.png"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-쓰기w-write",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-쓰기w-write",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "f = open(\"gc.txt\", \"w\")\n\nf.write(\"gc test\\n\")\n\nf.close()\n\n- 파일 생성 확인\n\n- 디렉토리 만들기\n\nexist_ok = True : 아래와 같이 Files이라는 폴더가 존재하면 있는 폴더를 쓰고 없을 경우 만들어서 씀\n\n\nPath(\"Files\").mkdir(exist_ok = True)\n\n- 에러문 확인!\n\nPath(\"Files\").mkdir(exist_ok = False)\n\nFileExistsError: [WinError 183] 파일이 이미 있으므로 만들 수 없습니다: 'Files'\n\n\n- 생성한 디렉토리에 파일을 쓰기\n\nf = open(\"Files/gc.txt\", \"w\")\n\nf.write(\"gc test\\n\")\n\nf.close()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-읽기-r-read",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-읽기-r-read",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "f = open(\"Files/gc.txt\",\"r\")\n\nprint(f.read())\n\nf.close()\n\ngc test"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-추가-a-append",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-추가-a-append",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "- 지정한 파일이 없으면 새로운 파일을 생성한다.\n\nf = open(\"Files/gc.txt\",\"a\")\n\nf.write(\"test를 확인 중입니다.\")\n\nf.close()\n\n\nf = open('Files/gc.txt', 'r')\nprint(f.read())\nf.close()\n\ngc test\ntest를 확인 중입니다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-존재-유무-확인-x",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-존재-유무-확인-x",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "- [Errno 17] File exists: ‘Files/gc.txt’\n\nf = open('Files/gc.txt', 'x')\n\nFileExistsError: [Errno 17] File exists: 'Files/gc.txt'\n\n\n\n\n\ntry : \n    f = open('Files/gc.txt', 'x')\nexcept FileExistsError :\n    print(\"이미 파일이 존재합니다.\")\nelse : \n    print (\"파일 쓰기 성공!\")\n\n이미 파일이 존재합니다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#excercise",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#excercise",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "f = open(\"test.txt\",\"w\")\nf.close()\n\n\n\n\n\n\nf = open(\"test.txt\",\"a\")\n\nf.write(\"이름 : 이강철\\n 나이 : 28세\")\n\nf.close()\n\n\n\n\n\nf = open(\"test.txt\",\"r\")\n\nprint(f.read())\n\n이름 : 이강철\n 나이 : 28세"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-쓰기-writelines",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-쓰기-writelines",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "l = [\"이강철\\n\",\"28세\\n\", \"통계학 전공\\n\"]\n\nf = open(\"test2.txt\",\"w\")\n\nf.writelines(l)\nf.close()\n\n\nf = open(\"test2.txt\",\"r\")\nprint(f.read())\n\n이강철\n28세\n통계학 전공"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-읽기readlines",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-읽기readlines",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "f = open(\"test2.txt\",\"r\")\nresult = f.readlines() \nprint(result)\n\n['이강철\\n', '28세\\n', '통계학 전공\\n']\n\n\n\nfor txt in result:\n    print(txt,end=\"\")\n\n이강철\n28세\n통계학 전공"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-읽기-readline-한-행씩",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-읽기-readline-한-행씩",
    "title": "05. Python Basic (6)",
    "section": "",
    "text": "f = open(\"test2.txt\",\"r\")\n\nresult = f.readline()\nwhile result : \n    print(result,end=\"\")\n    result = f.readline()\nf.close()\n\n이강철\n28세\n통계학 전공"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#패키지-설치",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#패키지-설치",
    "title": "05. Python Basic (6)",
    "section": "패키지 설치",
    "text": "패키지 설치\n\n#!pip install wordcloud\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#워드클라우드-생성",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#워드클라우드-생성",
    "title": "05. Python Basic (6)",
    "section": "워드클라우드 생성",
    "text": "워드클라우드 생성\n\n%config InlineBackend.figure_format='retina' ## 이미지 포맷\n\n# 워드 클라우드 만들기\nwordcloud = WordCloud(font_path = 'C:/Windiws/fonts/HMKMRHD.TTF',  ## 글씨 폰트\n                      width=2000,\n                      height=1000,\n                      background_color='white').generate_from_frequencies(w_c) ##우리가 만든 워드 카운트를전달\n\n# 표시하기\nplt.figure(figsize=(12, 6))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#extra-이미지-파일",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#extra-이미지-파일",
    "title": "05. Python Basic (6)",
    "section": "extra : 이미지 파일",
    "text": "extra : 이미지 파일\n- 이미지 파일을 사용해 워드클라우드의 프레임 변셩\n\nimport\n\n#pip install opencv-python\n\n\nimport numpy as np\nfrom PIL import Image ## 이미지를 불러오기 위한 모듈\nimport cv2 as cv\n\n\n\n해당 이미지 확인\n\nh = cv.imread(\"human.jpg\")\nplt.imshow(h)\n\n&lt;matplotlib.image.AxesImage at 0x1701cf10bd0&gt;\n\n\n\n\n\n\n\n워드클라우드와 함께 그리기\n\nm_image = np.array(Image.open(\"human.jpg\"))\n\nwordcloud = WordCloud(font_path = 'C:/Windiws/fonts/HMKMRHD.TTF',\n                      width=2000, \n                      height=1000, \n                      mask=m_image,\n                      background_color='white').generate_from_frequencies(w_c)\n\n\nfig, axes = plt.subplots(1,2,figsize=(12,8))\n\nax1,ax2 = axes\n\nax1.imshow(h)\nax2.imshow(wordcloud)\nfig.tight_layout()\n\n\n\n\n- 원래 강아지 사진으로 하려고 했는데 강아지 모양이 안나왔다.\n\n아마 해당 사진에 위 사진처럼 흰색의 공간이 없어서 그런것 같다..ㅜㅜ\n개인적으로 워드클라우드를 선호하지 않으니 쓰는 방법만 기록해두자!"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#꽃-사진으로-워드클라우드",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#꽃-사진으로-워드클라우드",
    "title": "05. Python Basic (6)",
    "section": "꽃 사진으로 워드클라우드!",
    "text": "꽃 사진으로 워드클라우드!\n\nflower=  cv.imread(\"flower.png\")\n\n\nm_image = np.array(Image.open(\"flower.png\"))\n\nwordcloud = WordCloud(font_path = 'C:/Windiws/fonts/HMKMRHD.TTF',\n                      width=2000, \n                      height=1000, \n                      mask=m_image,\n                      background_color='white').generate_from_frequencies(w_c)\n\n\nfig, axes = plt.subplots(1,2,figsize=(12,8))\n\nax1,ax2 = axes\n\nax1.imshow(flower)\nax2.imshow(wordcloud)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-load",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#파일-load",
    "title": "05. Python Basic (6)",
    "section": "파일 Load",
    "text": "파일 Load\n\ns1 = wb[\"Sheet1\"]\n\n\n셀이름으로 값 확인\n\ns1[\"A1\"].value\n\n'date'\n\n\n\n\n행과 열 변호로 셀 값확인\n\ns1.cell(row=1,column =1).value\n\n'date'\n\n\n\ns1.cell(row=2,column =6).value\n\n'F'\n\n\n\n\n데이터 영역 확인\n\nprint(s1.min_row,s1.max_row)\nprint(s1.min_column,s1.max_column)\n\n1 21\n1 6\n\n\n\n\nex1. 반복문을 이용해서 데이터를 출력\n\nfor i in range(s1.min_row,s1.max_row+1) :\n    for j in range(s1.min_column,s1.max_column+1) :\n        print(s1.cell(row = i, column=j).value,end=\" | \")\n    print(\"\\n\")\n\ndate | A | B | C | D | sex | \n\n2020-12-25 | 1.624345363663242 | -0.6117564136500754 | -0.5281717522634557 | -1.072968622156171 | F | \n\n2020-12-26 | 0.8654076293246785 | -2.301538696880283 | 1.74481176421648 | -0.7612069008951028 | M | \n\n2020-12-27 | 0.3190390960570985 | -0.2493703754774101 | 1.462107937044974 | -2.060140709497654 | F | \n\n2020-12-28 | -0.3224172040135075 | -0.3840543546684156 | 1.133769442335437 | -1.099891267314031 | M | \n\n2020-12-29 | -0.1724282075504357 | -0.8778584179213718 | 0.0422137467155928 | 0.5828152137158222 | F | \n\n2020-12-30 | -1.100619177212921 | 1.144723709839614 | 0.9015907205927955 | 0.5024943389018682 | M | \n\n2020-12-31 | 0.9008559492644118 | -0.6837278591743331 | -0.1228902255186481 | -0.9357694342590688 | F | \n\n2021-01-01 | -0.2678880796260159 | 0.530355466738186 | -0.691660751725309 | -0.3967535268559773 | M | \n\n2021-01-02 | -0.6871727001195994 | -0.8452056414987196 | -0.671246130836819 | -0.0126645989189013 | F | \n\n2021-01-03 | -1.117310348635278 | 0.2344156978170921 | 1.65980217710987 | 0.7420441605773356 | M | \n\n2021-01-04 | -0.1918355523616149 | -0.8876289640848363 | -0.7471582937508376 | 1.692454601027747 | F | \n\n2021-01-05 | 0.0508077547760289 | -0.6369956465693534 | 0.190915484667466 | 2.100255136478842 | M | \n\n2021-01-06 | 0.1201589524816291 | 0.6172031097074192 | 0.3001703199558275 | -0.3522498464935186 | F | \n\n2021-01-07 | -1.14251819802214 | -0.3493427224128775 | -0.2088942333747781 | 0.5866231911821976 | M | \n\n2021-01-08 | 0.8389834138745049 | 0.9311020813035572 | 0.2855873252542588 | 0.8851411642707281 | F | \n\n2021-01-09 | -0.7543979409966528 | 1.252868155233288 | 0.5129298204180088 | -0.2980928351027156 | M | \n\n2021-01-10 | 0.488518146537497 | -0.0755717130210557 | 1.131629387451427 | 1.519816816422199 | F | \n\n2021-01-11 | 2.185575406533161 | -1.396496335488138 | -1.444113805429589 | -0.5044658629464512 | M | \n\n2021-01-12 | 0.1600370694478304 | 0.8761689211162249 | 0.3156349472416052 | -2.022201215824003 | F | \n\n2021-01-13 | -0.3062040126283718 | 0.8279746426072462 | 0.2300947353643834 | 0.7620111803120247 | M | \n\n\n\n- 원데이터 확인\n\n_df = pd.read_excel(\"df.xlsx\")\n_df\n\n\n\n\n\n\n\n\ndate\nA\nB\nC\nD\nsex\n\n\n\n\n0\n2020-12-25\n1.624345\n-0.611756\n-0.528172\n-1.072969\nF\n\n\n1\n2020-12-26\n0.865408\n-2.301539\n1.744812\n-0.761207\nM\n\n\n2\n2020-12-27\n0.319039\n-0.249370\n1.462108\n-2.060141\nF\n\n\n3\n2020-12-28\n-0.322417\n-0.384054\n1.133769\n-1.099891\nM\n\n\n4\n2020-12-29\n-0.172428\n-0.877858\n0.042214\n0.582815\nF\n\n\n5\n2020-12-30\n-1.100619\n1.144724\n0.901591\n0.502494\nM\n\n\n6\n2020-12-31\n0.900856\n-0.683728\n-0.122890\n-0.935769\nF\n\n\n7\n2021-01-01\n-0.267888\n0.530355\n-0.691661\n-0.396754\nM\n\n\n8\n2021-01-02\n-0.687173\n-0.845206\n-0.671246\n-0.012665\nF\n\n\n9\n2021-01-03\n-1.117310\n0.234416\n1.659802\n0.742044\nM\n\n\n10\n2021-01-04\n-0.191836\n-0.887629\n-0.747158\n1.692455\nF\n\n\n11\n2021-01-05\n0.050808\n-0.636996\n0.190915\n2.100255\nM\n\n\n12\n2021-01-06\n0.120159\n0.617203\n0.300170\n-0.352250\nF\n\n\n13\n2021-01-07\n-1.142518\n-0.349343\n-0.208894\n0.586623\nM\n\n\n14\n2021-01-08\n0.838983\n0.931102\n0.285587\n0.885141\nF\n\n\n15\n2021-01-09\n-0.754398\n1.252868\n0.512930\n-0.298093\nM\n\n\n16\n2021-01-10\n0.488518\n-0.075572\n1.131629\n1.519817\nF\n\n\n17\n2021-01-11\n2.185575\n-1.396496\n-1.444114\n-0.504466\nM\n\n\n18\n2021-01-12\n0.160037\n0.876169\n0.315635\n-2.022201\nF\n\n\n19\n2021-01-13\n-0.306204\n0.827975\n0.230095\n0.762011\nM"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#엑셀값-수정",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#엑셀값-수정",
    "title": "05. Python Basic (6)",
    "section": "엑셀값 수정",
    "text": "엑셀값 수정\n\ndate \\(\\to\\) 날짜로 ㄹ바꿔보자\n\n\ns1[\"A1\"].value = \"날짜\"\n\n\ns1.cell(row=1,column=1).value\n\n'날짜'\n\n\n- 그러나 아직 파일에는 반영이 되지 않았음\n\n원본에 파일 반영하여 저장\n\nwb.save(\"df.xlsx\")\n\n- 다시 load후 결과 확인\n\nwb = xl.load_workbook(\"df.xlsx\")\n\n\ns1 = wb[\"Sheet1\"]\n\n\ns1.cell(row=1,column=1).value\n\n'날짜'\n\n\n\n\nex1. sex \\(\\to\\) 성별\n\ns1.cell(row=1,column=6).value\n\n'sex'\n\n\n\ns1[\"F1\"].value = \"성별\"\n\n\nwb.save(\"df.xlsx\")\n\n\nwb = xl.load_workbook(\"df.xlsx\")\ns1 = wb[\"Sheet1\"]\ns1.cell(row=1,column=6).value\n\n'성별'\n\n\n\n\n행 추가\n- 워크북 오브젝트 생성\n\nwb = xl.load_workbook(\"df.xlsx\")\n\n\ns1 = wb[\"Sheet1\"]\n\n- 두 번째 행에 빈 행 추가\n\ns1.insert_rows(2)\n\n- 빈 값이 들어간 것을 확인\n\nprint(s1.cell(2, 1).value, s1.cell(2, 2).value)b\n\nNone None\n\n\n\n\n열 추가\n\ns1.insert_cols(7)\n\n- 빈 값이 들어간 것을 확인\n\nprint(s1.cell(1, 7).value, s1.cell(2, 7).value)\n\nNone None\n\n\n- 전체 데이터 확인\n\nfor i in range(s1.min_row,s1.max_row+1) :\n    for j in range(s1.min_column,s1.max_column+1) :\n        print(s1.cell(row = i, column=j).value,end=\" | \")\n    print(\"\\n\")\n\n날짜 | A | B | C | D | 성별 | None | \n\nNone | None | None | None | None | None | None | \n\n2020-12-25 | 1.624345363663242 | -0.6117564136500754 | -0.5281717522634557 | -1.072968622156171 | F | None | \n\n2020-12-26 | 0.8654076293246785 | -2.301538696880283 | 1.74481176421648 | -0.7612069008951028 | M | None | \n\n2020-12-27 | 0.3190390960570985 | -0.2493703754774101 | 1.462107937044974 | -2.060140709497654 | F | None | \n\n2020-12-28 | -0.3224172040135075 | -0.3840543546684156 | 1.133769442335437 | -1.099891267314031 | M | None | \n\n성별 | -0.1724282075504357 | -0.8778584179213718 | 0.0422137467155928 | 0.5828152137158222 | F | None | \n\n2020-12-30 | -1.100619177212921 | 1.144723709839614 | 0.9015907205927955 | 0.5024943389018682 | M | None | \n\n2020-12-31 | 0.9008559492644118 | -0.6837278591743331 | -0.1228902255186481 | -0.9357694342590688 | F | None | \n\n2021-01-01 | -0.2678880796260159 | 0.530355466738186 | -0.691660751725309 | -0.3967535268559773 | M | None | \n\n2021-01-02 | -0.6871727001195994 | -0.8452056414987196 | -0.671246130836819 | -0.0126645989189013 | F | None | \n\n2021-01-03 | -1.117310348635278 | 0.2344156978170921 | 1.65980217710987 | 0.7420441605773356 | M | None | \n\n2021-01-04 | -0.1918355523616149 | -0.8876289640848363 | -0.7471582937508376 | 1.692454601027747 | F | None | \n\n2021-01-05 | 0.0508077547760289 | -0.6369956465693534 | 0.190915484667466 | 2.100255136478842 | M | None | \n\n2021-01-06 | 0.1201589524816291 | 0.6172031097074192 | 0.3001703199558275 | -0.3522498464935186 | F | None | \n\n2021-01-07 | -1.14251819802214 | -0.3493427224128775 | -0.2088942333747781 | 0.5866231911821976 | M | None | \n\n2021-01-08 | 0.8389834138745049 | 0.9311020813035572 | 0.2855873252542588 | 0.8851411642707281 | F | None | \n\n2021-01-09 | -0.7543979409966528 | 1.252868155233288 | 0.5129298204180088 | -0.2980928351027156 | M | None | \n\n2021-01-10 | 0.488518146537497 | -0.0755717130210557 | 1.131629387451427 | 1.519816816422199 | F | None | \n\n2021-01-11 | 2.185575406533161 | -1.396496335488138 | -1.444113805429589 | -0.5044658629464512 | M | None | \n\n2021-01-12 | 0.1600370694478304 | 0.8761689211162249 | 0.3156349472416052 | -2.022201215824003 | F | None | \n\n2021-01-13 | -0.3062040126283718 | 0.8279746426072462 | 0.2300947353643834 | 0.7620111803120247 | M | None | \n\n\n\n\n\n위에서 추가한 빈 행과 열을 삭제\n\ns1.delete_rows(2)\ns1.delete_cols(7)\n\n- 삭제 후 확인\n\nfor i in range(s1.min_row,s1.max_row+1) :\n    for j in range(s1.min_column,s1.max_column+1) :\n        print(s1.cell(row = i, column=j).value,end=\" | \")\n    print(\"\\n\")\n\n날짜 | A | B | C | D | 성별 | \n\n2020-12-25 | 1.624345363663242 | -0.6117564136500754 | -0.5281717522634557 | -1.072968622156171 | F | \n\n2020-12-26 | 0.8654076293246785 | -2.301538696880283 | 1.74481176421648 | -0.7612069008951028 | M | \n\n2020-12-27 | 0.3190390960570985 | -0.2493703754774101 | 1.462107937044974 | -2.060140709497654 | F | \n\n2020-12-28 | -0.3224172040135075 | -0.3840543546684156 | 1.133769442335437 | -1.099891267314031 | M | \n\n성별 | -0.1724282075504357 | -0.8778584179213718 | 0.0422137467155928 | 0.5828152137158222 | F | \n\n2020-12-30 | -1.100619177212921 | 1.144723709839614 | 0.9015907205927955 | 0.5024943389018682 | M | \n\n2020-12-31 | 0.9008559492644118 | -0.6837278591743331 | -0.1228902255186481 | -0.9357694342590688 | F | \n\n2021-01-01 | -0.2678880796260159 | 0.530355466738186 | -0.691660751725309 | -0.3967535268559773 | M | \n\n2021-01-02 | -0.6871727001195994 | -0.8452056414987196 | -0.671246130836819 | -0.0126645989189013 | F | \n\n2021-01-03 | -1.117310348635278 | 0.2344156978170921 | 1.65980217710987 | 0.7420441605773356 | M | \n\n2021-01-04 | -0.1918355523616149 | -0.8876289640848363 | -0.7471582937508376 | 1.692454601027747 | F | \n\n2021-01-05 | 0.0508077547760289 | -0.6369956465693534 | 0.190915484667466 | 2.100255136478842 | M | \n\n2021-01-06 | 0.1201589524816291 | 0.6172031097074192 | 0.3001703199558275 | -0.3522498464935186 | F | \n\n2021-01-07 | -1.14251819802214 | -0.3493427224128775 | -0.2088942333747781 | 0.5866231911821976 | M | \n\n2021-01-08 | 0.8389834138745049 | 0.9311020813035572 | 0.2855873252542588 | 0.8851411642707281 | F | \n\n2021-01-09 | -0.7543979409966528 | 1.252868155233288 | 0.5129298204180088 | -0.2980928351027156 | M | \n\n2021-01-10 | 0.488518146537497 | -0.0755717130210557 | 1.131629387451427 | 1.519816816422199 | F | \n\n2021-01-11 | 2.185575406533161 | -1.396496335488138 | -1.444113805429589 | -0.5044658629464512 | M | \n\n2021-01-12 | 0.1600370694478304 | 0.8761689211162249 | 0.3156349472416052 | -2.022201215824003 | F | \n\n2021-01-13 | -0.3062040126283718 | 0.8279746426072462 | 0.2300947353643834 | 0.7620111803120247 | M |"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#import-1",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#import-1",
    "title": "05. Python Basic (6)",
    "section": "import",
    "text": "import\n\nimport smtplib\nfrom email.mime.text import MIMEText"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step1.-기본-셋팅",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step1.-기본-셋팅",
    "title": "05. Python Basic (6)",
    "section": "step1. 기본 셋팅",
    "text": "step1. 기본 셋팅\n\n지메일, 모든 설정 \\(\\to\\) 전달 및 POP/IMAP \\(\\to\\) IMAP 엑세스(IMAP 사용 체크) \\(\\to\\) 변경사항 저장\n구글 계정 괸리 클랙 \\(\\to\\) 보안 \\(\\to\\) 2단계 인증 클릭 \\(\\to\\) 앱 비밀번호 \\(\\to\\) windows, 컴퓨터 메일 오픈\n컴퓨터용 앱 비밀번호 복사\n복사 후 첫 번째 인자에는 나의 이메일을, 두 번째 인자에는 복사한 비밀번호를 기입 후 실행\n\n\n# smtp 주소\ns = smtplib.SMTP('smtp.gmail.com', 587)\n\n# TLS 보안 시작\ns.starttls() \n\n## 로그인\ns.login('rkdcjf8232@gmail.com', 'zfkdrzytshqsucln') \n\n(235, b'2.7.0 Accepted')"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step2.-메일-내용구성",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step2.-메일-내용구성",
    "title": "05. Python Basic (6)",
    "section": "step2. 메일 내용구성",
    "text": "step2. 메일 내용구성\n\n## 본문\nm = MIMEText('''\n메일 보내기 테스트 테스트\n'''\n)\n\n## 제목\nm[\"Subject\"] = \"gc test\""
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step3.-메일-보내기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step3.-메일-보내기",
    "title": "05. Python Basic (6)",
    "section": "step3. 메일 보내기",
    "text": "step3. 메일 보내기\n- s.sendmail(발신주소, 수신주소, 메일)\n\ns.sendmail(\"rkdcjf8232@gmail.com\",\"rkdcjf202150256@gmail.com\",m.as_string())\ns.quit()\n\n(221,\n b'2.0.0 closing connection s11-20020a62e70b000000b006888029fd63sm2245220pfh.9 - gsmtp')"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step4.-메일-확인",
    "href": "posts/DX/00. 데이터 다루기/2023-08-17-05. Python Basic (6).html#step4.-메일-확인",
    "title": "05. Python Basic (6)",
    "section": "step4. 메일 확인",
    "text": "step4. 메일 확인"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html",
    "title": "03. Python Basic (4)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1.-특정-수보다-크거나-같으면-10-더하기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1.-특정-수보다-크거나-같으면-10-더하기",
    "title": "03. Python Basic (4)",
    "section": "ex1. 특정 수보다 크거나 같으면 10 더하기",
    "text": "ex1. 특정 수보다 크거나 같으면 10 더하기\n\nv = int(input(\"기준값을 입력하시오 : \"))\ns = int(input(\"비교값을 입력하시오 : \"))\nif s&gt;= v:\n    s1 = s+10\n    print(f\"입력값 {v}보다 크거나 같은 숫자가 입력되었습니다. {s}에 10을 더한값은 {s1}입니다.\")\nelse:\n    print(f\"입력값 {v}보다 작은 숫자입니다.\")\n\n기준값을 입력하시오 :  70\n비교값을 입력하시오 :  60\n\n\n입력값 70보다 작은 숫자입니다.\n\n\n\nv = int(input(\"기준값을 입력하시오 : \"))\ns = int(input(\"비교값을 입력하시오 : \"))\nif s&gt;= v:\n    s1 = s+10\n    print(f\"입력값 {v}보다 크거나 같은 숫자가 입력되었습니다. {s}에 10을 더한값은 {s1}입니다.\")\nelse:\n    print(f\"입력값 {v}보다 작은 숫자입니다.\")\n\n기준값을 입력하시오 :  70\n비교값을 입력하시오 :  70\n\n\n입력값 70보다 크거나 같은 숫자가 입력되었습니다. 70에 10을 더한값은 80입니다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2.-리스트-요소-확인",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2.-리스트-요소-확인",
    "title": "03. Python Basic (4)",
    "section": "ex2. 리스트 요소 확인",
    "text": "ex2. 리스트 요소 확인\n\ns = [1,2,3,4,5]\nif s :\n    print(s)\nelse :\n    print(\"요소 없음\")\n\n[1, 2, 3, 4, 5]\n\n\n\ns = []\nif s :\n    print(s)\nelse :\n    print(\"요소 없음\")\n\n요소 없음\n\n\n\ns = [1,2,3,4,5]\nif s :\n    pass ## 나중에 먼가 내가 조건문일 때 정의를 남기려고 `pass`!\nelse :\n    print(\"요소 없음\")"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1.-학점",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1.-학점",
    "title": "03. Python Basic (4)",
    "section": "ex1. 학점",
    "text": "ex1. 학점\n\nimport numpy as np\n\n\ns = list(range(0,100,10))\n\n\ndef grade(s) :\n    if s &gt;= 90:\n        return \"A\"\n    elif s&gt;=80:\n        return \"B\"\n    elif s&gt;=70:\n        return \"C\"\n    elif s&gt;=60:\n        return \"D\"\n    else :\n        return \"F\"        \n\n\ns\n\n[0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n\n\n\n[grade(i) for i in s]\n\n['F', 'F', 'F', 'F', 'F', 'F', 'D', 'C', 'B', 'A']"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2.-아래-인코딩을-수행",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2.-아래-인코딩을-수행",
    "title": "03. Python Basic (4)",
    "section": "ex2. 아래 인코딩을 수행",
    "text": "ex2. 아래 인코딩을 수행\n\n\n\n숫자\n요일\n\n\n\n\n0\n월요일\n\n\n1\n화요일\n\n\n2\n수요일\n\n\n3\n목요일\n\n\n4\n금요일\n\n\n5\n토요일\n\n\n6\n일요일\n\n\n\n\nnum = list(np.random.randint(0,7,20))\n\n\ndef days(n) :\n    if n == 0 :\n        return \"월\"\n    elif n == 1 :\n        return \"화\"\n    elif n == 2 :\n        return \"수\"\n    elif n == 3 :\n        return \"목\"\n    elif n == 4 :\n        return \"금\"\n    elif n == 5 :\n        return \"토\"\n    else :\n        return \"일\"\n\n\nweek = [days(n) for n in num]\n\n\nprint(week)\n\n['월', '일', '토', '수', '월', '금', '일', '목', '월', '월', '토', '금', '일', '수', '화', '월', '수', '목', '일', '일']"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex3.-60점-이하-과락",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex3.-60점-이하-과락",
    "title": "03. Python Basic (4)",
    "section": "ex3. 60점 이하 과락",
    "text": "ex3. 60점 이하 과락\n\ns = [62,59,70]\n\n\nfor i in s :\n    if i &lt;60 :\n        print (i,\"과락\")\n    else :\n        print(i)\n\n62\n59 과락\n70"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1-for-if-to-짝수만-출력",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1-for-if-to-짝수만-출력",
    "title": "03. Python Basic (4)",
    "section": "ex1) for + if \\(\\to\\) 짝수만 출력",
    "text": "ex1) for + if \\(\\to\\) 짝수만 출력\n\ns = list(np.random.randint(1,100,size=10))\ns\n\n[37, 10, 35, 31, 70, 28, 40, 74, 69, 55]\n\n\n\ns2 = [i for i in s if i%2==0]\n\n\nprint(f\"짝수 list는 {s2}, 합은 {sum(s2)}\")\n\n짝수 list는 [10, 70, 28, 40, 74], 합은 222"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2-리스트안에-원소-출력",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2-리스트안에-원소-출력",
    "title": "03. Python Basic (4)",
    "section": "ex2) 리스트안에 원소 출력",
    "text": "ex2) 리스트안에 원소 출력\n\nlst = [1,2, \"강철\",True, 1+2j]\n\n\n[i for i in lst]\n\n[1, 2, '강철', True, (1+2j)]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex3-문자열-리스트-출력",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex3-문자열-리스트-출력",
    "title": "03. Python Basic (4)",
    "section": "ex3) 문자열 리스트 출력",
    "text": "ex3) 문자열 리스트 출력\n\nl = list(\"abc\")\n\nfor i in l:\n    print(i)\n\na\nb\nc"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex4-구구단-구현",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex4-구구단-구현",
    "title": "03. Python Basic (4)",
    "section": "ex4) 구구단 구현",
    "text": "ex4) 구구단 구현\n\nlst = list(range(2,10))\n\n\nfor i in lst :\n    for j in range(1,10) : \n        print (f\"{i} x {j} = {i*j}\")\n\n2 x 1 = 2\n2 x 2 = 4\n2 x 3 = 6\n2 x 4 = 8\n2 x 5 = 10\n2 x 6 = 12\n2 x 7 = 14\n2 x 8 = 16\n2 x 9 = 18\n3 x 1 = 3\n3 x 2 = 6\n3 x 3 = 9\n3 x 4 = 12\n3 x 5 = 15\n3 x 6 = 18\n3 x 7 = 21\n3 x 8 = 24\n3 x 9 = 27\n4 x 1 = 4\n4 x 2 = 8\n4 x 3 = 12\n4 x 4 = 16\n4 x 5 = 20\n4 x 6 = 24\n4 x 7 = 28\n4 x 8 = 32\n4 x 9 = 36\n5 x 1 = 5\n5 x 2 = 10\n5 x 3 = 15\n5 x 4 = 20\n5 x 5 = 25\n5 x 6 = 30\n5 x 7 = 35\n5 x 8 = 40\n5 x 9 = 45\n6 x 1 = 6\n6 x 2 = 12\n6 x 3 = 18\n6 x 4 = 24\n6 x 5 = 30\n6 x 6 = 36\n6 x 7 = 42\n6 x 8 = 48\n6 x 9 = 54\n7 x 1 = 7\n7 x 2 = 14\n7 x 3 = 21\n7 x 4 = 28\n7 x 5 = 35\n7 x 6 = 42\n7 x 7 = 49\n7 x 8 = 56\n7 x 9 = 63\n8 x 1 = 8\n8 x 2 = 16\n8 x 3 = 24\n8 x 4 = 32\n8 x 5 = 40\n8 x 6 = 48\n8 x 7 = 56\n8 x 8 = 64\n8 x 9 = 72\n9 x 1 = 9\n9 x 2 = 18\n9 x 3 = 27\n9 x 4 = 36\n9 x 5 = 45\n9 x 6 = 54\n9 x 7 = 63\n9 x 8 = 72\n9 x 9 = 81"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex5-enumerate-to-짝수번째-인덱스만-출력",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex5-enumerate-to-짝수번째-인덱스만-출력",
    "title": "03. Python Basic (4)",
    "section": "ex5) enumerate \\(\\to\\) 짝수번째 인덱스만 출력",
    "text": "ex5) enumerate \\(\\to\\) 짝수번째 인덱스만 출력\n- 컨테이너 자료형(문자열(str), 튜플(tuple), 리스트(list), 딕셔터리(dictionary), 집합(set))을 입력받아, 순번과 요소를 포함하는 오브젝트를 출력\n\nlst = list(\"abcdefghi\")\n\n\nlist(enumerate(lst))\n\n[(0, 'a'),\n (1, 'b'),\n (2, 'c'),\n (3, 'd'),\n (4, 'e'),\n (5, 'f'),\n (6, 'g'),\n (7, 'h'),\n (8, 'i')]\n\n\n\nfor i,j in enumerate(lst) :\n    if i%2==0 :\n        print(f\"index : {i}, str = {j}\")\n\nindex : 0, str = a\nindex : 2, str = c\nindex : 4, str = e\nindex : 6, str = g\nindex : 8, str = i"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex6-여러개의-값을-입력받아-짝수들의-제곱을-구하기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex6-여러개의-값을-입력받아-짝수들의-제곱을-구하기",
    "title": "03. Python Basic (4)",
    "section": "ex6) 여러개의 값을 입력받아 짝수들의 제곱을 구하기",
    "text": "ex6) 여러개의 값을 입력받아 짝수들의 제곱을 구하기\n\nnum_list = list(map(int, input(\"숫자를 입력하세요 : \").split()))\n\n\ns_list = [i**2 for i in num_list if i % 2 == 0]\n\ns_list\n\n숫자를 입력하세요 :  1 2 3 4 5 6\n\n\n[4, 16, 36]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1-기본-반복문",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex1-기본-반복문",
    "title": "03. Python Basic (4)",
    "section": "ex1) 기본 반복문",
    "text": "ex1) 기본 반복문\n\ns = dict(a=100,b=55,c=74,d=87)\ns.items()\n\ndict_items([('a', 100), ('b', 55), ('c', 74), ('d', 87)])\n\n\n\nfor i,j in s.items() :\n    print(i,j)\n\na 100\nb 55\nc 74\nd 87"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2-기준값을-입력받은후-특정값보다-큰-keyvalue를-추출",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2-기준값을-입력받은후-특정값보다-큰-keyvalue를-추출",
    "title": "03. Python Basic (4)",
    "section": "ex2) 기준값을 입력받은후 특정값보다 큰 key,value를 추출",
    "text": "ex2) 기준값을 입력받은후 특정값보다 큰 key,value를 추출\n\nnum = int(input(\"숫자를 입력하시오 : \"))\n\nfor i,j in s.items() :\n    if j&gt;num :\n        print (i,j)\n\n숫자를 입력하시오 :  60\n\n\na 100\nc 74\nd 87"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex3-합구하기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex3-합구하기",
    "title": "03. Python Basic (4)",
    "section": "ex3) 합구하기",
    "text": "ex3) 합구하기\n\ns = {\"a\" : [1,2,3,4],\n     \"b\" : [5,6,7,8],\n     \"c\" : [6,7,8,9]}\n\n\n{i : sum(j) for i,j in s.items()}\n\n{'a': 10, 'b': 26, 'c': 30}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2.-break",
    "href": "posts/DX/00. 데이터 다루기/2023-08-14-03. Python Basic (4).html#ex2.-break",
    "title": "03. Python Basic (4)",
    "section": "ex2. break",
    "text": "ex2. break\n- 짝수합 구하기\n\ns,i =0,0\n\nwhile True :\n    i+=1\n    if i&gt;100 :\n        break ## 100d을 넘어가면 break\n    if i%2==0 :\n        s += i\n    else :\n        continue ## 다시 처음으로"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html",
    "title": "01. Python Basic (2)",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\ncd /content/drive/MyDrive/Colab Notebooks/DX/1wk\n\n/content/drive/MyDrive/Colab Notebooks/DX/1wk\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#슬라이싱-1",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#슬라이싱-1",
    "title": "01. Python Basic (2)",
    "section": "슬라이싱 1",
    "text": "슬라이싱 1\n\nn = len(txt)\ntxt[2:n]\n\n' 이름은 이강철입니다.'\n\n\n- 참고 역슬레시는 인데싱에서 제외된다.\n\nprint(\"he's\")\nprint(\"he\\'s\")\n\nhe's\nhe's"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#슬라이싱-2",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#슬라이싱-2",
    "title": "01. Python Basic (2)",
    "section": "슬라이싱 2",
    "text": "슬라이싱 2\n- 구조 : txt[start : end : stride]\n\ntxt\n\n'나의 이름은 이강철입니다.'\n\n\n\nprint(txt[0:n:2])\nprint(txt[::2])\nprint(txt[::3])\nprint(txt[::-1])\nprint(txt[::-2])\n\n나 름 강입다\n나 름 강입다\n나이 철다\n.다니입철강이 은름이 의나\n.니철이은이의"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#count",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#count",
    "title": "01. Python Basic (2)",
    "section": "Count",
    "text": "Count\n\ntxt\n\n'나의 이름은 이강철입니다.'\n\n\n- 공백 세기\n\ntxt.count(\" \")\n\n2\n\n\n- 특장 문자 세기\n\ntxt.count(\"이\")\n\n2\n\n\n- 리스트나 튜플로 넘겨주면 에러가 발생\n\ntxt.count((\"이\",\" \"))\n\nTypeError: ignored\n\n\n- 문자가 아닌 문자열 카운트\n\nprint(txt)\nprint(txt.count(\"이강철\"))\n\n나의 이름은 이강철입니다.\n1"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#find",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#find",
    "title": "01. Python Basic (2)",
    "section": "find",
    "text": "find\n- 특정 문자의 인덱싱을 반환\n\nprint(txt)\nprint(txt.find(\"이\"))\nprint(txt.find(\"이강철\"))\n\n나의 이름은 이강철입니다.\n3\n7\n\n\n- find함수에 문제점은 범위를 지정해주지 않으면 찾고자 하는 문자의 첫 인덱스만 반환한다.\n- 특정 문자열을 찾을때 문자열 시작지점과 끝지점을 정해서 인덱싱\n\nprint(txt)\nprint(txt.find(\"이\",6,n))\n\n나의 이름은 이강철입니다.\n7"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#잠깐-다른-이야기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#잠깐-다른-이야기",
    "title": "01. Python Basic (2)",
    "section": "잠깐 다른 이야기!",
    "text": "잠깐 다른 이야기!\n- 아래를 잘 살펴보자.\n\na = 3\nb = 3\nprint(id(a),id(b))\na +=1\nprint(id(a))\na *=2\nprint(id(a))\na =a-5\nprint(id(a))\n\n138123241308464 138123241308464\n138123241308496\n138123241308624\n138123241308464\n\n\n- a변수와 b변수에 3이라는 값을 할당하고, 각 메모리 주소를 출력하였다.\n- 질문 1 : 사칙 연산시 메모리 주소가 바뀐다?\n- 질문 2 : 그런데 동일한 값을 할당하면 같은 주소가 할당된다?\n- 질문 3 : 그런데 마지막에 a에서 5를 빼서 처음에 할당한 3과 동일하게 했더니 처음과 동일한 주소가 나왔다?\n- 내 생각 : 각각의 값(할당한 정수)들은 이미 각자의 고유한 주소를 가지고 있고, 변수들은 그 값들을 참조하는 포인터 역할을 하는 것 같다. 또한, 이는 정수 뿐이 아니라 단일 값을 가지는 모든 형태의 해당된다.\n\n문자열 주소확인\n\ns = \"apple\"\nprint(s)\nprint(id(s))\n\nprint(s.upper())\nprint(id(s.upper()))\n\napple\n138121951987056\nAPPLE\n138121951989872\n\n\n\n\n그렇다면 리스트도?\n\na = list(range(5))\nprint(a)\nprint(id(a))\na[1] = 100\nprint(a)\nprint(id(a))\n\n[0, 1, 2, 3, 4]\n138121952117504\n[0, 100, 2, 3, 4]\n138121952117504\n\n\n- 리스트는 바뀌지 않았다!!"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#capitalize-title",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#capitalize-title",
    "title": "01. Python Basic (2)",
    "section": "capitalize & title",
    "text": "capitalize & title\n- 첫글자만 대문자로 변환\n\na=\"i like apple\"\n\nprint(a.capitalize())\nprint(a.title())\n\nI like apple\nI Like Apple"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#rjust-ljust-center",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#rjust-ljust-center",
    "title": "01. Python Basic (2)",
    "section": "rjust, ljust, center",
    "text": "rjust, ljust, center\n- 각각, 오른쪽, 왼쪽, 중앙정렬을 하고 공백을 만든다\n\na = \"apple\"\nprint(\"[\"+a.rjust(7)+\"]\",sep=\"\")\nprint(\"[\",a.ljust(7),\"]\",sep=\"\")\nprint(\"[\",a.center(7),\"]\",sep=\"\")\n\n[  apple]\n[apple  ]\n[ apple ]\n\n\n- 근데 문장 단위로는 적용되지 않는다….\n\na = \"I like apple\"\nprint(\"[\"+a.rjust(7)+\"]\",sep=\"\")\nprint(\"[\",a.ljust(7),\"]\",sep=\"\")\nprint(\"[\",a.center(7),\"]\",sep=\"\")\n\n[I like apple]\n[I like apple]\n[I like apple]\n\n\n- 핳 근데 문장길이가 7보다 커서 그런거였당\n\na = \"I like apple\"\nprint(\"[\"+a.rjust(19)+\"]\",sep=\"\")\nprint(\"[\",a.ljust(19),\"]\",sep=\"\")\nprint(\"[\",a.center(19),\"]\",sep=\"\")\n\n[       I like apple]\n[I like apple       ]\n[    I like apple   ]\n\n\n- 즉, 전달되는 매개변수는 전체공간을 의미하고, 각각의 메소드는 어디로 정렬할지 정해준다!"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#replace",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#replace",
    "title": "01. Python Basic (2)",
    "section": "replace",
    "text": "replace\n- 값을 바꾼다고 객체가 변환되지는 않는다.\n\ntxt = \"사과\"\nprint(txt.replace(\"사과\",\"바나나\"))\nprint(txt)\n\n바나나\n사과\n\n\n- replace 함수를 자주 사용하는 이유!\n- 실제 데이터 전처리 시 아래와 같은 구조가 많다.\nnumber = \"123,456\"\n이러한 상황이 발생했을 때 replace 함수를 사용\n\nnumber =\"123,456\"\n\nint(number.replace(\",\",\"\"))\n\n123456"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#strip",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#strip",
    "title": "01. Python Basic (2)",
    "section": "strip",
    "text": "strip\n- 텍스트 문자열에서 양쪽 끝에 특정 문자(공백포함)를 제거\n\ntxt = \"  ###사과%%%%  \"\nprint(txt)\nprint(txt.strip(\" \"))\nprint(txt.strip(\"#%\"))  ## 공백이 포함되어 있어서 지워지지 않는 것 같다.\nprint(txt.strip(\" #%\")) ## 공백을 포함하니 깔끔하게 지워졌다.\n\n  ###사과%%%%  \n###사과%%%%\n  ###사과%%%%  \n사과"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#split",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#split",
    "title": "01. Python Basic (2)",
    "section": "split",
    "text": "split\n\n\nCode\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/covid19_20211202.csv\").iloc[1:,:]\ndf = df.set_index(\"일자\").iloc[:,1:18]\n\ndf = df.reset_index()\ndt = df[\"일자\"].tolist()\n\n\n\ndt[:5]\n\n['2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24']\n\n\n\nyear = [i.split(\"-\")[0] for i in dt]\nmonth = [i.split(\"-\")[1] for i in dt]\nday = [i.split(\"-\")[2] for i in dt]\n\n\nnew_df = pd.DataFrame({\"year\": year,\n                       \"month\": month,\n                       \"day\" : day})\nnew_df.head()\n\n\n\n  \n    \n      \n\n\n\n\n\n\nyear\nmonth\nday\n\n\n\n\n0\n2020\n01\n20\n\n\n1\n2020\n01\n21\n\n\n2\n2020\n01\n22\n\n\n3\n2020\n01\n23\n\n\n4\n2020\n01\n24"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#join",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#join",
    "title": "01. Python Basic (2)",
    "section": "join",
    "text": "join\n\ndate = [(\"-\").join([year[i],month[i],day[i]]) for i in range(len(dt))]\n\n\ndate[:5]\n\n['2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24']"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-basic",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-basic",
    "title": "01. Python Basic (2)",
    "section": "리스트 Basic",
    "text": "리스트 Basic\n\n[], list(), list(range(start,end)) 방법으로 리스트를 선언할 수 있다.\n\n\n리스트 선언 & 기본 method\n\na = [1,2,3,4,5]\nb = list((1,2,3,4,5))\nc = list(range(1,6))\n\n\nprint(f'''\n  a= {a}\n  b= {b}\n  c= {c}\n''')\n\n\n  a= [1, 2, 3, 4, 5]\n  b= [1, 2, 3, 4, 5]\n  c= [1, 2, 3, 4, 5]    \n\n\n\n- 선언한 리스트의 합을 구하기\n\nsum(a)\n\n15\n\n\n- 최대값과 최소값\n\nmin(a), max(a)\n\n(1, 5)\n\n\n- 특정 요소 카운트\n\nlst =  np.concatenate([np.ones(2), np.zeros(2)]).tolist()\nlst\n\n[1.0, 1.0, 0.0, 0.0]\n\n\n\nlst.count(0),lst.count(1)\n\n(2, 2)\n\n\n- 인덱스 반환\n\n리스트는 인덱스 반환 시, 맨 처음 인덱스만 반환한다 \\(\\to\\) 문자열.find 함수와 동일!\n\n\nlst.index(0)\n\n2\n\n\n\n그럼 다른 범위에 있는 “원소” 찾을때도 방법이 같지 않을까…???\n\n\nlst.index(0,3,5)\n\n3\n\n\n- 또한, 리스트는 자료형이 같지 않아도 다양한 자료형을 가질 수 있다.\n\n_lst = [True, 3.14, 1, \"에이블\"]\n\n\n[type(i) for i in _lst]\n\n[bool, float, int, str]\n\n\n\n\n리스트 중첩\n- 리스트안에 리스트를 집어넣을 수 있다.\n\nimport numpy as np\n\n\nX = np.arange(1,16).reshape(5,-1)\nprint(\n    f'''\n    X.shape = {X.shape}\n    listX = {X.tolist()}\n   '''\n)\n\n\n    X.shape = (5, 3)\n    listX = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]]\n   \n\n\n\n_X = X.tolist()\n\n\nlen(_X) ## 길이가 5인리스트로 인식됌\n\n5\n\n\n\n\n중첩된 리스트 flatten\n1 리스트 컴프리헨션\n\n[ j for i in _X for j in i ]\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n\n\n2 numpy 이용\n\nnp.array(_X).flatten().tolist()\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-연산",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-연산",
    "title": "01. Python Basic (2)",
    "section": "리스트 연산",
    "text": "리스트 연산\n- 리스트의 연산은 더하기와 곱하기만 지원한다.\n\n+ : 2개의 리스트를 이어붙임, R에서 처럼 브로드캐스팅이 수행되지 않음\n\n\na = [1,2]\nb = [3,4]\n\n\na+b\n\n[1, 2, 3, 4]\n\n\n\n\\(\\times\\) 는 특정 리스트를 얼마나 반복할지 결정해줌\n\n\na*2\n\n[1, 2, 1, 2]\n\n\n\na*0\n\n[]\n\n\n\na*(-2)\n\n[]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-원소-추가",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-원소-추가",
    "title": "01. Python Basic (2)",
    "section": "리스트 원소 추가",
    "text": "리스트 원소 추가\n\nappend\n\na=[]\n\nfor i in range(3):\n    a += [i]\n\na\n\n[0, 1, 2]\n\n\n\nappend 주의!\n- 아래와 같은 연산은 수행되지 않는다.\n\na.append(0).append(1).append(2)\n\nAttributeError: ignored\n\n\n- 또한, 매개변수로 리스트를 전달 시 아래처럼 수행된다.\n\na = [1,2,3]\nb = [4,5]\na.append(b)\na\n\n[1, 2, 3, [4, 5]]\n\n\n\n\nappend를 쓰지않고…\n\na=[]\n\nfor i in range(3):\n    a += [i]\na\n\n[0, 1, 2]\n\n\n\n\n+ 와 .append의 차이\n- append 함수의 경우 연산 수행 후 연산 대상 객체가 변화한다.\n\na = []\na.append(1)\na\n\n[1]\n\n\n- +는 그렇지 않음\n\na = []\na + [1]\na\n\n[]\n\n\n\n\n\nextend\n- 두개의 리스트를 더할 때 extend함수를 사용한다. (append는 리스트 오브 리스트로 붙여준다는점에서 차이가 명확함)\n- append처럼 +와의 차이가 같음.\n\na = [1,2]\nb = [3,4]\na.extend(b)\nprint(f'''\n      a.extend(b) = {a}\n      a = {a}\n      ''')\n\n\n      a.extend(b) = [1, 2, 3, 4]\n      a = [1, 2, 3, 4]\n      \n\n\n\na = [1,2]\nb = [3,4]\na+b\nprint(f'''\n      a + b = {a}\n      a = {a}\n      ''')\n\n\n      a + b = [1, 2]\n      a = [1, 2]\n      \n\n\n\n\ninsert\n- 원하는 인덱스의 요소를 추가한다.\n\na = list(np.round(np.random.normal(size=10),2))\na\n\n[0.51, -0.52, -0.57, -1.48, 0.57, -1.32, 1.71, 0.03, 0.18, 0.97]\n\n\n- 0과 2인덱스의 해당 값을 추가\n\na.insert(0,100)\na.insert(2,77)\n\n\nfor i in range(len(a)) :\n    print(f\"index : {i},  value : {a[i]}\")\n\nindex : 0,  value : 100\nindex : 1,  value : 0.51\nindex : 2,  value : 77\nindex : 3,  value : -0.52\nindex : 4,  value : -0.57\nindex : 5,  value : -1.48\nindex : 6,  value : 0.57\nindex : 7,  value : -1.32\nindex : 8,  value : 1.71\nindex : 9,  value : 0.03\nindex : 10,  value : 0.18\nindex : 11,  value : 0.97"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-원소-삭제",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-원소-삭제",
    "title": "01. Python Basic (2)",
    "section": "리스트 원소 삭제",
    "text": "리스트 원소 삭제\n\na = list(range(5))\na\n\n[0, 1, 2, 3, 4]\n\n\n\n단일 원소삭제\n\na = list(range(5))\na\n\ndel a[0]\n\n\na\n\n[1, 2, 3, 4]\n\n\n\n\n범위 삭제\n\na = list(range(5))\na\n\ndel a[0:2]\na\n\n[2, 3, 4]\n\n\n\n\nremove\n- 특정 원소를 삭제\n\na = list(range(5))\na\n\n[0, 1, 2, 3, 4]\n\n\n\na.remove(3)\n\n\na\n\n[0, 1, 2, 4]\n\n\n\n\npop\n- 특정 index값을 받아 해당 인덱스의 값을 출력하고, 리스트에서 제거된다. \\(\\to\\) 나머지 원소들은 자동으로 인덱스가 앞으로 땅겨짐\n\na = [1,2,3,4]\n\n\na.pop(0)\n\n1\n\n\n\na.pop(0)\n\n2\n\n\n\n\nclear\n- 전체 원소 삭제\n\na = [1,2,3,4]\na\n\n[1, 2, 3, 4]\n\n\n\na.clear()\na\n\n[]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-정렬",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#리스트-정렬",
    "title": "01. Python Basic (2)",
    "section": "리스트 정렬",
    "text": "리스트 정렬\n\na = [1,3,2,4]\na\n\n[1, 3, 2, 4]\n\n\n\na.sort()\na\n\n[1, 2, 3, 4]\n\n\n\na.sort(reverse= True)\na\n\n[4, 3, 2, 1]\n\n\n\na.reverse()\na\n\n[1, 2, 3, 4]\n\n\n리스트 카피\n- 카피함수를 사용하는 이유는 아래와 같은 경우를 방지하기 위함이다.\n\na = list(range(4))\nb = a\n\n\nid(a) == id(b)\n\nTrue\n\n\n- 위와 같이 같은 메모리 공간을 참조하고 있으면….\n\na.append(5)\n\n\na\n\n[0, 1, 2, 3, 5]\n\n\n\nb\n\n[0, 1, 2, 3, 5]\n\n\n- 이러한 경우를 방지하기 위해 copy함수를 사용\n\na = list(range(4))\nb = a.copy()\n\nid(a) == id(b)\n\nFalse\n\n\n\na.append(5)\n\n\nprint(a,b)\n\n[0, 1, 2, 3, 5] [0, 1, 2, 3]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#exercise-link",
    "href": "posts/DX/00. 데이터 다루기/2023-08-10-01. Python Basic (2) .html#exercise-link",
    "title": "01. Python Basic (2)",
    "section": "exercise Link",
    "text": "exercise Link\n- exercise 1\n- exercise 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DX track",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 3, 2023\n\n\n00. 딥러닝 (1)\n\n\nGC \n\n\n\n\nSep 28, 2023\n\n\n08. summary (1)\n\n\nGC \n\n\n\n\nSep 19, 2023\n\n\n07. 머신러닝 (6)\n\n\nGC \n\n\n\n\nSep 18, 2023\n\n\n06. 머신러닝 (5)\n\n\nGC \n\n\n\n\nSep 15, 2023\n\n\n04. 머신러닝 (4)\n\n\nGC \n\n\n\n\nSep 15, 2023\n\n\n05. 종합실습\n\n\nGC \n\n\n\n\nSep 14, 2023\n\n\n03. 머신러닝 (3)\n\n\nGC \n\n\n\n\nSep 13, 2023\n\n\n02. 머신러닝 (2)\n\n\nGC \n\n\n\n\nSep 12, 2023\n\n\n01. 머신러닝 (1)\n\n\nGC \n\n\n\n\nSep 11, 2023\n\n\n00. Intro\n\n\nGC \n\n\n\n\nSep 5, 2023\n\n\n01. 데이터 수집 (2)\n\n\nGC \n\n\n\n\nSep 4, 2023\n\n\n00. 데이터 수집 (1)\n\n\nGC \n\n\n\n\nSep 1, 2023\n\n\n02. 데이터 분석 (3)\n\n\nGC \n\n\n\n\nAug 31, 2023\n\n\n01. 데이터 분석 (2)\n\n\nGC \n\n\n\n\nAug 28, 2023\n\n\n00. 데이터 분석 (1)\n\n\nGC \n\n\n\n\nAug 24, 2023\n\n\n00. MP (1)\n\n\nGC \n\n\n\n\nAug 23, 2023\n\n\n04. numpy & pandas (5)\n\n\nGC \n\n\n\n\nAug 22, 2023\n\n\n03. numpy & pandas (4)\n\n\nGC \n\n\n\n\nAug 21, 2023\n\n\n02. numpy & pandas (3)\n\n\nGC \n\n\n\n\nAug 19, 2023\n\n\n01. Plotly test\n\n\nGC \n\n\n\n\nAug 18, 2023\n\n\n00. numpy & pandas (1)\n\n\nGC \n\n\n\n\nAug 18, 2023\n\n\n01. numpy & pandas (2)\n\n\nGC \n\n\n\n\nAug 17, 2023\n\n\n05. Python Basic (6)\n\n\nGC \n\n\n\n\nAug 16, 2023\n\n\n04. Python Basic (5)\n\n\nGC \n\n\n\n\nAug 15, 2023\n\n\nExtra 04. 클래스 탐구 (3)\n\n\nGC \n\n\n\n\nAug 14, 2023\n\n\n03. Python Basic (4)\n\n\nGC \n\n\n\n\nAug 14, 2023\n\n\nExtra 03. 클래스 탐구 (2)\n\n\nGC \n\n\n\n\nAug 11, 2023\n\n\n02. Python Basic (3)\n\n\nGC \n\n\n\n\nAug 10, 2023\n\n\n01. Python Basic (2)\n\n\nGC \n\n\n\n\nAug 10, 2023\n\n\nExtra 02. 클래스 탐구 (1)\n\n\nGC \n\n\n\n\nAug 9, 2023\n\n\n00. Python Basic (1)\n\n\nGC \n\n\n\n\nAug 9, 2023\n\n\nExtra 01. 클래스\n\n\nGC \n\n\n\n\nAug 8, 2023\n\n\nExtra 00. 밈\n\n\nGC \n\n\n\n\nJul 31, 2023\n\n\n00. Intro & setting\n\n\nGC \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n- 전북대학교 통계학과 학사(부전공: 컴퓨터공학) 졸업 | 3.67 / 4.50 | 2015. 03 ~ 2021. 02\n- 전북대학교 통계학과 석사 졸업 | 4.44 / 4.50 | 2021. 03 ~ 2023. 02"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\n- 국민연금공단 빅데이터부 현장실습 | 2020. 03 ~ 2020. 06\n- 지역 문화산업 융복합 데이터 전문가 과정 | 과학기술정보통신부, 한국데이터산업진흥원 | 2021. 06 ~ 2021. 08\n- 빅데이터 혁신공유대학사업 서포터즈 |전북대학교 빅데이터 현신공유대학사업| 2021. 07. 01 ~ 2021. 10. 31\n- KT AIVLE School DX Consultant Track | KT | 2023. 08 ~"
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "About Me",
    "section": "Publications",
    "text": "Publications\n- 데이터 분석을 통한 지역별 고령친화도 시각화\n`-` 김영선, 강민구, 이강철 등  | 문화융복합아카이빙연구소 | 2021. 10 | 기록관리/보존 \n- 핵심어 추출 및 데이터 증강기법을 이용한 텍스트 분류 모델 성능 개선\n`-` 이강철, 안정용 | 한국자료분석학회 | 한국자료분석학회 | 2022. 10 | 통계학"
  },
  {
    "objectID": "about.html#certificate",
    "href": "about.html#certificate",
    "title": "About Me",
    "section": "Certificate",
    "text": "Certificate\n- 워드프로세서 | 대한상공회의소 | 19-19-017981 | 2019. 08. 30\n- 데이터분석준전문가(ADsP) | 한국데이터진흥원 | ADsP-0223898 | 2019. 10. 01\n- 사회조사분석사 2급 | 한국산업인력공단 | 19201142418N | 2019. 10. 01"
  },
  {
    "objectID": "about.html#conctact",
    "href": "about.html#conctact",
    "title": "About Me",
    "section": "Conctact",
    "text": "Conctact\n- rkdcjf8232@gmail.com"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html",
    "title": "00. Python Basic (1)",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\ncd /content/drive/MyDrive/Colab Notebooks/DX/1wk\n\n/content/drive/MyDrive/Colab Notebooks/DX/1wk"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex1-홀수-짝수-구분",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex1-홀수-짝수-구분",
    "title": "00. Python Basic (1)",
    "section": "ex1) 홀수 짝수 구분",
    "text": "ex1) 홀수 짝수 구분\n\nlst = list(range(1,10))\nlst\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\nsol\n\nodd = [i for i in lst if i % 2 == 1]\nevn = [i for i in lst if i % 2 == 0]\n\n\nodd\n\n[1, 3, 5, 7, 9]\n\n\n\nevn\n\n[2, 4, 6, 8]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex2-특정-숫자가-입력되었을-때-각-자리의-숫자를-구하기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex2-특정-숫자가-입력되었을-때-각-자리의-숫자를-구하기",
    "title": "00. Python Basic (1)",
    "section": "ex2) 특정 숫자가 입력되었을 때 각 자리의 숫자를 구하기",
    "text": "ex2) 특정 숫자가 입력되었을 때 각 자리의 숫자를 구하기\n\nsol\n\nnum  = int(input())\n\na = num // 100\n\nb = (num - a*100) // 10\n\nc = num-(a*100+b*10)\n\nprint(\"백의자리는 {}, 십의자리는 {}, 일의 자리는 {}\".format(a,b,c))\n\n254\n백의자리는 2, 십의자리는 5, 일의 자리는 4"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex3-합과-평균",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex3-합과-평균",
    "title": "00. Python Basic (1)",
    "section": "ex3) 합과 평균",
    "text": "ex3) 합과 평균\n\nsol\n\nimport numpy as np\n\n\ns = list(range(1,10))\n\n\nsumm = sum(s)\n\nave = np.mean(s)\n\n\nprint(\"합 : {}, 평균: {}\".format(summ,ave))\n\n합 : 45, 평균: 5.0"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex4-비교-연산자",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#ex4-비교-연산자",
    "title": "00. Python Basic (1)",
    "section": "ex4) 비교 연산자",
    "text": "ex4) 비교 연산자\n- 숫자 비교\n\na = list(range(1,11))\nb = list(range(11,21))\n\n\na, b\n\n([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n\n\n\n[a[i] == b[i] for i in range(10)]\n\n[False, False, False, False, False, False, False, False, False, False]\n\n\n- 문자 비교\n\n(\"A\" == \"a\"), (\"A\" &gt;\"a\")\n\n(False, False)\n\n\n\nord(\"A\"), ord(\"a\")\n\n(65, 97)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#대표적인-자료형",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#대표적인-자료형",
    "title": "00. Python Basic (1)",
    "section": "대표적인 자료형",
    "text": "대표적인 자료형\n\n\n\nint\nfloat\nbool\nstr\ncomplex\n\n\n\n\n3\n3.14\nTrue\n“강철”\n3+2j\n\n\n5\n3.141551\nFalse\n“이강철”\n2-2j"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#형태변환",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#형태변환",
    "title": "00. Python Basic (1)",
    "section": "형태변환",
    "text": "형태변환\n\nfloat \\(\\to\\) int\n- 아래의 경우는 형태변환이 되었으나 정보의 손실이 발생한 것임\n\na = 3.4\n\n_a = int(a)\n\n\ntype(a), type(_a)\n\n(float, int)\n\n\n\n\n\\(\\text{bool} \\to \\text{(float, int)}\\,\\text{and}\\, \\text{(float, int)} \\to \\text{bool}\\)\n- bool \\(\\to\\) int, float\n\na = True\n_a1 = float(a)\n_a2 = int(a)\n\n\ntype(a), type(_a1), type(_a2)\n\n(bool, float, int)\n\n\n- int, float \\(\\to\\) bool\n\na1 = 1\na2 = 1.0\n\n_a1 = bool(a1)\n_a2 = bool(a2)\n\n\n_a1, _a2, type(_a1), type(_a2)\n\n(True, True, bool, bool)\n\n\n- str \\(\\to\\) bool\n\nbool(\"강철\")\n\nTrue\n\n\n\nbool(\"\")\n\nFalse\n\n\n\n\n암묵적 형변환\n\nTrue +1\n\n2\n\n\n\n1*1.0\n\n1.0\n\n\n\nTrue + True\n\n2\n\n\n\n\n형태변환이 불가능한 경우\n\ncomplex1 = 3+ 0j\ncomplex1\n\n(3+0j)\n\n\nfloat(complex1) ## 에러 발생\n\n\n문자열의 사칙연산(O)\n\n\"X\" + \"2\"\n\n'X2'\n\n\n\n\"X\"*2\n\n'XX'\n\n\n\n\n문자열의 사칙연산(x)\n\"X\" * \"Y\"\n\n\"X\" - \"2\"\n\n\"X\" / \"y\"\n\n- 즉 더하기를 제외한 나머지 사칙연산은 문자형 변수에 적용되지 않는다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#날짜형-자료",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#날짜형-자료",
    "title": "00. Python Basic (1)",
    "section": "날짜형 자료",
    "text": "날짜형 자료\n\nfrom datetime import datetime\n\n\nnow = datetime.now()\n\n\nnow\n\ndatetime.datetime(2023, 8, 9, 5, 45, 24, 616085)\n\n\n\nprint(now)\n\n2023-08-09 05:45:24.616085\n\n\n\nprint(\"{}년 {}월 {}일 {}시 {}분 {}초\".format(now.year,now.month,now.day,now.hour,now.minute,now.second))\n\n2023년 8월 9일 5시 45분 24초"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#기타-연산",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#기타-연산",
    "title": "00. Python Basic (1)",
    "section": "기타 연산",
    "text": "기타 연산\n\na = \"ABCD\"\nb = \"efgh\"\n\n\na.lower(),b.upper()\n\n('abcd', 'EFGH')"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#f-string요즘-쓰는-방식",
    "href": "posts/DX/00. 데이터 다루기/2023-08-09-00. Python Basic (1).html#f-string요즘-쓰는-방식",
    "title": "00. Python Basic (1)",
    "section": "f-string(요즘 쓰는 방식)",
    "text": "f-string(요즘 쓰는 방식)\n\nex1\n\nn = \"이강철\"\na = 28\ns = 100.213141\n\n\nprint(f\"{a}살의 {n}의 점수는 {s:.2f}입니다. \")\n\n28살의 이강철의 점수는 100.00입니다. \n\n\n\n\nex2\n\nn = \"이강철\"\na = 28\ns1 = 100.2\ns2 = 100.3\ns3 = 100.4\ns4 = 100.5\ns5 = 100.6\n\n\ntxt= f'''\n이름 : {n}\n\n연령대 : {age}\n\n점수 : {s1},{s2},{s3},{s4},{s5}\n\n합계 : {ts:,.0f} /평균 : {avg:,.2f}\n'''`\n\nprint(txt)\n\n\n이름 : 이강철\n\n연령대 : 20\n\n점수 : 100.2,100.3,100.4,100.5,100.6\n\n합계 : 502 /평균 : 100.40"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html",
    "title": "02. Python Basic (3)",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#why-use1",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#why-use1",
    "title": "02. Python Basic (3)",
    "section": "why use(1)?",
    "text": "why use(1)?\n- 빠르고 다중 작업에 유리\n- 메모리 관리측면에서도 좋음, 또한 소괄호 생략이 가능하다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-1-여러개의-변수를-동시-출력-및-할당",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-1-여러개의-변수를-동시-출력-및-할당",
    "title": "02. Python Basic (3)",
    "section": "예제 1 : 여러개의 변수를 동시 출력 및 할당",
    "text": "예제 1 : 여러개의 변수를 동시 출력 및 할당\n\nn,a,s,h,w = 1,2,3,4,5\n\n\nn,a,s,h,w\n\n(1, 2, 3, 4, 5)\n\n\n\na = 3.1,\na\n\n(3.1,)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-2.-서로-다른-타입의-원소들로-튜플",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-2.-서로-다른-타입의-원소들로-튜플",
    "title": "02. Python Basic (3)",
    "section": "예제 2. 서로 다른 타입의 원소들로 튜플?",
    "text": "예제 2. 서로 다른 타입의 원소들로 튜플?\n\ns = 90,80,70,\"A\",\"B\"\ns\n\n(90, 80, 70, 'A', 'B')"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-3-튜플-중첩",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-3-튜플-중첩",
    "title": "02. Python Basic (3)",
    "section": "예제 3: 튜플 중첩",
    "text": "예제 3: 튜플 중첩\n\ns = 90,80,70,(\"A\",\"B\")\ns\n\n(90, 80, 70, ('A', 'B'))"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-4-두-변수의-값을-교환",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-4-두-변수의-값을-교환",
    "title": "02. Python Basic (3)",
    "section": "예제 4 : 두 변수의 값을 교환",
    "text": "예제 4 : 두 변수의 값을 교환\n\na,b = 1,2\n\n\na,b\n\n(1, 2)\n\n\n\na,b = b,a\n\n\na,b\n\n(2, 1)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-5-for문",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-5-for문",
    "title": "02. Python Basic (3)",
    "section": "예제 5: for문",
    "text": "예제 5: for문\n\nlst = [['gc', 2021502565, 'M'],\n       ['iu',202254321, 'F'],\n       ['hodong', 202011223, 'M']]\nlst\n\n[['gc', 2021502565, 'M'], ['iu', 202254321, 'F'], ['hodong', 202011223, 'M']]\n\n\n\nfor name, s, sex in lst :\n    print(name,s,sex)\n\ngc 2021502565 M\niu 202254321 F\nhodong 202011223 M"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-6-range-함수를-사용해-만들기",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-6-range-함수를-사용해-만들기",
    "title": "02. Python Basic (3)",
    "section": "예제 6 : range 함수를 사용해 만들기",
    "text": "예제 6 : range 함수를 사용해 만들기\n\ntest = tuple(range(1,11))\ntest\n\n(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-7-for-tuple-_",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-7-for-tuple-_",
    "title": "02. Python Basic (3)",
    "section": "예제 7 : for +  tuple + \"_\"",
    "text": "예제 7 : for +  tuple + \"_\"\n\nlst\n\n[['gc', 2021502565, 'M'], ['iu', 202254321, 'F'], ['hodong', 202011223, 'M']]\n\n\n\nfor _,s,_ in lst :\n    print(s)\n\n2021502565\n202254321\n202011223\n\n\n\nfor _,_,s in lst :\n    print(s)\n\nM\nF\nM"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-8-언패킹-연산자-for-starstar",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-8-언패킹-연산자-for-starstar",
    "title": "02. Python Basic (3)",
    "section": "예제 8 : 언패킹 연산자(*) + for (\\(\\star\\star\\))",
    "text": "예제 8 : 언패킹 연산자(*) + for (\\(\\star\\star\\))\n\n*는 특정하지 않은 여러개의 인자를 튜플 형태로 받는다.\n\n\nfor n,*a in lst :\n    print(n,*a)\n\ngc 2021502565 M\niu 202254321 F\nhodong 202011223 M\n\n\n\nfor n,*a in lst :\n    print(n,a)\n\ngc [2021502565, 'M']\niu [202254321, 'F']\nhodong [202011223, 'M']\n\n\n\nfor n,*a in lst :\n    print(n)\n\ngc\niu\nhodong\n\n\n\nh,b,*t = range(1,11)\n\n\nh,b,t\n\n(1, 2, [3, 4, 5, 6, 7, 8, 9, 10])\n\n\n\nh,b,*t\n\n(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n\n\nt\n\n[3, 4, 5, 6, 7, 8, 9, 10]\n\n\n- 언패킹 연산자를 아래처럼 단일값으로 쓸수는 없다. 대신 print문을 이욯아여 출력!\n\n*t\n\nSyntaxError: can't use starred expression here (3801933867.py, line 1)\n\n\n\nprint(*t)\n\n3 4 5 6 7 8 9 10\n\n\n\ntemp = h,b,t\n\n\ntemp\n\n(1, 2, [3, 5, 5, 6, 7, 8, 9, 10])\n\n\n- 튜플안에 선언한 리스트는 수정할 수 있다!\n\ntemp[2][1]=4\n\n\ntemp\n\n(1, 2, [3, 4, 5, 6, 7, 8, 9, 10])\n\n\n- 단, 튜플안에 선언된 리스트 통째?로는 바꿀 수 없음\n\ntemp[2] = d\n\nNameError: name 'd' is not defined\n\n\n\ntemp[2] = [1,2,3]\n\nTypeError: 'tuple' object does not support item assignment"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-9-함수",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#예제-9-함수",
    "title": "02. Python Basic (3)",
    "section": "예제 9 : 함수",
    "text": "예제 9 : 함수\n\n아래의 함수는 여러개의 값을 리턴하는 것처럼 보이나 사실은 길이가 4인, 튜플 1개만을 return한다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#왜-튜플만이-괄호를-생략",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#왜-튜플만이-괄호를-생략",
    "title": "02. Python Basic (3)",
    "section": "왜 튜플만이 괄호를 생략?",
    "text": "왜 튜플만이 괄호를 생략?\n\n튜플을 먼저 만들고, 괄호를 생략하는 문법을 추가한 것은 아닐것이다.\n원래는 괄호없이 벡터를 만들고 싶었을 것임\n차피 벡터는 한,두번 쓰고 버리는 경우가 많고, 대부분 이름도 필요없음 \\(\\to\\) (즉, 원소에 접근해서 sorting하고… 순서를 바꿀 필요가 없다는 것임)\n데이터를 분석하면서 우리에게 필요한것은, 데이터가 벡터 형태로 모여, 하나이 DataFrame을 구축하기만 하면된다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-추가",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-추가",
    "title": "02. Python Basic (3)",
    "section": "원소 추가",
    "text": "원소 추가\n\ns = {\"a\",\"b\"}\n\n\ns.add(\"c\")\ns\n\n{'a', 'b', 'c'}\n\n\n\ns.update([\"c\",\"d\"])\ns\n\n{'a', 'b', 'c', 'd'}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-삭제",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-삭제",
    "title": "02. Python Basic (3)",
    "section": "원소 삭제",
    "text": "원소 삭제\n\ns\n\n{'a', 'b', 'c', 'd'}\n\n\n\ns.remove(\"c\")\n\n\ns\n\n{'a', 'b', 'd'}\n\n\n- discard로 삭제시 에러메세지를 반환하지 않음\n\ns.remove(\"z\")\n\nKeyError: 'z'\n\n\n\ns.discard(\"z\")\n\n- 모든 원소 삭제\n\ns.clear()\n\n\ns\n\nset()"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#in",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#in",
    "title": "02. Python Basic (3)",
    "section": "in",
    "text": "in\n\n\"a\" in s\n\nTrue\n\n\n\n합,교,차 집합\n\nset1 = {\"a\",\"b\",\"c\"}\nset2 = {\"b\",\"c\",\"d\"}\n\n- 합집합\n\nset1|set2\n\n{'a', 'b', 'c', 'd'}\n\n\n\nset1.union(set2)\n\n{'a', 'b', 'c', 'd'}\n\n\n- 교집합\n\nset1 & set2\n\n{'b', 'c'}\n\n\n\nset1.intersection(set2)\n\n{'b', 'c'}\n\n\n- 차집합\n\nset1,set2\n\n({'a', 'b', 'c'}, {'b', 'c', 'd'})\n\n\n\nset2-set1\n\n{'d'}\n\n\n\n\n부분 집합\n\nset3 = set1|set2\n\n\nset2&lt;set3\n\nTrue"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#for문",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#for문",
    "title": "02. Python Basic (3)",
    "section": "for문",
    "text": "for문\n- 다음에 txt에서 각 알파벳이 몇 번 사용됬는지 구하기\n\ntxt = 'asdkflkjahsdlkjfhlaksglkjdhflkgjhlskdfjhglkajhsdlkfjhalsdkf'\ntxt\n\n'asdkflkjahsdlkjfhlaksglkjdhflkgjhlskdfjhglkajhsdlkfjhalsdkf'\n\n\n\n{i : list(txt).count(i) for i in set(txt)}\n\n{'l': 9, 'h': 7, 's': 6, 'd': 6, 'a': 5, 'g': 3, 'j': 7, 'f': 6, 'k': 10}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#선언",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#선언",
    "title": "02. Python Basic (3)",
    "section": "선언",
    "text": "선언\n\n방법 1. 가장 일반적\n\ndct=  {\"a\" : 1, \"b\":2}\ndct\n\n{'a': 1, 'b': 2}\n\n\n\n\n방법 2. dict(\\(\\star\\star\\))\n\ndct = dict(a=1, b=2)\ndct\n\n{'a': 1, 'b': 2}\n\n\n\n\n방법 3. 중첩된 리스트\n\ndct = dict([[\"a\",1],[\"b\",2]])\ndct\n\n{'a': 1, 'b': 2}\n\n\n\n\n방법 4. 튜플\n\ndct = (\"a\",1),(\"b\",2)\ndict(dct)\n\n{'a': 1, 'b': 2}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-추출",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-추출",
    "title": "02. Python Basic (3)",
    "section": "원소 추출",
    "text": "원소 추출\n- 딕셔너리는 key값을 이용해서 추출해야한다. (value로 key를 찾는 것은 불가!)\n\ndct =dict(dct)\n\n\ndct[\"a\"], dct[\"b\"]\n\n(1, 2)\n\n\n\nex1. 딕셔너리를 쓰는 이유?\n- 아래와 같은 구조가 있다고 하자.\n\nlst = [[\"a\",1],[\"b\",2]]\nlst\n\n[['a', 1], ['b', 2]]\n\n\n- 여기에서 a의 값을 알려면?\n\n[s for n,s in lst if n==\"a\"]\n\n[1]\n\n\n- 딕셔너리를 이용한 풀이\n\ndict(lst)[\"a\"]\n\n1"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-추가-1",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-추가-1",
    "title": "02. Python Basic (3)",
    "section": "원소 추가",
    "text": "원소 추가\n\ndct\n\n{'a': 1, 'b': 2}\n\n\n\ndct[\"c\"]=3\n\n\ndct\n\n{'a': 1, 'b': 2, 'c': 3}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-삭제-1",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#원소-삭제-1",
    "title": "02. Python Basic (3)",
    "section": "원소 삭제",
    "text": "원소 삭제\n- 방법 1\n\ndel dct[\"a\"]\n\n\ndct\n\n{'b': 2, 'c': 3}\n\n\n- 방법 2\n\ndct.pop(\"b\")\n\n2\n\n\n\ndct\n\n{'c': 3}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#연산",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#연산",
    "title": "02. Python Basic (3)",
    "section": "연산",
    "text": "연산\n\ndct = dict(a=1,b=2,c=3)\n\n\ndct\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\n\"a\" in dct\n\nTrue"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#특수-기능",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#특수-기능",
    "title": "02. Python Basic (3)",
    "section": "특수 기능",
    "text": "특수 기능\n\ndct\n\n{'a': 1, 'b': 2, 'c': 3}\n\n\n\ndct.keys()\n\ndict_keys(['a', 'b', 'c'])\n\n\n\ndct.values()\n\ndict_values([1, 2, 3])\n\n\n\ndct.items()\n\ndict_items([('a', 1), ('b', 2), ('c', 3)])"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#for-dictstarstar",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#for-dictstarstar",
    "title": "02. Python Basic (3)",
    "section": "for + dict(\\(\\star\\star\\))",
    "text": "for + dict(\\(\\star\\star\\))\n\nfor k in dct.keys() :\n    print(k)\n\na\nb\nc\n\n\n- 아 딕셔너리는 루프에서 객체 자체로 전달시 key값을 반환한다.\n\nfor k in dct:\n    print(k)\n\na\nb\nc\n\n\n- value 접근\n\nfor i in dct.values():\n    print(i)\n\n1\n2\n3\n\n\n- key,value 동시 접근\n\nfor i,j in dct.items():\n    print(i,j)\n\na 1\nb 2\nc 3"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#list-to-dict.values",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#list-to-dict.values",
    "title": "02. Python Basic (3)",
    "section": "list \\(\\to\\) dict.values",
    "text": "list \\(\\to\\) dict.values\n- 아래와 같은 원핫인코딩을 생각\n\n\n\n변환전\n변환후\n\n\n\n\na\n[1,0,0,0]\n\n\nb\n[0,1,0,0]\n\n\nc\n[0,0,1,0]\n\n\nd\n[0,0,0,1]\n\n\n\n- 주어진 리스트를 원핫인코딩하여라\n\nlst = list(\"abcd\")*2\nlst\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd']\n\n\n\nsol\n\ndct = {\"a\": [1,0,0,0],\n      \"b\": [0,1,0,0],\n      \"c\": [0,0,1,0],\n      \"d\": [0,0,0,1]}\n\n\ndct\n\n{'a': [1, 0, 0, 0], 'b': [0, 1, 0, 0], 'c': [0, 0, 1, 0], 'd': [0, 0, 0, 1]}"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#dict.values-to-list",
    "href": "posts/DX/00. 데이터 다루기/2023-08-11-02. Python Basic (3) .html#dict.values-to-list",
    "title": "02. Python Basic (3)",
    "section": "dict.values \\(\\to\\) list",
    "text": "dict.values \\(\\to\\) list\n- 위 원핫인코딩을 다시 변환\n\nsol\n\nvalue = [v for v in dct.values()] *2\nvalue\n\n[[1, 0, 0, 0],\n [0, 1, 0, 0],\n [0, 0, 1, 0],\n [0, 0, 0, 1],\n [1, 0, 0, 0],\n [0, 1, 0, 0],\n [0, 0, 1, 0],\n [0, 0, 0, 1]]\n\n\n\n[i for v in value for i,j in dct.items() if j == v]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd']"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html",
    "title": "04. Python Basic (5)",
    "section": "",
    "text": "*은 여러개의 인수를 튜플로 입력받아 처리해주는 메소드이다.\n\n\ndef a(*alpha) :\n    for a in alpha : \n        print(f\"입력된 문자는 {a}입니다.\")\n\n\na(\"A\",\"B\")\n\n입력된 문자는 A입니다.\n입력된 문자는 B입니다.\n\n\n- 또한, 임의의 매개변수를 여러개 전달받고, 고정변수를 따로 전달받아 아래와 같이 작성할 수 있다.\n\ndef a(*alpha,v) :\n    for a in alpha : \n        print(f\"입력된 문자는 {a}이며 종류는 {v}입니다.\")\n\n\na(\"A\",\"B\",v = \"알파벳\")\n\n입력된 문자는 A이며 종류는 알파벳입니다.\n입력된 문자는 B이며 종류는 알파벳입니다.\n\n\n\n단 고정값은 맨뒤에 전달해주어야 한다.\n\n\na(v = \"알파벳\",\"A\",\"B\")\n\nSyntaxError: positional argument follows keyword argument (1027399463.py, line 1)\n\n\n\n\n\n\\[\\text{result} = \\sum_{i=1}^{n} x^2\\]\n\ndef a(*a) :\n    result = sum([i**2 for i in a])\n    return result\n\n\na(1,2,3,4,5)\n\n55\n\n\n\nlst= [2,10,4]\n\n\ndef solution(sides):\n    sides.sort()\n    if sides[-1] &lt; sum(sides[:-1]) :\n        return 1\n    else :\n        return 2\n\n\nsolution(lst)\n\n2\n\n\n\n\n\n- 분수 덧셈후 결과의 기약분수의 분모와 분자를 출력\n\nimport math\n\n\ndef sol(n1,d1,n2,d2) :\n    d = d1*d2 ## 분모 \n    n = n1*d2 + n2*d1 ##분자\n\n    gcd = math.gcd(d,n) ## 최대공약수\n\n    return n//gcd,d//gcd\n\n\nn,d = sol(1,2,3,4)\n\n\nn\n\n5\n\n\n\nd\n\n4\n\n\n\n\n\n\n\n\na = 1\nb = -a\n\na == abs(b)\n\nTrue\n\n\n\n\n\n\na = list(\"abcd\")\n\nall(a)\n\nTrue\n\n\n- 0은 False와 같음\n\n0 == False\n\nTrue\n\n\n\na.append(0)\na\n\n['a', 'b', 'c', 'd', 0]\n\n\n\nall(a)\n\nFalse\n\n\n\n\n\n\na\n\n['a', 'b', 'c', 'd', 0]\n\n\n\nany(a)\n\nTrue\n\n\n\n\n\n\na\n\n['a', 'b', 'c', 'd', 0]\n\n\n\ndir(a)\n\n['__add__',\n '__class__',\n '__class_getitem__',\n '__contains__',\n '__delattr__',\n '__delitem__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rmul__',\n '__setattr__',\n '__setitem__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\n- 오리지날 메소드만 출력\n\nb = [i for i in dir(a) if i[0] != \"_\"]\n\n\nb\n\n['append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\n\n\n\n- x를 y로 나눈 몫과 나머지를 튜플로 반환\n\ndivmod(5,2)\n\n(2, 1)\n\n\n\n\n\n- 코드의 실행을 입력받아 결과를 받음.\n\neval('10+20')\n\n30\n\n\n\n\n\n- 함수에 매개변수를 전달해 참인 경우만 결과를 반환 \\(\\to\\) filter(f,a)\n- ex1\n\n\n\ndef f(x) :\n    if x % 2 == 0 :\n        return x\n\n\na = [1,2,3,4,5]\n\n\nlist(filter(f,a))\n\n[2, 4]\n\n\n\n\n\n\nlist(filter(lambda x : x % 2==0,a))\n\n[2, 4]\n\n\n\n\n\n\n- 문자의 아스키 코드반환\n\nord(\"A\")\n\n65\n\n\n\n\n\n- 짝수 선택 예제\n\nimport numpy as np\nimport pandas as pd\n\n\nnp.random.seed(1)\ndf2= pd.DataFrame(np.random.normal(size=(10,4)),columns=list('ABCD'))\ndf2.head()\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n1.624345\n-0.611756\n-0.528172\n-1.072969\n\n\n1\n0.865408\n-2.301539\n1.744812\n-0.761207\n\n\n2\n0.319039\n-0.249370\n1.462108\n-2.060141\n\n\n3\n-0.322417\n-0.384054\n1.133769\n-1.099891\n\n\n4\n-0.172428\n-0.877858\n0.042214\n0.582815\n\n\n\n\n\n\n\n- A열에서 0보다 큰값들만 출력\n\ndf2.iloc[map(lambda x : x&gt;0, df2.A),:]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n1.624345\n-0.611756\n-0.528172\n-1.072969\n\n\n1\n0.865408\n-2.301539\n1.744812\n-0.761207\n\n\n2\n0.319039\n-0.249370\n1.462108\n-2.060141\n\n\n6\n0.900856\n-0.683728\n-0.122890\n-0.935769\n\n\n\n\n\n\n\n- A,C열에서 둘다 0보다 큰값들만 출력\n\ndf2.loc[ map(lambda x,y : (x&gt;0) & (y&gt;0) , df2.A,df2.C),:]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n1\n0.865408\n-2.301539\n1.744812\n-0.761207\n\n\n2\n0.319039\n-0.249370\n1.462108\n-2.060141\n\n\n\n\n\n\n\n- 짝수에는 곱하기2, 홀수에는 곱하기 3\n\na = list(range(1,11))\na\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\nlist(map(lambda x : x*2 if x%2 ==0 else x*3,a))\n\n[3, 4, 9, 8, 15, 12, 21, 16, 27, 20]\n\n\n\n\n\n- 객체가 해당 자료형의 해당하는 객체인지 확인\n\na = list(\"abcd\")\nb = 1\n\nprint(isinstance(a,list))\nprint(isinstance(b,int))\n\nTrue\nTrue\n\n\n\n\n\n- 두 객체의 요소들을 쌍으로 묶어서 반환해줌\n\na = [1,2,3,4]\nb = [2,4,6,8]\nlist(zip(a,b))\n\n[(1, 2), (2, 4), (3, 6), (4, 8)]\n\n\n- 아래와 같이 인덱스 범위를 넘어가면 그냥 무시한다.\n\na = [1,2,3,4]\nb = [2,4,6,8,9]\nlist(zip(a,b))\n\n[(1, 2), (2, 4), (3, 6), (4, 8)]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#ex1.-여러개-인수를-입력받아-처리하는-함수",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#ex1.-여러개-인수를-입력받아-처리하는-함수",
    "title": "04. Python Basic (5)",
    "section": "",
    "text": "*은 여러개의 인수를 튜플로 입력받아 처리해주는 메소드이다.\n\n\ndef a(*alpha) :\n    for a in alpha : \n        print(f\"입력된 문자는 {a}입니다.\")\n\n\na(\"A\",\"B\")\n\n입력된 문자는 A입니다.\n입력된 문자는 B입니다.\n\n\n- 또한, 임의의 매개변수를 여러개 전달받고, 고정변수를 따로 전달받아 아래와 같이 작성할 수 있다.\n\ndef a(*alpha,v) :\n    for a in alpha : \n        print(f\"입력된 문자는 {a}이며 종류는 {v}입니다.\")\n\n\na(\"A\",\"B\",v = \"알파벳\")\n\n입력된 문자는 A이며 종류는 알파벳입니다.\n입력된 문자는 B이며 종류는 알파벳입니다.\n\n\n\n단 고정값은 맨뒤에 전달해주어야 한다.\n\n\na(v = \"알파벳\",\"A\",\"B\")\n\nSyntaxError: positional argument follows keyword argument (1027399463.py, line 1)"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#ex2.-아래를-만족하는-함수를-작성하라.",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#ex2.-아래를-만족하는-함수를-작성하라.",
    "title": "04. Python Basic (5)",
    "section": "",
    "text": "\\[\\text{result} = \\sum_{i=1}^{n} x^2\\]\n\ndef a(*a) :\n    result = sum([i**2 for i in a])\n    return result\n\n\na(1,2,3,4,5)\n\n55\n\n\n\nlst= [2,10,4]\n\n\ndef solution(sides):\n    sides.sort()\n    if sides[-1] &lt; sum(sides[:-1]) :\n        return 1\n    else :\n        return 2\n\n\nsolution(lst)\n\n2"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#ex3.-여러-개의-값-return",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#ex3.-여러-개의-값-return",
    "title": "04. Python Basic (5)",
    "section": "",
    "text": "- 분수 덧셈후 결과의 기약분수의 분모와 분자를 출력\n\nimport math\n\n\ndef sol(n1,d1,n2,d2) :\n    d = d1*d2 ## 분모 \n    n = n1*d2 + n2*d1 ##분자\n\n    gcd = math.gcd(d,n) ## 최대공약수\n\n    return n//gcd,d//gcd\n\n\nn,d = sol(1,2,3,4)\n\n\nn\n\n5\n\n\n\nd\n\n4"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#내장함수",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#내장함수",
    "title": "04. Python Basic (5)",
    "section": "",
    "text": "a = 1\nb = -a\n\na == abs(b)\n\nTrue\n\n\n\n\n\n\na = list(\"abcd\")\n\nall(a)\n\nTrue\n\n\n- 0은 False와 같음\n\n0 == False\n\nTrue\n\n\n\na.append(0)\na\n\n['a', 'b', 'c', 'd', 0]\n\n\n\nall(a)\n\nFalse\n\n\n\n\n\n\na\n\n['a', 'b', 'c', 'd', 0]\n\n\n\nany(a)\n\nTrue\n\n\n\n\n\n\na\n\n['a', 'b', 'c', 'd', 0]\n\n\n\ndir(a)\n\n['__add__',\n '__class__',\n '__class_getitem__',\n '__contains__',\n '__delattr__',\n '__delitem__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rmul__',\n '__setattr__',\n '__setitem__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\n- 오리지날 메소드만 출력\n\nb = [i for i in dir(a) if i[0] != \"_\"]\n\n\nb\n\n['append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n\n\n\n\n\n- x를 y로 나눈 몫과 나머지를 튜플로 반환\n\ndivmod(5,2)\n\n(2, 1)\n\n\n\n\n\n- 코드의 실행을 입력받아 결과를 받음.\n\neval('10+20')\n\n30\n\n\n\n\n\n- 함수에 매개변수를 전달해 참인 경우만 결과를 반환 \\(\\to\\) filter(f,a)\n- ex1\n\n\n\ndef f(x) :\n    if x % 2 == 0 :\n        return x\n\n\na = [1,2,3,4,5]\n\n\nlist(filter(f,a))\n\n[2, 4]\n\n\n\n\n\n\nlist(filter(lambda x : x % 2==0,a))\n\n[2, 4]\n\n\n\n\n\n\n- 문자의 아스키 코드반환\n\nord(\"A\")\n\n65\n\n\n\n\n\n- 짝수 선택 예제\n\nimport numpy as np\nimport pandas as pd\n\n\nnp.random.seed(1)\ndf2= pd.DataFrame(np.random.normal(size=(10,4)),columns=list('ABCD'))\ndf2.head()\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n1.624345\n-0.611756\n-0.528172\n-1.072969\n\n\n1\n0.865408\n-2.301539\n1.744812\n-0.761207\n\n\n2\n0.319039\n-0.249370\n1.462108\n-2.060141\n\n\n3\n-0.322417\n-0.384054\n1.133769\n-1.099891\n\n\n4\n-0.172428\n-0.877858\n0.042214\n0.582815\n\n\n\n\n\n\n\n- A열에서 0보다 큰값들만 출력\n\ndf2.iloc[map(lambda x : x&gt;0, df2.A),:]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n0\n1.624345\n-0.611756\n-0.528172\n-1.072969\n\n\n1\n0.865408\n-2.301539\n1.744812\n-0.761207\n\n\n2\n0.319039\n-0.249370\n1.462108\n-2.060141\n\n\n6\n0.900856\n-0.683728\n-0.122890\n-0.935769\n\n\n\n\n\n\n\n- A,C열에서 둘다 0보다 큰값들만 출력\n\ndf2.loc[ map(lambda x,y : (x&gt;0) & (y&gt;0) , df2.A,df2.C),:]\n\n\n\n\n\n\n\n\nA\nB\nC\nD\n\n\n\n\n1\n0.865408\n-2.301539\n1.744812\n-0.761207\n\n\n2\n0.319039\n-0.249370\n1.462108\n-2.060141\n\n\n\n\n\n\n\n- 짝수에는 곱하기2, 홀수에는 곱하기 3\n\na = list(range(1,11))\na\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\n\nlist(map(lambda x : x*2 if x%2 ==0 else x*3,a))\n\n[3, 4, 9, 8, 15, 12, 21, 16, 27, 20]\n\n\n\n\n\n- 객체가 해당 자료형의 해당하는 객체인지 확인\n\na = list(\"abcd\")\nb = 1\n\nprint(isinstance(a,list))\nprint(isinstance(b,int))\n\nTrue\nTrue\n\n\n\n\n\n- 두 객체의 요소들을 쌍으로 묶어서 반환해줌\n\na = [1,2,3,4]\nb = [2,4,6,8]\nlist(zip(a,b))\n\n[(1, 2), (2, 4), (3, 6), (4, 8)]\n\n\n- 아래와 같이 인덱스 범위를 넘어가면 그냥 무시한다.\n\na = [1,2,3,4]\nb = [2,4,6,8,9]\nlist(zip(a,b))\n\n[(1, 2), (2, 4), (3, 6), (4, 8)]"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#sub",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#sub",
    "title": "04. Python Basic (5)",
    "section": "sub",
    "text": "sub\n\np = \"강철 : 961230-1111111 호연 : 961231-1111111\" \n\n\nimport re\n\n- 해당 패턴을 아래와 같이 기억\n\nmask = re.compile(\"(\\d{6})[-]\\d{7}\")\n\n- g&lt;?&gt; : 그룹을 의미하며 위 컴파일에서 ()로 구분한다. \\(\\to\\) g&lt;0&gt;은 전체 패턴을 의미\n- () : g&lt;1&gt;\n\nmask.sub(\"\\g&lt;1&gt;-XXXXXXX\",p)\n\n'강철 : 961230-XXXXXXX 호연 : 961231-XXXXXXX'\n\n\n- ()[-] : g&lt;0&gt;\n\nmask.sub(\"\\g&lt;0&gt;-XXXXXXX\",p)\n\n'강철 : 961230-1111111-XXXXXXX 호연 : 961231-1111111-XXXXXXX'\n\n\n- 아래와 같이 1명만 바꿀 수 있음\n\nmask.sub(\"\\g&lt;1&gt;-XXXXXXX\",p,count=1)\n\n'강철 : 961230-XXXXXXX 호연 : 961231-1111111'"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#basic",
    "href": "posts/DX/00. 데이터 다루기/2023-08-16-04. Python Basic (5).html#basic",
    "title": "04. Python Basic (5)",
    "section": "basic",
    "text": "basic\n\nimport re\n\n\nmatch\n- 문자열의 첫 글자가 정규식과 일치하는지 확인\n\ns = \"I am gc\"\n\n\nresult = re.match(\"I\",s)\nif result:\n    print(\"o\")\nelse :\n    print(\"x\")\n\no\n\n\n\n\nsearch\n- 문자열 전체에서 정규식과 일치하는 확인\n\ns = \"I am gcg\"\n\n\nresult = re.search(\"gc\",s)\n\n\nif result:\n    print(\"o\")\nelse :\n    print(\"x\")\n\no\n\n\n- 매치된 결과를 다음과 같은 메소드로 확인할 수 있다.\n\ns = \"I am gc\"\nresult = re.search(\"g\",s)\n\n\ngroup() : 매치된 문자열을 반환\n\n\nresult.group()\n\n'g'\n\n\n\nstart(),end() : 매치된 문자열의 시작과 끝의 위치를 반환\n\nend() : 끝위치-1을 반환한다.\n\n\n\nresult.start()\n\n5\n\n\n\nresult.end()\n\n6\n\n\n\ns[5]\n\n'g'\n\n\n\ns[6]\n\n'c'\n\n\n\nspan() : 매치된 문자열의 시작, 끝을 튜플로 반환\n\n\nresult.span()\n\n(5, 6)\n\n\n\n\nfindall\n- 정규식과 매치되는 모든 문자열을 리스트로 반환\n\ns= 'I am gc gc'\n\n\nre.findall(\"g\",s)\n\n['g', 'g']\n\n\n\nre.findall(\"gc\",s)\n\n['gc', 'gc']\n\n\n\n\nfinditer\n- 정규식과 매치되는 모든 문자열을 반복 가능한 객체로 변환\n\ns\n\n'I am gc gc'\n\n\n\nresult = re.finditer(\"gc\",s)\n\n\nfor i in result : \n    print(i)\n\n&lt;re.Match object; span=(5, 7), match='gc'&gt;\n&lt;re.Match object; span=(8, 10), match='gc'&gt;\n\n\n\n\n나열된 문자 포함여부 확인\n\ns\n\n'I am gc gc'\n\n\n\nre.findall(\"[gc]\",s)\n\n['g', 'c', 'g', 'c']\n\n\n- 같은 문자 한번만 표시\n\nlist(set(re.findall(\"[gc]\",s)))\n\n['c', 'g']\n\n\n\n^ : 해당 문자열을 제외한 문자들을 리스트로 출력\n\n\ns\n\n'I am gc gc'\n\n\n\nlist(set(re.findall(\"[^gc]\",s)))\n\n[' ', 'm', 'a', 'I']\n\n\n\nlist(set(re.findall(\"[^ gc]\",s))) ## 공백 제거\n\n['m', 'a', 'I']\n\n\n\n\n범위안에 문자 포함여부확인\n\ns\n\n'I am gc gc'\n\n\n- 소문자만 출력\n\nre.findall(\"[a-z]\",s)\n\n['a', 'm', 'g', 'c', 'g', 'c']\n\n\n- 대문자만 출력\n\nre.findall(\"[A-Z]\",s)\n\n['I']\n\n\n- 대,소문자 둘다 출력\n\nre.findall(\"[A-Za-z]\",s)\n\n['I', 'a', 'm', 'g', 'c', 'g', 'c']\n\n\n- 숫자 찾기\n\ns = \"gc is 28 years\"\n\n\nre.findall(\"[0-9]\",s)\n\n['2', '8']\n\n\n\n\n두 문자 사이의 포함 여부 확인\n\ns = \"sabe\"\n\n\n.은 한글자를 대체하는 단어로 다음과 같은 패턴으로 활용할 수 있다.\n\n\ns\n\n'sabe'\n\n\n\nre.findall(\"a.e\",s) \n\n['abe']\n\n\n\n\n문자 반복 확인\n- 일정한 패턴이 얼마나 반복되는지 아래와 같은 형식으로 확인할 수 있다.\n\ns = \"gc gcc\"\n\n\ns\n\n'gc gcc'\n\n\n\nc가 0회이상 반복\n\n\nre.findall(\"g*c\",s)\n\n['gc', 'gc', 'c']\n\n\n\nc가 1회 이상 반복\n\n\nre.findall(\"gc{1}\",s)\n\n['gc', 'gc']\n\n\n\nc가 1~2회 반복\n\n\nre.findall(\"gc{1,2}\",s)\n\n['gc', 'gcc']\n\n\n\nc가 0에서 1회 반복\n\n\nre.findall(\"gc?\",s)\n\n['gc', 'gc']"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html",
    "title": "Extra 00. 밈",
    "section": "",
    "text": "- 점프투파이썬 : 클래스는 과자틀과 비슷하다. 클래스란 똑같은 무엇인가를 계속 만들어 낼 수도 잇는 설계도면이고 객체란 클래스로 만든 피조물을 뜻한다.\n- 위키피디아 : 객체지향 프로그래밍에서 클래스는 상태(멤버 변수) 및 동작 구현(멤버 함수 또는 메서드)에 대한 초기값을 제공하는 객체 생성을 위한 확장 가능한 프로그램 코드 템플릿이다.\n- TCP 스쿨 : 클래스란 객체를 정의하는 틀 또는 설계도와 같은 의미로 사용\n- 교수님 생각 : 클래스는 복제, 변형, 재생산을 용이하게 하기 위해 만들어진 확장가능한 프로그램이 코드 단위(extensible program-code-template)이다.\n\n\nfrom IPython.core.display import HTML"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#sum_i15-ai-quad-a0.5",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#sum_i15-ai-quad-a0.5",
    "title": "Extra 00. 밈",
    "section": "\\(\\sum_{i=1}^{5} a^{i} \\quad a=0.5\\)",
    "text": "\\(\\sum_{i=1}^{5} a^{i} \\quad a=0.5\\)\n- 방법1\n\na = 0.5\n\n\na + a**2 + a**3 + a**4 +a**5\n\n0.96875\n\n\n- 방법2\n\na + \\\na**2 \\\n+ a**3 \\\n+ a**4\\\n+a**5\n\n0.96875\n\n\n\n```으로 선언하는 문자열\n- 에시 1\n\nstring = '\\n1. asdf\\n2. sdfa\\n3. dfas\\n4. fasd\\n'\nprint(string)\n\n\n1. asdf\n2. sdfa\n3. dfas\n4. fasd\n\n\n\n\nstring = \\\n'''\n1. asdf\n2. sdfa\n3. dfas\n4. fasd\n'''\nprint(string)\n\n\n1. asdf\n2. sdfa\n3. dfas\n4. fasd\n\n\n\n- 예시 2\n\nstring = \\\n'''\n1. asdf\n2. sdfa\n3. dfas\n4. fasd\n5. {}\n6. {}\n'''\n\n\nprint(string.format(\"aaa\",\"bbb\"))\n\n\n1. asdf\n2. sdfa\n3. dfas\n4. fasd\n5. aaa\n6. bbb\n\n\n\n\n\nHTML\n- 예제1. 텍스트 출력\n\nhtml_str = '''\n&lt;p&gt; 파이썬 프로그래밍 &lt;/p&gt;\n'''\n\n\nHTML(html_str)\n\n\n 파이썬 프로그래밍 \n\n\n- 예제 2 : 스타일 변경\n\nhtml_str = '''\n&lt;style&gt;\n    .title {\n         font-family : \"Times New Roman\", sefif;\n         font-size : 30px;\n         font-weight : 900;\n        }\n&lt;/style&gt;\n&lt;p class=\"title\"&gt; 파이썬 프로그래밍 &lt;/p&gt;\n'''\n\n\nHTML(html_str)\n\n\n\n 파이썬 프로그래밍 \n\n\n- 예제 3 : 이미지 삽입\n\nhtml_str = '''\n\n&lt;img src = \"hani.jpeg\" width = 300&gt;\n'''\n\n\nHTML(html_str)\n\n\n\n\n\n\n\ndisplay(HTML(html_str))"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-밈의-구상",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-밈의-구상",
    "title": "Extra 00. 밈",
    "section": "1단계 : 밈의 구상",
    "text": "1단계 : 밈의 구상\n\ntitle : 타이틀에 해당하는 텍스트\nimg : 데프트의 인터뷰 이미지\nQ : 인터뷰 질문에 해당하는 텍스트 (.text)\nA : 인터뷰 답변에 해당하는 텍스트 (.text)\nhighlight : “마음”\n\n\nhtml_str = '''\n&lt;style&gt;\n    .title {\n        font-family: \"Times New Roman\", serif;\n        font-size: 30px;\n        font-weight: 900;\n    }\n    .text {\n        font-family: \"Arial\", sans-serif;\n        font-size: 20px;\n        font-style: italic;\n    }\n    .highlight {\n        font-family: \"Montserrat\", monospace;\n        font-size: 35px;\n        font-weight: 900;\n        text-decoration: underline; ## 밑줄\n        font-style: normal;\n        color: darkblue;\n        background-color: #FFFF00;\n    }\n&lt;/style&gt;\n\n&lt;p class=\"title\"&gt;RGE전 패배는 괜찮다.&lt;/p&gt;\n&lt;img src=https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true width=\"600\"&gt;\n&lt;p&gt; \\n &lt;/p&gt;\n&lt;p class=\"text\"&gt; Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까?&lt;/p&gt;\n&lt;p class=\"text\"&gt; A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n&lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt;마음&lt;/span&gt;&lt;/p&gt;\n'''\n\n\ndisplay(HTML(html_str))\n\n\n\n\nRGE전 패배는 괜찮다.\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까?\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는 마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-양식틀의-완성함수-이용",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-양식틀의-완성함수-이용",
    "title": "Extra 00. 밈",
    "section": "2단계 : 양식틀의 완성(함수 이용)",
    "text": "2단계 : 양식틀의 완성(함수 이용)\n\nhtml_str = '''\n&lt;style&gt;\n    .title {{\n        font-family: \"Times New Roman\", serif;\n        font-size: 30px;\n        font-weight: 900;\n    }}\n    .text {{\n        font-family: \"Arial\", sans-serif;\n        font-size: 20px;\n        font-style: italic;\n    }}\n    .highlight {{\n        font-family: \"Montserrat\", monospace;\n        font-size: 35px;\n        font-weight: 900;\n        text-decoration: underline; ## 밑줄\n        font-style: normal;\n        color: darkblue;\n        background-color: #FFFF00;\n    }}\n&lt;/style&gt;\n\n&lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n&lt;img src={url} width=\"600\"&gt;\n&lt;p&gt; \\n &lt;/p&gt;\n&lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n&lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n&lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n'''\n\n\ntitle = \"중요한건 꺽이지 않는 마음\"\n\nurl = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\nQ = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\nA = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\nh1 = \"마음\"\n\n\n_str = html_str.format(\n    tt1 = title,\n    url = url,\n    Q = Q,\n    A = A,\n    h1 = h1\n)\ndisplay(HTML(_str))\n\n\n\n\n중요한건 꺽이지 않는 마음\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-밈놀이함수",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-밈놀이함수",
    "title": "Extra 00. 밈",
    "section": "3단계 : 밈놀이(함수)",
    "text": "3단계 : 밈놀이(함수)\n\ndef JM (html_str,title,url,Q,A,h1) : \n    _str = html_str.format(\n        tt1 = title,\n        url = url,\n        Q = Q,\n        A = A,\n        h1 = h1\n    )\n    display(HTML(_str))\n\n\nJM(html_str,title,url,Q,A,h1)\n\n\n\n\n중요한건 꺽이지 않는 마음\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는  마음 \n\n\n\n이러한 코드들의 비판\n- 변수들이 정리가 되어있지 않고 산만함"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-밈놀이-클래스",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-08-Extra 00. 밈.html#단계-밈놀이-클래스",
    "title": "Extra 00. 밈",
    "section": "4단계 밈놀이 (클래스)",
    "text": "4단계 밈놀이 (클래스)\n- 클래스 선언 : 도화지 만들기\n\nclass jkm :\n     pass\n\n\ntest = jkm()\ntest\n\n&lt;__main__.jkm at 0x1c07fdfa2d0&gt;\n\n\n\n뼈대 생성\n\ntest.title = \"중요한건 꺽이지 않는 마음\"\n\ntest.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\ntest.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\ntest.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\ntest.h1 = \"마음\"\n\ntest.html_str =  '''\n&lt;style&gt;\n    .title {{\n        font-family: \"Times New Roman\", serif;\n        font-size: 30px;\n        font-weight: 900;\n    }}\n    .text {{\n        font-family: \"Arial\", sans-serif;\n        font-size: 20px;\n        font-style: italic;\n    }}\n    .highlight {{\n        font-family: \"Montserrat\", monospace;\n        font-size: 35px;\n        font-weight: 900;\n        text-decoration: underline; ## 밑줄\n        font-style: normal;\n        color: darkblue;\n        background-color: #FFFF00;\n    }}\n&lt;/style&gt;\n\n&lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n&lt;img src={url} width=\"600\"&gt;\n&lt;p&gt; \\n &lt;/p&gt;\n&lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n&lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n&lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n'''\n\n\n\nshow 함수선언\n\ndef show(test):\n    _str = test.html_str.format(\n        tt1 = test.title,\n        url = test.url,\n        Q = test.Q,\n        A = test.A,\n        h1 = test.h1\n    )\n    display(HTML(_str))\n\n\nshow(test)\n\n\n\n\n중요한건 꺽이지 않는 마음\n\n \n \n Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "from IPython.core.display import HTML\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n\nclass jkm:\n    def __init__(self) :\n        self.title = \"중요한건 꺽이지 않는 마음\"\n\n        self.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\n        self.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\n        self.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\n        self.h1 = \"마음\"\n\n        self.html_str =  '''\n                    &lt;style&gt;\n                        .title {{\n                            font-family: \"Times New Roman\", serif;\n                            font-size: 30px;\n                            font-weight: 900;\n                        }}\n                        .text {{\n                            font-family: \"Arial\", sans-serif;\n                            font-size: 20px;\n                            font-style: italic;\n                        }}\n                        .highlight {{\n                            font-family: \"Montserrat\", monospace;\n                            font-size: 35px;\n                            font-weight: 900;\n                            text-decoration: underline; ## 밑줄\n                            font-style: normal;\n                            color: darkblue;\n                            background-color: #FFFF00;\n                        }}\n                    &lt;/style&gt;\n\n                    &lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n                    &lt;img src={url} width=\"600\"&gt;\n                    &lt;p&gt; \\n &lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    &lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n                    '''\n        \n    def show(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        display(HTML(_str))\n\n\ntest = jkm()\n\n\ntest.show()\n\n\n                    \n\n                    중요한건 꺽이지 않는 마음\n                    \n                     \n \n                     Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n                     A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    중요한 것은 꺾이지 않는  마음 \n                    \n\n\n\n\n\n- 아래처럼 우리가 생성한 test의 타입을 확인하니 type 이 jkm 으로 나온다.\n\ntest?\n\n\nType:        jkm\nString form: &lt;__main__.jkm object at 0x000001E17B1E7850&gt;\nDocstring:   &lt;no docstring&gt;\n\n\n\n- 아래의 리스트, 튜플, 리스트(튜플)의 타입을 확인해보자.\n\ntype([1,2,3])\n\nlist\n\n\n\ntype((1,2,3))\n\ntuple\n\n\n\ntype(list((1,2,3)))\n\nlist\n\n\n- 깨달음1. 우리가 어떤 인스턴스 객체를 생성할 떄 그 자료형은 파이썬 내부, 혹은 우리가 작성한 클래스의 이름이다.\n\n\n\n\na = \"123\"\nlist(a)\n\n['1', '2', '3']\n\n\n\na = list()\n\na.__init__(\"123\")\na\n\n['1', '2', '3']\n\n\n\na = list()\na.__init__('123') \na.__init__() # 리스트 최기화\na\n\n[]\n\n\n- 깨달음 2. 우리가 list(\"123\") 과 같은 메소드를 입력할 때 사실 자료형을 변환하는 것이 아니라, list 라는 클래스의 __init__()으로 인스턴스를 생성하는 것이었다.\n\n\n\n- 아래의 클래스를 관찰하자\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def show(self):\n        print('a={}'.format(self.a))\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na?\n\n\nType:        UpJump\nString form: &lt;__main__.UpJump object at 0x000001E17A4FE650&gt;\nDocstring:   &lt;no docstring&gt;\n\n\n\n\na.up()\n\na의 값이 1 증가합니다.\n\n\n\na.jump(-2)\n\na의 값이 -2 증가합니다.\n\n\n\na.reset()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na.show()\n\na=0\n\n\n- show 함수를 살펴보자.\n\nshow 함수는 print와 비슷하다 \\(\\to\\) 그렇다면….?\nprint(a)를 하면 a.show() 와 동일한 효과를 내도록 만들 수 있을까?\n\n\nprint(a)\n\n&lt;__main__.UpJump object at 0x000001E17A4FE650&gt;\n\n\n\nprint는 파이썬의 내장기능이다. 내장기능을 우리가 마음대로 변환해서 사용하면 많은 문제들이 생긴다.\n\n\\(\\divideontimes\\) 그런데 a의 자료형에 해당하는 인스턴스들에 한정하여 print를 수정하는 방법이 있다면?\n\n즉, 다른 클래스 오브젝트들은 영향을 받지 않고, UpJump로 생성된 오브젝트들만 가능하게끔 하는 것이다.\n\n\n\n- 아래둘은 같은 역할을 한다. \\(\\to\\) 즉, print(“a”)는 print(\"a\".__str__())의 축약 버전이다.\n\n print(\"a\")\n\na\n\n\n\nprint(\"a\".__str__())\n\na\n\n\n- 우리가 정의한 show함수는 다음과 같다.\ndef show(self):\n        print('a={}'.format(self.a))\n- 즉, 작성한 show함수는 단지 print문을 호출하는 함수이므로, a.__str__()의 기능을 재정의하면? print(a)의 결과도 바뀌지 않을까?\n\n\n\n\ndef f():\n    print(\"강철\")\n    \nf()\n\n강철\n\n\n\ndef f() :\n    print(\"DX 강철\")\nf()\n\nDX 강철\n\n\n- 함수를 덮어씌울 수 있다는 것을 확인하였다.\n\n\n\n\ndef show() \\(\\to\\) def __str__(), print \\(\\to\\) return\n\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def __str__(self):\n        return 'a={}'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na.__str__()\n\n'a=0'\n\n\n\nprint(a) ## 성공했다!!\n\na=0\n\n\n\n\n\n\n- 우리가 어떤 변수를 할당하고 실행할때 사용되는 내장 함수는 __repr__() \\(\\to\\) representation의 약자이다.\n- 그러면 __repr__도 우리가 정의할 수 있지 않을까?\n- __str()__ 과 비교해보자.\n\na = np.arange(4).reshape(2,2)\n\n\na.__str__()\n\n'[[0 1]\\n [2 3]]'\n\n\n\na.__repr__()\n\n'array([[0, 1],\\n       [2, 3]])'\n\n\n- print 문을 사용한 비교.\n\nprint(a.__str__())\n\n[[0 1]\n [2 3]]\n\n\n\nprint(a.__repr__())\n\narray([[0, 1],\n       [2, 3]])\n\n\n\n\ndef __repr__(self):\n    return 'a={}'.format(self.a)\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def __str__(self):\n        return 'a의 값은 {}입니다.'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n    def __repr__(self):\n        return 'a={}'.format(self.a)  \n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\nprint(a)\n\na의 값은 0입니다.\n\n\n\na\n\na=0\n\n\n\n\n\n- 만약 __repr__()만 정의되어 있고 __str__()이 정의되있지 않았다면 __repr__()의 내용이 __str__()의 내용을 대신한다. (단, 역은 성립하지 않음)\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n   # def __str__(self):\n    #    return 'a의 값은 {}입니다.'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n    def __repr__(self):\n        return 'a={}'.format(self.a)  \n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na\n\na=0\n\n\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def __str__(self):\n        return 'a의 값은 {}입니다.'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n   # def __repr__(self):\n    #    return 'a={}'.format(self.a)  \n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na\n\n&lt;__main__.UpJump at 0x1e17b574090&gt;\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n2\n\n\n1\n2\n3\n\n\n2\n3\n4\n\n\n\n\n\n\n\n\nprint(df.__repr__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n\nprint(df.__str__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n- 뭔가 이상하다. 앞서 배운대로라면 코드를 실행할 때 나오는 표처럼 예쁘게 나와야 하는데 그렇지 않다…\n- 아래를 살펴보자.\n\ndf._repr_html_()\n\n'&lt;div&gt;\\n&lt;style scoped&gt;\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n&lt;/style&gt;\\n&lt;table border=\"1\" class=\"dataframe\"&gt;\\n  &lt;thead&gt;\\n    &lt;tr style=\"text-align: right;\"&gt;\\n      &lt;th&gt;&lt;/th&gt;\\n      &lt;th&gt;a&lt;/th&gt;\\n      &lt;th&gt;b&lt;/th&gt;\\n    &lt;/tr&gt;\\n  &lt;/thead&gt;\\n  &lt;tbody&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;0&lt;/th&gt;\\n      &lt;td&gt;1&lt;/td&gt;\\n      &lt;td&gt;2&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;1&lt;/th&gt;\\n      &lt;td&gt;2&lt;/td&gt;\\n      &lt;td&gt;3&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;2&lt;/th&gt;\\n      &lt;td&gt;3&lt;/td&gt;\\n      &lt;td&gt;4&lt;/td&gt;\\n    &lt;/tr&gt;\\n  &lt;/tbody&gt;\\n&lt;/table&gt;\\n&lt;/div&gt;'\n\n\n\nHTML(df._repr_html_())\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n2\n\n\n1\n2\n3\n\n\n2\n3\n4\n\n\n\n\n\n\n\n- 깨달음5. 데이터 프레임은 html로 작성되어 있으며 _repr_html_()은 html 구조를 확인할 수 있는 명령어이다!!\n- 그러면 df.__repr__()의 역할은?\n\n아 우리가 대화형 콘솔(anaconda prompt)에서 작성하면 나오는 출력형식을 지원한다!\n\n\n\n\n\n- 초기\ndef show(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        display(HTML(_str))\n- 수정후\ndef _repr_html_(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        return _str\n\nclass jkm:\n    def __init__(self) :\n        self.title = \"중요한건 꺽이지 않는 마음\"\n\n        self.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\n        self.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\n        self.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\n        self.h1 = \"마음\"\n\n        self.html_str =  '''\n                    &lt;style&gt;\n                        .title {{\n                            font-family: \"Times New Roman\", serif;\n                            font-size: 30px;\n                            font-weight: 900;\n                        }}\n                        .text {{\n                            font-family: \"Arial\", sans-serif;\n                            font-size: 20px;\n                            font-style: italic;\n                        }}\n                        .highlight {{\n                            font-family: \"Montserrat\", monospace;\n                            font-size: 35px;\n                            font-weight: 900;\n                            text-decoration: underline; ## 밑줄\n                            font-style: normal;\n                            color: darkblue;\n                            background-color: #FFFF00;\n                        }}\n                    &lt;/style&gt;\n\n                    &lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n                    &lt;img src={url} width=\"600\"&gt;\n                    &lt;p&gt; \\n &lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    &lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n                    '''\n        \n    def _repr_html_(self):\n                _str = self.html_str.format(\n                    tt1 = self.title,\n                    url = self.url,\n                    Q = self.Q,\n                    A = self.A,\n                    h1 = self.h1)\n                return _str\n\n\na = jkm()\na\n\n\n                    \n\n                    중요한건 꺽이지 않는 마음\n                    \n                     \n \n                     Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n                     A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#작성한-class-등록",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#작성한-class-등록",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "class jkm:\n    def __init__(self) :\n        self.title = \"중요한건 꺽이지 않는 마음\"\n\n        self.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\n        self.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\n        self.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\n        self.h1 = \"마음\"\n\n        self.html_str =  '''\n                    &lt;style&gt;\n                        .title {{\n                            font-family: \"Times New Roman\", serif;\n                            font-size: 30px;\n                            font-weight: 900;\n                        }}\n                        .text {{\n                            font-family: \"Arial\", sans-serif;\n                            font-size: 20px;\n                            font-style: italic;\n                        }}\n                        .highlight {{\n                            font-family: \"Montserrat\", monospace;\n                            font-size: 35px;\n                            font-weight: 900;\n                            text-decoration: underline; ## 밑줄\n                            font-style: normal;\n                            color: darkblue;\n                            background-color: #FFFF00;\n                        }}\n                    &lt;/style&gt;\n\n                    &lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n                    &lt;img src={url} width=\"600\"&gt;\n                    &lt;p&gt; \\n &lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    &lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n                    '''\n        \n    def show(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        display(HTML(_str))\n\n\ntest = jkm()\n\n\ntest.show()\n\n\n                    \n\n                    중요한건 꺽이지 않는 마음\n                    \n                     \n \n                     Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n                     A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-1.-type-class",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-1.-type-class",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "- 아래처럼 우리가 생성한 test의 타입을 확인하니 type 이 jkm 으로 나온다.\n\ntest?\n\n\nType:        jkm\nString form: &lt;__main__.jkm object at 0x000001E17B1E7850&gt;\nDocstring:   &lt;no docstring&gt;\n\n\n\n- 아래의 리스트, 튜플, 리스트(튜플)의 타입을 확인해보자.\n\ntype([1,2,3])\n\nlist\n\n\n\ntype((1,2,3))\n\ntuple\n\n\n\ntype(list((1,2,3)))\n\nlist\n\n\n- 깨달음1. 우리가 어떤 인스턴스 객체를 생성할 떄 그 자료형은 파이썬 내부, 혹은 우리가 작성한 클래스의 이름이다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-2.-__init__",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-2.-__init__",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "a = \"123\"\nlist(a)\n\n['1', '2', '3']\n\n\n\na = list()\n\na.__init__(\"123\")\na\n\n['1', '2', '3']\n\n\n\na = list()\na.__init__('123') \na.__init__() # 리스트 최기화\na\n\n[]\n\n\n- 깨달음 2. 우리가 list(\"123\") 과 같은 메소드를 입력할 때 사실 자료형을 변환하는 것이 아니라, list 라는 클래스의 __init__()으로 인스턴스를 생성하는 것이었다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-3.-__str__",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-3.-__str__",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "- 아래의 클래스를 관찰하자\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def show(self):\n        print('a={}'.format(self.a))\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na?\n\n\nType:        UpJump\nString form: &lt;__main__.UpJump object at 0x000001E17A4FE650&gt;\nDocstring:   &lt;no docstring&gt;\n\n\n\n\na.up()\n\na의 값이 1 증가합니다.\n\n\n\na.jump(-2)\n\na의 값이 -2 증가합니다.\n\n\n\na.reset()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na.show()\n\na=0\n\n\n- show 함수를 살펴보자.\n\nshow 함수는 print와 비슷하다 \\(\\to\\) 그렇다면….?\nprint(a)를 하면 a.show() 와 동일한 효과를 내도록 만들 수 있을까?\n\n\nprint(a)\n\n&lt;__main__.UpJump object at 0x000001E17A4FE650&gt;\n\n\n\nprint는 파이썬의 내장기능이다. 내장기능을 우리가 마음대로 변환해서 사용하면 많은 문제들이 생긴다.\n\n\\(\\divideontimes\\) 그런데 a의 자료형에 해당하는 인스턴스들에 한정하여 print를 수정하는 방법이 있다면?\n\n즉, 다른 클래스 오브젝트들은 영향을 받지 않고, UpJump로 생성된 오브젝트들만 가능하게끔 하는 것이다.\n\n\n\n- 아래둘은 같은 역할을 한다. \\(\\to\\) 즉, print(“a”)는 print(\"a\".__str__())의 축약 버전이다.\n\n print(\"a\")\n\na\n\n\n\nprint(\"a\".__str__())\n\na\n\n\n- 우리가 정의한 show함수는 다음과 같다.\ndef show(self):\n        print('a={}'.format(self.a))\n- 즉, 작성한 show함수는 단지 print문을 호출하는 함수이므로, a.__str__()의 기능을 재정의하면? print(a)의 결과도 바뀌지 않을까?\n\n\n\n\ndef f():\n    print(\"강철\")\n    \nf()\n\n강철\n\n\n\ndef f() :\n    print(\"DX 강철\")\nf()\n\nDX 강철\n\n\n- 함수를 덮어씌울 수 있다는 것을 확인하였다.\n\n\n\n\ndef show() \\(\\to\\) def __str__(), print \\(\\to\\) return\n\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def __str__(self):\n        return 'a={}'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na.__str__()\n\n'a=0'\n\n\n\nprint(a) ## 성공했다!!\n\na=0"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-4.-__repr__",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-4.-__repr__",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "- 우리가 어떤 변수를 할당하고 실행할때 사용되는 내장 함수는 __repr__() \\(\\to\\) representation의 약자이다.\n- 그러면 __repr__도 우리가 정의할 수 있지 않을까?\n- __str()__ 과 비교해보자.\n\na = np.arange(4).reshape(2,2)\n\n\na.__str__()\n\n'[[0 1]\\n [2 3]]'\n\n\n\na.__repr__()\n\n'array([[0, 1],\\n       [2, 3]])'\n\n\n- print 문을 사용한 비교.\n\nprint(a.__str__())\n\n[[0 1]\n [2 3]]\n\n\n\nprint(a.__repr__())\n\narray([[0, 1],\n       [2, 3]])\n\n\n\n\ndef __repr__(self):\n    return 'a={}'.format(self.a)\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def __str__(self):\n        return 'a의 값은 {}입니다.'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n    def __repr__(self):\n        return 'a={}'.format(self.a)  \n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\nprint(a)\n\na의 값은 0입니다.\n\n\n\na\n\na=0\n\n\n\n\n\n- 만약 __repr__()만 정의되어 있고 __str__()이 정의되있지 않았다면 __repr__()의 내용이 __str__()의 내용을 대신한다. (단, 역은 성립하지 않음)\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n   # def __str__(self):\n    #    return 'a의 값은 {}입니다.'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n    def __repr__(self):\n        return 'a={}'.format(self.a)  \n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na\n\na=0\n\n\n\nclass UpJump:\n    def __init__(self):\n        self.reset()\n    def up(self):\n        self.a = self.a + 1  \n        print(\"a의 값이 1 증가합니다.\")\n    def jump(self,jump_size):\n        self.a = self.a + jump_size      \n        print(\"a의 값이 {} 증가합니다.\".format(jump_size))\n    def __str__(self):\n        return 'a의 값은 {}입니다.'.format(self.a)\n    def reset(self):\n        self.a = 0\n        print(\"a의 값이 0으로 초기화 되었습니다.\")\n   # def __repr__(self):\n    #    return 'a={}'.format(self.a)  \n\n\na = UpJump()\n\na의 값이 0으로 초기화 되었습니다.\n\n\n\na\n\n&lt;__main__.UpJump at 0x1e17b574090&gt;"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-5.-_repr_html_",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-10-Extra 02. 클래스 탐구 (1).html#깨달음-5.-_repr_html_",
    "title": "Extra 02. 클래스 탐구 (1)",
    "section": "",
    "text": "df = pd.DataFrame({'a':[1,2,3],'b':[2,3,4]})\ndf\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n2\n\n\n1\n2\n3\n\n\n2\n3\n4\n\n\n\n\n\n\n\n\nprint(df.__repr__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n\nprint(df.__str__())\n\n   a  b\n0  1  2\n1  2  3\n2  3  4\n\n\n- 뭔가 이상하다. 앞서 배운대로라면 코드를 실행할 때 나오는 표처럼 예쁘게 나와야 하는데 그렇지 않다…\n- 아래를 살펴보자.\n\ndf._repr_html_()\n\n'&lt;div&gt;\\n&lt;style scoped&gt;\\n    .dataframe tbody tr th:only-of-type {\\n        vertical-align: middle;\\n    }\\n\\n    .dataframe tbody tr th {\\n        vertical-align: top;\\n    }\\n\\n    .dataframe thead th {\\n        text-align: right;\\n    }\\n&lt;/style&gt;\\n&lt;table border=\"1\" class=\"dataframe\"&gt;\\n  &lt;thead&gt;\\n    &lt;tr style=\"text-align: right;\"&gt;\\n      &lt;th&gt;&lt;/th&gt;\\n      &lt;th&gt;a&lt;/th&gt;\\n      &lt;th&gt;b&lt;/th&gt;\\n    &lt;/tr&gt;\\n  &lt;/thead&gt;\\n  &lt;tbody&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;0&lt;/th&gt;\\n      &lt;td&gt;1&lt;/td&gt;\\n      &lt;td&gt;2&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;1&lt;/th&gt;\\n      &lt;td&gt;2&lt;/td&gt;\\n      &lt;td&gt;3&lt;/td&gt;\\n    &lt;/tr&gt;\\n    &lt;tr&gt;\\n      &lt;th&gt;2&lt;/th&gt;\\n      &lt;td&gt;3&lt;/td&gt;\\n      &lt;td&gt;4&lt;/td&gt;\\n    &lt;/tr&gt;\\n  &lt;/tbody&gt;\\n&lt;/table&gt;\\n&lt;/div&gt;'\n\n\n\nHTML(df._repr_html_())\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n2\n\n\n1\n2\n3\n\n\n2\n3\n4\n\n\n\n\n\n\n\n- 깨달음5. 데이터 프레임은 html로 작성되어 있으며 _repr_html_()은 html 구조를 확인할 수 있는 명령어이다!!\n- 그러면 df.__repr__()의 역할은?\n\n아 우리가 대화형 콘솔(anaconda prompt)에서 작성하면 나오는 출력형식을 지원한다!\n\n\n\n\n\n- 초기\ndef show(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        display(HTML(_str))\n- 수정후\ndef _repr_html_(self):\n        _str = self.html_str.format(\n            tt1 = self.title,\n            url = self.url,\n            Q = self.Q,\n            A = self.A,\n            h1 = self.h1 )\n        return _str\n\nclass jkm:\n    def __init__(self) :\n        self.title = \"중요한건 꺽이지 않는 마음\"\n\n        self.url = \"https://github.com/guebin/PP2023/blob/main/posts/03_Class/JungGGuckMa.jpg?raw=true\"\n\n        self.Q = \"Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\"\n\n        self.A = \"A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\"\n\n        self.h1 = \"마음\"\n\n        self.html_str =  '''\n                    &lt;style&gt;\n                        .title {{\n                            font-family: \"Times New Roman\", serif;\n                            font-size: 30px;\n                            font-weight: 900;\n                        }}\n                        .text {{\n                            font-family: \"Arial\", sans-serif;\n                            font-size: 20px;\n                            font-style: italic;\n                        }}\n                        .highlight {{\n                            font-family: \"Montserrat\", monospace;\n                            font-size: 35px;\n                            font-weight: 900;\n                            text-decoration: underline; ## 밑줄\n                            font-style: normal;\n                            color: darkblue;\n                            background-color: #FFFF00;\n                        }}\n                    &lt;/style&gt;\n\n                    &lt;p class=\"title\"&gt;{tt1}&lt;/p&gt;\n                    &lt;img src={url} width=\"600\"&gt;\n                    &lt;p&gt; \\n &lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {Q}&lt;/p&gt;\n                    &lt;p class=\"text\"&gt; {A}: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    &lt;p class=\"title\"&gt;중요한 것은 꺾이지 않는 &lt;span class=\"highlight\"&gt; {h1} &lt;/span&gt;&lt;/p&gt;\n                    '''\n        \n    def _repr_html_(self):\n                _str = self.html_str.format(\n                    tt1 = self.title,\n                    url = self.url,\n                    Q = self.Q,\n                    A = self.A,\n                    h1 = self.h1)\n                return _str\n\n\na = jkm()\na\n\n\n                    \n\n                    중요한건 꺽이지 않는 마음\n                    \n                     \n \n                     Q: 로그와 2라운드 재대결, 어떤 점에 유의해야 할까\n                     A: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.: 상대팀에 대해서 더 분석할 건 없는 것 같고, 저희가 저희 플레이 잘하는 게 제일 중요한 것 같고 오늘 지긴 했지만 저희끼리만 안 무너지면 충분히 이길 수 있을 것 같아요.\n                    중요한 것은 꺾이지 않는  마음"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html",
    "title": "Extra 04. 클래스 탐구 (3)",
    "section": "",
    "text": "- 클래스를 조금 수정하고 싶을때, 아래와 같은 문법을 이용하면 편리하다.(지난 챕터 복기!!)\nclass 새로운클래스 (수정할 클래스) :\n    def 수정 및 추가 함수 : \n        return ...\n\n\n\nclass a1 :\n    def __init__(self,v) :\n        ## 여기는 a1클래스\n        print(\"init 클래스에서 정의된 __init__을 실행합니다.\")\n        self.v = v\n\n\nclass a2 (a1):\n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\n\n\na = a2(5)\n\ninit 클래스에서 정의된 __init__을 실행합니다.\n\n\n\na.show()\n\na2 클래스에서 정의한 show를 실행합니다.\nvalue = 5\n\n\n\na.show??\n\n\nSignature: a.show()\nDocstring: &lt;no docstring&gt;\nSource:   \n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1064789111.py\nType:      method\n\n\n\n\na.__init__??\n\n\nSignature: a.__init__(v)\nDocstring: Initialize self.  See help(type(self)) for accurate signature.\nSource:   \n    def __init__(self,v) :\n        ## 여기는 a1클래스\n        print(\"init 클래스에서 정의된 __init__을 실행합니다.\")\n        self.v = v\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\3688838073.py\nType:      method"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#ex1",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#ex1",
    "title": "Extra 04. 클래스 탐구 (3)",
    "section": "",
    "text": "class a1 :\n    def __init__(self,v) :\n        ## 여기는 a1클래스\n        print(\"init 클래스에서 정의된 __init__을 실행합니다.\")\n        self.v = v\n\n\nclass a2 (a1):\n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\n\n\na = a2(5)\n\ninit 클래스에서 정의된 __init__을 실행합니다.\n\n\n\na.show()\n\na2 클래스에서 정의한 show를 실행합니다.\nvalue = 5\n\n\n\na.show??\n\n\nSignature: a.show()\nDocstring: &lt;no docstring&gt;\nSource:   \n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1064789111.py\nType:      method\n\n\n\n\na.__init__??\n\n\nSignature: a.__init__(v)\nDocstring: Initialize self.  See help(type(self)) for accurate signature.\nSource:   \n    def __init__(self,v) :\n        ## 여기는 a1클래스\n        print(\"init 클래스에서 정의된 __init__을 실행합니다.\")\n        self.v = v\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\3688838073.py\nType:      method"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#수퍼클래스",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#수퍼클래스",
    "title": "Extra 04. 클래스 탐구 (3)",
    "section": "수퍼클래스",
    "text": "수퍼클래스\n\n방법 1 : 직접 수퍼클래스 명시\n\nclass a3(a2) :\n    def __init__(self,v) :\n        ## a3클래스 명시\n        print(\"짠~!\")\n        a2.__init__(self,v)\n        print(\"짠짠~!!\")\n\n\ndeco = a3(5)\n\n짠~!\ninit 클래스에서 정의된 __init__을 실행합니다.\n짠짠~!!\n\n\n\ndeco.show??\n\n\nSignature: deco.show()\nDocstring: &lt;no docstring&gt;\nSource:   \n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1064789111.py\nType:      method\n\n\n\n\ndeco.__init__??\n\n\nSignature: deco.__init__(v)\nDocstring: Initialize self.  See help(type(self)) for accurate signature.\nSource:   \n    def __init__(self,v) :\n        ## a3클래스 명시\n        print(\"짠~!\")\n        a2.__init__(self,v)\n        print(\"짠짠~!!\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1708323518.py\nType:      method\n\n\n\n\n\n방법 2 : super 이용, 생략 x)\n\nclass a3(a2) :\n    def __init__(self,v) :\n        ## a3클래스 명시\n        print(\"짠~!\")\n        super(a3,self).__init__(v)\n        print(\"짠짠~!!\")\n\n\na = a3(5)\n\n짠~!\ninit 클래스에서 정의된 __init__을 실행합니다.\n짠짠~!!\n\n\n\na.show??\n\n\nSignature: a.show()\nDocstring: &lt;no docstring&gt;\nSource:   \n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1064789111.py\nType:      method\n\n\n\n\na.__init__??\n\n\nSignature: a.__init__(v)\nDocstring: Initialize self.  See help(type(self)) for accurate signature.\nSource:   \n    def __init__(self,v) :\n        ## a3클래스 명시\n        print(\"짠~!\")\n        super(a3,self).__init__(v)\n        print(\"짠짠~!!\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\2997847713.py\nType:      method\n\n\n\n\n\n방법 3 : super 이용, 생략 o) (\\(\\star\\star\\star\\))\n\nclass a3(a2) :\n    def __init__(self,v) :\n        ## a3클래스 명시\n        print(\"짠~!\")\n        super().__init__(v)  ## 생략전 -&gt; super(a3,self).__init__(v)\n        print(\"짠짠~!!\")\n\n\na = a3(5)\n\n짠~!\ninit 클래스에서 정의된 __init__을 실행합니다.\n짠짠~!!\n\n\n\na3.show??\n\n\nSignature: a3.show(self)\nDocstring: &lt;no docstring&gt;\nSource:   \n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1064789111.py\nType:      function\n\n\n\n\na3.__init__??\n\n\nSignature: a3.__init__(self, v)\nDocstring: Initialize self.  See help(type(self)) for accurate signature.\nSource:   \n    def __init__(self,v) :\n        ## a3클래스 명시\n        print(\"짠~!\")\n        super().__init__(v)  ## 생략전 -&gt; super(a3,self).__init__(v)\n        print(\"짠짠~!!\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\2474030909.py\nType:      function\n\n\n\n\n\n방법 4 : super()이용, 방법 3을 이해하기위한 코드\n\nclass a4(a2) :\n    def __init__(self,v) :\n        ## a4클래스 \n        print(\"짠~!\")\n        super(__class__,self).__init__(v)  ## 생략전 -&gt; super(a3,self).__init__(v)\n        print(\"짠짠~!!\")\n\n\na = a4(5)\n\n짠~!\ninit 클래스에서 정의된 __init__을 실행합니다.\n짠짠~!!\n\n\n\na.show()\n\na2 클래스에서 정의한 show를 실행합니다.\nvalue = 5\n\n\n\na.show??\n\n\nSignature: a.show()\nDocstring: &lt;no docstring&gt;\nSource:   \n    def show(self) :\n        ## 여기는 a2클래스\n        print(\"a2 클래스에서 정의한 show를 실행합니다.\")\n        print(f\"value = {self.v}\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1064789111.py\nType:      method\n\n\n\n\na.__init__??\n\n\nSignature: a.__init__(v)\nDocstring: Initialize self.  See help(type(self)) for accurate signature.\nSource:   \n    def __init__(self,v) :\n        ## a4클래스 \n        print(\"짠~!\")\n        super(__class__,self).__init__(v)  ## 생략전 -&gt; super(a3,self).__init__(v)\n        print(\"짠짠~!!\")\nFile:      c:\\users\\user\\appdata\\local\\temp\\ipykernel_15308\\1093371131.py\nType:      method"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#다중상속-super-x",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#다중상속-super-x",
    "title": "Extra 04. 클래스 탐구 (3)",
    "section": "다중상속 (super X)",
    "text": "다중상속 (super X)\n\n일반적인 다중 상속\n- Add 클래스 선언\n\nclass Add:\n    def __init__(self,value):\n        self.value = value \n    def __add__(self,value2):\n        return self.value + value2\n\n- 초기화\n\na = Add(2)\n\n\na.value\n\n2\n\n\n\na + 5 \n\n7\n\n\n- Mul 클래스 선언\n\nclass Mul:\n    def __init__(self,value):\n        self.value = value \n    def __mul__(self,value2):\n        return self.value * value2\n\n\na = Mul(5)\n\n\na.value\n\n5\n\n\n- 더하기는 위에서 정의한적 없음\n\na+2\n\nTypeError: unsupported operand type(s) for +: 'Mul' and 'int'\n\n\n- 곱하기 수행\n\na*2\n\n10\n\n\n- 위 2개의 클래스를 상속\n\nclass am(Add,Mul) :\n      pass\n\n\na = am(5)\na.value\n\n5\n\n\n\na + 2\n\n7\n\n\n\na*5\n\n25\n\n\n\n\n다중상속(__init__이 겹친다…)\n\nclass Add:\n    def __init__(self,value):\n        print(\"Add클래스에서 정의된 __init__ 메소드가 실행됩니다\")\n        self.value = value \n    def __add__(self,value2):\n        return self.value + value2\n              \nclass Mul:\n    def __init__(self,value):\n        print(\"Mul클래스에서 정의된 __init__ 메소드가 실행됩니다\")        \n        self.value = value \n    def __mul__(self,value2):\n        return self.value * value2        \n    \nclass am(Add,Mul):\n    pass     \n\n- 현재 Add클래스가 우선 순위인 것 같다.\n\na = am(5)\n\nAdd클래스에서 정의된 __init__ 메소드가 실행됩니다\n\n\n\n\n믹스인 클래스(\\(\\star\\star\\star\\))\n\nclass Init:\n    def __init__(self,value):\n        ## 여기는 Init 클래스야 \n        print(\"Init클래스에서 정의된 __init__메소드를 실행합니다\")        \n        self.value = value\n\nclass Add(Init):\n    def __add__(self,value2):\n        return self.value + value2\n              \nclass Mul(Init):\n    def __mul__(self,value2):\n        return self.value * value2        \n    \nclass am(Add,Mul):\n    pass     \n\n\na = am(5)\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n\na + 2\n\n7\n\n\n\na*5\n\n25"
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#다중상속-super-o",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#다중상속-super-o",
    "title": "Extra 04. 클래스 탐구 (3)",
    "section": "다중상속 (super O)",
    "text": "다중상속 (super O)\n\nsuper를 쓰지 않는 좋지 못한 예시\n\nclass Init:\n    def __init__(self,value):\n        ## 여기는 Init 클래스야 \n        print(\"Init클래스에서 정의된 __init__메소드를 실행합니다\")        \n        self.value = value\n\n- 위 intit을 상속 받아서\n\n초기값 = 초기값 x 2\n초기값 = 초기값 + 5\n\n를 객채 생성과 동시 에 수행하는 클래스를 각각 만듬\n\nclass a1(Init):\n    def __init__(self,value):\n        Init.__init__(self,value)\n        self.value = self.value * 2\n\n\na = a1(5)\na.value\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n10\n\n\n\nclass a2(Init):\n    def __init__(self,value):\n        Init.__init__(self,value)\n        self.value = self.value + 5\n\n\na = a2(4)\na.value\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n9\n\n\n- 근데 초기값 = 초기갑 x 2 + 5를 객체 생성과 동시에 수행해주는 클래스를 만들고 싶음.\n\nclass a3(a1,a2) :\n    print(\"초기값 = 초기값 x2 + 5를 수행ㅎ는 클래스입니다.\")\n    def __init__(self,value) :\n        a1.__init__(self,value)\n        a2.__init__(self,self.value)\n\n초기값 = 초기값 x2 + 5를 수행ㅎ는 클래스입니다.\n\n\n\na = a3(5)\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n\na.value\n\n15\n\n\n\n싫은 이유\n\n코드가 지저분함\n먼가 상속이란 단어의 진정성이 없음\n\n\n\n\n\nsuper()을 활용한 좋은 예시\n\nclass Init(object):\n    def __init__(self,value):\n        ## 여기는 Init 클래스야 \n        print(\"Init클래스에서 정의된 __init__메소드를 실행합니다\")        \n        self.value = value\n        \nclass a1(Init):\n    def __init__(self,value):\n        super().__init__(value)\n        self.value = self.value * 2\n        \nclass a2(Init):\n    def __init__(self,value):\n        super().__init__(value)\n        self.value = self.value + 5\n        \nclass a3(a2,a1):\n    def __init__(self,value):\n        super().__init__(value)\n\n\na = a3(5)\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n\na.value\n\n15\n\n\n\n\nsuper의 사용방법\n- (“초기값 x 2 + 5) x 2” 를 수행해주는 클래스를 만들고 싶음.\n\nclass Init(object):\n    def __init__(self,value):\n        ## 여기는 Init 클래스야 \n        print(\"Init클래스에서 정의된 __init__메소드를 실행합니다\")        \n        self.value = value\n        \nclass a1(Init):\n    def __init__(self,value):\n        super().__init__(value)\n        self.value = self.value * 2\n        \nclass a2(Init):\n    def __init__(self,value):\n        super().__init__(value)\n        self.value = self.value + 5\n        \nclass a3(a2,a1): ## 파라미터 순서에 따라 mro 상속 순서가 달라짐\n    def __init__(self,value):\n        super().__init__(value)\n        super(a2,self).__init__(self.value)\n\n- super().__init__(value) : 상위 클래스인 init,a1,a2의 __init__를 순서대로 실행하되 중복실행하지 않는다.\n- super(a2,self).__init__(self.value) : a2보다 상위 클래스인 init, a1의 __init__을 순서대로 실행하되 중복실행은 하지 않음.\n\na = a3(5)\na.value\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n30\n\n\n\na3.mro()\n\n[__main__.a3, __main__.a2, __main__.a1, __main__.Init, object]\n\n\n- 그냥 이게 더 낫지 않나?\n\nclass Init(object):\n    def __init__(self,value):\n        ## 여기는 Init 클래스야 \n        print(\"Init클래스에서 정의된 __init__메소드를 실행합니다\")        \n        self.value = value\n        \nclass a1(Init):\n    def aa1(self):\n        self.value = self.value * 2\n        \nclass a2(Init):\n    def aa2(self):\n        self.value = self.value + 5\n        \nclass a3(a2,a1):\n    def aa3(self):\n        self.aa1()\n        self.aa2()\n        self.aa1()\n\n\na = a3(5)\n\nInit클래스에서 정의된 __init__메소드를 실행합니다\n\n\n\na.value\n\n5\n\n\n\na.aa3()\n\n\na.value\n\n30\n\n\n- 그래도 이전 방법들을 잘 알아야한다.\n\n어떠한 클래스를 상속 받을때는 “내가 만든 클래스”가 아닐 경우가 대부분이다. 따라서 “애초부터 메소드가 겹치지 않게 클래스들을 깔끔하게 디자인을 하는것”은 불가능한 경우가 많다."
  },
  {
    "objectID": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#리스트의-상속",
    "href": "posts/DX/00. 데이터 다루기/extra/2023-08-15-Extra 04. 클래스 탐구 (3).html#리스트의-상속",
    "title": "Extra 04. 클래스 탐구 (3)",
    "section": "리스트의 상속",
    "text": "리스트의 상속\n- list와 비슷하면서… 멤버들의 빈도가 계산되는 메소드를 갖는 나만의 list 클래스를 만들고 싶다.\n\nlst = list('asdfasssdfa')\nlst \n\n['a', 's', 'd', 'f', 'a', 's', 's', 's', 'd', 'f', 'a']\n\n\n- 각 원소들의 빈도\n\n{i : lst.count(i) for i in set(lst)}\n\n{'d': 2, 's': 4, 'f': 2, 'a': 3}\n\n\n\nlst.freq()를 수행하면 위의 결과가 나왔으면 좋겠음\n\n\nclass List(list) :\n    def freq(self) :\n        return {i : self.count(i) for i in set(self)}\n\n\nlst2 = List('asdfasssdfa')\n\n\nlst2\n\n['a', 's', 'd', 'f', 'a', 's', 's', 's', 'd', 'f', 'a']\n\n\n\nlst2.freq()\n\n{'d': 2, 's': 4, 'f': 2, 'a': 3}"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html",
    "title": "01. numpy & pandas (2)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#list-to-df",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#list-to-df",
    "title": "01. numpy & pandas (2)",
    "section": "list \\(\\to\\) df",
    "text": "list \\(\\to\\) df\n\na1 = list(np.random.randint(0,100,10))\na2 = list(np.random.randint(0,100,10))\na3 = list(np.random.randint(0,100,10))\na4= list(np.random.randint(0,100,10))\n\ndf = pd.DataFrame([a1,a2,a3,a4]).T\n\n\ndf.head()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n81\n45\n16\n73\n\n\n1\n74\n74\n11\n50\n\n\n2\n0\n85\n13\n77\n\n\n3\n97\n53\n97\n52\n\n\n4\n31\n21\n84\n14\n\n\n\n\n\n\n\n\n날짜 데이터 \\(\\to\\) df.index\n\ndate = pd.date_range(\"2023-08-18\",\"2023-08-27\",freq =\"D\")\n\n\ndf.index = date\n\n\n\n컬럼 이름 생성\n\nname = [\"a\" + str(i) for i in range(len(df.columns))]\n\n\ndf.columns= name\n\n\ndf.head()\n\n\n\n\n\n\n\n\na0\na1\na2\na3\n\n\n\n\n2023-08-18\n81\n45\n16\n73\n\n\n2023-08-19\n74\n74\n11\n50\n\n\n2023-08-20\n0\n85\n13\n77\n\n\n2023-08-21\n97\n53\n97\n52\n\n\n2023-08-22\n31\n21\n84\n14"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#dict-to-df-starstarstar",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#dict-to-df-starstarstar",
    "title": "01. numpy & pandas (2)",
    "section": "dict \\(\\to\\) df (\\(\\star\\star\\star\\))",
    "text": "dict \\(\\to\\) df (\\(\\star\\star\\star\\))\n\nimport random\n\n\ncode = [\"a\" + str(i) for i in range(10)]\nheight = np.linspace(160,180,10)\nweight = np.linspace(60,80,10)\nsmoke = random.choices([True, False],k=10) ## 복원 추출\ndate = pd.date_range(\"2023-08-18\",\"2023-08-27\",freq =\"D\")\n\ndic = {\"code\" : code,\n      \"height\" : height,\n      \"weight\" : weight,\n      \"smoke\" : smoke}\n\ndf = pd.DataFrame(dic,index= date)\n\n\ndf.head()\n\n\n\n\n\n\n\n\ncode\nheight\nweight\nsmoke\n\n\n\n\n2023-08-18\na0\n160.000000\n60.000000\nFalse\n\n\n2023-08-19\na1\n162.222222\n62.222222\nTrue\n\n\n2023-08-20\na2\n164.444444\n64.444444\nTrue\n\n\n2023-08-21\na3\n166.666667\n66.666667\nFalse\n\n\n2023-08-22\na4\n168.888889\n68.888889\nTrue"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-정의",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-정의",
    "title": "01. numpy & pandas (2)",
    "section": "인덱스 정의",
    "text": "인덱스 정의\n\n_lst = random.choices(\"ABC\",k= len(df)) ## 중복허용\n_n = list(np.random.choice(range(1, len(df)+1), len(df), replace=False)) ## 중복 허용 안함\n\n\nindex = [i + str(j) for i,j in zip(_lst,_n)]\n\n\ndf.index = index"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-중복-확인",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-중복-확인",
    "title": "01. numpy & pandas (2)",
    "section": "인덱스 중복 확인",
    "text": "인덱스 중복 확인\n\nlen(df) == len(df.index.unique())\n\nTrue"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-생성확인",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-생성확인",
    "title": "01. numpy & pandas (2)",
    "section": "인덱스 생성확인",
    "text": "인덱스 생성확인\n\ndf.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\n\n\nA115\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\nB64\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\nA172\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\nA215\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\nB86\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 234 entries, A115 to C75\nData columns (total 11 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   manufacturer  234 non-null    object \n 1   model         234 non-null    object \n 2   displ         234 non-null    float64\n 3   year          234 non-null    int64  \n 4   cyl           234 non-null    int64  \n 5   trans         234 non-null    object \n 6   drv           234 non-null    object \n 7   cty           234 non-null    int64  \n 8   hwy           234 non-null    int64  \n 9   fl            234 non-null    object \n 10  class         234 non-null    object \ndtypes: float64(1), int64(4), object(6)\nmemory usage: 21.9+ KB"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#df-load-index-1",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#df-load-index-1",
    "title": "01. numpy & pandas (2)",
    "section": "df load + index (1)",
    "text": "df load + index (1)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/main/posts/mpg.csv\",\n                 index_col=\"manufacturer\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\nmanufacturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#df-load-index-2",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#df-load-index-2",
    "title": "01. numpy & pandas (2)",
    "section": "df load + index (2)",
    "text": "df load + index (2)\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DV2022/main/posts/mpg.csv\")\ndf = df.set_index(\"manufacturer\") # == df.set_index(\"manufacturer\",inplace= True)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\nmanufacturer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n- 인덱스 이름 삭제\n\ndf.index.name = None\ndf.head()\n\n\n\n\n\n\n\n\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\n\n\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-삭제index-버리기-x",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-삭제index-버리기-x",
    "title": "01. numpy & pandas (2)",
    "section": "인덱스 삭제(index 버리기 x)",
    "text": "인덱스 삭제(index 버리기 x)\n\n_df = df.reset_index()\n_df.head()\n\n\n\n\n\n\n\n\nindex\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-삭제index-버리기-o",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#인덱스-삭제index-버리기-o",
    "title": "01. numpy & pandas (2)",
    "section": "인덱스 삭제(index 버리기 o)",
    "text": "인덱스 삭제(index 버리기 o)\n\n_df = df.reset_index(drop=True)\n_df.head()\n\n\n\n\n\n\n\n\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\nclass\n\n\n\n\n0\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#import-1",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#import-1",
    "title": "01. numpy & pandas (2)",
    "section": "import",
    "text": "import\n\nimport random\nimport pandas as pd\nimport plotly.express as px\n\n- tip 데이터는 plotly 모듈에서 제공한다.\n\ntip = px.data.tips()\n\n\ntip.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   total_bill  244 non-null    float64\n 1   tip         244 non-null    float64\n 2   sex         244 non-null    object \n 3   smoker      244 non-null    object \n 4   day         244 non-null    object \n 5   time        244 non-null    object \n 6   size        244 non-null    int64  \ndtypes: float64(2), int64(1), object(4)\nmemory usage: 13.5+ KB\n\n\n\ntip.shape\n\n(244, 7)\n\n\n\ntip.index\n\nRangeIndex(start=0, stop=244, step=1)\n\n\n- 값 확인\n\ntip.values\n\narray([[16.99, 1.01, 'Female', ..., 'Sun', 'Dinner', 2],\n       [10.34, 1.66, 'Male', ..., 'Sun', 'Dinner', 3],\n       [21.01, 3.5, 'Male', ..., 'Sun', 'Dinner', 3],\n       ...,\n       [22.67, 2.0, 'Male', ..., 'Sat', 'Dinner', 2],\n       [17.82, 1.75, 'Male', ..., 'Sat', 'Dinner', 2],\n       [18.78, 3.0, 'Female', ..., 'Thur', 'Dinner', 2]], dtype=object)\n\n\n- 기초통계정보 확인\n\ntip.describe()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsize\n\n\n\n\ncount\n244.000000\n244.000000\n244.000000\n\n\nmean\n19.785943\n2.998279\n2.569672\n\n\nstd\n8.902412\n1.383638\n0.951100\n\n\nmin\n3.070000\n1.000000\n1.000000\n\n\n25%\n13.347500\n2.000000\n2.000000\n\n\n50%\n17.795000\n2.900000\n2.000000\n\n\n75%\n24.127500\n3.562500\n3.000000\n\n\nmax\n50.810000\n10.000000\n6.000000\n\n\n\n\n\n\n\n\ntip.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#sort",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#sort",
    "title": "01. numpy & pandas (2)",
    "section": "sort",
    "text": "sort\n- total_bill 기준 오름차순 정렬\n\ntip.sort_values(by = \"total_bill\").head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n\n\n111\n7.25\n1.00\nFemale\nNo\nSat\nDinner\n1\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n\n\n\n\n\n\n\n- 내림차순 정렬\n\ntip.sort_values(by = \"total_bill\",ascending=False).head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n156\n48.17\n5.00\nMale\nNo\nSun\nDinner\n6\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n\n\n\n\n\n\n\n- 복합열 정렬 : total_bill은 오름차순, tip은 내림차순 기준으로 정렬\n\ntip.sort_values(by = [\"total_bill\",\"tip\"],ascending=[False,True])\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n170\n50.81\n10.00\nMale\nYes\nSat\nDinner\n3\n\n\n212\n48.33\n9.00\nMale\nNo\nSat\nDinner\n4\n\n\n59\n48.27\n6.73\nMale\nNo\nSat\nDinner\n4\n\n\n156\n48.17\n5.00\nMale\nNo\nSun\nDinner\n6\n\n\n182\n45.35\n3.50\nMale\nYes\nSun\nDinner\n3\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n149\n7.51\n2.00\nMale\nNo\nThur\nLunch\n2\n\n\n111\n7.25\n1.00\nFemale\nNo\nSat\nDinner\n1\n\n\n172\n7.25\n5.15\nMale\nYes\nSun\nDinner\n2\n\n\n92\n5.75\n1.00\nFemale\nYes\nFri\nDinner\n2\n\n\n67\n3.07\n1.00\nFemale\nYes\nSat\nDinner\n1\n\n\n\n\n244 rows × 7 columns"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#unique값-확인-범주형-데이터",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#unique값-확인-범주형-데이터",
    "title": "01. numpy & pandas (2)",
    "section": "unique값 확인 (범주형 데이터)",
    "text": "unique값 확인 (범주형 데이터)\n- day열의 unique값 확인\n\n#tip.day\n\n\ntip.day.unique()\n\narray(['Sun', 'Sat', 'Thur', 'Fri'], dtype=object)\n\n\n- unique값 개수 확인\n\ntip.day.value_counts()\n\nSat     87\nSun     76\nThur    62\nFri     19\nName: day, dtype: int64\n\n\n- 시각화\n\ntip.day.value_counts().plot(kind=\"barh\",title=\"count of day\",figsize = (4,4))\n\n&lt;Axes: title={'center': 'count of day'}&gt;\n\n\n\n\n\n- smoker 몇 명이나 있는지 확인\n\ntip.smoker.value_counts()\n\nNo     151\nYes     93\nName: smoker, dtype: int64\n\n\n- 비율 확인\n\ntip.smoker.value_counts() / len(tip) # = tip.smoker.value_counts(normalize = True)\n\nNo     0.618852\nYes    0.381148\nName: smoker, dtype: float64\n\n\n- 비율 시각화\n\n(tip.smoker.value_counts() / len(tip)).plot(kind=\"bar\",title=\"count of smoker\",figsize = (4,4))\n\n&lt;Axes: title={'center': 'count of smoker'}&gt;\n\n\n\n\n\n- total_bill의 lineplot 확인\n\ntip.total_bill.plot(figsize=(4,4))\n\n&lt;Axes: &gt;"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#최빈값",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#최빈값",
    "title": "01. numpy & pandas (2)",
    "section": "최빈값",
    "text": "최빈값\n\ntip.day.value_counts()\n\nSat     87\nSun     76\nThur    62\nFri     19\nName: day, dtype: int64\n\n\n\ntip.day.mode()\n\n0    Sat\nName: day, dtype: object\n\n\n\ntip.smoker.mode()\n\n0    No\nName: smoker, dtype: object"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#df.sum",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-18-01. numpy & pandas (2).html#df.sum",
    "title": "01. numpy & pandas (2)",
    "section": "df.sum",
    "text": "df.sum\n\naxis=0 (개별 컬럼의 합을 계산)\n\ntip.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\ntip.sum(axis=0)\n\ntotal_bill                                              4827.77\ntip                                                      731.58\nsex           FemaleMaleMaleMaleFemaleMaleMaleMaleMaleMaleMa...\nsmoker        NoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNoNo...\nday           SunSunSunSunSunSunSunSunSunSunSunSunSunSunSunS...\ntime          DinnerDinnerDinnerDinnerDinnerDinnerDinnerDinn...\nsize                                                        627\ndtype: object\n\n\n\n\n평균과 중앙값\n\ntip[[\"total_bill\",\"tip\"]].mean()\n\ntotal_bill    19.785943\ntip            2.998279\ndtype: float64\n\n\n\ntip[[\"total_bill\",\"tip\"]].median()\n\ntotal_bill    17.795\ntip            2.900\ndtype: float64"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html",
    "title": "03. numpy & pandas (4)",
    "section": "",
    "text": "import plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#import-및-data-load",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#import-및-data-load",
    "title": "03. numpy & pandas (4)",
    "section": "import 및 data load",
    "text": "import 및 data load\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/tips(2).csv'\n\n\ndf = pd.read_csv(path)\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   total_bill_amount  244 non-null    float64\n 1   tip                244 non-null    float64\n 2   male_female        244 non-null    object \n 3   smoke_yes_no       244 non-null    object \n 4   week_name          244 non-null    object \n 5   dinner_lunch       244 non-null    object \n 6   size               244 non-null    int64  \ndtypes: float64(2), int64(1), object(4)\nmemory usage: 13.5+ KB"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-이름-변경-1.-rename",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-이름-변경-1.-rename",
    "title": "03. numpy & pandas (4)",
    "section": "컬럼 이름 변경 1. rename",
    "text": "컬럼 이름 변경 1. rename\n\ndf.rename(columns = {\"total_bill_amount\" : \"total_bill\",\n            \"male_female\" : \"sex\",\n            \"smoke_yes_no\" : \"smoker\",\n            \"week_name\": \"day\",\n             \"dinner_lunch\" : \"time\"},inplace=True) \n\n\ndf\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n239\n29.03\n5.92\nMale\nNo\nSat\nDinner\n3\n\n\n240\n27.18\n2.00\nFemale\nYes\nSat\nDinner\n2\n\n\n241\n22.67\n2.00\nMale\nYes\nSat\nDinner\n2\n\n\n242\n17.82\n1.75\nMale\nNo\nSat\nDinner\n2\n\n\n243\n18.78\n3.00\nFemale\nNo\nThur\nDinner\n2\n\n\n\n\n244 rows × 7 columns"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-이름-변경-2.-list",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-이름-변경-2.-list",
    "title": "03. numpy & pandas (4)",
    "section": "컬럼 이름 변경 2. list",
    "text": "컬럼 이름 변경 2. list\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/tips(2).csv'\ndf = pd.read_csv(path)\n\n\ndf.columns = ['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-추가-1.-df.eval",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-추가-1.-df.eval",
    "title": "03. numpy & pandas (4)",
    "section": "컬럼 추가 1. df.eval",
    "text": "컬럼 추가 1. df.eval\n\ndf = df.eval(\"f_amt = total_bill + tip\")\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n18.00\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n12.00\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n24.51\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n26.99\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n28.20"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼추가-2.-dff_amt",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼추가-2.-dff_amt",
    "title": "03. numpy & pandas (4)",
    "section": "컬럼추가 2. df[\"f_amt\"]",
    "text": "컬럼추가 2. df[\"f_amt\"]\n\ndf[\"f_amt\"] = df.total_bill + df.tip\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n18.00\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n12.00\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n24.51\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n26.99\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n28.20"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼추가-3.-insert",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼추가-3.-insert",
    "title": "03. numpy & pandas (4)",
    "section": "컬럼추가 3. insert()",
    "text": "컬럼추가 3. insert()\n\ndf.insert(1,\"div_tb\",df[\"total_bill\"]/df[\"size\"] )\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\n\n\n\n\n0\n16.99\n8.495000\n1.01\nFemale\nNo\nSun\nDinner\n2\n18.00\n\n\n1\n10.34\n3.446667\n1.66\nMale\nNo\nSun\nDinner\n3\n12.00\n\n\n2\n21.01\n7.003333\n3.50\nMale\nNo\nSun\nDinner\n3\n24.51\n\n\n3\n23.68\n11.840000\n3.31\nMale\nNo\nSun\nDinner\n2\n26.99\n\n\n4\n24.59\n6.147500\n3.61\nFemale\nNo\nSun\nDinner\n4\n28.20\n\n\n\n\n\n\n\n- day변수를 이용하여 휴일 변수 holiday열을 만들기\n\ndf.day.value_counts()\n\nday\nSat     87\nSun     76\nThur    62\nFri     19\nName: count, dtype: int64\n\n\n\ndf[\"holiday\"]=[1 if \"S\" in i  else 0 for i in df.day]\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\n1.01\nFemale\nNo\nSun\nDinner\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\n1.66\nMale\nNo\nSun\nDinner\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\n3.50\nMale\nNo\nSun\nDinner\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\n3.31\nMale\nNo\nSun\nDinner\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\n3.61\nFemale\nNo\nSun\nDinner\n4\n28.20\n1"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-삭제",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#컬럼-삭제",
    "title": "03. numpy & pandas (4)",
    "section": "컬럼 삭제",
    "text": "컬럼 삭제\n- 단일 열 삭제\n\ndf.drop(\"tip\",axis=1).head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\nFemale\nNo\nSun\nDinner\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\nMale\nNo\nSun\nDinner\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\nMale\nNo\nSun\nDinner\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\nMale\nNo\nSun\nDinner\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\nFemale\nNo\nSun\nDinner\n4\n28.20\n1\n\n\n\n\n\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\n1.01\nFemale\nNo\nSun\nDinner\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\n1.66\nMale\nNo\nSun\nDinner\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\n3.50\nMale\nNo\nSun\nDinner\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\n3.31\nMale\nNo\nSun\nDinner\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\n3.61\nFemale\nNo\nSun\nDinner\n4\n28.20\n1\n\n\n\n\n\n\n\n- 다중 열 삭제\n\ndf.drop([\"tip\",\"sex\"],axis=1).head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\nNo\nSun\nDinner\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\nNo\nSun\nDinner\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\nNo\nSun\nDinner\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\nNo\nSun\nDinner\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\nNo\nSun\nDinner\n4\n28.20\n1"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#범주값-변경",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#범주값-변경",
    "title": "03. numpy & pandas (4)",
    "section": "범주값 변경",
    "text": "범주값 변경\n\n1. map\n- 남자는 1, 여자는 0으로 인코딩\n\ndf[\"sex\"] = df[\"sex\"].map({\"Male\":0,\"Female\":1})\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\n1.01\n1\nNo\nSun\nDinner\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\n1.66\n0\nNo\nSun\nDinner\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\n3.50\n0\nNo\nSun\nDinner\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\n3.31\n0\nNo\nSun\nDinner\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\n3.61\n1\nNo\nSun\nDinner\n4\n28.20\n1\n\n\n\n\n\n\n\n\n\n2. replace\n\ndf.sex = df.sex.replace([0,1],[\"Male\",\"Female\"])\n\n\n_df = df\n\n\n_df.sex = df.sex.replace({\"Male\":0,\"Female\":1})\n\n\n_df.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\n1.01\n1\nNo\nSun\nDinner\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\n1.66\n0\nNo\nSun\nDinner\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\n3.50\n0\nNo\nSun\nDinner\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\n3.31\n0\nNo\nSun\nDinner\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\n3.61\n1\nNo\nSun\nDinner\n4\n28.20\n1\n\n\n\n\n\n\n\n\ndf.time = df.time.replace([\"Dinner\",\"Lunch\"],[0,1])\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\n1.01\n1\nNo\nSun\n0\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\n1.66\n0\nNo\nSun\n0\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\n3.50\n0\nNo\nSun\n0\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\n3.31\n0\nNo\nSun\n0\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\n3.61\n1\nNo\nSun\n0\n4\n28.20\n1\n\n\n\n\n\n\n\n\ndf.smoker = df.smoker.replace([\"No\",\"Yes\"],[0,1])\n\n\ndf.head()\n\n\n\n\n\n\n\n\ntotal_bill\ndiv_tb\ntip\nsex\nsmoker\nday\ntime\nsize\nf_amt\nholiday\n\n\n\n\n0\n16.99\n8.495000\n1.01\n1\n0\nSun\n0\n2\n18.00\n1\n\n\n1\n10.34\n3.446667\n1.66\n0\n0\nSun\n0\n3\n12.00\n1\n\n\n2\n21.01\n7.003333\n3.50\n0\n0\nSun\n0\n3\n24.51\n1\n\n\n3\n23.68\n11.840000\n3.31\n0\n0\nSun\n0\n2\n26.99\n1\n\n\n4\n24.59\n6.147500\n3.61\n1\n0\nSun\n0\n4\n28.20\n1"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#범주값-만들기",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#범주값-만들기",
    "title": "03. numpy & pandas (4)",
    "section": "범주값 만들기",
    "text": "범주값 만들기\n\n1. cut\n- 크기(그룹의 수) 를 기준으로 구간을 나눈다.\n\nlabel = list(\"ABCD\")\n\n\n_df[\"g1\"] = pd.cut(df[\"tip\"],4,labels = label)\n\n\n_df[\"g1\"].value_counts()\n\ng1\nA    163\nB     69\nC     10\nD      2\nName: count, dtype: int64\n\n\n- 결과가 좀 그렇다…..\n\n_df.boxplot(backend=\"plotly\",y=\"tip\",x=\"g1\",color=\"g1\")\n\n\n                                                \n\n\n\n\n2. qcut\n- 간격(bins)외 lables을 건네줘서 구체적으로 나눈다. \\(\\to\\) 항상, 간격 = labels + 1\n\n예비학습 (qcut x)\n\n\n\n그룹\n구간\n\n\n\n\nA\n\\(x \\leq\\) 3\n\n\nB\n3 &lt; \\(x \\leq\\) 6\n\n\nC\n6 &lt; \\(x\\)\n\n\n\n\ntest = pd.DataFrame(np.arange(0,10),columns=[\"num\"])\n\n\nlable = list(\"ABC\")\n\n\nbin = [-np.Inf,3,6,np.Inf]\n\n\npd.DataFrame(np.arange(0,10)).shape\n\n(10, 1)\n\n\n\ntest[\"g\"]= pd.cut(np.arange(0,10),bins = bin,labels = lable)\n\n\ntest\n\n\n\n\n\n\n\n\nnum\ng\n\n\n\n\n0\n0\nA\n\n\n1\n1\nA\n\n\n2\n2\nA\n\n\n3\n3\nA\n\n\n4\n4\nB\n\n\n5\n5\nB\n\n\n6\n6\nB\n\n\n7\n7\nC\n\n\n8\n8\nC\n\n\n9\n9\nC\n\n\n\n\n\n\n\n\n\n실습 qcut (o)\n\n_df[\"tip\"].describe()\n\ncount    244.000000\nmean       2.998279\nstd        1.383638\nmin        1.000000\n25%        2.000000\n50%        2.900000\n75%        3.562500\nmax       10.000000\nName: tip, dtype: float64\n\n\n\nA = [-np.Inf, 2.0, 2.9, 3.5625, np.Inf]\n\n\nlabels = list(\"ABCD\")\n\n\n_df[\"g2\"]= pd.cut(_df[\"tip\"], bins=A,labels=labels)\n\n\n_df[\"g3\"] = pd.qcut(_df[\"tip\"],4)\n\n- 4분위수로 값을 나누어도 개수가 다른 이유는 값이 같은 것들이 존재하기 때문이다..\n\n_df[\"g3\"].value_counts()\n\ng3\n(0.999, 2.0]     78\n(2.9, 3.562]     61\n(3.562, 10.0]    61\n(2.0, 2.9]       44\nName: count, dtype: int64\n\n\n\n_df.g2.value_counts()\n\ng2\nA    78\nC    61\nD    61\nB    44\nName: count, dtype: int64\n\n\n\n_df.boxplot(backend=\"plotly\",y=\"tip\",x=\"g2\",color=\"g2\")\n\n\n                                                \n\n\n\ntotal_bill 변수의 4분위수를 저장\n\n\nq1 = df.total_bill.describe()[\"25%\"]\nq2 = df.total_bill.describe()[\"50%\"]\nq3 = df.total_bill.describe()[\"75%\"]\n\n\nq1,q2,q3\n\n(13.3475, 17.795, 24.127499999999998)\n\n\n\ndf[\"t_g1\"] = pd.cut(df[\"total_bill\"], bins = [-np.Inf,q1,q2,q3,np.Inf],labels = list(\"ABCD\"))\n\n\ndf.t_g1.value_counts()\n\nt_g1\nA    61\nB    61\nC    61\nD    61\nName: count, dtype: int64\n\n\n\n_df.t_g1.value_counts()\n\nt_g1\nA    61\nB    61\nC    61\nD    61\nName: count, dtype: int64\n\n\n\n_df.boxplot(backend=\"plotly\",y=\"total_bill\",x=\"t_g1\",color=\"t_g1\")"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#결측치-처리",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#결측치-처리",
    "title": "03. numpy & pandas (4)",
    "section": "결측치 처리",
    "text": "결측치 처리\n\ndata load\n[airquality 데이터 셋 정보]\n\nOzone: 오존 농도\n\nSolar.R: 태양복사량\nWind: 풍속\nTemp: 기온\nMonth: 월\nDay: 일\n\n\n\nCode\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/airquality.csv'\ndf = pd.read_csv(path)\n\n# 확인\ndf.head()\n\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n0\n41.0\n190.0\n7.4\n67\n5\n1\n\n\n1\n36.0\n118.0\n8.0\n72\n5\n2\n\n\n2\n12.0\n149.0\n12.6\n74\n5\n3\n\n\n3\n18.0\n313.0\n11.5\n62\n5\n4\n\n\n4\nNaN\nNaN\n14.3\n56\n5\n5\n\n\n\n\n\n\n\n\n\n결측치 확인법(\\(\\star\\star\\))\n- 확인 1. df.into() : Ozone, Solar.R에서 결측치가 있는 것으로 보인다.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    116 non-null    float64\n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(3), int64(3)\nmemory usage: 7.3 KB\n\n\n- 확인 2. df.isna()==df.isnull()\n\n#df.isna()\ndf.isnull().head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\ndf.notnull().head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n0\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n1\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n2\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n3\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n4\nFalse\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n\n\n\n\n\n- 방법 3 : df.isna().sum()\n\ndf.isna().sum()\n\nOzone      37\nSolar.R     7\nWind        0\nTemp        0\nMonth       0\nDay         0\ndtype: int64\n\n\n- 결측치 비율 구하기\n\ndf.isna().sum() / len(df)\n\nOzone      0.241830\nSolar.R    0.045752\nWind       0.000000\nTemp       0.000000\nMonth      0.000000\nDay        0.000000\ndtype: float64\n\n\n\n\n결측치 제거\n\naxis=1로 하면 열이 통째로 날아가지 지양하자\n\n\n_df=df.dropna(axis=0).reset_index(drop=True)\n\n\n_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 111 entries, 0 to 110\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    111 non-null    float64\n 1   Solar.R  111 non-null    float64\n 2   Wind     111 non-null    float64\n 3   Temp     111 non-null    int64  \n 4   Month    111 non-null    int64  \n 5   Day      111 non-null    int64  \ndtypes: float64(3), int64(3)\nmemory usage: 5.3 KB\n\n\n- 제거된 행 확인\n\nlen(df)-len(_df)\n\n42\n\n\n\n\n특정 열에 결측치가 있는 행 제거\n\n_df = df.copy()\n\n\n_df.dropna(subset = [\"Ozone\"],axis=0,inplace=True)\n\n\nlen(df) - len(_df)\n\n37\n\n\n\n_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 116 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    116 non-null    float64\n 1   Solar.R  111 non-null    float64\n 2   Wind     116 non-null    float64\n 3   Temp     116 non-null    int64  \n 4   Month    116 non-null    int64  \n 5   Day      116 non-null    int64  \ndtypes: float64(3), int64(3)\nmemory usage: 6.3 KB\n\n\n\n_df.isna().sum()\n\nOzone      0\nSolar.R    5\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\n\n결측치 채우기\n- 평균값으로 채우기\n\n_df = df.copy()\n\n\nmo = _df.Ozone.mean()\n\n\n_df[\"Ozone\"].fillna(mo,inplace=True)\n\n\n_df.isna().sum()\n\nOzone      0\nSolar.R    7\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n- 특정값으로 채우기 : Solar.R==na $\\to$ 0\n\n_df[\"Solar.R\"].fillna(0,inplace=True)\n\n\n_df.isna().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n- 직전 행 또는 바로 다음 행의 값으로 채우기\n\n해당 데이터는 시계열 데이터 이므로 직전이나, 다음 행의 값으로 결측치를 대체해도 될 것 같다.\n\n\n_df = df.copy()\n\n- 직전값으로 채우기 \\(\\to\\) fillna(,method=“ffill”)\n\n_df.Ozone.fillna(method=\"ffill\",inplace=True)\n\n\n_df.isna().sum()\n\nOzone      0\nSolar.R    7\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n- 다음값으로 채우기 \\(\\to\\) fillna(, method = “bfill”)\n\n_df[\"Solar.R\"].fillna(method = \"bfill\",inplace=True)\n\n\n_df.isna().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n- 선형보간법으로 채우기 \\(\\to\\) interpolate()\n- 다음과 같이 결측치를 선형방식으로 채운다. (빨간색점!)\n\n\nCode\nx = [1,2,3,4]\ny = [1,2,3,4]\nn = [\"T\",\"T\",\"F\",\"T\"]\na = pd.DataFrame([x,y,n]).T\na.columns=list(\"xyn\")\n\na.plot(kind= \"scatter\",x=\"x\",y=\"y\",color=\"n\",backend=\"plotly\")\n\n\n\n                                                \n\n\n\n_df = df.copy()\n_df[\"Ozone\"].interpolate(method=\"linear\",inplace=True)\n_df[\"Solar.R\"].interpolate(method=\"linear\",inplace=True)\n_df.isna().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n\n\n\n참고 : 이상치\n1 데이터 로드\n\ntip = px.data.tips()\ntip.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n2 열 데이터 분포 확인 (hist)\n- tip데이터를 살펴본결과 몇몇 이상치들이 보인다.\n\n\nCode\ntip.plot(backend = \"plotly\",kind = \"hist\", x=\"tip\")\n\n\n\n                                                \n\n\n3 boxplot\n\n\nCode\ntip.plot(backend=\"plotly\", kind=\"box\",x=\"tip\",width=500,height=400)\n\n\n\n                                                \n\n\n4 Q3에서 Q1에서 뺀다\n\nq1 = tip.tip.describe()[\"25%\"]\nq3 = tip.tip.describe()[\"75%\"]\n\n\niqr = q3-q1\n\n5 $ $\n\n_m = q1-iqr*1.5\n_M = q3+iqr*1.5\n\n\n_m,_M\n\n(-0.34375, 5.90625)\n\n\n해당 범위를 벗어나는 값을 이상치로 판단\n\\[\\text{outlier} \\leq \\text{Q1 - IQR}\\times 1.5\\quad \\& \\quad \\text{outlier} \\geq \\text{Q3 + IQR}\\times 1.5\\]\n6 이상치 판별 컬럼 추가\n\ntip[\"t_out\"] = [\"outlier\" if (i &lt;= q1-iqr*1.5) or ((i &gt;= q3+iqr*1.5)) else \"normal\" for i in tip.tip]\n\n\ntip.t_out.value_counts()\n\nt_out\nnormal     235\noutlier      9\nName: count, dtype: int64\n\n\n\n\nCode\ntip.plot(backend=\"plotly\", kind=\"box\",y=\"tip\",color = \"t_out\",points=\"all\",width=500,height=400)\n\n\n\n                                                \n\n\n\n\nCode\ntip.plot(backend=\"plotly\", kind=\"scatter\",x=\"tip\",y=\"tip\",color = \"t_out\",width=500,height=400)"
  },
  {
    "objectID": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#가변수-만들기",
    "href": "posts/DX/01. 데이터 다듬기/2023-08-22-03. numpy & pandas (4).html#가변수-만들기",
    "title": "03. numpy & pandas (4)",
    "section": "가변수 만들기",
    "text": "가변수 만들기\n\n\n\nsurvived\n\\(Y_1\\)\n\\(Y_2\\)\n\n\n\n\nYes\n1\n0\n\n\nNo\n0\n1\n\n\n\n\n1. 데이터 로드\n\ntip  = px.data.tips()\n\n\ntip.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   total_bill  244 non-null    float64\n 1   tip         244 non-null    float64\n 2   sex         244 non-null    object \n 3   smoker      244 non-null    object \n 4   day         244 non-null    object \n 5   time        244 non-null    object \n 6   size        244 non-null    int64  \ndtypes: float64(2), int64(1), object(4)\nmemory usage: 13.5+ KB\n\n\n\n\n2. 개별 변수 처리\n(1) 가변수 처리할 컬럼을 정의\n\nd_cols = [\"sex\"]\n\n\ndefault \\(\\to\\) drop_first = False\ndrop_first = True \\(\\to\\) 첫 번째로 생성된 가변수를 삭제\nsex열은 사라지고 가변수 처리된 변수들만 생성됨\n\n(2) 가변수 처리\n\npd.get_dummies(tip,columns = d_cols).head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsmoker\nday\ntime\nsize\nsex_Female\nsex_Male\n\n\n\n\n0\n16.99\n1.01\nNo\nSun\nDinner\n2\nTrue\nFalse\n\n\n1\n10.34\n1.66\nNo\nSun\nDinner\n3\nFalse\nTrue\n\n\n2\n21.01\n3.50\nNo\nSun\nDinner\n3\nFalse\nTrue\n\n\n3\n23.68\n3.31\nNo\nSun\nDinner\n2\nFalse\nTrue\n\n\n4\n24.59\n3.61\nNo\nSun\nDinner\n4\nTrue\nFalse\n\n\n\n\n\n\n\n\n_df = pd.get_dummies(tip,columns = d_cols,drop_first= True)\n\n\n_df.plot(kind = \"box\", x= \"sex_Male\", y=\"tip\" , backend =\"plotly\",color = \"sex_Male\", width=400,height =400)\n\n\n                                                \n\n\n\n\n3. 여러 변수를 가변수 처리\n\nd_cols = [\"smoker\",\"day\",\"time\",\"sex\"]\n\n_df = pd.get_dummies(tip,columns = d_cols,drop_first=True)\n\n\n_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 244 entries, 0 to 243\nData columns (total 9 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   total_bill  244 non-null    float64\n 1   tip         244 non-null    float64\n 2   size        244 non-null    int64  \n 3   smoker_Yes  244 non-null    bool   \n 4   day_Sat     244 non-null    bool   \n 5   day_Sun     244 non-null    bool   \n 6   day_Thur    244 non-null    bool   \n 7   time_Lunch  244 non-null    bool   \n 8   sex_Male    244 non-null    bool   \ndtypes: bool(6), float64(2), int64(1)\nmemory usage: 7.3 KB\n\n\n\n_df.plot(kind = \"box\", x= \"smoker_Yes\", y=\"tip\" , backend =\"plotly\",color = \"sex_Male\", width=800,height =400,points=\"all\")"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html",
    "title": "00. 데이터 분석 (1)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'Malgun Gothic'\nplt.rcParams['axes.unicode_minus'] = False"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#기본-정보-조회",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#기본-정보-조회",
    "title": "00. 데이터 분석 (1)",
    "section": "기본 정보 조회",
    "text": "기본 정보 조회\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 8 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   Fare         891 non-null    float64\n 7   Embarked     889 non-null    object \ndtypes: float64(2), int64(3), object(3)\nmemory usage: 55.8+ KB"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#조건-조회",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#조건-조회",
    "title": "00. 데이터 분석 (1)",
    "section": "조건 조회",
    "text": "조건 조회\n- 객실 등급(Pclass) 1등급, 나이(Age) 10살 이하 탑승객 조회\n\ndf.loc[ map(lambda x,y  : (x==1) & (y &lt;=10), df.Pclass, df.Age), : ]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nFare\nEmbarked\n\n\n\n\n297\n298\n0\n1\nAllison, Miss. Helen Loraine\nfemale\n2.00\n151.5500\nSouthampton\n\n\n305\n306\n1\n1\nAllison, Master. Hudson Trevor\nmale\n0.92\n151.5500\nSouthampton\n\n\n445\n446\n1\n1\nDodge, Master. Washington\nmale\n4.00\n81.8583\nSouthampton\n\n\n\n\n\n\n\n- 객실 등급(Pclass)별 탑승객 수\n\ndf.Pclass.value_counts().reset_index()\n\n\n\n\n\n\n\n\nPclass\ncount\n\n\n\n\n0\n3\n491\n\n\n1\n1\n216\n\n\n2\n2\n184\n\n\n\n\n\n\n\n- 성별(Sex)이 남자인 탑승객과 여자인 탑승객의 나이를 각각 저장하시오.\n\n_m = df.loc[df.Sex==\"male\",[\"Sex\",\"Age\"]]\n_f = df.loc[df.Sex==\"female\",[\"Age\",\"Sex\"]]\n\n- 나이(Age)에 NaN이 아닌 탑승객을 조회하시오.\n\ndf.loc[df.Age ==True, :]\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nFare\nEmbarked\n\n\n\n\n164\n165\n0\n3\nPanula, Master. Eino Viljami\nmale\n1.0\n39.6875\nSouthampton\n\n\n172\n173\n1\n3\nJohnson, Miss. Eleanor Ileen\nfemale\n1.0\n11.1333\nSouthampton\n\n\n183\n184\n1\n2\nBecker, Master. Richard F\nmale\n1.0\n39.0000\nSouthampton\n\n\n381\n382\n1\n3\nNakid, Miss. Maria (\"Mary\")\nfemale\n1.0\n15.7417\nCherbourg\n\n\n386\n387\n0\n3\nGoodwin, Master. Sidney Leonard\nmale\n1.0\n46.9000\nSouthampton\n\n\n788\n789\n1\n3\nDean, Master. Bertram Vere\nmale\n1.0\n20.5750\nSouthampton\n\n\n827\n828\n1\n2\nMallet, Master. Andre\nmale\n1.0\n37.0042\nCherbourg\n\n\n\n\n\n\n\n- 아래의 데이터에서 날짜(Date)가, 1973-05-01, 1973-06-01, 1973-07-01.1973-08-01을 조회\n\npath = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/air2.csv'\nair = pd.read_csv(path)\n\n\nd_l = [\"1973-05-01\", \"1973-06-01\", \"1973-07-01\",\"1973-08-01\"]\n\n\nair.loc[map(lambda x : x in d_l, air.Date),:]\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nDate\n\n\n\n\n0\n41\n190.0\n7.4\n67\n1973-05-01\n\n\n31\n34\n286.0\n8.6\n78\n1973-06-01\n\n\n61\n135\n269.0\n4.1\n84\n1973-07-01\n\n\n92\n39\n83.0\n6.9\n81\n1973-08-01\n\n\n\n\n\n\n\n- 오존 농도 10~20 사이의 데이터를 조회\n\nair.loc[air.Ozone.between(10,20),:].head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nDate\n\n\n\n\n2\n12\n149.0\n12.6\n74\n1973-05-03\n\n\n3\n18\n313.0\n11.5\n62\n1973-05-04\n\n\n4\n19\nNaN\n14.3\n56\n1973-05-05\n\n\n7\n19\n99.0\n13.8\n59\n1973-05-08\n\n\n9\n20\n194.0\n8.6\n69\n1973-05-10"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#값-변경",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#값-변경",
    "title": "00. 데이터 분석 (1)",
    "section": "값 변경",
    "text": "값 변경\n[titanic] 승선지역(Embarked)을 변경 * Southamton –&gt; S * Cherbourg –&gt; C * Queenstown –&gt; Q\n\ndf.Embarked\n\n0      Southampton\n1        Cherbourg\n2      Southampton\n3      Southampton\n4      Southampton\n          ...     \n886    Southampton\n887    Southampton\n888    Southampton\n889      Cherbourg\n890     Queenstown\nName: Embarked, Length: 891, dtype: object\n\n\n\ndf.Embarked=df[\"Embarked\"].map({\"Southampton\":\"S\",\n                   \"Cherbourg\" : \"C\",\n                   \"Queenstown\":\"Q\"})\n\n\ndf.Embarked.unique()\n\narray(['S', 'C', 'Q', nan], dtype=object)\n\n\n- [titanic] 운임(Fare)을 다음과 같이 변경\n\n&lt;= 30 ==&gt; ‘L’\n&lt;= 100 ==&gt; ‘M’\n100 &lt; ==&gt; ‘H’\n\n\nbins = [-np.Inf, 30, 100, np.Inf]\n\n\nlabels = list(\"LMH\")\n\n\ndf.Fare = pd.cut(df.Fare,bins = bins, labels= labels)\n\n\ndf.Fare.unique()\n\n['L', 'M', 'H']\nCategories (3, object): ['L' &lt; 'M' &lt; 'H']\n\n\n\nnp.where(\\(\\star\\star\\star\\))\n- [titanic] 성별(Sex)을 다음과 같이 변경\n\nfemale ==&gt; 0\nmale ==&gt; 1\n\n\ndf.Sex = np.where(df.Sex==\"male\",1,0).tolist()\n\n\ndf.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nFare\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\n1\n22.0\nL\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n0\n38.0\nM\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\n0\n26.0\nL\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n0\n35.0\nM\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\n1\n35.0\nL\nS"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#데이터-로드",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#데이터-로드",
    "title": "00. 데이터 분석 (1)",
    "section": "데이터 로드",
    "text": "데이터 로드\n\npath = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/airquality_simple2.csv'\ndata = pd.read_csv(path)\ndata['Date'] = pd.to_datetime(data['Date'])\ndata.dropna(axis = 0, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nDate\n\n\n\n\n0\n34.0\n286.0\n8.6\n78.0\n1973-06-01\n\n\n1\n29.0\n287.0\n9.7\n74.0\n1973-06-02\n\n\n2\n18.0\n242.0\n16.1\n67.0\n1973-06-03\n\n\n3\n48.0\n186.0\n9.2\n84.0\n1973-06-04\n\n\n4\n49.0\n220.0\n8.6\n85.0\n1973-06-05"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#기본-차트-그리기-matplotlib",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#기본-차트-그리기-matplotlib",
    "title": "00. 데이터 분석 (1)",
    "section": "기본 차트 그리기 matplotlib",
    "text": "기본 차트 그리기 matplotlib\n\n기본\n\ndata.plot(x=\"Date\",y=\"Temp\",figsize=(10,2))\n\n&lt;Axes: xlabel='Date'&gt;\n\n\n\n\n\n\ndata.plot(x=\"Date\", y= \"Ozone\",figsize=(10,3),\n            xlabel =\"Date\",ylabel=\"Ozone\",title = \"Daily Airquality\")\n\n&lt;Axes: title={'center': 'Daily Airquality'}, xlabel='Date', ylabel='Ozone'&gt;\n\n\n\n\n\n\ndata.plot(x=\"Date\", y= \"Ozone\",figsize=(10,3),\n            xlabel =\"Date\",ylabel=\"Ozone\",title = \"Daily Airquality\",\n             color = \"green\",marker=\"o\",alpha=0.3)\n\n&lt;Axes: title={'center': 'Daily Airquality'}, xlabel='Date', ylabel='Ozone'&gt;\n\n\n\n\n\n\n\n그래프 겹처그리기\n\nplt.plot(data.Date, data.Temp,\"--r\")\nplt.plot(data.Date, data.Ozone,\"--g\")\nplt.legend([\"Temp\",\"Ozone\"],loc=\"upper right\")\nplt.title(\"Temp, Ozone\")\nplt.grid()\nplt.xlabel(\"Date\")\nplt.ylabel(\"value\")\nplt.xticks(rotation=45)\n\n(array([1247., 1251., 1255., 1259., 1263., 1267., 1271., 1275., 1277.]),\n [Text(1247.0, 0, '1973-06-01'),\n  Text(1251.0, 0, '1973-06-05'),\n  Text(1255.0, 0, '1973-06-09'),\n  Text(1259.0, 0, '1973-06-13'),\n  Text(1263.0, 0, '1973-06-17'),\n  Text(1267.0, 0, '1973-06-21'),\n  Text(1271.0, 0, '1973-06-25'),\n  Text(1275.0, 0, '1973-06-29'),\n  Text(1277.0, 0, '1973-07-01')])\n\n\n\n\n\n\n\n그래프 범위\n\ndata.plot(x=\"Date\",y=\"Ozone\",\n          ylim=(min(data.Ozone)-1,max(data.Ozone)+1),\n          grid=True,ylabel=\"Ozone\",figsize=(4,4))\n\n&lt;Axes: xlabel='Date', ylabel='Ozone'&gt;\n\n\n\n\n\n\n\n다중 그래프 그리기\n- 방법 1 : 내가 쓰던 방식\n\nfig,axes =plt.subplots(1,4,figsize=(12,4))\nfig.autofmt_xdate(rotation=45)\nl1 = data.columns\ncolor = [\"red\",\"green\",\"blue\",\"orange\"]\nfor i in range(4) :\n    axes[i].plot(data[\"Date\"],data[l1[i]],color=color[i],linestyle=\"dashed\",alpha=0.4)\n    axes[i].set_title(l1[i])\n\nfig.tight_layout()\n\n\n\n\n\nplt.figure(figsize = (12,4))\nplt.subplot(1,3,1)\nplt.plot('Date', 'Temp', data = data)\nplt.title('Temp')\nplt.xticks(rotation = 40)\nplt.grid()\n\nplt.subplot(1,3,2)\nplt.plot('Date', 'Wind', data = data)\nplt.title('Wind')\nplt.xticks(rotation = 40)\nplt.grid()\n\nplt.subplot(1,3,3)\nplt.plot('Date', 'Ozone', data = data)\nplt.title('Ozone')\nplt.xticks(rotation = 40)\nplt.grid()\n\nplt.tight_layout() # 그래프간 간격을 적절히 맞추기\nplt.show()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#데이터-로드-1",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#데이터-로드-1",
    "title": "00. 데이터 분석 (1)",
    "section": "데이터 로드",
    "text": "데이터 로드\n\npath1 = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/titanic_simple.csv'\ntitanic = pd.read_csv(path1)\npath2 = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/air2.csv'\nair = pd.read_csv(path2)"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#분포-시각화-hist",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#분포-시각화-hist",
    "title": "00. 데이터 분석 (1)",
    "section": "분포 시각화 (hist)",
    "text": "분포 시각화 (hist)\n\nbasic\n\nplt.hist(titanic.Fare, bins = 5, edgecolor = 'gray')\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n구간개수 조절\n\nplt.hist(titanic.Fare, bins = 30, edgecolor = 'gray')\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\nfig, axes = plt.subplots(1,2, figsize= (10,4))\n\n(ax1,ax2)= axes\nax1.hist(titanic.Fare,bins = 5, edgecolor = 'gray')\nax1.set_title(\"hist of Fare (bins =5)\")\nax2.hist(titanic.Fare,bins = 30, edgecolor = 'gray')\nax2.set_title(\"hist of Fare (bins =30)\")\n\nText(0.5, 1.0, 'hist of Fare (bins =30)')\n\n\n\n\n\n\n\nseaborn\n\nfig, axes = plt.subplots(1,2, figsize= (10,4))\n\n(ax1,ax2)= axes\nsns.histplot(x=titanic.Fare,ax=ax1, bins = 5)\nsns.histplot(x=titanic.Fare,ax=ax2, bins = 30)\nax1.set_title(\"hist of Fare (bins =5)\")\nax2.set_title(\"hist of Fare (bins =30)\")\n\nText(0.5, 1.0, 'hist of Fare (bins =30)')\n\n\n\n\n\n\n\n\n밀도함수 그래프 (kde plot)\n- 히스토그램의 구간(bin)에 따라 그래프의 모양이 달라진다.\n\n밀도함수 그래프는 막대의 너비를 가정하지 않고 모든 점에서 데이터의 밀도(확률)을 추정\n이는 커널 밀도 방식을 사용하기 때문에 모양이 달라져 발생할 수 있는 혼동을 방지할 수 있다.\n\n\n#sns.histplot(titanic[\"Fare\"])\nsns.kdeplot(titanic[\"Fare\"])\n\n&lt;Axes: xlabel='Fare', ylabel='Density'&gt;\n\n\n\n\n\n\ntitanic.Fare.describe()\n\ncount    891.000000\nmean      32.204208\nstd       49.693429\nmin        0.000000\n25%        7.910400\n50%       14.454200\n75%       31.000000\nmax      512.329200\nName: Fare, dtype: float64\n\n\n- 위 그래프는 0보다 작은 값도 표현하고 있다.\n\n원 데이터의 0보다 작은값은 없지만 컴퓨터에서 확률을 추정하려고 하다보니 위 같이 표현된 것 뿐이다.\n\n- 아래와 같이 히스토그램과 같이 그릴 수도 있다.\n\nsns.histplot(x=titanic.Age,kde=True)\n\n&lt;Axes: xlabel='Age', ylabel='Count'&gt;\n\n\n\n\n\n\n\nboxplot\n- 주의사항 : Nan값이 있으면 그려지지 않는다!\n1 matplot\n\ntitanic.plot(kind=\"box\", y=\"Age\")\n\n&lt;Axes: &gt;\n\n\n\n\n\n\ntitanic.plot(kind=\"box\", y=\"Age\",vert=False)\n\n&lt;Axes: &gt;\n\n\n\n\n\n2 seaborn\n\nfig, axes = plt.subplots(1,2,figsize=(8,4))\nax1,ax2=axes\nsns.boxplot(x = titanic['Age'],ax=ax1)\nsns.boxplot(y = titanic['Age'],ax=ax2)\n\n&lt;Axes: ylabel='Age'&gt;"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#import-1",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#import-1",
    "title": "00. 데이터 분석 (1)",
    "section": "import",
    "text": "import\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom ISLP import load_data\nimport seaborn as sns\n\n\ndata = load_data(\"Boston\")\n\n\ndata.head()\n\n\n\n\n\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nlstat\nmedv\n\n\n\n\n0\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n4.98\n24.0\n\n\n1\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n9.14\n21.6\n\n\n2\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n4.03\n34.7\n\n\n3\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n2.94\n33.4\n\n\n4\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n5.33\n36.2\n\n\n\n\n\n\n\n변수설명\n\n\nmedv : 1978 보스턴 주택 가격, 506개 타운의 주택 가격 중앙값 (단위 1,000 달러) &lt;== Target\n\n\n\ncrim 범죄율\nzn 25,000 평방피트를 초과 거주지역 비율\nindus 비소매상업지역 면적 비율\nchas 찰스강변 위치(범주 : 강변1, 아니면 0)\nnox 일산화질소 농도\nrm 주택당 방 수\nage 1940년 이전에 건축된 주택의 비율\ndis 직업센터의 거리\nrad 방사형 고속도로까지의 거리\ntax 재산세율\nptratio 학생/교사 비율\nlstat 인구 중 하위 계층 비율"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#주어진-변수에-대한-hist-boxplot을-그리는-함수-작성",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#주어진-변수에-대한-hist-boxplot을-그리는-함수-작성",
    "title": "00. 데이터 분석 (1)",
    "section": "주어진 변수에 대한 hist, boxplot을 그리는 함수 작성",
    "text": "주어진 변수에 대한 hist, boxplot을 그리는 함수 작성\n\ndef f(data,var,bins=30) : \n    fig,axes = plt.subplots(1,2, figsize=(8,3))\n    ax1,ax2 = axes\n    \n    sns.histplot(x=data[var],kde = True,ax=ax1,bins=bins)\n    ax1.set_title(f\"hist of {var}\")\n    sns.boxplot(x=data[var],ax=ax2)\n    ax2.set_title(f\"boxplot of {var}\")\n\n\nmedv(집값)\n\nf(data,\"medv\")\n\n\n\n\n\n정규분포와 유사한 형태이나 medv=50에서 이상치로 보이는 수치들이 보인다.\n대부분에 데이터들이 중앙에 모여있다.\n\n\n\ncrim(범죄율)\n\nf(data,\"crim\",bins=10)\n\n\n\n\n\n범죄율의 분포를 살펴보니 최솟값이 0.6% 이며 최댓값은 89.97%이다.\n대부분은 범죄율이 굉장히 낮다.\n박스플랏의 꼬리가길게 늘어짐\n로그변환 등을 고려해봐도 괜찮을것 같다.\n\n\n\nlstat(하위계층 비율)\n\nf(data,\"lstat\",bins=50)\n\n\n\n\n\n하위계층의 정의가 뭔지.. 궁금해진다.\n하위계층의 비율이 대부분 10 ~ 20% 구간에 몰려있다.\n\n\n\nptratio(교사1명당 학생수)\n\nf(data,\"ptratio\")\n\n\n\n\n\n교육환경이 좋은 동네는 교사 1명당 학생수가 높나?? \\(\\to\\) 이런걸 보고싶을 때가 있으니 역시 다차원 그래프 표현이 필요한 것 같다.\n\n\n\ntax(재산세)\n\nf(data,\"tax\")\n\n\n\n\n\n제산세가 굉장히 높은 구간이 있는데 부자동네인가? 라는 생각을 가지게 된다.\n또한, 제산세가 높은 구간의 비중이 가장 높은데 재산세에 대한 기준이 궁금해진다.\n분포를 살펴본 결과 2개의 분포가 보인다. \\(\\to\\) 두 개의 그룹으로 나누어서 살펴보아야 한다."
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#데이터-전처리",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#데이터-전처리",
    "title": "00. 데이터 분석 (1)",
    "section": "데이터 전처리",
    "text": "데이터 전처리\n\ne_table = titanic.Embarked.\\\n            value_counts(normalize=True).reset_index()\ne_table\n\n\n\n\n\n\n\n\nEmbarked\nproportion\n\n\n\n\n0\nSouthampton\n0.724409\n\n\n1\nCherbourg\n0.188976\n\n\n2\nQueenstown\n0.086614\n\n\n\n\n\n\n\n- 생존률이 매우 낮다.\n\n고민 1 : 그럼 구명보트에 가까운사람, 1등석에 탄 사람들만 살았나?? (이런 상황에 대한 도메인 지식이 필요할 때가 있다….)\n\n\ntitanic.Survived.\\\n            value_counts(normalize=True).\\\n                    reset_index()\n\n\n\n\n\n\n\n\nSurvived\nproportion\n\n\n\n\n0\n0\n0.616162\n\n\n1\n1\n0.383838"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#시각화-1.-bar-chart",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#시각화-1.-bar-chart",
    "title": "00. 데이터 분석 (1)",
    "section": "시각화 1. bar chart",
    "text": "시각화 1. bar chart\n\nfig,axe = plt.subplots(1,2,figsize=(8,3))\nax1,ax2 =axe\nsns.countplot(y= titanic.Pclass,ax=ax1)\nax1.set_title(\"count of Pclass\")\nsns.countplot(y= titanic.Embarked,ax=ax2)\nax2.set_title(\"count of Embarked\")\nfig.tight_layout()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#시각화-2.-pie-chart",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#시각화-2.-pie-chart",
    "title": "00. 데이터 분석 (1)",
    "section": "시각화 2. Pie chart",
    "text": "시각화 2. Pie chart\n- 범주형 비율을 비교할 때 사용\n\n사실 난 그렇게 좋아하지 않음… \\(\\to\\) 비율로 먼가 어떤 현상을 설명할 때 직관적으로 와닿지가 않는다…\n\n\ntitanic.Pclass.\\\n        value_counts()\n\nPclass\n3    491\n1    216\n2    184\nName: count, dtype: int64\n\n\n- 기본\n\ntitanic.Pclass.\\\n        value_counts().\\\n                plot(kind=\"pie\",y=\"count\",\n                     autopct= \"%.2f%%\")\n\n&lt;Axes: ylabel='count'&gt;\n\n\n\n\n\n- 시작점과 방향 지정\n\ntitanic.Pclass.\\\n        value_counts().\\\n                plot(kind=\"pie\",y=\"count\",\n                     autopct= \"%.2f%%\", startangle=90,\n                    counterclock = False)\n\n&lt;Axes: ylabel='count'&gt;"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#소감",
    "href": "posts/DX/02. 데이터 분석/2023-08-28-00. 데이터 분석 (1).html#소감",
    "title": "00. 데이터 분석 (1)",
    "section": "소감",
    "text": "소감\n\n확실히 나는 데이터를 보고 인사이트를 도출하는 능력이 떨어진다.\n비즈니즈적 의사결정을 위해선 많은 도메인에서의 지식이 필요한 것 같다….\n다른 에이블러님들이 인사이트를 도출하시는 것들을 보고 많이 반성했다….\n데이터를 잘 다루는 것은 누구나 할 수 있는거라고 생각하나 인사이트를 도출하기 위해선 평소에 다양한 분야에 관심을 가져야 할 필요성을 느꼈다.\n부족한점을 알고 있었지만, 오늘 더 뼈저리게 느낀것 같다…"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-09-01-02. 데이터 분석 (2).html",
    "href": "posts/DX/02. 데이터 분석/2023-09-01-02. 데이터 분석 (2).html",
    "title": "02. 데이터 분석 (3)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n# import random as rd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic      #mosaic plot!\n\nimport scipy.stats as spst"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-09-01-02. 데이터 분석 (2).html#시각화-1.-survived---age",
    "href": "posts/DX/02. 데이터 분석/2023-09-01-02. 데이터 분석 (2).html#시각화-1.-survived---age",
    "title": "02. 데이터 분석 (3)",
    "section": "시각화 1. (Survived <-> Age)",
    "text": "시각화 1. (Survived &lt;-&gt; Age)\n\ncommon_norm = True (기본값) : 칵 클래스의 비율을 합쳐서 표시 (두 그래프의 아래 면적의 합이 1)\ncommon_norm = False: 각각의 클래스로 니누어서 비율을 표시 (각 클래스의 아래 면적은 1)\nmultiple = ‘fill’: 각 클래스에 따른 비율을 비교 (각 클래스의 아래 면적은 1)\n\n\ntitanic.Survived.value_counts(normalize=True)\n\nSurvived\n0    0.616162\n1    0.383838\nName: proportion, dtype: float64\n\n\n\n\nCode\nfig, axes = plt.subplots(2,3,figsize=(12,8))\n\n(ax1,ax2,ax3), (ax4,ax5,ax6) = axes\n\nsns.histplot(x='Age', data = titanic, hue = 'Survived',ax=ax1,stat=\"density\")\nsns.histplot(x='Age', data = titanic, hue = 'Survived', common_norm = False,ax=ax2,stat=\"density\")\nsns.histplot(x='Age', data = titanic, hue = 'Survived', multiple=\"fill\",ax=ax3)\n\nax3.axhline(titanic['Survived'].mean(), color = 'r')\nsns.kdeplot(x='Age', data = titanic, hue ='Survived',ax=ax4)\nsns.kdeplot(x='Age', data = titanic, hue ='Survived',\n            common_norm = False,ax=ax5)\nsns.kdeplot(x='Age', data = titanic, hue ='Survived'\n            , multiple = 'fill',ax=ax6)\nax6.axhline(titanic['Survived'].mean(), color = 'r')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/DX/02. 데이터 분석/2023-09-01-02. 데이터 분석 (2).html#시각화-2.-survived---fare",
    "href": "posts/DX/02. 데이터 분석/2023-09-01-02. 데이터 분석 (2).html#시각화-2.-survived---fare",
    "title": "02. 데이터 분석 (3)",
    "section": "시각화 2. (Survived <-> Fare)",
    "text": "시각화 2. (Survived &lt;-&gt; Fare)\n\n\nCode\nfig, axes = plt.subplots(2,3,figsize=(12,8))\n\n(ax1,ax2,ax3), (ax4,ax5,ax6) = axes\n\nsns.histplot(x='Fare', data = titanic, hue = 'Survived',bins=40,ax=ax1,stat=\"density\")\nsns.histplot(x='Fare', data = titanic, hue = 'Survived',bins=40, common_norm = False,ax=ax2,stat=\"density\")\nsns.histplot(x='Fare', data = titanic, hue = 'Survived', multiple=\"fill\",ax=ax3,bins=40)\n\nax3.axhline(titanic['Survived'].mean(), color = 'r')\nsns.kdeplot(x='Fare', data = titanic, hue ='Survived',ax=ax4)\nsns.kdeplot(x='Fare', data = titanic, hue ='Survived',\n            common_norm = False,ax=ax5)\nsns.kdeplot(x='Fare', data = titanic, hue ='Survived'\n            , multiple = 'fill',ax=ax6)\nax6.axhline(titanic['Survived'].mean(), color = 'r')\nfig.tight_layout()\n\n\n\n\n\n\nx = np.linspace(0,1,100)\ny = [1]*100\n\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html",
    "title": "01. 데이터 수집 (2)",
    "section": "",
    "text": "- 크롤링 단계\n\n크롬 개발자 도구를 이용하여 URL을 찾기\nrequest(url) &lt;-&gt; response( data(json,html) )\ndata(json, html) \\(\\to\\) list, dict \\(\\to\\) 데이터프레임으로 변환!"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#step-1.-request-token-얻기",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#step-1.-request-token-얻기",
    "title": "01. 데이터 수집 (2)",
    "section": "step 1. request token 얻기",
    "text": "step 1. request token 얻기\n1. 링크로 가서 로그인\n2. application 등록\n\n3 발급받은 Id와 key값 가져오기\n\nclient_id = \"mLybjqT4lxorLlFR0q21\"\n\nclient_secret = \"AhgPjWhfH_\"\n\n- 잠시요약\n\n어제와 다른점 1 : API를 등록하고 key값을 받아서 request를 해야함\n어제와 다른점 2 : 문서를 확인해서 url을 받아옴"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#step2.-파파고-번역-api",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#step2.-파파고-번역-api",
    "title": "01. 데이터 수집 (2)",
    "section": "step2. 파파고 번역 api",
    "text": "step2. 파파고 번역 api\n\n파파고 번역 api\n\n\nhttps://developers.naver.com/docs/papago/\n사용법\n\nhttps://developers.naver.com/docs/papago/papago-nmt-api-reference.md\n\n\n\n(1) url, header data, 임의 data를 입력\n\n# url\nurl = \"https://openapi.naver.com/v1/papago/n2mt\"\n\n# header data\nheaders = {\n    \"Content-Type\" : \"application/json\",\n    \"X-Naver-Client-Id\" : client_id,\n    \"X-Naver-Client-Secret\" : client_secret\n}\n\n# data\nko_text = \"웹크롤링은 재미있고 돈이 됩니다.\"\nparams = {\"source\" : \"ko\", \"target\" : \"en\", \"text\" : ko_text}\nparams\n\n{'source': 'ko', 'target': 'en', 'text': '웹크롤링은 재미있고 돈이 됩니다.'}\n\n\n\n\n(2) Request(url,headers,data), Response\n- 일단 에러(400)이 뜬다. 당황하지말자\n\nresponse = requests.post(url,data=params, headers=headers)\nresponse\n\n&lt;Response [400]&gt;\n\n\n\nresponse.text\n\n'{\"errorCode\":\"-10001\",\"errorMessage\":\"INVALID_REQUEST\"}'\n\n\n- 에러를 확인헤보니 내가 요청할 때 뭔가 잘못요청했다….\n\n이유 : 웹 환경에서는 한글을 쓸 수가 없음 (영문, 숫자, 특수문자만 사용이 가능하다.)\n'웹크롤링은 재미있고 돈이 됩니다.' 이것 때문에 그럼\n인코딩 후 인코딩한 데이터를 전달하면 끝!\n\n\njson.dumps(params)\n\n'{\"source\": \"ko\", \"target\": \"en\", \"text\": \"\\\\uc6f9\\\\ud06c\\\\ub864\\\\ub9c1\\\\uc740 \\\\uc7ac\\\\ubbf8\\\\uc788\\\\uace0 \\\\ub3c8\\\\uc774 \\\\ub429\\\\ub2c8\\\\ub2e4.\"}'\n\n\n- 인코딩한 데이터를 전달하니 정상적으로 작동한다!\n\nresponse = requests.post(url,data=json.dumps(params), headers=headers)\nresponse\n\n&lt;Response [200]&gt;\n\n\n\nresponse.json()\n\n{'message': {'result': {'srcLangType': 'ko',\n   'tarLangType': 'en',\n   'translatedText': 'Web crawling is fun and money.',\n   'engineType': 'N2MT'},\n  '@type': 'response',\n  '@service': 'naverservice.nmt.proxy',\n  '@version': '1.0.0'}}\n\n\n- 위에 딕셔너리의 구조에 맞게 접근하여 번역된 글씨체를 읽어옴\n\nen_text = response.json()[\"message\"][\"result\"][\"translatedText\"]\nen_text\n\n'Web crawling is fun and money.'\n\n\n\n\n(3) 위 과정을 함수로 작성\n\ndef translate (ko_text) :\n    # 1. 어플리케이션 key가 필요\n        client_id = \"mLybjqT4lxorLlFR0q21\"\n\n        client_secret = \"AhgPjWhfH_\"\n    # 2. url, header, 요청할 data가 필요\n        url = \"https://openapi.naver.com/v1/papago/n2mt\"\n        headers = {\n            \"Content-Type\" : \"application/json\",\n            \"X-Naver-Client-Id\" : client_id,\n            \"X-Naver-Client-Secret\" : client_secret\n        }\n        params = {\"source\" : \"ko\", \"target\" : \"en\", \"text\" : ko_text}\n    # 3. request(url,header,json.dumper(한국어 데이터)) -&gt; response\n        response = requests.post(url,data=json.dumps(params), headers=headers)\n    # 4. response.json()[\"message\"][\"result\"][\"translatedText\"]\n        en_text = response.json()[\"message\"][\"result\"][\"translatedText\"]\n        \n        return en_text\n\n\ntranslate(\"난 짱\")\n\n\"I'm the best\"\n\n\n\n\n(4) 한글 엑셀파일을 영문으로…\n\n%ls covid.xlsx\n\n D 드라이브의 볼륨: 새 볼륨\n 볼륨 일련 번호: EC13-2D50\n\n D:\\projects\\mysite2\\posts\\DX\\03. 데이터 수집 디렉터리\n\n2023-09-05  오전 11:16             8,911 covid.xlsx\n               1개 파일               8,911 바이트\n               0개 디렉터리  1,985,536,040,960 바이트 남음\n\n\n\ndf =  pd.read_excel(\"covid.xlsx\")\ndf.head()\n\n\n\n\n\n\n\n\ncategory\ntitle\n\n\n\n\n0\n101\nSK바이오사이언스, 코로나19 백신 임상 3상 시험계획 제출\n\n\n1\n102\n고양시 노래연습장 코로나19 누적확진 41명\n\n\n2\n103\n코로나19 신규 감염, 28일 오후 9시까지 542명\n\n\n3\n103\n프로야구 수도권 구단서 코로나19 확진자 발생\n\n\n4\n104\n\"코로나 확진자 '0명'인 날은 절대 오지 않는다\" 美전문가\n\n\n\n\n\n\n\n\ndf[\"en_title\"] = df[\"title\"].apply(translate)\ndf.head()\n\n\n\n\n\n\n\n\ncategory\ntitle\nen_title\n\n\n\n\n0\n101\nSK바이오사이언스, 코로나19 백신 임상 3상 시험계획 제출\nSK Bioscience Submits Phase 3 Trial Plan for C...\n\n\n1\n102\n고양시 노래연습장 코로나19 누적확진 41명\n41 cumulative confirmed cases of COVID-19 at t...\n\n\n2\n103\n코로나19 신규 감염, 28일 오후 9시까지 542명\nNew COVID-19 infections, 542 people by 9 p.m. ...\n\n\n3\n103\n프로야구 수도권 구단서 코로나19 확진자 발생\nA confirmed case of COVID-19 occurred at a clu...\n\n\n4\n104\n\"코로나 확진자 '0명'인 날은 절대 오지 않는다\" 美전문가\n\"The day when there are '0' confirmed cases of..."
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#일반-인증키decoding을-복사",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#일반-인증키decoding을-복사",
    "title": "01. 데이터 수집 (2)",
    "section": "1. 일반 인증키(Decoding)을 복사",
    "text": "1. 일반 인증키(Decoding)을 복사\n\nkey = \"2CjDf/qtlvs6cVGGPWlOxuA17ErE10FWrFyaKbxNGn6A0xcnckRQLFzLIMF2X1/3K/bfREKbKEv/PkfB7zVSuw==\""
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#url-key-zonename",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#url-key-zonename",
    "title": "01. 데이터 수집 (2)",
    "section": "2. url + key + zonename",
    "text": "2. url + key + zonename\n\nzonename = \"서울역\"\nurl = 'http://apis.data.go.kr/1613000/CarSharingInfoService/getCarZoneListByName'\nurl += f\"?serviceKey={key}&zoneName={zonename}&_type=json\"\nurl\n\n'http://apis.data.go.kr/1613000/CarSharingInfoService/getCarZoneListByName?serviceKey=2CjDf/qtlvs6cVGGPWlOxuA17ErE10FWrFyaKbxNGn6A0xcnckRQLFzLIMF2X1/3K/bfREKbKEv/PkfB7zVSuw==&zoneName=서울역&_type=json'"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#response",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#response",
    "title": "01. 데이터 수집 (2)",
    "section": "3. response",
    "text": "3. response\n\nresponse = requests.get(url)\n#response.json()\n\n\ndata = response.json()[\"response\"][\"body\"][\"items\"][\"item\"]\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\naddress\nlatitude\nlongitude\ntype\nzoneId\nzoneName\n\n\n\n\n0\n서울 중구 남대문로5가 581\n37.554298\n126.973892\n1\nS0000808\n서울역 10번출구(서울시티타워)(운영종료)\n\n\n1\n서울 용산구 동자동 43-205 서울역(철도역)\n37.555862\n126.970505\n2\n10519\n서울역사\n\n\n2\n서울 용산구 동자동 45 센트레빌아스테리움서울\n37.551563\n126.973236\n2\n10981\n서울역 12번출구(KDB생명타워)\n\n\n3\n서울 중구 남대문로5가 827 T타워\n37.553902\n126.975677\n2\n12196\n서울역 10번출구 옆(T타워)\n\n\n4\n서울 용산구 청파로 369(서계동)\n37.552456\n126.968330\n2\n1754\n롯데렌탈 서울역지점 2층(B)\n\n\n5\n서울 용산구 동자동 56 트윈시티 남산\n37.551189\n126.972939\n2\n7426\n서울역 12번출구(갈월동)\n\n\n6\n서울 용산구 서계동 47-2 대한통운서울지사\n37.552486\n126.968964\n2\n9442\n서울역 15번출구(국립극단옆EV)"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#html-intro",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#html-intro",
    "title": "01. 데이터 수집 (2)",
    "section": "1. html intro",
    "text": "1. html intro\n- 웹페이지의 레이아웃 및 텍스트 데이터를 출력하는 언어\n- 아래와 같은 계층적 구조를 가짐 (각각의 계층은 같은 계층끼리도 서로 하위에 포함시킬 수 있다.)\n\nelement : 시작 tag와 끝 tag로 구성 (&lt;div&gt; python /&lt;div&gt;)\n\ntag :\n\ntext\n\n\n\n- 시작태그(&lt;div&gt;) 안에는 속성값이 들어있다. ((id, class, attribute 등등))\n- id, class : 엘리먼트를 선택하기위한 용도로 사용되는 속성값 (id는 고유값, 클래스는 중복된 값을 가질 수 있으나.. 띄어쓰기로 구분한다.)\n- attribute : 정보를 저장하기 위한 속성값\n\nimg src = \"url......\""
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#tag-종류",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#tag-종류",
    "title": "01. 데이터 수집 (2)",
    "section": "2. tag 종류",
    "text": "2. tag 종류\n- div : 레이아웃을 나타내는 tag\n- p, span : 문자열을 나타내주는 tag\n- ul, li : 목록을 나타내주는 tag\n- a : link를 나타내주는 tag -&gt; 속성값으로 href를 가짐\n- img : 이미지, source 약자인 src를 속성값으로 가지는 tag"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#css-selector",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#css-selector",
    "title": "01. 데이터 수집 (2)",
    "section": "3. css selector",
    "text": "3. css selector\n- 엘리먼트를 선택하기 위한 문법\n- 아래와 같은 두 개의 element가 있다고하자.\n&lt;div&gt; id=\"d1\" class = \"data no1\" data1 value = \"1\"&lt;/div&gt;\n&lt;p&gt; id=\"d2\" class = \"data no2\" data2&lt;/p&gt;\n- element 선택 1. tag를 이용\n\ntag -&gt; div -&gt; data1\ntag -&gt; p -&gt; data2\n\n- element 선택 2. id를 이용\n\n#d1 : 엘리먼트 1 선택\n\n- element 선택 3. class를 이용\n\nclass : .data1 \\(\\to\\) data1,data2 엘리먼트 선택\nclass : .no1, .no2 \\(\\to\\) data1,data2 엘리먼트 선택\n\n- 속성값을 이용하여 선택\n\nattribute : [value = “1”] : data1 엘리먼트 선택\n\n- n번째 엘리먼트 선택법\n\np:nth-child(2) : data2 엘리먼트 선택 (각 레이아웃에서 두 번째 엘리먼트 중에 tag가 p이면 선택하라는 의미)\n\n&lt;div&gt;\n    &lt;p class=\"d\"&gt;data1&lt;/p&gt;\n    &lt;p class=\" \"&gt;data2&lt;/p&gt;\n    &lt;span class=\"d\" data3&gt; \n&lt;\\div&gt;\n\n* .d:nth-child(2) : `두 번째` 엘리먼트 중에 `class`가 `d`이면 선택하라는 의미 $\\to$ 아무것도 선택안됌\n* .d:nth-child(3) : `data3` 엘리먼트 선택\n\n***\n\n`-` 계층적 선택\n\n```python\n&lt;div&gt;\n    &lt;p class=\"d\"&gt;data1&lt;/p&gt;\n    &lt;p class=\" \"&gt;data2&lt;/p&gt;\n    &lt;span class=\"d\" data3&gt; \n    &lt;div class= \"\"&gt; &lt;p class=\"d\"&gt;data4&lt;/p&gt; &lt;/div&gt;\n&lt;/div&gt;\n\n* div &gt; p : data1, data2 선택 (한 단계 아래의 엘리먼트 중에서!)\n\n* div p : data1, data2, data3 엘리먼트 선택 (모든 하위 엘리먼트 중에서!)\n\n## 실습 1 : 네이버 연관 검색어 수집\n\n`-` 정적 데이터 수집(`html`)\n\n`-` 삼성전자 연관검색어 수집\n\n### 0. import\n\n::: {.cell tags='[]' execution_count=84}\n``` {.python .cell-code}\nimport pandas as pd \nimport requests \nfrom bs4 import BeautifulSoup\n:::\n\n1. URL 찾기\n\nquery = '삼성전자' \nurl = f'https://search.naver.com/search.naver?query={query}' \nurl\n\n'https://search.naver.com/search.naver?query=삼성전자'\n\n\n\n\n2. request(url), response(data)\n\nresponse = requests.get(url)\nresponse\n\n&lt;Response [200]&gt;\n\n\n\n\n3. html(str), bs object\n- bs 오브젝트 생성\n\ndom = BeautifulSoup(response.text,\"html.parser\")\n\ntype(dom)\n\nbs4.BeautifulSoup\n\n\n\n\n4. 크롤링\n- 브라우저에서 해당 연관검색어의 selector을 카피\n\nselector = \"#nx_right_related_keywords &gt; div &gt; div.related_srch &gt; ul &gt; li\"\n\n- .select(css-selector) \\(\\to\\) text\n\nelements = dom.select(selector)\n\n\nlen(elements)\n\n10\n\n\n- .select_one(css-selector) \\(\\to\\) text\n\nelements[0].select_one(\".tit\").text\n\n'삼성전자주가'\n\n\n- 리스트 컴프리헨션으로 연관검색어 정리\n\nkeywords = [i.select_one(\".tit\").text for i in elements]\n#pd.DataFrame({\"keywords\" : keywords})\n\n\n\n5. 함수로 작성\n\ndef c(query = '삼성전자') : \n    # 1. url 입력\n    url = f'https://search.naver.com/search.naver?query={query}' \n    # 2. requset -&gt; response\n    response = requests.get(url)\n    # 3. bs객체 생성\n    dom = BeautifulSoup(response.text,\"html.parser\")\n    # 4. 연관검색어 개체의 selector 카피\n    selector = \"#nx_right_related_keywords &gt; div &gt; div.related_srch &gt; ul &gt; li\"\n    # 5. 키워드로 저장\n    elements = dom.select(selector)\n    keywords = [i.select_one(\".tit\").text for i in elements]\n    \n    return pd.DataFrame({\"keywords\" : keywords})\n\n\n#c()"
  },
  {
    "objectID": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#실습-2-지마켓-크롤링",
    "href": "posts/DX/03. 데이터 수집/2023-09-05-01. 데이터 수집 (2).html#실습-2-지마켓-크롤링",
    "title": "01. 데이터 수집 (2)",
    "section": "실습 2 : 지마켓 크롤링",
    "text": "실습 2 : 지마켓 크롤링\n- 지마켓 베스트 상품 크롤링\n\n1. url 등록\n\nurl = \"https://www.gmarket.co.kr/n/best\"\n\n\n\n2 response\n\nresponse = requests.get(url)\n\n\n\n3 bs객체 생성\n\ndom = BeautifulSoup(response.text,\"html.parser\")\n\n\n\n4 selector 카피\n\nselector = \"#gBestWrap &gt; div.best-list &gt; ul &gt; li\"\n\n\n\n5 elements 생성 후 타이틀, 이미지url, 할인가 불러오기\n\nelements = dom.select(selector)\n\n\nelement = elements[0]\n\n\ndata = {\n    \"title\": element.select_one(\".itemname\").text,\n    \"img\" : \"http:\" + element.select_one(\"img\").get(\"src\"),\n    \"sprice\": element.select_one(\".s-price\").text\n}\n\n\ndata\n\n{'title': '자연산 손질 통 오징어 10미(1.3kg내외)',\n 'img': 'http://gdimg.gmarket.co.kr/3106295509/still/300?ver=20230905',\n 'sprice': '할인가24,500원 30%'}\n\n\n\n\n6 loop로 모든 데이터를 읽은 후 데이터 프레임을 변환\n\nitems = []\nfor element in elements :\n    items.append({\n    \"title\": element.select_one(\".itemname\").text,\n    \"img\" : \"http:\" + element.select_one(\"img\").get(\"src\"),\n    \"sprice\": element.select_one(\".s-price\").text\n    })\n\n\ndf = pd.DataFrame(items)\n\n\n\n7 상품 이미지 데이터 저장\n(1) 디렉토리 생성\n\nimport os\npath = \"imgs\"\nos.makedirs(path)\n\n\n%ls\n\n D 드라이브의 볼륨: 새 볼륨\n 볼륨 일련 번호: EC13-2D50\n\n D:\\projects\\mysite2\\posts\\DX\\03. 데이터 수집 디렉터리\n\n2023-09-05  오후 03:56    &lt;DIR&gt;          .\n2023-09-04  오후 05:12    &lt;DIR&gt;          ..\n2023-09-05  오전 09:31    &lt;DIR&gt;          .ipynb_checkpoints\n2023-09-04  오후 05:11           235,320 2023-09-04-00. 데이터 수집 (1).ipynb\n2023-09-05  오후 03:54            44,753 2023-09-05-01. 데이터 수집 (2).ipynb\n2023-09-05  오전 10:18            60,688 API.png\n2023-09-05  오전 11:16             8,911 covid.xlsx\n2023-09-05  오후 03:56    &lt;DIR&gt;          imgs\n               4개 파일             349,672 바이트\n               4개 디렉터리  1,985,535,983,616 바이트 남음\n\n\n(2) img-url\n\nlink = df.loc[0,\"img\"]\nlink\n\n'http://gdimg.gmarket.co.kr/3106295509/still/300?ver=20230905'\n\n\n(3) request\n\nresponse = requests.get(link)\nresponse\n\n&lt;Response [200]&gt;\n\n\n(4) 이미지 저장\n\nwith open(f\"{path}/test.jpg\",\"wb\") as file :\n    file.write(response.content)\n\n(5) 이미지 열어보기\n\nfrom PIL import Image as pil\npil.open(f\"{path}/test.jpg\")\n\n\n\n\n(6) loop를 이용하여 작성\n\nfor idx, data in df[:5].iterrows() : \n    link = data[\"img\"]\n    response = requests.get(link)\n    with open(f\"{path}/{idx}.jpg\",\"wb\") as file :\n        file.write(response.content)\n\n오 신기 신기\n\npil.open(f\"{path}/3.jpg\")"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html",
    "title": "01. 머신러닝 (1)",
    "section": "",
    "text": "Code\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터로드",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터로드",
    "title": "01. 머신러닝 (1)",
    "section": "데이터로드",
    "text": "데이터로드\n\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/airquality_simple.csv'\ndata = pd.read_csv(path)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-준비",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-준비",
    "title": "01. 머신러닝 (1)",
    "section": "데이터 준비",
    "text": "데이터 준비\n- 결측치 체우기\n\n# 전날 값으로 결측치 채우기\ndata.fillna(method='ffill', inplace=True)\n\n# 확인\ndata.isnull().sum()\n\nOzone      0\nSolar.R    0\nWind       0\nTemp       0\nMonth      0\nDay        0\ndtype: int64\n\n\n- 변수제거\n\n# 변수 제거\ndrop_cols = ['Month', 'Day']\ndata.drop(drop_cols, axis=1, inplace=True)\n\n# 확인\ndata.head()\n\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\n\n\n\n\n0\n41\n190.0\n7.4\n67\n\n\n1\n36\n118.0\n8.0\n72\n\n\n2\n12\n149.0\n12.6\n74\n\n\n3\n18\n313.0\n11.5\n62\n\n\n4\n19\n313.0\n14.3\n56\n\n\n\n\n\n\n\n- \\((x,y)\\) 분리\n\n# target 확인\ntarget = 'Ozone'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n- 학습용, 평가용 데이터 분리\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링",
    "title": "01. 머신러닝 (1)",
    "section": "모델링",
    "text": "모델링\n\n# 1단계: 불러오기\nfrom sklearn.linear_model import LinearRegression\n\n# 2단계 : 모델선언\nmodel = LinearRegression()\n\n# 3단계 : 학습하기\n\nmodel.fit(x_train, y_train)\n\n# 4단계 : 예측하기\ny_pred = model.predict(x_test)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모형-평가",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모형-평가",
    "title": "01. 머신러닝 (1)",
    "section": "모형 평가",
    "text": "모형 평가\n\n\nCode\nfrom sklearn.metrics import *\n\n\nprint(\"MAE :\", mean_absolute_error(y_test,y_pred))\nprint(\"MSE :\", mean_squared_error(y_test,y_pred))\nprint(\"RMSE :\", mean_squared_error(y_test,y_pred)**(1/2))\nprint(\"MAPE :\", mean_absolute_percentage_error(y_test,y_pred))\nprint(\"R2\", r2_score(y_test,y_pred))\n\n\nMAE : 13.976843190385711\nMSE : 341.678874066819\nRMSE : 18.484557718993955\nMAPE : 0.47185976988482603\nR2 0.5744131358040061\n\n\n\nprint(\"MAE : \", mean_absolute_error(y_test,y_pred))\n\nMAE :  13.976843190385711"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step0.-import",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step0.-import",
    "title": "01. 머신러닝 (1)",
    "section": "step0. import",
    "text": "step0. import\n\nimport statsmodels.api as sm\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)\nfrom sklearn.metrics import * ## 모델 평가지표\nfrom sklearn.model_selection import train_test_split"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-1.-xy-분리-및-훈련데이터와-평가-데이터-분리",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-1.-xy-분리-및-훈련데이터와-평가-데이터-분리",
    "title": "01. 머신러닝 (1)",
    "section": "step 1. \\((X,y)\\) 분리 및 훈련데이터와 평가 데이터 분리",
    "text": "step 1. \\((X,y)\\) 분리 및 훈련데이터와 평가 데이터 분리\n\ntarget = \"Ozone\"\n\nx = data.drop(target, axis=1)\nX = MS(x).fit_transform(data)\ny = data[target]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-2.-최소제곱법을-이용하여-모델을-적합하겠다고-선언",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-2.-최소제곱법을-이용하여-모델을-적합하겠다고-선언",
    "title": "01. 머신러닝 (1)",
    "section": "step 2. 최소제곱법을 이용하여 모델을 적합하겠다고 선언",
    "text": "step 2. 최소제곱법을 이용하여 모델을 적합하겠다고 선언\n\nmodel = sm.OLS(y_train,x_train)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-3.-모형에-대한-유의성-확인",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-3.-모형에-대한-유의성-확인",
    "title": "01. 머신러닝 (1)",
    "section": "step 3. 모형에 대한 유의성 확인",
    "text": "step 3. 모형에 대한 유의성 확인\n\nmodel.fit().summary().tables[0]\n\n\nOLS Regression Results\n\n\nDep. Variable:\nOzone\nR-squared:\n0.576\n\n\nModel:\nOLS\nAdj. R-squared:\n0.564\n\n\nMethod:\nLeast Squares\nF-statistic:\n46.73\n\n\nDate:\nTue, 12 Sep 2023\nProb (F-statistic):\n3.80e-19\n\n\nTime:\n16:51:34\nLog-Likelihood:\n-469.88\n\n\nNo. Observations:\n107\nAIC:\n947.8\n\n\nDf Residuals:\n103\nBIC:\n958.5\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-4.-개별-회귀-계수에-대한-유의성-확인",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-4.-개별-회귀-계수에-대한-유의성-확인",
    "title": "01. 머신러닝 (1)",
    "section": "step 4. 개별 회귀 계수에 대한 유의성 확인",
    "text": "step 4. 개별 회귀 계수에 대한 유의성 확인\n\nmodel.fit().summary().tables[1]\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nintercept\n-59.5062\n20.882\n-2.850\n0.005\n-100.920\n-18.092\n\n\nSolar.R\n0.0560\n0.022\n2.555\n0.012\n0.013\n0.099\n\n\nWind\n-3.3585\n0.604\n-5.564\n0.000\n-4.556\n-2.161\n\n\nTemp\n1.5799\n0.234\n6.760\n0.000\n1.116\n2.043"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-5.-평가-데이터에-대한-모형-평가",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#step-5.-평가-데이터에-대한-모형-평가",
    "title": "01. 머신러닝 (1)",
    "section": "step 5. 평가 데이터에 대한 모형 평가",
    "text": "step 5. 평가 데이터에 대한 모형 평가\n\nl_model = model.fit()\n\ny_pred = l_model.predict(x_test)\n\n\n\nCode\nprint(\"MAE :\", mean_absolute_error(y_test,y_pred))\nprint(\"MSE :\", mean_squared_error(y_test,y_pred))\nprint(\"RMSE :\", mean_squared_error(y_test,y_pred)**(1/2))\nprint(\"MAPE :\", mean_absolute_percentage_error(y_test,y_pred))\nprint(\"R2\", r2_score(y_test,y_pred))\n\n\nMAE : 13.976843190385711\nMSE : 341.6788740668187\nRMSE : 18.484557718993948\nMAPE : 0.4718597698848258\nR2 0.5744131358040064"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#import-1",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#import-1",
    "title": "01. 머신러닝 (1)",
    "section": "0. import",
    "text": "0. import\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nimport statsmodels.api as sm\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)\nfrom sklearn.metrics import * ## 모델 평가지표\nfrom sklearn.model_selection import train_test_split"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-로드",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-로드",
    "title": "01. 머신러닝 (1)",
    "section": "1. 데이터 로드",
    "text": "1. 데이터 로드\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/income_happy.csv'\ndata = pd.read_csv(path)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-이해",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-이해",
    "title": "01. 머신러닝 (1)",
    "section": "2. 데이터 이해",
    "text": "2. 데이터 이해\n- income : 수입 (단위 : 10,000$)\n- happiness : 행복정도 (1 ~ 10)\n\ndata.shape\n\n(498, 2)\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 498 entries, 0 to 497\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   income     498 non-null    float64\n 1   happiness  498 non-null    float64\ndtypes: float64(2)\nmemory usage: 7.9 KB\n\n\n- 기술통계 확인\n\ndata.describe().T\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nincome\n498.0\n4.466902\n1.737527\n1.506275\n3.006256\n4.423710\n5.991913\n7.481521\n\n\nhappiness\n498.0\n3.392859\n1.432813\n0.266044\n2.265864\n3.472536\n4.502621\n6.863388\n\n\n\n\n\n\n\n\ndata.corr()\n\n\n\n\n\n\n\n\nincome\nhappiness\n\n\n\n\nincome\n1.000000\n0.865634\n\n\nhappiness\n0.865634\n1.000000"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링1-강의",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링1-강의",
    "title": "01. 머신러닝 (1)",
    "section": "모델링1 : 강의",
    "text": "모델링1 : 강의\n\nstep 1. 데이터셋 분리\n\ntarget = \"income\"\nx = data.drop(target, axis = 1)\ny = data[target]\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, random_state=1, test_size = 0.3)\n\n\n\nstep 2. 모델 선언\n\nmodel1 = LinearRegression()\n\n\n\nstep 3. 모델 fit\n\nmodel1.fit(x_train,y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\n\n\n\nstep 4. predict\n\ny_pred = model1.predict(x_test)\n\n\n\nstep 5. 성능 평가\n\n\nCode\nprint(\"MAE :\", mean_absolute_error(y_test,y_pred))\nprint(\"MSE :\", mean_squared_error(y_test,y_pred))\nprint(\"RMSE :\", mean_squared_error(y_test,y_pred)**(1/2))\nprint(\"MAPE :\", mean_absolute_percentage_error(y_test,y_pred))\nprint(\"R2\", r2_score(y_test,y_pred))\n\n\nMAE : 0.6968383731427477\nMSE : 0.7812638184683306\nRMSE : 0.8838912933547488\nMAPE : 0.20292339169383194\nR2 0.7540887980989224\n\n\n\n\nstep 5. 시각화\n\nplt.figure(figsize = (4,4))\nplt.plot(x_test,y_test,\".r\",alpha = 0.3,label =r\"$(x,y)$\")\nplt.plot(x_test,y_pred,\".b\",alpha = 0.3,label =r\"$(x,\\hat {y})$\" )\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x20636f2d350&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링-2-islp",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링-2-islp",
    "title": "01. 머신러닝 (1)",
    "section": "모델링 2 : ISLP",
    "text": "모델링 2 : ISLP\n\n\nCode\nimport statsmodels.api as sm\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)\nfrom sklearn.metrics import * ## 모델 평가지표\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/income_happy.csv'\ndata = pd.read_csv(path)\n\n\nstep 1. 데이터셋 분리\n\ntarget = \"income\"\n\nx = data.drop(target, axis=1)\nX = MS(x).fit_transform(data)\ny = data[target]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\n\n\nstep 2. 모델 선언\n\nmodel2 = sm.OLS(y_train, x_train).fit()\n\n\n\nstep 3. 모델 report 확인\n\nresults = model2.summary()\n\n\nresults.tables[0]\n\n\nOLS Regression Results\n\n\nDep. Variable:\nincome\nR-squared:\n0.747\n\n\nModel:\nOLS\nAdj. R-squared:\n0.746\n\n\nMethod:\nLeast Squares\nF-statistic:\n1020.\n\n\nDate:\nTue, 12 Sep 2023\nProb (F-statistic):\n3.14e-105\n\n\nTime:\n16:51:35\nLog-Likelihood:\n-442.54\n\n\nNo. Observations:\n348\nAIC:\n889.1\n\n\nDf Residuals:\n346\nBIC:\n896.8\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\nresults.tables[1]\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nintercept\n0.9640\n0.119\n8.121\n0.000\n0.731\n1.197\n\n\nhappiness\n1.0337\n0.032\n31.945\n0.000\n0.970\n1.097\n\n\n\n\n\n\n\nstep 4. 평가 데이터에 대한 모형 평가\n\ny_pred = model2.predict(x_test)\n\n\nfrom sklearn.metrics import *\n\n\nprint(\"MAE :\", mean_absolute_error(y_test,y_pred))\nprint(\"MSE :\", mean_squared_error(y_test,y_pred))\nprint(\"RMSE :\", mean_squared_error(y_test,y_pred)**(1/2))\nprint(\"MAPE :\", mean_absolute_percentage_error(y_test,y_pred))\nprint(\"R2\", r2_score(y_test,y_pred))\n\nMAE : 0.6968383731427479\nMSE : 0.7812638184683306\nRMSE : 0.8838912933547488\nMAPE : 0.2029233916938319\nR2 0.7540887980989224\n\n\n\n\nstep 5. 결과 시각화\n\nplt.figure(figsize = (4,4))\nplt.plot(x_test[\"happiness\"],y_test,\".r\",alpha = 0.3,label =r\"$(x,y)$\")\nplt.plot(x_test[\"happiness\"],y_pred,\".b\",alpha = 0.3,label =r\"$(x,\\hat {y})$\" )\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x2063232d350&gt;"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#summary-1",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#summary-1",
    "title": "01. 머신러닝 (1)",
    "section": "summary 1",
    "text": "summary 1\n- 강의에서 다룬 sklearn.linear_model에서는 model fitting 시 다음과 같은 구조로 입력해야 한다.\n\n예측변수가 첫 번째인자, 반응변수가 두 번째 인자\n\nfrom sklearn.linear_model import LinearRegression\n\nmodel1.fit(x_train,y_train)\n- ISLP에서는 위와 반대!\n\nmodel1.fit?\n\n\nSignature: model1.fit(X, y, sample_weight=None)\nDocstring:\nFit linear model.\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples, n_features)\n    Training data.\ny : array-like of shape (n_samples,) or (n_samples, n_targets)\n    Target values. Will be cast to X's dtype if necessary.\nsample_weight : array-like of shape (n_samples,), default=None\n    Individual weights for each sample.\n    .. versionadded:: 0.17\n       parameter *sample_weight* support to LinearRegression.\nReturns\n-------\nself : object\n    Fitted Estimator.\nFile:      c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages\\sklearn\\linear_model\\_base.py\nType:      method\n\n\n\nimport statsmodels.api as sm\nfrom ISLP.models import (ModelSpec as MS, summarize, poly)\nmodel2 = sm.OLS(y_train, x_train).fit()\n\nsm.OLS?\n\n\nInit signature: sm.OLS(endog, exog=None, missing='none', hasconst=None, **kwargs)\nDocstring:     \nOrdinary Least Squares\nParameters\n----------\nendog : array_like\n    A 1-d endogenous response variable. The dependent variable.\nexog : array_like\n    A nobs x k array where `nobs` is the number of observations and `k`\n    is the number of regressors. An intercept is not included by default\n    and should be added by the user. See\n    :func:`statsmodels.tools.add_constant`.\nmissing : str\n    Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n    checking is done. If 'drop', any observations with nans are dropped.\n    If 'raise', an error is raised. Default is 'none'.\nhasconst : None or bool\n    Indicates whether the RHS includes a user-supplied constant. If True,\n    a constant is not checked for and k_constant is set to 1 and all\n    result statistics are calculated as if a constant is present. If\n    False, a constant is not checked for and k_constant is set to 0.\n**kwargs\n    Extra arguments that are used to set model properties when using the\n    formula interface.\nAttributes\n----------\nweights : scalar\n    Has an attribute weights = array(1.0) due to inheritance from WLS.\nSee Also\n--------\nWLS : Fit a linear model using Weighted Least Squares.\nGLS : Fit a linear model using Generalized Least Squares.\nNotes\n-----\nNo constant is added by the model unless you are using formulas.\nExamples\n--------\n&gt;&gt;&gt; import statsmodels.api as sm\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; duncan_prestige = sm.datasets.get_rdataset(\"Duncan\", \"carData\")\n&gt;&gt;&gt; Y = duncan_prestige.data['income']\n&gt;&gt;&gt; X = duncan_prestige.data['education']\n&gt;&gt;&gt; X = sm.add_constant(X)\n&gt;&gt;&gt; model = sm.OLS(Y,X)\n&gt;&gt;&gt; results = model.fit()\n&gt;&gt;&gt; results.params\nconst        10.603498\neducation     0.594859\ndtype: float64\n&gt;&gt;&gt; results.tvalues\nconst        2.039813\neducation    6.892802\ndtype: float64\n&gt;&gt;&gt; print(results.t_test([1, 0]))\n                             Test for Constraints\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nc0            10.6035      5.198      2.040      0.048       0.120      21.087\n==============================================================================\n&gt;&gt;&gt; print(results.f_test(np.identity(2)))\n&lt;F test: F=array([[159.63031026]]), p=1.2607168903696672e-20,\n df_denom=43, df_num=2&gt;\nFile:           c:\\users\\rkdcj\\anaconda3\\envs\\dx\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\nType:           type\nSubclasses:     \n\n\n\n- 인자값을 명시해주고 전달하면 상관이 없으나, 귀찮으니 그냥 바꿔가면서 쓰자 핳"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-로드-및-확인",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-로드-및-확인",
    "title": "01. 머신러닝 (1)",
    "section": "1. 데이터 로드 및 확인",
    "text": "1. 데이터 로드 및 확인\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/admission_simple.csv'\ndata = pd.read_csv(path)\n\n\n# 상/하위 몇 개 행 확인\ndata.head()\n\n\n\n\n\n\n\n\nGRE\nTOEFL\nRANK\nSOP\nLOR\nGPA\nRESEARCH\nADMIT\n\n\n\n\n0\n337\n118\n4\n4.5\n4.5\n9.65\n1\n1\n\n\n1\n324\n107\n4\n4.0\n4.5\n8.87\n1\n1\n\n\n2\n316\n104\n3\n3.0\n3.5\n8.00\n1\n0\n\n\n3\n322\n110\n3\n3.5\n2.5\n8.67\n1\n1\n\n\n4\n314\n103\n2\n2.0\n3.0\n8.21\n0\n0\n\n\n\n\n\n\n\n\n# 변수 확인\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 500 entries, 0 to 499\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   GRE       500 non-null    int64  \n 1   TOEFL     500 non-null    int64  \n 2   RANK      500 non-null    int64  \n 3   SOP       500 non-null    float64\n 4   LOR       500 non-null    float64\n 5   GPA       500 non-null    float64\n 6   RESEARCH  500 non-null    int64  \n 7   ADMIT     500 non-null    int64  \ndtypes: float64(3), int64(5)\nmemory usage: 31.4 KB\n\n\n\n# 기술통계 확인\ndata.describe()\n\n\n\n\n\n\n\n\nGRE\nTOEFL\nRANK\nSOP\nLOR\nGPA\nRESEARCH\nADMIT\n\n\n\n\ncount\n500.000000\n500.000000\n500.000000\n500.000000\n500.00000\n500.000000\n500.000000\n500.000000\n\n\nmean\n316.472000\n107.192000\n3.114000\n3.374000\n3.48400\n8.576440\n0.560000\n0.436000\n\n\nstd\n11.295148\n6.081868\n1.143512\n0.991004\n0.92545\n0.604813\n0.496884\n0.496384\n\n\nmin\n290.000000\n92.000000\n1.000000\n1.000000\n1.00000\n6.800000\n0.000000\n0.000000\n\n\n25%\n308.000000\n103.000000\n2.000000\n2.500000\n3.00000\n8.127500\n0.000000\n0.000000\n\n\n50%\n317.000000\n107.000000\n3.000000\n3.500000\n3.50000\n8.560000\n1.000000\n0.000000\n\n\n75%\n325.000000\n112.000000\n4.000000\n4.000000\n4.00000\n9.040000\n1.000000\n1.000000\n\n\nmax\n340.000000\n120.000000\n5.000000\n5.000000\n5.00000\n9.920000\n1.000000\n1.000000"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-셋-분리",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-셋-분리",
    "title": "01. 머신러닝 (1)",
    "section": "2. 데이터 셋 분리",
    "text": "2. 데이터 셋 분리\n\ntarget = 'ADMIT'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n# 모듈 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링-1",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링-1",
    "title": "01. 머신러닝 (1)",
    "section": "3. 모델링",
    "text": "3. 모델링\n\n# 1단계: 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 2단계: 선언하기\nmodel = KNeighborsClassifier()\n\n# 3단계: 학습하기\nmodel.fit(x_train, y_train)\n\n# 4단계: 예측하기\ny_pred = model.predict(x_test)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#예측결과-시각화",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#예측결과-시각화",
    "title": "01. 머신러닝 (1)",
    "section": "4. 예측결과 시각화",
    "text": "4. 예측결과 시각화\n\nfrom sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test,y_pred))\n\n[[76  8]\n [16 50]]\n\n\n\nplt.figure(figsize = (4,4))\nsns.heatmap(confusion_matrix(y_test,y_pred),\n            annot = True,\n            cmap = \"Blues\",\n            cbar = False)\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n5. 정확도, 정밀도, 재현율 계산\n\nprint(f\"accuarcy : {accuracy_score(y_test,y_pred):.2f}\")\npre = precision_score(y_test,y_pred,average=\"binary\")\npre2 = precision_score(y_test,y_pred,average=None)\nprint(f\"precision : {pre :.2f}\")\nprint(f\"precision of 0 : {pre2[0] :.2f}, precision of 0 : {pre2[1] : .2f}\")\nprint(f\"recall of 0: {recall_score(y_test,y_pred,average=None)[0]:.2f}, recall of 1: {recall_score(y_test,y_pred,average=None)[1]:.2f}\")\nprint(f\"F1-score of 0: {f1_score(y_test,y_pred,average=None)[0]:.2f}, F1-score of 1: {f1_score(y_test,y_pred,average=None)[1]:.2f}\")\n\naccuarcy : 0.84\nprecision : 0.86\nprecision of 0 : 0.83, precision of 0 :  0.86\nrecall of 0: 0.90, recall of 1: 0.76\nF1-score of 0: 0.86, F1-score of 1: 0.81"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#import-2",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#import-2",
    "title": "01. 머신러닝 (1)",
    "section": "0. import",
    "text": "0. import\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nimport statsmodels.api as sm\nfrom ISLP.models import (ModelSpec as MS,\nsummarize,poly)\nfrom sklearn.metrics import * ## 모델 평가지표\nfrom sklearn.model_selection import train_test_split"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-로드-및-eda",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-로드-및-eda",
    "title": "01. 머신러닝 (1)",
    "section": "1. 데이터 로드 및 EDA",
    "text": "1. 데이터 로드 및 EDA\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/titanic.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n\ndata.isna().sum()\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-전처리",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-전처리",
    "title": "01. 머신러닝 (1)",
    "section": "2. 데이터 전처리",
    "text": "2. 데이터 전처리\n- 필요없는 변수 제거\n\n# Title  열 추가 (이름에서 Mr, Mrs)만 뽑기\n\ndata[\"Title\"] = data[\"Name\"].str.extract(\"([a-zA-z]+)\\.\")\n\n- Master까지만 자르고 나머지를 others로 묶어버리자\n\ndata.Title.value_counts()\n\nTitle\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nMlle          2\nMajor         2\nCol           2\nCountess      1\nCapt          1\nMs            1\nSir           1\nLady          1\nMme           1\nDon           1\nJonkheer      1\nName: count, dtype: int64\n\n\n\nmain_title = [\"Mr\",\"Miss\",\"Mrs\",\"Master\"]\n\n\ndata.loc[data['Title'].isin(main_title)==False, 'Title'] = 'Others'\n\n\ndata.Title.value_counts()\n\nTitle\nMr        517\nMiss      182\nMrs       125\nMaster     40\nOthers     27\nName: count, dtype: int64\n\n\n- 삭제할 컬럼 지정\n\nd_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n\ndata.drop(d_cols, axis=1,inplace=True)\ndata.head()\n\n\n\n\n\n\n\n\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nFare\nEmbarked\nTitle\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nMr\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nMrs\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nMiss\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nMrs\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nMr\n\n\n\n\n\n\n\n- 결측치 채우기\n\n## 탑승자 Title별, 나이의 중앙값.\n## 4개의 값을 transform을 이용하여 전체의 행의 개수로 맞추고 결측치를 채운다.\ntitle_age_median = data.groupby(\"Title\")[\"Age\"].transform(\"median\")\n\n\ntitle_age_median.unique()\n\narray([30. , 35. , 21. ,  3.5, 44.5])\n\n\n\n# Age 결측치를 각 title의 중앙값으로 바꾸기\n\ndata.Age.fillna(title_age_median, inplace=True)\n\n# Embarked 최빈값 'S'로 채우기\n\ndata.Embarked.fillna(value = \"S\", inplace=True)\n\n\ndata.isna().sum()\n\nSurvived    0\nPclass      0\nSex         0\nAge         0\nSibSp       0\nParch       0\nFare        0\nEmbarked    0\nTitle       0\ndtype: int64"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-분리-및-가변수화",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#데이터-분리-및-가변수화",
    "title": "01. 머신러닝 (1)",
    "section": "3. 데이터 분리 및 가변수화",
    "text": "3. 데이터 분리 및 가변수화\n\ntarget = \"Survived\"\n\nx = data.drop(target, axis=1)\ny = data[target]\n\nd_cols = [\"Pclass\", \"Sex\", \"Embarked\", \"Title\"]\n\nx = pd.get_dummies(x, columns = d_cols, drop_first = True, dtype=float)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#훈련-및-평가",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#훈련-및-평가",
    "title": "01. 머신러닝 (1)",
    "section": "4. 훈련 및 평가",
    "text": "4. 훈련 및 평가\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, random_state=1, test_size=0.3)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링-knn",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#모델링-knn",
    "title": "01. 머신러닝 (1)",
    "section": "5. 모델링 KNN",
    "text": "5. 모델링 KNN\n\nx_train.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 623 entries, 114 to 37\nData columns (total 13 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Age           623 non-null    float64\n 1   SibSp         623 non-null    int64  \n 2   Parch         623 non-null    int64  \n 3   Fare          623 non-null    float64\n 4   Pclass_2      623 non-null    float64\n 5   Pclass_3      623 non-null    float64\n 6   Sex_male      623 non-null    float64\n 7   Embarked_Q    623 non-null    float64\n 8   Embarked_S    623 non-null    float64\n 9   Title_Miss    623 non-null    float64\n 10  Title_Mr      623 non-null    float64\n 11  Title_Mrs     623 non-null    float64\n 12  Title_Others  623 non-null    float64\ndtypes: float64(11), int64(2)\nmemory usage: 68.1 KB\n\n\n\n# 1단계: 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 2단계: 선언하기\nmodel = KNeighborsClassifier()\n\n# 3단계: 학습하기\nmodel.fit(x_train, y_train)\n\n# 4단계: 예측하기\ny_pred = model.predict(x_test.values)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#분류-성능-평가",
    "href": "posts/DX/04. 머신러닝/2023-09-12-01. 머신러닝 (1).html#분류-성능-평가",
    "title": "01. 머신러닝 (1)",
    "section": "6. 분류 성능 평가",
    "text": "6. 분류 성능 평가\n\nfrom sklearn.metrics import *\n\n\nacc = accuracy_score(y_pred, y_test)\npre = precision_score(y_pred,y_test,average = None)\nre = recall_score(y_pred,y_test,average = None)\nf = f1_score(y_pred,y_test,average = None)\n\n\ndied = pd.DataFrame({\"measure\" : [\"acc\",\"precision\",\"recall\",\"f1-score\"],\n              \"value\" : [acc, pre[0], re[0], f[0]],\n              \"label\" : [\"died\"]*4})\n\nsurvived = pd.DataFrame({\"measure\" : [\"acc\",\"precision\",\"recall\",\"f1-score\"],\n              \"value\" : [acc, pre[1], re[1], f[1]],\n              \"label\" : [\"Survived\"]*4})\n\n\npd.concat([died, survived],axis=0)\n\n\n\n\n\n\n\n\nmeasure\nvalue\nlabel\n\n\n\n\n0\nacc\n0.686567\ndied\n\n\n1\nprecision\n0.823529\ndied\n\n\n2\nrecall\n0.688525\ndied\n\n\n3\nf1-score\n0.750000\ndied\n\n\n0\nacc\n0.686567\nSurvived\n\n\n1\nprecision\n0.504348\nSurvived\n\n\n2\nrecall\n0.682353\nSurvived\n\n\n3\nf1-score\n0.580000\nSurvived\n\n\n\n\n\n\n\n\nfig = pd.concat([died, survived],axis=0).\\\n            plot(x= \"label\", y = \"value\", color= \"label\", kind= \"bar\",\n                facet_col = \"measure\",facet_col_wrap = 2, backend= \"plotly\",width=500,height=500)\n\nfig.update_yaxes(range = [0.45, 0.85])"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html",
    "href": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html",
    "title": "03. 머신러닝 (3)",
    "section": "",
    "text": "= 지금까지 모델을 선언하고 학습한 후 바로 평가를 진행함\n\n일반화 성능, 즉 이후 새로운 데이터에 대한 모델의 성능을 예측하지 못한 상태에서 최종 평가를 수행\n검증용 데이터가 모델의 일반화된 성능을 예측할 수 있게 도와 줌\n지만 이것 역시 단 하나의 데이터 셋에 대한 추정일 뿐\n하나의 데이터 셋에서 얻은 성능으로 정확도에 확신을 가질 수 없음\n국 더욱 정교한 평가 절차가 필요함\n\n\n\n\n모든 데이터가 평가에 한 번, 학습에 k-1번 사용\nK개의 분할(Fold)에 대한 성능을 예측 → 평균과 표준편차 계산 → 일반화 성능\n단, k는 2 이상이 되어야 함(최소한 한 개씩의 학습용, 검증용 데이터가 필요)\n\n\n\n\n\n장점\n\n\n모든 데이터를 학습과 평가에 사용할 수 있음\n반복 학습과 평가를 통해 정확도를 향상시킬 수 있음\n데이터가 부족해서 발생하는 과소적합 문제를 방지할 수 있음\n평가에 사용되는 데이터의 편향을 막을 수 있음\n좀 더 일반화된 모델을 만들 수 있음\n\n\n단점\n\n\n반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요됨\n\n\n\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format='retina'\n\n\n\n데이터설명\n\nPregnancies: 임신 횟수\nGlucose: 포도당 부하 검사 수치\nBloodPressure: 혈압(mm Hg)\nSkinThickness: 팔 삼두근 뒤쪽의 피하지방 측정값(mm)\nInsulin: 혈청 인슐린(mu U/ml)\nBMI: 체질량지수(체중(kg)/키(m))^2\nDiabetesPedigreeFunction: 당뇨 내력 가중치 값\nAge: 나이\nOutcome: 클래스 결정 값(0 또는 1)\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/diabetes.csv'\ndata = pd.read_csv(path)\n\n\n# 데이터 살펴보기\ndata.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n\n# 기술통계 확인\ndata.describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n0.348958\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n0.476951\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n0.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n0.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n0.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n1.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\n\n# Target 확인\ntarget = 'Outcome'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n\n# 라이브러리 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 학습용, 평가용 데이터 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n- 정규화\n\nKNN 알고리즘을 사용하기 위해 정규화를 진행\n\n\n# 모듈 불러오기\nfrom sklearn.preprocessing import MinMaxScaler\n\n# 정규화\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n\n- 의사결정나무\n\n# 불러오기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 선언하기\nmodel = DecisionTreeClassifier(max_depth=5,  random_state=1)\n\n# 검증하기\ncv_score = cross_val_score(model, x_train, y_train, cv=10)\n\n# 확인\nprint(cv_score)\nprint('평균:', cv_score.mean())\nprint('표준편차:', cv_score.std())\n\n# 기록\nresult = {}\nresult[\"Decision Tree\"] = cv_score.mean()\n\n[0.66666667 0.75925926 0.74074074 0.64814815 0.7037037  0.74074074\n 0.75925926 0.81132075 0.79245283 0.67924528]\n평균: 0.7301537386443047\n표준편차: 0.05141448587329709\n\n\n- KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel2 = KNeighborsClassifier(n_neighbors=5)\n\ncv_score = cross_val_score(model2, x_train_s, y_train,cv=10)\n\n# 확인\nprint(cv_score)\nprint('평균:', cv_score.mean())\nprint('표준편차:', cv_score.std())\nresult[\"KNN\"] = cv_score.mean()\n\n[0.64814815 0.68518519 0.72222222 0.64814815 0.72222222 0.74074074\n 0.68518519 0.66037736 0.77358491 0.60377358]\n평균: 0.6889587700908455\n표준편차: 0.04846522080635871\n\n\n- 로지스틱\n\nfrom sklearn.linear_model  import LogisticRegression\n\nmodel3 = LogisticRegression()\n\ncv_score = cross_val_score(model3, x_train, y_train, cv = 10)\n\nresult[\"Logistic\"] = cv_score.mean()\n\n- 결과\n\nk-fold 교차검증결과 : Logisitc 모형이 성능이 가장 좋아보인다.\n\n\nresult\n\n{'Decision Tree': 0.7301537386443047,\n 'KNN': 0.6889587700908455,\n 'Logistic': 0.7690426275331936}\n\n\n\n\n\n\nplt.figure(figsize = (4,4))\nplt.barh(y=list(result), width = result.values(), height = 0.5)\n\n&lt;BarContainer object of 3 artists&gt;\n\n\n\n\n\n\n\n\n- fitting을 다시 하는 이유\n\ntrain data set의 전체 데이터로 학습한 적은 없음……\n\n\ndef score(range = [0.5, 0.71]) : \n            fig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\n            fig.update_yaxes(range = range)\n            return fig\n\n\nmodel3.fit(x_train, y_train)\n\ny_pred = model3.predict(x_test)\n\nfrom sklearn.metrics import * \n\nacc = accuracy_score(y_test,y_pred)\npre = precision_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nf1_score = f1_score(y_test,y_pred)\n\n\nscore(range = [0.5,0.8])\n\n\n                                                \n\n\n\n\n\n\n\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/boston.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 506 entries, 0 to 505\nData columns (total 14 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   crim     506 non-null    float64\n 1   zn       506 non-null    float64\n 2   indus    506 non-null    float64\n 3   chas     506 non-null    int64  \n 4   nox      506 non-null    float64\n 5   rm       506 non-null    float64\n 6   age      506 non-null    float64\n 7   dis      506 non-null    float64\n 8   rad      506 non-null    int64  \n 9   tax      506 non-null    int64  \n 10  ptratio  506 non-null    float64\n 11  black    506 non-null    float64\n 12  lstat    506 non-null    float64\n 13  medv     506 non-null    float64\ndtypes: float64(11), int64(3)\nmemory usage: 55.5 KB\n\n\n\ndata.head()\n\n\n\n\n\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nblack\nlstat\nmedv\n\n\n\n\n0\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n1\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n2\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n3\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n4\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n\n\n\n\n\n\ndata.isna().sum()\n\ncrim       0\nzn         0\nindus      0\nchas       0\nnox        0\nrm         0\nage        0\ndis        0\nrad        0\ntax        0\nptratio    0\nblack      0\nlstat      0\nmedv       0\ndtype: int64\n\n\n\n\n\n\ntarget = \"medv\"\n\nx = data.drop(target, axis = 1)\ny = data[[target]]\n\nfrom sklearn.preprocessing import MinMaxScaler\n# 정규화\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\n\n\nmodel1 = DecisionTreeRegressor(max_depth = 5)\nmodel2 = KNeighborsRegressor(n_neighbors=5)\nmodel3 = LinearRegression()\n\ncv_score1 = cross_val_score(model1, x_train, y_train, cv = 10, scoring = \"r2\")\ncv_score2 = cross_val_score(model2, x_train_s, y_train, cv = 10, scoring = \"r2\")\ncv_score3 = cross_val_score(model3, x_train, y_train, cv = 10, scoring = \"r2\")\n\nresult = pd.DataFrame({\"model\" : [\"tree\", \"knn\", \"linear reg\"],\n                            \"score\" : [cv_score1.mean(),cv_score2.mean(), cv_score3.mean()]})\n\n\nresult.sort_values(\"score\", ascending = False).\\\n                    plot(y = \"model\", x= \"score\", kind =\"barh\",\n                            backend = \"plotly\", color = \"model\")\n\n\n                                                \n\n\n\n\n\n\nmodel = DecisionTreeRegressor()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nmeasure = [\"MAE\", \"R2\"]\nscore = [mean_absolute_error(y_test, y_pred) ,r2_score(y_test, y_pred)]\n\n\npd.DataFrame({ \"measure\" : measure, \n                             \"score\" : score}).sort_values(\"score\", ascending = False).\\\n                                        plot( y= \"measure\", x=\"score\", kind = \"barh\", backend =\"plotly\", color = \"measure\")\n\n\n                                                \n\n\n\n\n\n\n\n\n데이터 설명\n\nCOLLEGE: 대학 졸업여부\nINCOME: 연수입\nOVERAGE: 월평균 초과사용 시간(분)\nLEFTOVER: 월평균 잔여시간비율(%)\nHOUSE: 집값\nHANDSET_PRICE: 스마트폰 가격\nOVER_15MINS_CALLS_PER_MONTH: 월평균 장기통화(15분이상) 횟수\nAVERAGE_CALL_DURATION: 평균 통화 시간\nREPORTED_SATISFACTION: 만족도 설문조사 결과\nREPORTED_USAGE_LEVEL: 사용도 자가진단 결과\nCONSIDERING_CHANGE_OF_PLAN: 향후 변경계획 설문조사 결과\nCHURN: 이탈(번호이동) 여부 (Target 변수)\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/mobile_cust_churn.csv'\ndata = pd.read_csv(path)\n\n\n# 데이터 살펴보기\ndata.head()\n\n\n\n\n\n\n\n\nid\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n1\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\nSTAY\n\n\n1\n2\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\nSTAY\n\n\n2\n3\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\nSTAY\n\n\n3\n4\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\nLEAVE\n\n\n4\n5\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\nSTAY\n\n\n\n\n\n\n\n\n\n\n\ndata.drop(\"id\", axis = 1, inplace =True)\ndata.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\nSTAY\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\nSTAY\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\nSTAY\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\nLEAVE\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\nSTAY\n\n\n\n\n\n\n\n- x, y 분리\n\ntarget = \"CHURN\"\n\nx = data.drop(target, axis = 1)\ny = [1 if i == \"LEAVE\" else 0 for i in data[target]]\n\n- 가변수화\n\nd_cols = [\"REPORTED_SATISFACTION\", \"REPORTED_USAGE_LEVEL\", \"CONSIDERING_CHANGE_OF_PLAN\"]\n\nx = pd.get_dummies(x, columns= d_cols, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION_sat\nREPORTED_SATISFACTION_unsat\nREPORTED_SATISFACTION_very_sat\nREPORTED_SATISFACTION_very_unsat\nREPORTED_USAGE_LEVEL_high\nREPORTED_USAGE_LEVEL_little\nREPORTED_USAGE_LEVEL_very_high\nREPORTED_USAGE_LEVEL_very_little\nCONSIDERING_CHANGE_OF_PLAN_considering\nCONSIDERING_CHANGE_OF_PLAN_never_thought\nCONSIDERING_CHANGE_OF_PLAN_no\nCONSIDERING_CHANGE_OF_PLAN_perhaps\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습용 평가 데이터 분리\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n- 정규화\n\nfrom sklearn.preprocessing import MinMaxScaler\n# 정규화\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nmodel1 = DecisionTreeClassifier(max_depth= 5, random_state = 1)\nmodel2 = KNeighborsClassifier(n_neighbors=5)\nmodel3 = LogisticRegression(random_state = 1)\n\ncvs1 = cross_val_score(model1, x_train, y_train, cv = 10).mean()\ncvs2 = cross_val_score(model2, x_train_s, y_train, cv = 10).mean()\ncvs3 = cross_val_score(model3, x_train, y_train, cv = 10).mean()\n\nresult = pd.DataFrame({\"model\" : [\"tree\", \"knn\", \"logistic\"],\n                                           \"score\" : [cvs1, cvs2, cvs3]})\n\n\nresult.sort_values(\"score\", ascending = False).\\\n                        plot(x = \"score\", y = \"model\", kind = \"barh\",\n                                backend = \"plotly\",color = \"model\")\n\n\n                                                \n\n\n\n\n\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nfrom sklearn import metrics\nacc, pre, recall, f1_score = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), metrics.f1_score(y_test, y_pred)\n\n\ndef score(range = [0.5, 0.71]) : \n            fig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\n            fig.update_yaxes(range = range)\n            return fig\n\n\nscore([0.5,0.65])"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#개념",
    "href": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#개념",
    "title": "03. 머신러닝 (3)",
    "section": "",
    "text": "모든 데이터가 평가에 한 번, 학습에 k-1번 사용\nK개의 분할(Fold)에 대한 성능을 예측 → 평균과 표준편차 계산 → 일반화 성능\n단, k는 2 이상이 되어야 함(최소한 한 개씩의 학습용, 검증용 데이터가 필요)"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#장단점",
    "href": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#장단점",
    "title": "03. 머신러닝 (3)",
    "section": "",
    "text": "장점\n\n\n모든 데이터를 학습과 평가에 사용할 수 있음\n반복 학습과 평가를 통해 정확도를 향상시킬 수 있음\n데이터가 부족해서 발생하는 과소적합 문제를 방지할 수 있음\n평가에 사용되는 데이터의 편향을 막을 수 있음\n좀 더 일반화된 모델을 만들 수 있음\n\n\n단점\n\n\n반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요됨"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#실습",
    "href": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#실습",
    "title": "03. 머신러닝 (3)",
    "section": "",
    "text": "# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format='retina'\n\n\n\n데이터설명\n\nPregnancies: 임신 횟수\nGlucose: 포도당 부하 검사 수치\nBloodPressure: 혈압(mm Hg)\nSkinThickness: 팔 삼두근 뒤쪽의 피하지방 측정값(mm)\nInsulin: 혈청 인슐린(mu U/ml)\nBMI: 체질량지수(체중(kg)/키(m))^2\nDiabetesPedigreeFunction: 당뇨 내력 가중치 값\nAge: 나이\nOutcome: 클래스 결정 값(0 또는 1)\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/diabetes.csv'\ndata = pd.read_csv(path)\n\n\n# 데이터 살펴보기\ndata.head()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\n0\n6\n148\n72\n35\n0\n33.6\n0.627\n50\n1\n\n\n1\n1\n85\n66\n29\n0\n26.6\n0.351\n31\n0\n\n\n2\n8\n183\n64\n0\n0\n23.3\n0.672\n32\n1\n\n\n3\n1\n89\n66\n23\n94\n28.1\n0.167\n21\n0\n\n\n4\n0\n137\n40\n35\n168\n43.1\n2.288\n33\n1\n\n\n\n\n\n\n\n\n# 기술통계 확인\ndata.describe()\n\n\n\n\n\n\n\n\nPregnancies\nGlucose\nBloodPressure\nSkinThickness\nInsulin\nBMI\nDiabetesPedigreeFunction\nAge\nOutcome\n\n\n\n\ncount\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n768.000000\n\n\nmean\n3.845052\n120.894531\n69.105469\n20.536458\n79.799479\n31.992578\n0.471876\n33.240885\n0.348958\n\n\nstd\n3.369578\n31.972618\n19.355807\n15.952218\n115.244002\n7.884160\n0.331329\n11.760232\n0.476951\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.078000\n21.000000\n0.000000\n\n\n25%\n1.000000\n99.000000\n62.000000\n0.000000\n0.000000\n27.300000\n0.243750\n24.000000\n0.000000\n\n\n50%\n3.000000\n117.000000\n72.000000\n23.000000\n30.500000\n32.000000\n0.372500\n29.000000\n0.000000\n\n\n75%\n6.000000\n140.250000\n80.000000\n32.000000\n127.250000\n36.600000\n0.626250\n41.000000\n1.000000\n\n\nmax\n17.000000\n199.000000\n122.000000\n99.000000\n846.000000\n67.100000\n2.420000\n81.000000\n1.000000\n\n\n\n\n\n\n\n\n\n\n\n# Target 확인\ntarget = 'Outcome'\n\n# 데이터 분리\nx = data.drop(target, axis=1)\ny = data.loc[:, target]\n\n\n# 라이브러리 불러오기\nfrom sklearn.model_selection import train_test_split\n\n# 학습용, 평가용 데이터 7:3으로 분리\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n- 정규화\n\nKNN 알고리즘을 사용하기 위해 정규화를 진행\n\n\n# 모듈 불러오기\nfrom sklearn.preprocessing import MinMaxScaler\n\n# 정규화\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n\n- 의사결정나무\n\n# 불러오기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 선언하기\nmodel = DecisionTreeClassifier(max_depth=5,  random_state=1)\n\n# 검증하기\ncv_score = cross_val_score(model, x_train, y_train, cv=10)\n\n# 확인\nprint(cv_score)\nprint('평균:', cv_score.mean())\nprint('표준편차:', cv_score.std())\n\n# 기록\nresult = {}\nresult[\"Decision Tree\"] = cv_score.mean()\n\n[0.66666667 0.75925926 0.74074074 0.64814815 0.7037037  0.74074074\n 0.75925926 0.81132075 0.79245283 0.67924528]\n평균: 0.7301537386443047\n표준편차: 0.05141448587329709\n\n\n- KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel2 = KNeighborsClassifier(n_neighbors=5)\n\ncv_score = cross_val_score(model2, x_train_s, y_train,cv=10)\n\n# 확인\nprint(cv_score)\nprint('평균:', cv_score.mean())\nprint('표준편차:', cv_score.std())\nresult[\"KNN\"] = cv_score.mean()\n\n[0.64814815 0.68518519 0.72222222 0.64814815 0.72222222 0.74074074\n 0.68518519 0.66037736 0.77358491 0.60377358]\n평균: 0.6889587700908455\n표준편차: 0.04846522080635871\n\n\n- 로지스틱\n\nfrom sklearn.linear_model  import LogisticRegression\n\nmodel3 = LogisticRegression()\n\ncv_score = cross_val_score(model3, x_train, y_train, cv = 10)\n\nresult[\"Logistic\"] = cv_score.mean()\n\n- 결과\n\nk-fold 교차검증결과 : Logisitc 모형이 성능이 가장 좋아보인다.\n\n\nresult\n\n{'Decision Tree': 0.7301537386443047,\n 'KNN': 0.6889587700908455,\n 'Logistic': 0.7690426275331936}\n\n\n\n\n\n\nplt.figure(figsize = (4,4))\nplt.barh(y=list(result), width = result.values(), height = 0.5)\n\n&lt;BarContainer object of 3 artists&gt;\n\n\n\n\n\n\n\n\n- fitting을 다시 하는 이유\n\ntrain data set의 전체 데이터로 학습한 적은 없음……\n\n\ndef score(range = [0.5, 0.71]) : \n            fig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\n            fig.update_yaxes(range = range)\n            return fig\n\n\nmodel3.fit(x_train, y_train)\n\ny_pred = model3.predict(x_test)\n\nfrom sklearn.metrics import * \n\nacc = accuracy_score(y_test,y_pred)\npre = precision_score(y_test,y_pred)\nrecall = recall_score(y_test,y_pred)\nf1_score = f1_score(y_test,y_pred)\n\n\nscore(range = [0.5,0.8])"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#exercise.-1",
    "href": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#exercise.-1",
    "title": "03. 머신러닝 (3)",
    "section": "",
    "text": "# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/boston.csv'\ndata = pd.read_csv(path)\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 506 entries, 0 to 505\nData columns (total 14 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   crim     506 non-null    float64\n 1   zn       506 non-null    float64\n 2   indus    506 non-null    float64\n 3   chas     506 non-null    int64  \n 4   nox      506 non-null    float64\n 5   rm       506 non-null    float64\n 6   age      506 non-null    float64\n 7   dis      506 non-null    float64\n 8   rad      506 non-null    int64  \n 9   tax      506 non-null    int64  \n 10  ptratio  506 non-null    float64\n 11  black    506 non-null    float64\n 12  lstat    506 non-null    float64\n 13  medv     506 non-null    float64\ndtypes: float64(11), int64(3)\nmemory usage: 55.5 KB\n\n\n\ndata.head()\n\n\n\n\n\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nblack\nlstat\nmedv\n\n\n\n\n0\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n396.90\n4.98\n24.0\n\n\n1\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n396.90\n9.14\n21.6\n\n\n2\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n392.83\n4.03\n34.7\n\n\n3\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n394.63\n2.94\n33.4\n\n\n4\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n396.90\n5.33\n36.2\n\n\n\n\n\n\n\n\ndata.isna().sum()\n\ncrim       0\nzn         0\nindus      0\nchas       0\nnox        0\nrm         0\nage        0\ndis        0\nrad        0\ntax        0\nptratio    0\nblack      0\nlstat      0\nmedv       0\ndtype: int64\n\n\n\n\n\n\ntarget = \"medv\"\n\nx = data.drop(target, axis = 1)\ny = data[[target]]\n\nfrom sklearn.preprocessing import MinMaxScaler\n# 정규화\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\n\n\nmodel1 = DecisionTreeRegressor(max_depth = 5)\nmodel2 = KNeighborsRegressor(n_neighbors=5)\nmodel3 = LinearRegression()\n\ncv_score1 = cross_val_score(model1, x_train, y_train, cv = 10, scoring = \"r2\")\ncv_score2 = cross_val_score(model2, x_train_s, y_train, cv = 10, scoring = \"r2\")\ncv_score3 = cross_val_score(model3, x_train, y_train, cv = 10, scoring = \"r2\")\n\nresult = pd.DataFrame({\"model\" : [\"tree\", \"knn\", \"linear reg\"],\n                            \"score\" : [cv_score1.mean(),cv_score2.mean(), cv_score3.mean()]})\n\n\nresult.sort_values(\"score\", ascending = False).\\\n                    plot(y = \"model\", x= \"score\", kind =\"barh\",\n                            backend = \"plotly\", color = \"model\")\n\n\n                                                \n\n\n\n\n\n\nmodel = DecisionTreeRegressor()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nmeasure = [\"MAE\", \"R2\"]\nscore = [mean_absolute_error(y_test, y_pred) ,r2_score(y_test, y_pred)]\n\n\npd.DataFrame({ \"measure\" : measure, \n                             \"score\" : score}).sort_values(\"score\", ascending = False).\\\n                                        plot( y= \"measure\", x=\"score\", kind = \"barh\", backend =\"plotly\", color = \"measure\")"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#exercise.-2",
    "href": "posts/DX/04. 머신러닝/2023-09-14-03. 머신러닝 (3).html#exercise.-2",
    "title": "03. 머신러닝 (3)",
    "section": "",
    "text": "데이터 설명\n\nCOLLEGE: 대학 졸업여부\nINCOME: 연수입\nOVERAGE: 월평균 초과사용 시간(분)\nLEFTOVER: 월평균 잔여시간비율(%)\nHOUSE: 집값\nHANDSET_PRICE: 스마트폰 가격\nOVER_15MINS_CALLS_PER_MONTH: 월평균 장기통화(15분이상) 횟수\nAVERAGE_CALL_DURATION: 평균 통화 시간\nREPORTED_SATISFACTION: 만족도 설문조사 결과\nREPORTED_USAGE_LEVEL: 사용도 자가진단 결과\nCONSIDERING_CHANGE_OF_PLAN: 향후 변경계획 설문조사 결과\nCHURN: 이탈(번호이동) 여부 (Target 변수)\n\n\n# 데이터 읽어오기\npath = 'https://raw.githubusercontent.com/Jangrae/csv/master/mobile_cust_churn.csv'\ndata = pd.read_csv(path)\n\n\n# 데이터 살펴보기\ndata.head()\n\n\n\n\n\n\n\n\nid\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n1\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\nSTAY\n\n\n1\n2\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\nSTAY\n\n\n2\n3\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\nSTAY\n\n\n3\n4\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\nLEAVE\n\n\n4\n5\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\nSTAY\n\n\n\n\n\n\n\n\n\n\n\ndata.drop(\"id\", axis = 1, inplace =True)\ndata.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION\nREPORTED_USAGE_LEVEL\nCONSIDERING_CHANGE_OF_PLAN\nCHURN\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\nunsat\nlittle\nno\nSTAY\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\nunsat\nlittle\nconsidering\nSTAY\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\nunsat\nvery_little\nperhaps\nSTAY\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\nunsat\nvery_high\nconsidering\nLEAVE\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\nvery_unsat\nlittle\nnever_thought\nSTAY\n\n\n\n\n\n\n\n- x, y 분리\n\ntarget = \"CHURN\"\n\nx = data.drop(target, axis = 1)\ny = [1 if i == \"LEAVE\" else 0 for i in data[target]]\n\n- 가변수화\n\nd_cols = [\"REPORTED_SATISFACTION\", \"REPORTED_USAGE_LEVEL\", \"CONSIDERING_CHANGE_OF_PLAN\"]\n\nx = pd.get_dummies(x, columns= d_cols, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nCOLLEGE\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nREPORTED_SATISFACTION_sat\nREPORTED_SATISFACTION_unsat\nREPORTED_SATISFACTION_very_sat\nREPORTED_SATISFACTION_very_unsat\nREPORTED_USAGE_LEVEL_high\nREPORTED_USAGE_LEVEL_little\nREPORTED_USAGE_LEVEL_very_high\nREPORTED_USAGE_LEVEL_very_little\nCONSIDERING_CHANGE_OF_PLAN_considering\nCONSIDERING_CHANGE_OF_PLAN_never_thought\nCONSIDERING_CHANGE_OF_PLAN_no\nCONSIDERING_CHANGE_OF_PLAN_perhaps\n\n\n\n\n0\n0\n31953\n0\n6\n313378\n161\n0\n4\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n1\n36147\n0\n13\n800586\n244\n0\n6\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n1\n27273\n230\n0\n305049\n201\n16\n15\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n\n\n3\n0\n120070\n38\n33\n788235\n780\n3\n2\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n4\n1\n29215\n208\n85\n224784\n241\n21\n1\n0.0\n0.0\n0.0\n1.0\n0.0\n1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습용 평가 데이터 분리\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n- 정규화\n\nfrom sklearn.preprocessing import MinMaxScaler\n# 정규화\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nmodel1 = DecisionTreeClassifier(max_depth= 5, random_state = 1)\nmodel2 = KNeighborsClassifier(n_neighbors=5)\nmodel3 = LogisticRegression(random_state = 1)\n\ncvs1 = cross_val_score(model1, x_train, y_train, cv = 10).mean()\ncvs2 = cross_val_score(model2, x_train_s, y_train, cv = 10).mean()\ncvs3 = cross_val_score(model3, x_train, y_train, cv = 10).mean()\n\nresult = pd.DataFrame({\"model\" : [\"tree\", \"knn\", \"logistic\"],\n                                           \"score\" : [cvs1, cvs2, cvs3]})\n\n\nresult.sort_values(\"score\", ascending = False).\\\n                        plot(x = \"score\", y = \"model\", kind = \"barh\",\n                                backend = \"plotly\",color = \"model\")\n\n\n                                                \n\n\n\n\n\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nfrom sklearn import metrics\nacc, pre, recall, f1_score = accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred), metrics.f1_score(y_test, y_pred)\n\n\ndef score(range = [0.5, 0.71]) : \n            fig = pd.DataFrame({\"score\" : [acc,pre,recall,f1_score],\n                            \"measure\" : [\"acc\",\"precision\",\"recall\",\"f1_score\"]}).\\\n                                    plot(x = \"measure\", y = \"score\",  color = \"measure\",\n                                            backend = \"plotly\", kind =  \"bar\",height = 500, width = 600)\n            fig.update_yaxes(range = range)\n            return fig\n\n\nscore([0.5,0.65])"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-15-05. 종합실습.html",
    "href": "posts/DX/04. 머신러닝/2023-09-15-05. 종합실습.html",
    "title": "05. 종합실습",
    "section": "",
    "text": "0. import\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\nimport plotly.express as px\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n1. 데이터 이해\n\n# 데이터 불러오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/airline_satisfaction_small.csv'\ndata = pd.read_csv(path)\n\n\n# 데이터 살펴보기\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\ndeparture/arrival_time_convenient\nease_of_online_booking\n...\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\ndeparture_delay_in_minutes\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\n70172\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n4\n3\n...\n5\n4\n3\n4\n4\n5\n5\n25\n18.0\n0\n\n\n1\n5047\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n2\n3\n...\n1\n1\n5\n3\n1\n4\n1\n1\n6.0\n0\n\n\n2\n110028\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n2\n...\n5\n4\n3\n4\n4\n4\n5\n0\n0.0\n1\n\n\n3\n24026\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n5\n...\n2\n2\n5\n3\n1\n4\n2\n11\n9.0\n0\n\n\n4\n119299\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n3\n...\n3\n3\n4\n4\n3\n3\n3\n0\n0.0\n1\n\n\n\n\n5 rows × 24 columns\n\n\n\n데이터 설명\n\nid : 탑승자 고유 아이디\ngender: 성별 (Female, Male)\ncustomer_type: 고객 유형 (Loyal customer, disloyal customer)\nage: 탑승자 나이\ntype_of_travel: 비행 목적(Personal Travel, Business Travel)\nclass: 등급 (Business, Eco, Eco Plus)\nflight_distance: 비행 거리\ninflight_wifi_service: 와이파이 서비스 만족도 (0:N/A; 1-5)\ndeparture/arrival_time_convenient: 출발, 도착 시간 만족도 (0:N/A; 1-5)\nease_of_online_booking: 온라인 부킹 만족도 (0:N/A; 1-5)\ngate_location: 게이트 위치 만족도 (0:N/A; 1-5)\nfood_and_drink: 식사와 음료 만족도 (0:N/A; 1-5)\nonline_boarding: 온라인 보딩 만족도 (0:N/A; 1-5)\nseat_comfort: 좌석 편안함 만족도 (0:N/A; 1-5)\ninflight_entertainment: 기내 엔터테인먼트 만족도 (0:N/A; 1-5)\non-board_service: 온 보드 서비스 만족도 (0:N/A; 1-5)\nleg_room_service: 다리 공간 만족도 (0:N/A; 1-5)\nbaggage_handling: 수하물 처리 만족도 (0:N/A; 1-5)\ncheck-in_service: 체크인 서비스 만족도 (0:N/A; 1-5)\ninflight_service: 기내 서비스 만족도 (0:N/A; 1-5)\ncleanliness: 청결 만족도 (0:N/A; 1-5)\ndeparture_delay_in_minutes: 출발 지연 시간(분)\narrival_delay_in_minutes: 도착 지연 시간(분)\nsatisfaction: 항공 만족도(1: Satisfaction, 0: Neutral or Dissatisfaction) - Target\n\n\n\n2. 데이터 준비\n\n# 변수 제거\nd_cols = [\"id\", \"departure/arrival_time_convenient\", \"gate_location\", \"departure_delay_in_minutes\"]\n\n\ndata.drop(d_cols,axis=1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n0\n\n\n1\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n0\n\n\n2\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n1\n\n\n3\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0\n\n\n4\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1\n\n\n\n\n\n\n\n\n# 결측치 제거\nprint(data.isna().sum())\n\nplt.hist(data[\"arrival_delay_in_minutes\"],bins = 50)\nplt.show()\n\ngender                      0\ncustomer_type               0\nage                         0\ntype_of_travel              0\nclass                       0\nflight_distance             0\ninflight_wifi_service       0\nease_of_online_booking      0\nfood_and_drink              0\nonline_boarding             0\nseat_comfort                0\ninflight_entertainment      0\non-board_service            0\nleg_room_service            0\nbaggage_handling            0\ncheckin_service             0\ninflight_service            0\ncleanliness                 0\narrival_delay_in_minutes    6\nsatisfaction                0\ndtype: int64\n\n\n\n\n\n- 그래프를 그려본 결과 대부분의 값들이 0값으로 몰려있고, 왼쪽으로 치우쳐진 형태이다.\n\n결측값을 0으로 대체\n\n\ndata[\"arrival_delay_in_minutes\"].fillna(0,inplace = True)\ndata.isna().sum()\n\ngender                      0\ncustomer_type               0\nage                         0\ntype_of_travel              0\nclass                       0\nflight_distance             0\ninflight_wifi_service       0\nease_of_online_booking      0\nfood_and_drink              0\nonline_boarding             0\nseat_comfort                0\ninflight_entertainment      0\non-board_service            0\nleg_room_service            0\nbaggage_handling            0\ncheckin_service             0\ninflight_service            0\ncleanliness                 0\narrival_delay_in_minutes    0\nsatisfaction                0\ndtype: int64\n\n\n- x, y 분리\n\ntarget = \"satisfaction\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd = [\"gender\", \"customer_type\", \"type_of_travel\", \"class\"]\n\nx = pd.get_dummies(x, columns = d, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nage\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\ngender_Male\ncustomer_type_disloyal Customer\ntype_of_travel_Personal Travel\nclass_Eco\nclass_Eco Plus\n\n\n\n\n0\n13\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n1.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n25\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n1.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n26\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n25\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n61\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습용, 평가용 데이터 분리\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n- 정규화\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n# 정규화\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_s = scaler.transform(x_train)\nx_test_s = scaler.transform(x_test)\n\n\n\n3. 모델 성능 예측 (k-fold cv)\n\n# 1. knn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.cv = cross_val_score(knn, x_train_s, y_train, cv = 5)\n\nknn.cv_m = knn.cv.mean()\n\n# 2. tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\n\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\n\ntree.cv_m = tree.cv.mean()\n\n# 3. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\n\nlogit.cv_m = logit.cv.mean()\n\n# 4. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\n\nrf.cv = cross_val_score(rf, x_train,y_train)\n\nrf.cv_m = rf.cv.mean()\n\n# 5. XGBoost\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\n\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\n\nxgb.cv_m  = xgb.cv.mean()\n\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(max_depth = 5, random_state = 1,verbose = -100) \n\nlgbm.cv = cross_val_score(lgbm, x_train, y_train, cv = 5)\n\nlgbm.cv_m = lgbm.cv.mean()\n\n\nresult = [knn.cv_m, tree.cv_m, logit.cv_m, rf.cv_m,  xgb.cv_m, lgbm.cv_m]\nmodel = [\"knn\",\"tree\",\"logit\", \"rf\", \"xgb\", \"lgbm\"]\n\nfig = pd.DataFrame({\"model\" : model, \"result\" : result}).\\\n            sort_values(\"result\", ascending = False).plot(x = \"result\", y = \"model\", kind = \"bar\", backend = \"plotly\",color = \"model\")\n\nfig.update_xaxes(range = [0.7, 1.0])\n\n\n                                                \n\n\n\n\n4. 모델 튜닝(여기부터 다시…)\n- XGB가 가장 성능이 잘 된 모델이라고 가정\n\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring='r2')\n\n\nmodel.fit(x_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='r2')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='r2')estimator: XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)\n\n\n\ny_pred = model.predict(x_test)\n\n\n# 예측 결과 확인\nprint(model.best_params_)\nprint(model.best_score_)\n\n{'max_depth': 3}\n0.7376528379505405\n\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmeasure = [\"accuracy\", \"precision\", \"reacll\", \"f1-score\"]\n\nacc = accuracy_score(y_test, y_pred)\npre = precision_score(y_test, y_pred)\nre = recall_score(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred)\n\n\npd.DataFrame({\"measure\" : measure, \"score\" : [acc, pre, re, f1_score]})\n\n\n\n\n\n\n\n\nmeasure\nscore\n\n\n\n\n0\naccuracy\n0.931525\n\n\n1\nprecision\n0.949102\n\n\n2\nreacll\n0.898017\n\n\n3\nf1-score\n0.922853"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-19-07. 머신러닝 (6).html",
    "href": "posts/DX/04. 머신러닝/2023-09-19-07. 머신러닝 (6).html",
    "title": "07. 머신러닝 (6)",
    "section": "",
    "text": "# 기본 라이브러리 가져오기\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import *\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n\ndata = pd.read_excel('bankrupt.xlsx')\ndata.head()\n\n\n\n\n\n\n\n\ntarget\ncol1\ncol2\ncol3\ncol4\ncol5\ncol6\ncol7\ncol8\ncol9\n...\ncol84\ncol85\ncol86\ncol87\ncol88\ncol89\ncol90\ncol91\ncol92\ncol93\n\n\n\n\n0\n1\n0.370594\n0.424389\n0.405750\n0.601457\n0.601457\n0.998969\n0.796887\n0.808809\n0.302646\n...\n0.118250\n0.716845\n0.009219\n0.622879\n0.601453\n0.827890\n0.290202\n0.026601\n0.564050\n0.016469\n\n\n1\n1\n0.464291\n0.538214\n0.516730\n0.610235\n0.610235\n0.998946\n0.797380\n0.809301\n0.303556\n...\n0.047775\n0.795297\n0.008323\n0.623652\n0.610237\n0.839969\n0.283846\n0.264577\n0.570175\n0.020794\n\n\n2\n1\n0.426071\n0.499019\n0.472295\n0.601450\n0.601364\n0.998857\n0.796403\n0.808388\n0.302035\n...\n0.025346\n0.774670\n0.040003\n0.623841\n0.601449\n0.836774\n0.290189\n0.026555\n0.563706\n0.016474\n\n\n3\n1\n0.399844\n0.451265\n0.457733\n0.583541\n0.583541\n0.998700\n0.796967\n0.808966\n0.303350\n...\n0.067250\n0.739555\n0.003252\n0.622929\n0.583538\n0.834697\n0.281721\n0.026697\n0.564663\n0.023982\n\n\n4\n1\n0.465022\n0.538432\n0.522298\n0.598783\n0.598783\n0.998973\n0.797366\n0.809304\n0.303475\n...\n0.047725\n0.795016\n0.003878\n0.623521\n0.598782\n0.839973\n0.278514\n0.024752\n0.575617\n0.035490\n\n\n\n\n5 rows × 94 columns\n\n\n\n\n#data.info()\n\n\ntarget = \"target\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\n\nx_train, x_val, y_train, y_val = train_test_split(x,y, random_state = 1, test_size = .3)\n\n- 거리계산 기반 차원축소이므로 스케일링이 필요\n\nscaler = MinMaxScaler()\n\nx_train_s = scaler.fit_transform(x_train)\nx_val_s = scaler.fit_transform(x_val)\n\n# 옵션 데이터프레임 변환\nx_train_s = pd.DataFrame(x_train_s, columns = list(x))\nx_val_s = pd.DataFrame(x_val_s, columns = list(x))\n\n\n\n\n주성분 만들기\n\n전체 변수의 수로 주성분을 생성\n분산 누적그래프를 그리고 적절한 주성분 수 선택\n\n적용\n\n저차원 시각화\n지도학습 연계\n\n\n\nfrom sklearn.decomposition import PCA\n\nn = x_train_s.shape[1]\nfor i in range(1,n+1):\n    exec(f\"pca{i} = PCA(n_components = {i})\")\n    exec(f\"x_train_pca{i} = pca{i}.fit_transform(x_train_s)\")\n\n- 적절한 주성분의 개수는 7개가 좋아보임\n\nplt.figure(figsize = (12, 4))\nplt.plot(pca93.explained_variance_ratio_,\"--.\",alpha=0.3)\nplt.xticks(range(1,n+1,2))\nplt.show()\n\n\n\n\n- 주성분 개수를 12개로 설정!\n\nx_train_pc = pd.DataFrame(x_train_pca12)\nx_val_pc = pd.DataFrame(pca12.fit_transform(x_val_s))\nx_train_pc.columns = [\"PC\" + str(i) for i  in range(1,13)]\nx_val_pc.columns = [\"PC\" + str(i) for i  in range(1,13)]\n\n- 상위 2개의 주성분을 뽑아 시각화 해보기\n\nsns.scatterplot(x = 'PC1', y = 'PC2', data = x_train_pc, hue = y_train)\n\n&lt;Axes: xlabel='PC1', ylabel='PC2'&gt;\n\n\n\n\n\n- 주성분간 상관관계 확인\n\nplt.figure(figsize = (12, 4))\nsns.heatmap(x_train_pc.corr(),\n            annot = True,\n            fmt = \".2f\",\n            cmap = \"Blues\")\n\n&lt;Axes: &gt;\n\n\n\n\n\n- 지도학습으로 연계\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import *\n\nmodel = LogisticRegression()\nmodel.fit(x_train_s, y_train)\n\ny_pred = model.predict(x_val_s)\n\n\nprint(classification_report(y_val, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98      1975\n           1       0.25      0.01      0.03        71\n\n    accuracy                           0.96      2046\n   macro avg       0.61      0.51      0.50      2046\nweighted avg       0.94      0.96      0.95      2046\n\n\n\n\nacc,pre,recall, f1 = accuracy_score(y_val,y_pred),precision_score(y_val,y_pred), recall_score(y_val, y_pred),f1_score(y_val,y_pred)\n\n\n\nCode\npd.DataFrame({\"score\" : [acc, pre, recall, f1],\n              \"measure\" : [\"accuracy\", \"precision\",\"recall\",\"f1_score\"]}).\\\n                sort_values(\"score\",ascending = False).\\\n                plot(x = \"score\", y = \"measure\", kind = \"barh\",\n                     backend = \"plotly\", color = \"measure\")\n\n\n\n                                                \n\n\n- 주성분분석으로 데이터 모델링\n\nKNN\n\n\nmodel2 = LogisticRegression()\nmodel2.fit(x_train_pc, y_train)\n\ny_pred = model2.predict(x_val_pc)\n\n\nconfusion_matrix(y_val, y_pred)\n\narray([[1970,    5],\n       [  71,    0]], dtype=int64)\n\n\n\nprint(classification_report(y_val, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98      1975\n           1       0.00      0.00      0.00        71\n\n    accuracy                           0.96      2046\n   macro avg       0.48      0.50      0.49      2046\nweighted avg       0.93      0.96      0.95      2046"
  },
  {
    "objectID": "posts/DX/04. 머신러닝/2023-09-19-07. 머신러닝 (6).html#pca",
    "href": "posts/DX/04. 머신러닝/2023-09-19-07. 머신러닝 (6).html#pca",
    "title": "07. 머신러닝 (6)",
    "section": "",
    "text": "주성분 만들기\n\n전체 변수의 수로 주성분을 생성\n분산 누적그래프를 그리고 적절한 주성분 수 선택\n\n적용\n\n저차원 시각화\n지도학습 연계\n\n\n\nfrom sklearn.decomposition import PCA\n\nn = x_train_s.shape[1]\nfor i in range(1,n+1):\n    exec(f\"pca{i} = PCA(n_components = {i})\")\n    exec(f\"x_train_pca{i} = pca{i}.fit_transform(x_train_s)\")\n\n- 적절한 주성분의 개수는 7개가 좋아보임\n\nplt.figure(figsize = (12, 4))\nplt.plot(pca93.explained_variance_ratio_,\"--.\",alpha=0.3)\nplt.xticks(range(1,n+1,2))\nplt.show()\n\n\n\n\n- 주성분 개수를 12개로 설정!\n\nx_train_pc = pd.DataFrame(x_train_pca12)\nx_val_pc = pd.DataFrame(pca12.fit_transform(x_val_s))\nx_train_pc.columns = [\"PC\" + str(i) for i  in range(1,13)]\nx_val_pc.columns = [\"PC\" + str(i) for i  in range(1,13)]\n\n- 상위 2개의 주성분을 뽑아 시각화 해보기\n\nsns.scatterplot(x = 'PC1', y = 'PC2', data = x_train_pc, hue = y_train)\n\n&lt;Axes: xlabel='PC1', ylabel='PC2'&gt;\n\n\n\n\n\n- 주성분간 상관관계 확인\n\nplt.figure(figsize = (12, 4))\nsns.heatmap(x_train_pc.corr(),\n            annot = True,\n            fmt = \".2f\",\n            cmap = \"Blues\")\n\n&lt;Axes: &gt;\n\n\n\n\n\n- 지도학습으로 연계\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import *\n\nmodel = LogisticRegression()\nmodel.fit(x_train_s, y_train)\n\ny_pred = model.predict(x_val_s)\n\n\nprint(classification_report(y_val, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98      1975\n           1       0.25      0.01      0.03        71\n\n    accuracy                           0.96      2046\n   macro avg       0.61      0.51      0.50      2046\nweighted avg       0.94      0.96      0.95      2046\n\n\n\n\nacc,pre,recall, f1 = accuracy_score(y_val,y_pred),precision_score(y_val,y_pred), recall_score(y_val, y_pred),f1_score(y_val,y_pred)\n\n\n\nCode\npd.DataFrame({\"score\" : [acc, pre, recall, f1],\n              \"measure\" : [\"accuracy\", \"precision\",\"recall\",\"f1_score\"]}).\\\n                sort_values(\"score\",ascending = False).\\\n                plot(x = \"score\", y = \"measure\", kind = \"barh\",\n                     backend = \"plotly\", color = \"measure\")\n\n\n\n                                                \n\n\n- 주성분분석으로 데이터 모델링\n\nKNN\n\n\nmodel2 = LogisticRegression()\nmodel2.fit(x_train_pc, y_train)\n\ny_pred = model2.predict(x_val_pc)\n\n\nconfusion_matrix(y_val, y_pred)\n\narray([[1970,    5],\n       [  71,    0]], dtype=int64)\n\n\n\nprint(classification_report(y_val, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98      1975\n           1       0.00      0.00      0.00        71\n\n    accuracy                           0.96      2046\n   macro avg       0.48      0.50      0.49      2046\nweighted avg       0.93      0.96      0.95      2046"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html",
    "title": "00. 딥러닝 (1)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import clear_session\n\nimport plotly.express as px"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#전처리",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#전처리",
    "title": "00. 딥러닝 (1)",
    "section": "(1) 전처리",
    "text": "(1) 전처리\n\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.fit_transform(x_test)"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#import-1",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#import-1",
    "title": "00. 딥러닝 (1)",
    "section": "(2) import",
    "text": "(2) import\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import clear_session"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#모델-선언",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#모델-선언",
    "title": "00. 딥러닝 (1)",
    "section": "(3) 모델 선언",
    "text": "(3) 모델 선언\n\nn_features = x_train.shape[1] ## 컬럼 개수\n\n\n# 메모리 정리\nclear_session()\n\n# Sequential 타입 모델 선언\nmodel = Sequential(Dense(1, input_shape = (n_features,)))\n\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 1)                 4         \n                                                                 \n=================================================================\nTotal params: 4 (16.00 Byte)\nTrainable params: 4 (16.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n- 초기 셋팅된 파라미터 값을 살펴보자.\n\n일단 아래와 같은 값으로 기본 셋팅이 되어있다…\n\n\nmodel.weights\n\n[&lt;tf.Variable 'dense/kernel:0' shape=(3, 1) dtype=float32, numpy=\n array([[ 0.21143973],\n        [-0.36714107],\n        [ 1.0211834 ]], dtype=float32)&gt;,\n &lt;tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;]\n\n\n- 일단 초기셋팅한값으로 test data를 적합시 얼만큼 잘 예측하는지 시각화 해보자..\n\nimport tensorflow.experimental.numpy as tnp\ntnp.experimental_enable_numpy_behavior() ## tnf 를 numpy 처럼 사용할 수 있도록 해줌\n\n- 일단 \\(X\\)를 우리가 잘 알고 있는 회귀 분석 형태로 바꿔주고 \\(y_{init}\\)를 예측\n\\[\\bf \\hat {y}_{init} = X \\bf{\\hat {\\beta}_{init}}\\]\n\nw_init = np.concatenate([tnp.array(model.weights[1]).reshape(1,1),\n                         tnp.array(model.weights[0])],axis = 0)\n\nx_test_matrix = np.concatenate([np.ones(x_test.shape[0]).reshape(-1,1),\n                                 x_test],axis = 1)\n\ny_pred_init = x_test_matrix @ w_init\n\n\ny_pred_init = x_test_matrix @ w_init\n\n- 초기값이라 그런지 잘 예측하는 것 같지는 않음\n\n\nCode\nplt.figure(figsize = (4,4))\nplt.plot(y_test,label = r\"$(y_{test})$\",alpha = 0.5)\nplt.plot(y_pred_init,label = r\"$(\\hat {y}_{init})$\",alpha = 0.6)\nplt.title(r\"($y_{test}, \\hat {y}_{init}$)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n- 이제 keras에서 제공하는 compile과 fit을 이용하여 모델 적합후 비교해보자\n\n## compile\nmodel.compile(optimizer = \"adam\", loss = \"mse\")\n\n## fit\nmodel.fit(x_train, y_train)\n\n5/5 [==============================] - 6s 5ms/step - loss: 219.7330\n\n\n&lt;keras.src.callbacks.History at 0x7ddedaf4cac0&gt;\n\n\n- 예측값 저장 (기본 epoch = 5 이므로 y_pred_5라고 저장)\n\ny_pred_5 = model.predict(x_test)\n\n2/2 [==============================] - 0s 9ms/step\n\n\n\n#model.predict?\n\n- 여전히 성능이 쓰레기임\n\n\nCode\nplt.figure(figsize = (4,4))\nplt.plot(y_test,label = r\"$(y_{test})$\",alpha = 0.5)\nplt.plot(y_pred_init,label = r\"$(\\hat {y}_{init})$\",alpha = 0.6)\nplt.plot(y_pred_5,label = r\"$(\\hat {y}_{5})$\",alpha = 0.6)\nplt.title(r\"($y_{test}, \\hat {y}_{init}, \\hat {y}_{5}$)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n- epochs를 늘려서 다시 예측해보자\n\nmodel.fit?\n\n\nmodel.compile?\n\n\n## compile\nmodel.compile(optimizer = \"adam\", loss = \"mse\")\n\n## fit\nmodel.fit(x_train, y_train, epochs = 1000)\n\ny_pred_final = model.predict(x_test,verbose = 0)\n\nEpoch 1/1000\n5/5 [==============================] - 1s 6ms/step - loss: 109.4172\nEpoch 2/1000\n5/5 [==============================] - 0s 5ms/step - loss: 109.1868\nEpoch 3/1000\n5/5 [==============================] - 0s 5ms/step - loss: 108.9626\nEpoch 4/1000\n5/5 [==============================] - 0s 5ms/step - loss: 108.7299\nEpoch 5/1000\n5/5 [==============================] - 0s 5ms/step - loss: 108.4981\nEpoch 6/1000\n5/5 [==============================] - 0s 5ms/step - loss: 108.2746\nEpoch 7/1000\n5/5 [==============================] - 0s 5ms/step - loss: 108.0486\nEpoch 8/1000\n5/5 [==============================] - 0s 7ms/step - loss: 107.8185\nEpoch 9/1000\n5/5 [==============================] - 0s 7ms/step - loss: 107.6013\nEpoch 10/1000\n5/5 [==============================] - 0s 6ms/step - loss: 107.3712\nEpoch 11/1000\n5/5 [==============================] - 0s 5ms/step - loss: 107.1475\nEpoch 12/1000\n5/5 [==============================] - 0s 5ms/step - loss: 106.9191\nEpoch 13/1000\n5/5 [==============================] - 0s 5ms/step - loss: 106.6953\nEpoch 14/1000\n5/5 [==============================] - 0s 4ms/step - loss: 106.4616\nEpoch 15/1000\n5/5 [==============================] - 0s 5ms/step - loss: 106.2446\nEpoch 16/1000\n5/5 [==============================] - 0s 7ms/step - loss: 106.0105\nEpoch 17/1000\n5/5 [==============================] - 0s 6ms/step - loss: 105.7884\nEpoch 18/1000\n5/5 [==============================] - 0s 5ms/step - loss: 105.5647\nEpoch 19/1000\n5/5 [==============================] - 0s 5ms/step - loss: 105.3465\nEpoch 20/1000\n5/5 [==============================] - 0s 5ms/step - loss: 105.1217\nEpoch 21/1000\n5/5 [==============================] - 0s 5ms/step - loss: 104.8943\nEpoch 22/1000\n5/5 [==============================] - 0s 6ms/step - loss: 104.6774\nEpoch 23/1000\n5/5 [==============================] - 0s 7ms/step - loss: 104.4532\nEpoch 24/1000\n5/5 [==============================] - 0s 5ms/step - loss: 104.2285\nEpoch 25/1000\n5/5 [==============================] - 0s 6ms/step - loss: 104.0009\nEpoch 26/1000\n5/5 [==============================] - 0s 8ms/step - loss: 103.7801\nEpoch 27/1000\n5/5 [==============================] - 0s 5ms/step - loss: 103.5532\nEpoch 28/1000\n5/5 [==============================] - 0s 5ms/step - loss: 103.3343\nEpoch 29/1000\n5/5 [==============================] - 0s 5ms/step - loss: 103.1174\nEpoch 30/1000\n5/5 [==============================] - 0s 5ms/step - loss: 102.8944\nEpoch 31/1000\n5/5 [==============================] - 0s 4ms/step - loss: 102.6777\nEpoch 32/1000\n5/5 [==============================] - 0s 4ms/step - loss: 102.4613\nEpoch 33/1000\n5/5 [==============================] - 0s 6ms/step - loss: 102.2449\nEpoch 34/1000\n5/5 [==============================] - 0s 7ms/step - loss: 102.0379\nEpoch 35/1000\n5/5 [==============================] - 0s 6ms/step - loss: 101.8212\nEpoch 36/1000\n5/5 [==============================] - 0s 8ms/step - loss: 101.6037\nEpoch 37/1000\n5/5 [==============================] - 0s 6ms/step - loss: 101.4005\nEpoch 38/1000\n5/5 [==============================] - 0s 6ms/step - loss: 101.1897\nEpoch 39/1000\n5/5 [==============================] - 0s 5ms/step - loss: 100.9803\nEpoch 40/1000\n5/5 [==============================] - 0s 7ms/step - loss: 100.7659\nEpoch 41/1000\n5/5 [==============================] - 0s 7ms/step - loss: 100.5528\nEpoch 42/1000\n5/5 [==============================] - 0s 7ms/step - loss: 100.3409\nEpoch 43/1000\n5/5 [==============================] - 0s 6ms/step - loss: 100.1284\nEpoch 44/1000\n5/5 [==============================] - 0s 7ms/step - loss: 99.9098\nEpoch 45/1000\n5/5 [==============================] - 0s 7ms/step - loss: 99.7002\nEpoch 46/1000\n5/5 [==============================] - 0s 7ms/step - loss: 99.4929\nEpoch 47/1000\n5/5 [==============================] - 0s 6ms/step - loss: 99.2754\nEpoch 48/1000\n5/5 [==============================] - 0s 6ms/step - loss: 99.0601\nEpoch 49/1000\n5/5 [==============================] - 0s 7ms/step - loss: 98.8559\nEpoch 50/1000\n5/5 [==============================] - 0s 7ms/step - loss: 98.6416\nEpoch 51/1000\n5/5 [==============================] - 0s 8ms/step - loss: 98.4370\nEpoch 52/1000\n5/5 [==============================] - 0s 6ms/step - loss: 98.2309\nEpoch 53/1000\n5/5 [==============================] - 0s 6ms/step - loss: 98.0138\nEpoch 54/1000\n5/5 [==============================] - 0s 6ms/step - loss: 97.8093\nEpoch 55/1000\n5/5 [==============================] - 0s 6ms/step - loss: 97.6044\nEpoch 56/1000\n5/5 [==============================] - 0s 6ms/step - loss: 97.3957\nEpoch 57/1000\n5/5 [==============================] - 0s 6ms/step - loss: 97.1901\nEpoch 58/1000\n5/5 [==============================] - 0s 4ms/step - loss: 96.9841\nEpoch 59/1000\n5/5 [==============================] - 0s 5ms/step - loss: 96.7849\nEpoch 60/1000\n5/5 [==============================] - 0s 6ms/step - loss: 96.5910\nEpoch 61/1000\n5/5 [==============================] - 0s 7ms/step - loss: 96.3754\nEpoch 62/1000\n5/5 [==============================] - 0s 5ms/step - loss: 96.1752\nEpoch 63/1000\n5/5 [==============================] - 0s 7ms/step - loss: 95.9621\nEpoch 64/1000\n5/5 [==============================] - 0s 6ms/step - loss: 95.7588\nEpoch 65/1000\n5/5 [==============================] - 0s 6ms/step - loss: 95.5547\nEpoch 66/1000\n5/5 [==============================] - 0s 7ms/step - loss: 95.3460\nEpoch 67/1000\n5/5 [==============================] - 0s 6ms/step - loss: 95.1421\nEpoch 68/1000\n5/5 [==============================] - 0s 6ms/step - loss: 94.9393\nEpoch 69/1000\n5/5 [==============================] - 0s 8ms/step - loss: 94.7284\nEpoch 70/1000\n5/5 [==============================] - 0s 6ms/step - loss: 94.5297\nEpoch 71/1000\n5/5 [==============================] - 0s 7ms/step - loss: 94.3307\nEpoch 72/1000\n5/5 [==============================] - 0s 8ms/step - loss: 94.1278\nEpoch 73/1000\n5/5 [==============================] - 0s 7ms/step - loss: 93.9289\nEpoch 74/1000\n5/5 [==============================] - 0s 6ms/step - loss: 93.7272\nEpoch 75/1000\n5/5 [==============================] - 0s 7ms/step - loss: 93.5285\nEpoch 76/1000\n5/5 [==============================] - 0s 6ms/step - loss: 93.3294\nEpoch 77/1000\n5/5 [==============================] - 0s 7ms/step - loss: 93.1322\nEpoch 78/1000\n5/5 [==============================] - 0s 7ms/step - loss: 92.9389\nEpoch 79/1000\n5/5 [==============================] - 0s 6ms/step - loss: 92.7353\nEpoch 80/1000\n5/5 [==============================] - 0s 8ms/step - loss: 92.5323\nEpoch 81/1000\n5/5 [==============================] - 0s 11ms/step - loss: 92.3321\nEpoch 82/1000\n5/5 [==============================] - 0s 7ms/step - loss: 92.1339\nEpoch 83/1000\n5/5 [==============================] - 0s 8ms/step - loss: 91.9349\nEpoch 84/1000\n5/5 [==============================] - 0s 6ms/step - loss: 91.7386\nEpoch 85/1000\n5/5 [==============================] - 0s 9ms/step - loss: 91.5411\nEpoch 86/1000\n5/5 [==============================] - 0s 6ms/step - loss: 91.3418\nEpoch 87/1000\n5/5 [==============================] - 0s 5ms/step - loss: 91.1438\nEpoch 88/1000\n5/5 [==============================] - 0s 5ms/step - loss: 90.9459\nEpoch 89/1000\n5/5 [==============================] - 0s 7ms/step - loss: 90.7521\nEpoch 90/1000\n5/5 [==============================] - 0s 9ms/step - loss: 90.5549\nEpoch 91/1000\n5/5 [==============================] - 0s 8ms/step - loss: 90.3532\nEpoch 92/1000\n5/5 [==============================] - 0s 6ms/step - loss: 90.1659\nEpoch 93/1000\n5/5 [==============================] - 0s 5ms/step - loss: 89.9669\nEpoch 94/1000\n5/5 [==============================] - 0s 4ms/step - loss: 89.7709\nEpoch 95/1000\n5/5 [==============================] - 0s 4ms/step - loss: 89.5775\nEpoch 96/1000\n5/5 [==============================] - 0s 4ms/step - loss: 89.3882\nEpoch 97/1000\n5/5 [==============================] - 0s 9ms/step - loss: 89.1998\nEpoch 98/1000\n5/5 [==============================] - 0s 4ms/step - loss: 89.0053\nEpoch 99/1000\n5/5 [==============================] - 0s 5ms/step - loss: 88.8156\nEpoch 100/1000\n5/5 [==============================] - 0s 6ms/step - loss: 88.6220\nEpoch 101/1000\n5/5 [==============================] - 0s 5ms/step - loss: 88.4300\nEpoch 102/1000\n5/5 [==============================] - 0s 7ms/step - loss: 88.2422\nEpoch 103/1000\n5/5 [==============================] - 0s 13ms/step - loss: 88.0466\nEpoch 104/1000\n5/5 [==============================] - 0s 5ms/step - loss: 87.8566\nEpoch 105/1000\n5/5 [==============================] - 0s 5ms/step - loss: 87.6699\nEpoch 106/1000\n5/5 [==============================] - 0s 5ms/step - loss: 87.4792\nEpoch 107/1000\n5/5 [==============================] - 0s 6ms/step - loss: 87.2927\nEpoch 108/1000\n5/5 [==============================] - 0s 4ms/step - loss: 87.1079\nEpoch 109/1000\n5/5 [==============================] - 0s 9ms/step - loss: 86.9185\nEpoch 110/1000\n5/5 [==============================] - 0s 5ms/step - loss: 86.7362\nEpoch 111/1000\n5/5 [==============================] - 0s 5ms/step - loss: 86.5498\nEpoch 112/1000\n5/5 [==============================] - 0s 5ms/step - loss: 86.3623\nEpoch 113/1000\n5/5 [==============================] - 0s 5ms/step - loss: 86.1762\nEpoch 114/1000\n5/5 [==============================] - 0s 8ms/step - loss: 85.9827\nEpoch 115/1000\n5/5 [==============================] - 0s 9ms/step - loss: 85.8061\nEpoch 116/1000\n5/5 [==============================] - 0s 6ms/step - loss: 85.6136\nEpoch 117/1000\n5/5 [==============================] - 0s 4ms/step - loss: 85.4308\nEpoch 118/1000\n5/5 [==============================] - 0s 5ms/step - loss: 85.2473\nEpoch 119/1000\n5/5 [==============================] - 0s 4ms/step - loss: 85.0604\nEpoch 120/1000\n5/5 [==============================] - 0s 5ms/step - loss: 84.8720\nEpoch 121/1000\n5/5 [==============================] - 0s 4ms/step - loss: 84.6853\nEpoch 122/1000\n5/5 [==============================] - 0s 5ms/step - loss: 84.4953\nEpoch 123/1000\n5/5 [==============================] - 0s 4ms/step - loss: 84.3089\nEpoch 124/1000\n5/5 [==============================] - 0s 5ms/step - loss: 84.1167\nEpoch 125/1000\n5/5 [==============================] - 0s 4ms/step - loss: 83.9305\nEpoch 126/1000\n5/5 [==============================] - 0s 5ms/step - loss: 83.7400\nEpoch 127/1000\n5/5 [==============================] - 0s 6ms/step - loss: 83.5551\nEpoch 128/1000\n5/5 [==============================] - 0s 4ms/step - loss: 83.3687\nEpoch 129/1000\n5/5 [==============================] - 0s 4ms/step - loss: 83.1797\nEpoch 130/1000\n5/5 [==============================] - 0s 5ms/step - loss: 82.9989\nEpoch 131/1000\n5/5 [==============================] - 0s 4ms/step - loss: 82.8167\nEpoch 132/1000\n5/5 [==============================] - 0s 4ms/step - loss: 82.6315\nEpoch 133/1000\n5/5 [==============================] - 0s 6ms/step - loss: 82.4512\nEpoch 134/1000\n5/5 [==============================] - 0s 4ms/step - loss: 82.2664\nEpoch 135/1000\n5/5 [==============================] - 0s 4ms/step - loss: 82.0849\nEpoch 136/1000\n5/5 [==============================] - 0s 5ms/step - loss: 81.9010\nEpoch 137/1000\n5/5 [==============================] - 0s 5ms/step - loss: 81.7232\nEpoch 138/1000\n5/5 [==============================] - 0s 5ms/step - loss: 81.5365\nEpoch 139/1000\n5/5 [==============================] - 0s 4ms/step - loss: 81.3612\nEpoch 140/1000\n5/5 [==============================] - 0s 5ms/step - loss: 81.1757\nEpoch 141/1000\n5/5 [==============================] - 0s 4ms/step - loss: 80.9972\nEpoch 142/1000\n5/5 [==============================] - 0s 4ms/step - loss: 80.8143\nEpoch 143/1000\n5/5 [==============================] - 0s 4ms/step - loss: 80.6310\nEpoch 144/1000\n5/5 [==============================] - 0s 5ms/step - loss: 80.4510\nEpoch 145/1000\n5/5 [==============================] - 0s 5ms/step - loss: 80.2664\nEpoch 146/1000\n5/5 [==============================] - 0s 4ms/step - loss: 80.0901\nEpoch 147/1000\n5/5 [==============================] - 0s 5ms/step - loss: 79.9080\nEpoch 148/1000\n5/5 [==============================] - 0s 4ms/step - loss: 79.7365\nEpoch 149/1000\n5/5 [==============================] - 0s 5ms/step - loss: 79.5604\nEpoch 150/1000\n5/5 [==============================] - 0s 7ms/step - loss: 79.3853\nEpoch 151/1000\n5/5 [==============================] - 0s 5ms/step - loss: 79.2035\nEpoch 152/1000\n5/5 [==============================] - 0s 5ms/step - loss: 79.0299\nEpoch 153/1000\n5/5 [==============================] - 0s 5ms/step - loss: 78.8572\nEpoch 154/1000\n5/5 [==============================] - 0s 8ms/step - loss: 78.6763\nEpoch 155/1000\n5/5 [==============================] - 0s 6ms/step - loss: 78.5045\nEpoch 156/1000\n5/5 [==============================] - 0s 5ms/step - loss: 78.3235\nEpoch 157/1000\n5/5 [==============================] - 0s 5ms/step - loss: 78.1519\nEpoch 158/1000\n5/5 [==============================] - 0s 5ms/step - loss: 77.9853\nEpoch 159/1000\n5/5 [==============================] - 0s 6ms/step - loss: 77.8087\nEpoch 160/1000\n5/5 [==============================] - 0s 5ms/step - loss: 77.6422\nEpoch 161/1000\n5/5 [==============================] - 0s 8ms/step - loss: 77.4701\nEpoch 162/1000\n5/5 [==============================] - 0s 6ms/step - loss: 77.3006\nEpoch 163/1000\n5/5 [==============================] - 0s 5ms/step - loss: 77.1299\nEpoch 164/1000\n5/5 [==============================] - 0s 5ms/step - loss: 76.9655\nEpoch 165/1000\n5/5 [==============================] - 0s 5ms/step - loss: 76.7956\nEpoch 166/1000\n5/5 [==============================] - 0s 4ms/step - loss: 76.6254\nEpoch 167/1000\n5/5 [==============================] - 0s 4ms/step - loss: 76.4598\nEpoch 168/1000\n5/5 [==============================] - 0s 6ms/step - loss: 76.2882\nEpoch 169/1000\n5/5 [==============================] - 0s 6ms/step - loss: 76.1207\nEpoch 170/1000\n5/5 [==============================] - 0s 6ms/step - loss: 75.9494\nEpoch 171/1000\n5/5 [==============================] - 0s 6ms/step - loss: 75.7812\nEpoch 172/1000\n5/5 [==============================] - 0s 6ms/step - loss: 75.6123\nEpoch 173/1000\n5/5 [==============================] - 0s 6ms/step - loss: 75.4423\nEpoch 174/1000\n5/5 [==============================] - 0s 5ms/step - loss: 75.2715\nEpoch 175/1000\n5/5 [==============================] - 0s 5ms/step - loss: 75.1068\nEpoch 176/1000\n5/5 [==============================] - 0s 8ms/step - loss: 74.9383\nEpoch 177/1000\n5/5 [==============================] - 0s 6ms/step - loss: 74.7736\nEpoch 178/1000\n5/5 [==============================] - 0s 5ms/step - loss: 74.6112\nEpoch 179/1000\n5/5 [==============================] - 0s 5ms/step - loss: 74.4437\nEpoch 180/1000\n5/5 [==============================] - 0s 5ms/step - loss: 74.2781\nEpoch 181/1000\n5/5 [==============================] - 0s 5ms/step - loss: 74.1164\nEpoch 182/1000\n5/5 [==============================] - 0s 5ms/step - loss: 73.9501\nEpoch 183/1000\n5/5 [==============================] - 0s 4ms/step - loss: 73.7829\nEpoch 184/1000\n5/5 [==============================] - 0s 6ms/step - loss: 73.6218\nEpoch 185/1000\n5/5 [==============================] - 0s 5ms/step - loss: 73.4603\nEpoch 186/1000\n5/5 [==============================] - 0s 5ms/step - loss: 73.2937\nEpoch 187/1000\n5/5 [==============================] - 0s 5ms/step - loss: 73.1317\nEpoch 188/1000\n5/5 [==============================] - 0s 5ms/step - loss: 72.9703\nEpoch 189/1000\n5/5 [==============================] - 0s 9ms/step - loss: 72.8072\nEpoch 190/1000\n5/5 [==============================] - 0s 7ms/step - loss: 72.6443\nEpoch 191/1000\n5/5 [==============================] - 0s 5ms/step - loss: 72.4829\nEpoch 192/1000\n5/5 [==============================] - 0s 5ms/step - loss: 72.3209\nEpoch 193/1000\n5/5 [==============================] - 0s 7ms/step - loss: 72.1542\nEpoch 194/1000\n5/5 [==============================] - 0s 6ms/step - loss: 71.9928\nEpoch 195/1000\n5/5 [==============================] - 0s 5ms/step - loss: 71.8223\nEpoch 196/1000\n5/5 [==============================] - 0s 5ms/step - loss: 71.6613\nEpoch 197/1000\n5/5 [==============================] - 0s 5ms/step - loss: 71.4974\nEpoch 198/1000\n5/5 [==============================] - 0s 4ms/step - loss: 71.3324\nEpoch 199/1000\n5/5 [==============================] - 0s 5ms/step - loss: 71.1688\nEpoch 200/1000\n5/5 [==============================] - 0s 5ms/step - loss: 71.0114\nEpoch 201/1000\n5/5 [==============================] - 0s 5ms/step - loss: 70.8453\nEpoch 202/1000\n5/5 [==============================] - 0s 5ms/step - loss: 70.6870\nEpoch 203/1000\n5/5 [==============================] - 0s 5ms/step - loss: 70.5309\nEpoch 204/1000\n5/5 [==============================] - 0s 5ms/step - loss: 70.3735\nEpoch 205/1000\n5/5 [==============================] - 0s 4ms/step - loss: 70.2070\nEpoch 206/1000\n5/5 [==============================] - 0s 3ms/step - loss: 70.0521\nEpoch 207/1000\n5/5 [==============================] - 0s 4ms/step - loss: 69.8928\nEpoch 208/1000\n5/5 [==============================] - 0s 3ms/step - loss: 69.7288\nEpoch 209/1000\n5/5 [==============================] - 0s 4ms/step - loss: 69.5711\nEpoch 210/1000\n5/5 [==============================] - 0s 4ms/step - loss: 69.4174\nEpoch 211/1000\n5/5 [==============================] - 0s 6ms/step - loss: 69.2545\nEpoch 212/1000\n5/5 [==============================] - 0s 3ms/step - loss: 69.0938\nEpoch 213/1000\n5/5 [==============================] - 0s 3ms/step - loss: 68.9379\nEpoch 214/1000\n5/5 [==============================] - 0s 4ms/step - loss: 68.7842\nEpoch 215/1000\n5/5 [==============================] - 0s 4ms/step - loss: 68.6311\nEpoch 216/1000\n5/5 [==============================] - 0s 4ms/step - loss: 68.4770\nEpoch 217/1000\n5/5 [==============================] - 0s 3ms/step - loss: 68.3204\nEpoch 218/1000\n5/5 [==============================] - 0s 4ms/step - loss: 68.1703\nEpoch 219/1000\n5/5 [==============================] - 0s 4ms/step - loss: 68.0143\nEpoch 220/1000\n5/5 [==============================] - 0s 3ms/step - loss: 67.8609\nEpoch 221/1000\n5/5 [==============================] - 0s 4ms/step - loss: 67.7008\nEpoch 222/1000\n5/5 [==============================] - 0s 4ms/step - loss: 67.5489\nEpoch 223/1000\n5/5 [==============================] - 0s 4ms/step - loss: 67.3931\nEpoch 224/1000\n5/5 [==============================] - 0s 4ms/step - loss: 67.2387\nEpoch 225/1000\n5/5 [==============================] - 0s 6ms/step - loss: 67.0818\nEpoch 226/1000\n5/5 [==============================] - 0s 4ms/step - loss: 66.9349\nEpoch 227/1000\n5/5 [==============================] - 0s 3ms/step - loss: 66.7776\nEpoch 228/1000\n5/5 [==============================] - 0s 4ms/step - loss: 66.6269\nEpoch 229/1000\n5/5 [==============================] - 0s 4ms/step - loss: 66.4755\nEpoch 230/1000\n5/5 [==============================] - 0s 4ms/step - loss: 66.3197\nEpoch 231/1000\n5/5 [==============================] - 0s 4ms/step - loss: 66.1673\nEpoch 232/1000\n5/5 [==============================] - 0s 4ms/step - loss: 66.0209\nEpoch 233/1000\n5/5 [==============================] - 0s 4ms/step - loss: 65.8644\nEpoch 234/1000\n5/5 [==============================] - 0s 4ms/step - loss: 65.7159\nEpoch 235/1000\n5/5 [==============================] - 0s 5ms/step - loss: 65.5645\nEpoch 236/1000\n5/5 [==============================] - 0s 4ms/step - loss: 65.4146\nEpoch 237/1000\n5/5 [==============================] - 0s 4ms/step - loss: 65.2609\nEpoch 238/1000\n5/5 [==============================] - 0s 4ms/step - loss: 65.1096\nEpoch 239/1000\n5/5 [==============================] - 0s 4ms/step - loss: 64.9635\nEpoch 240/1000\n5/5 [==============================] - 0s 4ms/step - loss: 64.8139\nEpoch 241/1000\n5/5 [==============================] - 0s 4ms/step - loss: 64.6613\nEpoch 242/1000\n5/5 [==============================] - 0s 5ms/step - loss: 64.5168\nEpoch 243/1000\n5/5 [==============================] - 0s 4ms/step - loss: 64.3741\nEpoch 244/1000\n5/5 [==============================] - 0s 4ms/step - loss: 64.2218\nEpoch 245/1000\n5/5 [==============================] - 0s 4ms/step - loss: 64.0745\nEpoch 246/1000\n5/5 [==============================] - 0s 4ms/step - loss: 63.9305\nEpoch 247/1000\n5/5 [==============================] - 0s 4ms/step - loss: 63.7846\nEpoch 248/1000\n5/5 [==============================] - 0s 4ms/step - loss: 63.6388\nEpoch 249/1000\n5/5 [==============================] - 0s 4ms/step - loss: 63.4942\nEpoch 250/1000\n5/5 [==============================] - 0s 5ms/step - loss: 63.3476\nEpoch 251/1000\n5/5 [==============================] - 0s 4ms/step - loss: 63.1938\nEpoch 252/1000\n5/5 [==============================] - 0s 4ms/step - loss: 63.0518\nEpoch 253/1000\n5/5 [==============================] - 0s 4ms/step - loss: 62.9031\nEpoch 254/1000\n5/5 [==============================] - 0s 4ms/step - loss: 62.7571\nEpoch 255/1000\n5/5 [==============================] - 0s 4ms/step - loss: 62.6089\nEpoch 256/1000\n5/5 [==============================] - 0s 4ms/step - loss: 62.4629\nEpoch 257/1000\n5/5 [==============================] - 0s 4ms/step - loss: 62.3235\nEpoch 258/1000\n5/5 [==============================] - 0s 6ms/step - loss: 62.1681\nEpoch 259/1000\n5/5 [==============================] - 0s 4ms/step - loss: 62.0225\nEpoch 260/1000\n5/5 [==============================] - 0s 4ms/step - loss: 61.8753\nEpoch 261/1000\n5/5 [==============================] - 0s 4ms/step - loss: 61.7347\nEpoch 262/1000\n5/5 [==============================] - 0s 4ms/step - loss: 61.5874\nEpoch 263/1000\n5/5 [==============================] - 0s 7ms/step - loss: 61.4472\nEpoch 264/1000\n5/5 [==============================] - 0s 6ms/step - loss: 61.3046\nEpoch 265/1000\n5/5 [==============================] - 0s 4ms/step - loss: 61.1633\nEpoch 266/1000\n5/5 [==============================] - 0s 4ms/step - loss: 61.0200\nEpoch 267/1000\n5/5 [==============================] - 0s 5ms/step - loss: 60.8783\nEpoch 268/1000\n5/5 [==============================] - 0s 4ms/step - loss: 60.7334\nEpoch 269/1000\n5/5 [==============================] - 0s 4ms/step - loss: 60.5928\nEpoch 270/1000\n5/5 [==============================] - 0s 4ms/step - loss: 60.4547\nEpoch 271/1000\n5/5 [==============================] - 0s 4ms/step - loss: 60.3142\nEpoch 272/1000\n5/5 [==============================] - 0s 4ms/step - loss: 60.1754\nEpoch 273/1000\n5/5 [==============================] - 0s 4ms/step - loss: 60.0314\nEpoch 274/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.8938\nEpoch 275/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.7521\nEpoch 276/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.6135\nEpoch 277/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.4678\nEpoch 278/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.3272\nEpoch 279/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.1913\nEpoch 280/1000\n5/5 [==============================] - 0s 4ms/step - loss: 59.0542\nEpoch 281/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.9133\nEpoch 282/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.7831\nEpoch 283/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.6413\nEpoch 284/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.5093\nEpoch 285/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.3760\nEpoch 286/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.2422\nEpoch 287/1000\n5/5 [==============================] - 0s 4ms/step - loss: 58.1078\nEpoch 288/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.9742\nEpoch 289/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.8433\nEpoch 290/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.7075\nEpoch 291/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.5726\nEpoch 292/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.4412\nEpoch 293/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.3087\nEpoch 294/1000\n5/5 [==============================] - 0s 3ms/step - loss: 57.1790\nEpoch 295/1000\n5/5 [==============================] - 0s 4ms/step - loss: 57.0443\nEpoch 296/1000\n5/5 [==============================] - 0s 4ms/step - loss: 56.9131\nEpoch 297/1000\n5/5 [==============================] - 0s 4ms/step - loss: 56.7780\nEpoch 298/1000\n5/5 [==============================] - 0s 4ms/step - loss: 56.6474\nEpoch 299/1000\n5/5 [==============================] - 0s 4ms/step - loss: 56.5108\nEpoch 300/1000\n5/5 [==============================] - 0s 5ms/step - loss: 56.3796\nEpoch 301/1000\n5/5 [==============================] - 0s 4ms/step - loss: 56.2542\nEpoch 302/1000\n5/5 [==============================] - 0s 4ms/step - loss: 56.1182\nEpoch 303/1000\n5/5 [==============================] - 0s 3ms/step - loss: 55.9865\nEpoch 304/1000\n5/5 [==============================] - 0s 4ms/step - loss: 55.8526\nEpoch 305/1000\n5/5 [==============================] - 0s 4ms/step - loss: 55.7226\nEpoch 306/1000\n5/5 [==============================] - 0s 5ms/step - loss: 55.5918\nEpoch 307/1000\n5/5 [==============================] - 0s 4ms/step - loss: 55.4582\nEpoch 308/1000\n5/5 [==============================] - 0s 4ms/step - loss: 55.3261\nEpoch 309/1000\n5/5 [==============================] - 0s 4ms/step - loss: 55.1961\nEpoch 310/1000\n5/5 [==============================] - 0s 4ms/step - loss: 55.0635\nEpoch 311/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.9340\nEpoch 312/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.8050\nEpoch 313/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.6801\nEpoch 314/1000\n5/5 [==============================] - 0s 5ms/step - loss: 54.5537\nEpoch 315/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.4235\nEpoch 316/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.2932\nEpoch 317/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.1632\nEpoch 318/1000\n5/5 [==============================] - 0s 4ms/step - loss: 54.0377\nEpoch 319/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.9120\nEpoch 320/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.7802\nEpoch 321/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.6514\nEpoch 322/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.5197\nEpoch 323/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.3958\nEpoch 324/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.2674\nEpoch 325/1000\n5/5 [==============================] - 0s 5ms/step - loss: 53.1462\nEpoch 326/1000\n5/5 [==============================] - 0s 4ms/step - loss: 53.0176\nEpoch 327/1000\n5/5 [==============================] - 0s 4ms/step - loss: 52.8951\nEpoch 328/1000\n5/5 [==============================] - 0s 5ms/step - loss: 52.7723\nEpoch 329/1000\n5/5 [==============================] - 0s 4ms/step - loss: 52.6477\nEpoch 330/1000\n5/5 [==============================] - 0s 4ms/step - loss: 52.5222\nEpoch 331/1000\n5/5 [==============================] - 0s 4ms/step - loss: 52.3993\nEpoch 332/1000\n5/5 [==============================] - 0s 4ms/step - loss: 52.2694\nEpoch 333/1000\n5/5 [==============================] - 0s 5ms/step - loss: 52.1483\nEpoch 334/1000\n5/5 [==============================] - 0s 4ms/step - loss: 52.0245\nEpoch 335/1000\n5/5 [==============================] - 0s 4ms/step - loss: 51.9006\nEpoch 336/1000\n5/5 [==============================] - 0s 4ms/step - loss: 51.7825\nEpoch 337/1000\n5/5 [==============================] - 0s 6ms/step - loss: 51.6610\nEpoch 338/1000\n5/5 [==============================] - 0s 4ms/step - loss: 51.5370\nEpoch 339/1000\n5/5 [==============================] - 0s 4ms/step - loss: 51.4139\nEpoch 340/1000\n5/5 [==============================] - 0s 5ms/step - loss: 51.2943\nEpoch 341/1000\n5/5 [==============================] - 0s 4ms/step - loss: 51.1699\nEpoch 342/1000\n5/5 [==============================] - 0s 4ms/step - loss: 51.0519\nEpoch 343/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.9301\nEpoch 344/1000\n5/5 [==============================] - 0s 3ms/step - loss: 50.8085\nEpoch 345/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.6923\nEpoch 346/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.5699\nEpoch 347/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.4486\nEpoch 348/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.3319\nEpoch 349/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.2106\nEpoch 350/1000\n5/5 [==============================] - 0s 4ms/step - loss: 50.0934\nEpoch 351/1000\n5/5 [==============================] - 0s 5ms/step - loss: 49.9753\nEpoch 352/1000\n5/5 [==============================] - 0s 6ms/step - loss: 49.8542\nEpoch 353/1000\n5/5 [==============================] - 0s 4ms/step - loss: 49.7329\nEpoch 354/1000\n5/5 [==============================] - 0s 5ms/step - loss: 49.6102\nEpoch 355/1000\n5/5 [==============================] - 0s 5ms/step - loss: 49.4957\nEpoch 356/1000\n5/5 [==============================] - 0s 4ms/step - loss: 49.3757\nEpoch 357/1000\n5/5 [==============================] - 0s 4ms/step - loss: 49.2565\nEpoch 358/1000\n5/5 [==============================] - 0s 4ms/step - loss: 49.1384\nEpoch 359/1000\n5/5 [==============================] - 0s 4ms/step - loss: 49.0170\nEpoch 360/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.8998\nEpoch 361/1000\n5/5 [==============================] - 0s 5ms/step - loss: 48.7802\nEpoch 362/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.6622\nEpoch 363/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.5403\nEpoch 364/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.4258\nEpoch 365/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.3085\nEpoch 366/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.1905\nEpoch 367/1000\n5/5 [==============================] - 0s 4ms/step - loss: 48.0724\nEpoch 368/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.9572\nEpoch 369/1000\n5/5 [==============================] - 0s 5ms/step - loss: 47.8384\nEpoch 370/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.7237\nEpoch 371/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.6069\nEpoch 372/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.4938\nEpoch 373/1000\n5/5 [==============================] - 0s 5ms/step - loss: 47.3777\nEpoch 374/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.2671\nEpoch 375/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.1494\nEpoch 376/1000\n5/5 [==============================] - 0s 4ms/step - loss: 47.0368\nEpoch 377/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.9225\nEpoch 378/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.8118\nEpoch 379/1000\n5/5 [==============================] - 0s 6ms/step - loss: 46.6949\nEpoch 380/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.5846\nEpoch 381/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.4744\nEpoch 382/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.3639\nEpoch 383/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.2491\nEpoch 384/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.1356\nEpoch 385/1000\n5/5 [==============================] - 0s 4ms/step - loss: 46.0280\nEpoch 386/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.9145\nEpoch 387/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.8056\nEpoch 388/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.6956\nEpoch 389/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.5848\nEpoch 390/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.4730\nEpoch 391/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.3627\nEpoch 392/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.2467\nEpoch 393/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.1336\nEpoch 394/1000\n5/5 [==============================] - 0s 4ms/step - loss: 45.0182\nEpoch 395/1000\n5/5 [==============================] - 0s 3ms/step - loss: 44.9069\nEpoch 396/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.7960\nEpoch 397/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.6828\nEpoch 398/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.5724\nEpoch 399/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.4627\nEpoch 400/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.3568\nEpoch 401/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.2480\nEpoch 402/1000\n5/5 [==============================] - 0s 5ms/step - loss: 44.1431\nEpoch 403/1000\n5/5 [==============================] - 0s 4ms/step - loss: 44.0344\nEpoch 404/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.9286\nEpoch 405/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.8260\nEpoch 406/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.7172\nEpoch 407/1000\n5/5 [==============================] - 0s 5ms/step - loss: 43.6140\nEpoch 408/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.5114\nEpoch 409/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.4022\nEpoch 410/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.2967\nEpoch 411/1000\n5/5 [==============================] - 0s 5ms/step - loss: 43.1923\nEpoch 412/1000\n5/5 [==============================] - 0s 4ms/step - loss: 43.0855\nEpoch 413/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.9789\nEpoch 414/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.8722\nEpoch 415/1000\n5/5 [==============================] - 0s 3ms/step - loss: 42.7677\nEpoch 416/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.6625\nEpoch 417/1000\n5/5 [==============================] - 0s 3ms/step - loss: 42.5556\nEpoch 418/1000\n5/5 [==============================] - 0s 3ms/step - loss: 42.4544\nEpoch 419/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.3536\nEpoch 420/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.2517\nEpoch 421/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.1512\nEpoch 422/1000\n5/5 [==============================] - 0s 4ms/step - loss: 42.0489\nEpoch 423/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.9487\nEpoch 424/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.8482\nEpoch 425/1000\n5/5 [==============================] - 0s 5ms/step - loss: 41.7451\nEpoch 426/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.6453\nEpoch 427/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.5382\nEpoch 428/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.4426\nEpoch 429/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.3368\nEpoch 430/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.2396\nEpoch 431/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.1349\nEpoch 432/1000\n5/5 [==============================] - 0s 4ms/step - loss: 41.0359\nEpoch 433/1000\n5/5 [==============================] - 0s 3ms/step - loss: 40.9330\nEpoch 434/1000\n5/5 [==============================] - 0s 4ms/step - loss: 40.8305\nEpoch 435/1000\n5/5 [==============================] - 0s 4ms/step - loss: 40.7265\nEpoch 436/1000\n5/5 [==============================] - 0s 6ms/step - loss: 40.6280\nEpoch 437/1000\n5/5 [==============================] - 0s 4ms/step - loss: 40.5216\nEpoch 438/1000\n5/5 [==============================] - 0s 4ms/step - loss: 40.4232\nEpoch 439/1000\n5/5 [==============================] - 0s 4ms/step - loss: 40.3209\nEpoch 440/1000\n5/5 [==============================] - 0s 5ms/step - loss: 40.2173\nEpoch 441/1000\n5/5 [==============================] - 0s 5ms/step - loss: 40.1160\nEpoch 442/1000\n5/5 [==============================] - 0s 5ms/step - loss: 40.0195\nEpoch 443/1000\n5/5 [==============================] - 0s 5ms/step - loss: 39.9192\nEpoch 444/1000\n5/5 [==============================] - 0s 5ms/step - loss: 39.8198\nEpoch 445/1000\n5/5 [==============================] - 0s 4ms/step - loss: 39.7249\nEpoch 446/1000\n5/5 [==============================] - 0s 4ms/step - loss: 39.6241\nEpoch 447/1000\n5/5 [==============================] - 0s 4ms/step - loss: 39.5308\nEpoch 448/1000\n5/5 [==============================] - 0s 4ms/step - loss: 39.4315\nEpoch 449/1000\n5/5 [==============================] - 0s 4ms/step - loss: 39.3370\nEpoch 450/1000\n5/5 [==============================] - 0s 4ms/step - loss: 39.2424\nEpoch 451/1000\n5/5 [==============================] - 0s 5ms/step - loss: 39.1430\nEpoch 452/1000\n5/5 [==============================] - 0s 5ms/step - loss: 39.0463\nEpoch 453/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.9474\nEpoch 454/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.8517\nEpoch 455/1000\n5/5 [==============================] - 0s 6ms/step - loss: 38.7598\nEpoch 456/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.6580\nEpoch 457/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.5671\nEpoch 458/1000\n5/5 [==============================] - 0s 6ms/step - loss: 38.4681\nEpoch 459/1000\n5/5 [==============================] - 0s 6ms/step - loss: 38.3767\nEpoch 460/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.2845\nEpoch 461/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.1909\nEpoch 462/1000\n5/5 [==============================] - 0s 5ms/step - loss: 38.0949\nEpoch 463/1000\n5/5 [==============================] - 0s 4ms/step - loss: 38.0021\nEpoch 464/1000\n5/5 [==============================] - 0s 4ms/step - loss: 37.9094\nEpoch 465/1000\n5/5 [==============================] - 0s 6ms/step - loss: 37.8159\nEpoch 466/1000\n5/5 [==============================] - 0s 6ms/step - loss: 37.7213\nEpoch 467/1000\n5/5 [==============================] - 0s 5ms/step - loss: 37.6292\nEpoch 468/1000\n5/5 [==============================] - 0s 5ms/step - loss: 37.5367\nEpoch 469/1000\n5/5 [==============================] - 0s 5ms/step - loss: 37.4457\nEpoch 470/1000\n5/5 [==============================] - 0s 4ms/step - loss: 37.3529\nEpoch 471/1000\n5/5 [==============================] - 0s 6ms/step - loss: 37.2637\nEpoch 472/1000\n5/5 [==============================] - 0s 6ms/step - loss: 37.1712\nEpoch 473/1000\n5/5 [==============================] - 0s 4ms/step - loss: 37.0785\nEpoch 474/1000\n5/5 [==============================] - 0s 4ms/step - loss: 36.9892\nEpoch 475/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.8996\nEpoch 476/1000\n5/5 [==============================] - 0s 6ms/step - loss: 36.8071\nEpoch 477/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.7154\nEpoch 478/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.6271\nEpoch 479/1000\n5/5 [==============================] - 0s 6ms/step - loss: 36.5370\nEpoch 480/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.4459\nEpoch 481/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.3619\nEpoch 482/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.2655\nEpoch 483/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.1804\nEpoch 484/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.0937\nEpoch 485/1000\n5/5 [==============================] - 0s 5ms/step - loss: 36.0053\nEpoch 486/1000\n5/5 [==============================] - 0s 5ms/step - loss: 35.9187\nEpoch 487/1000\n5/5 [==============================] - 0s 5ms/step - loss: 35.8312\nEpoch 488/1000\n5/5 [==============================] - 0s 7ms/step - loss: 35.7396\nEpoch 489/1000\n5/5 [==============================] - 0s 6ms/step - loss: 35.6515\nEpoch 490/1000\n5/5 [==============================] - 0s 6ms/step - loss: 35.5634\nEpoch 491/1000\n5/5 [==============================] - 0s 5ms/step - loss: 35.4748\nEpoch 492/1000\n5/5 [==============================] - 0s 5ms/step - loss: 35.3852\nEpoch 493/1000\n5/5 [==============================] - 0s 5ms/step - loss: 35.2970\nEpoch 494/1000\n5/5 [==============================] - 0s 4ms/step - loss: 35.2093\nEpoch 495/1000\n5/5 [==============================] - 0s 4ms/step - loss: 35.1211\nEpoch 496/1000\n5/5 [==============================] - 0s 4ms/step - loss: 35.0373\nEpoch 497/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.9543\nEpoch 498/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.8651\nEpoch 499/1000\n5/5 [==============================] - 0s 5ms/step - loss: 34.7807\nEpoch 500/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.6964\nEpoch 501/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.6105\nEpoch 502/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.5256\nEpoch 503/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.4368\nEpoch 504/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.3538\nEpoch 505/1000\n5/5 [==============================] - 0s 5ms/step - loss: 34.2686\nEpoch 506/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.1831\nEpoch 507/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.1008\nEpoch 508/1000\n5/5 [==============================] - 0s 4ms/step - loss: 34.0150\nEpoch 509/1000\n5/5 [==============================] - 0s 4ms/step - loss: 33.9333\nEpoch 510/1000\n5/5 [==============================] - 0s 4ms/step - loss: 33.8483\nEpoch 511/1000\n5/5 [==============================] - 0s 5ms/step - loss: 33.7659\nEpoch 512/1000\n5/5 [==============================] - 0s 4ms/step - loss: 33.6827\nEpoch 513/1000\n5/5 [==============================] - 0s 4ms/step - loss: 33.5989\nEpoch 514/1000\n5/5 [==============================] - 0s 4ms/step - loss: 33.5174\nEpoch 515/1000\n5/5 [==============================] - 0s 4ms/step - loss: 33.4336\nEpoch 516/1000\n5/5 [==============================] - 0s 7ms/step - loss: 33.3516\nEpoch 517/1000\n5/5 [==============================] - 0s 5ms/step - loss: 33.2701\nEpoch 518/1000\n5/5 [==============================] - 0s 6ms/step - loss: 33.1877\nEpoch 519/1000\n5/5 [==============================] - 0s 6ms/step - loss: 33.1066\nEpoch 520/1000\n5/5 [==============================] - 0s 5ms/step - loss: 33.0231\nEpoch 521/1000\n5/5 [==============================] - 0s 6ms/step - loss: 32.9393\nEpoch 522/1000\n5/5 [==============================] - 0s 6ms/step - loss: 32.8592\nEpoch 523/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.7752\nEpoch 524/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.6948\nEpoch 525/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.6120\nEpoch 526/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.5309\nEpoch 527/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.4440\nEpoch 528/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.3647\nEpoch 529/1000\n5/5 [==============================] - 0s 3ms/step - loss: 32.2823\nEpoch 530/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.2004\nEpoch 531/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.1229\nEpoch 532/1000\n5/5 [==============================] - 0s 5ms/step - loss: 32.0423\nEpoch 533/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.9624\nEpoch 534/1000\n5/5 [==============================] - 0s 6ms/step - loss: 31.8825\nEpoch 535/1000\n5/5 [==============================] - 0s 4ms/step - loss: 31.8034\nEpoch 536/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.7254\nEpoch 537/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.6465\nEpoch 538/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.5661\nEpoch 539/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.4873\nEpoch 540/1000\n5/5 [==============================] - 0s 4ms/step - loss: 31.4104\nEpoch 541/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.3303\nEpoch 542/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.2503\nEpoch 543/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.1750\nEpoch 544/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.0955\nEpoch 545/1000\n5/5 [==============================] - 0s 5ms/step - loss: 31.0163\nEpoch 546/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.9374\nEpoch 547/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.8584\nEpoch 548/1000\n5/5 [==============================] - 0s 7ms/step - loss: 30.7822\nEpoch 549/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.7001\nEpoch 550/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.6283\nEpoch 551/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.5488\nEpoch 552/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.4735\nEpoch 553/1000\n5/5 [==============================] - 0s 6ms/step - loss: 30.3945\nEpoch 554/1000\n5/5 [==============================] - 0s 4ms/step - loss: 30.3201\nEpoch 555/1000\n5/5 [==============================] - 0s 6ms/step - loss: 30.2444\nEpoch 556/1000\n5/5 [==============================] - 0s 4ms/step - loss: 30.1680\nEpoch 557/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.0925\nEpoch 558/1000\n5/5 [==============================] - 0s 5ms/step - loss: 30.0174\nEpoch 559/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.9458\nEpoch 560/1000\n5/5 [==============================] - 0s 6ms/step - loss: 29.8712\nEpoch 561/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.7962\nEpoch 562/1000\n5/5 [==============================] - 0s 4ms/step - loss: 29.7245\nEpoch 563/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.6522\nEpoch 564/1000\n5/5 [==============================] - 0s 4ms/step - loss: 29.5799\nEpoch 565/1000\n5/5 [==============================] - 0s 4ms/step - loss: 29.5083\nEpoch 566/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.4381\nEpoch 567/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.3650\nEpoch 568/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.2906\nEpoch 569/1000\n5/5 [==============================] - 0s 4ms/step - loss: 29.2215\nEpoch 570/1000\n5/5 [==============================] - 0s 4ms/step - loss: 29.1483\nEpoch 571/1000\n5/5 [==============================] - 0s 6ms/step - loss: 29.0739\nEpoch 572/1000\n5/5 [==============================] - 0s 5ms/step - loss: 29.0021\nEpoch 573/1000\n5/5 [==============================] - 0s 4ms/step - loss: 28.9290\nEpoch 574/1000\n5/5 [==============================] - 0s 4ms/step - loss: 28.8564\nEpoch 575/1000\n5/5 [==============================] - 0s 4ms/step - loss: 28.7855\nEpoch 576/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.7110\nEpoch 577/1000\n5/5 [==============================] - 0s 4ms/step - loss: 28.6394\nEpoch 578/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.5659\nEpoch 579/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.4939\nEpoch 580/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.4196\nEpoch 581/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.3451\nEpoch 582/1000\n5/5 [==============================] - 0s 6ms/step - loss: 28.2769\nEpoch 583/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.2060\nEpoch 584/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.1330\nEpoch 585/1000\n5/5 [==============================] - 0s 5ms/step - loss: 28.0656\nEpoch 586/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.9918\nEpoch 587/1000\n5/5 [==============================] - 0s 8ms/step - loss: 27.9268\nEpoch 588/1000\n5/5 [==============================] - 0s 6ms/step - loss: 27.8551\nEpoch 589/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.7834\nEpoch 590/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.7162\nEpoch 591/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.6466\nEpoch 592/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.5792\nEpoch 593/1000\n5/5 [==============================] - 0s 4ms/step - loss: 27.5096\nEpoch 594/1000\n5/5 [==============================] - 0s 4ms/step - loss: 27.4396\nEpoch 595/1000\n5/5 [==============================] - 0s 4ms/step - loss: 27.3770\nEpoch 596/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.3092\nEpoch 597/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.2382\nEpoch 598/1000\n5/5 [==============================] - 0s 4ms/step - loss: 27.1730\nEpoch 599/1000\n5/5 [==============================] - 0s 5ms/step - loss: 27.1056\nEpoch 600/1000\n5/5 [==============================] - 0s 4ms/step - loss: 27.0381\nEpoch 601/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.9691\nEpoch 602/1000\n5/5 [==============================] - 0s 5ms/step - loss: 26.9043\nEpoch 603/1000\n5/5 [==============================] - 0s 5ms/step - loss: 26.8376\nEpoch 604/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.7712\nEpoch 605/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.7014\nEpoch 606/1000\n5/5 [==============================] - 0s 5ms/step - loss: 26.6381\nEpoch 607/1000\n5/5 [==============================] - 0s 5ms/step - loss: 26.5720\nEpoch 608/1000\n5/5 [==============================] - 0s 6ms/step - loss: 26.5011\nEpoch 609/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.4388\nEpoch 610/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.3725\nEpoch 611/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.3077\nEpoch 612/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.2456\nEpoch 613/1000\n5/5 [==============================] - 0s 5ms/step - loss: 26.1798\nEpoch 614/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.1112\nEpoch 615/1000\n5/5 [==============================] - 0s 4ms/step - loss: 26.0461\nEpoch 616/1000\n5/5 [==============================] - 0s 5ms/step - loss: 25.9779\nEpoch 617/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.9133\nEpoch 618/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.8432\nEpoch 619/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.7800\nEpoch 620/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.7182\nEpoch 621/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.6539\nEpoch 622/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.5888\nEpoch 623/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.5322\nEpoch 624/1000\n5/5 [==============================] - 0s 5ms/step - loss: 25.4698\nEpoch 625/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.4075\nEpoch 626/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.3453\nEpoch 627/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.2828\nEpoch 628/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.2210\nEpoch 629/1000\n5/5 [==============================] - 0s 4ms/step - loss: 25.1583\nEpoch 630/1000\n5/5 [==============================] - 0s 6ms/step - loss: 25.0965\nEpoch 631/1000\n5/5 [==============================] - 0s 5ms/step - loss: 25.0364\nEpoch 632/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.9744\nEpoch 633/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.9118\nEpoch 634/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.8497\nEpoch 635/1000\n5/5 [==============================] - 0s 5ms/step - loss: 24.7894\nEpoch 636/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.7274\nEpoch 637/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.6661\nEpoch 638/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.6014\nEpoch 639/1000\n5/5 [==============================] - 0s 5ms/step - loss: 24.5450\nEpoch 640/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.4826\nEpoch 641/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.4204\nEpoch 642/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.3599\nEpoch 643/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.2974\nEpoch 644/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.2401\nEpoch 645/1000\n5/5 [==============================] - 0s 5ms/step - loss: 24.1785\nEpoch 646/1000\n5/5 [==============================] - 0s 4ms/step - loss: 24.1187\nEpoch 647/1000\n5/5 [==============================] - 0s 5ms/step - loss: 24.0647\nEpoch 648/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.9968\nEpoch 649/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.9405\nEpoch 650/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.8835\nEpoch 651/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.8229\nEpoch 652/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.7650\nEpoch 653/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.7102\nEpoch 654/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.6512\nEpoch 655/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.5948\nEpoch 656/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.5357\nEpoch 657/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.4748\nEpoch 658/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.4178\nEpoch 659/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.3566\nEpoch 660/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.2999\nEpoch 661/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.2418\nEpoch 662/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.1838\nEpoch 663/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.1242\nEpoch 664/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.0704\nEpoch 665/1000\n5/5 [==============================] - 0s 4ms/step - loss: 23.0129\nEpoch 666/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.9543\nEpoch 667/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.9018\nEpoch 668/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.8433\nEpoch 669/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.7890\nEpoch 670/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.7336\nEpoch 671/1000\n5/5 [==============================] - 0s 3ms/step - loss: 22.6772\nEpoch 672/1000\n5/5 [==============================] - 0s 5ms/step - loss: 22.6222\nEpoch 673/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.5660\nEpoch 674/1000\n5/5 [==============================] - 0s 5ms/step - loss: 22.5096\nEpoch 675/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.4520\nEpoch 676/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.3993\nEpoch 677/1000\n5/5 [==============================] - 0s 5ms/step - loss: 22.3445\nEpoch 678/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.2849\nEpoch 679/1000\n5/5 [==============================] - 0s 5ms/step - loss: 22.2329\nEpoch 680/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.1730\nEpoch 681/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.1222\nEpoch 682/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.0637\nEpoch 683/1000\n5/5 [==============================] - 0s 4ms/step - loss: 22.0129\nEpoch 684/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.9549\nEpoch 685/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.9017\nEpoch 686/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.8466\nEpoch 687/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.7943\nEpoch 688/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.7382\nEpoch 689/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.6870\nEpoch 690/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.6327\nEpoch 691/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.5814\nEpoch 692/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.5298\nEpoch 693/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.4793\nEpoch 694/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.4253\nEpoch 695/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.3740\nEpoch 696/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.3258\nEpoch 697/1000\n5/5 [==============================] - 0s 3ms/step - loss: 21.2724\nEpoch 698/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.2199\nEpoch 699/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.1677\nEpoch 700/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.1189\nEpoch 701/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.0677\nEpoch 702/1000\n5/5 [==============================] - 0s 4ms/step - loss: 21.0157\nEpoch 703/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.9669\nEpoch 704/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.9148\nEpoch 705/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.8642\nEpoch 706/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.8117\nEpoch 707/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.7637\nEpoch 708/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.7118\nEpoch 709/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.6631\nEpoch 710/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.6139\nEpoch 711/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.5660\nEpoch 712/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.5182\nEpoch 713/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.4726\nEpoch 714/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.4229\nEpoch 715/1000\n5/5 [==============================] - 0s 5ms/step - loss: 20.3765\nEpoch 716/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.3263\nEpoch 717/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.2788\nEpoch 718/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.2285\nEpoch 719/1000\n5/5 [==============================] - 0s 5ms/step - loss: 20.1772\nEpoch 720/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.1296\nEpoch 721/1000\n5/5 [==============================] - 0s 4ms/step - loss: 20.0787\nEpoch 722/1000\n5/5 [==============================] - 0s 5ms/step - loss: 20.0297\nEpoch 723/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.9842\nEpoch 724/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.9311\nEpoch 725/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.8837\nEpoch 726/1000\n5/5 [==============================] - 0s 5ms/step - loss: 19.8337\nEpoch 727/1000\n5/5 [==============================] - 0s 5ms/step - loss: 19.7892\nEpoch 728/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.7411\nEpoch 729/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.6975\nEpoch 730/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.6529\nEpoch 731/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.6085\nEpoch 732/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.5596\nEpoch 733/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.5153\nEpoch 734/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.4715\nEpoch 735/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.4245\nEpoch 736/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.3801\nEpoch 737/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.3360\nEpoch 738/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.2912\nEpoch 739/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.2477\nEpoch 740/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.2046\nEpoch 741/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.1574\nEpoch 742/1000\n5/5 [==============================] - 0s 5ms/step - loss: 19.1171\nEpoch 743/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.0719\nEpoch 744/1000\n5/5 [==============================] - 0s 4ms/step - loss: 19.0285\nEpoch 745/1000\n5/5 [==============================] - 0s 5ms/step - loss: 18.9849\nEpoch 746/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.9404\nEpoch 747/1000\n5/5 [==============================] - 0s 5ms/step - loss: 18.8968\nEpoch 748/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.8528\nEpoch 749/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.8114\nEpoch 750/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.7648\nEpoch 751/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.7215\nEpoch 752/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.6781\nEpoch 753/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.6329\nEpoch 754/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.5904\nEpoch 755/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.5466\nEpoch 756/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.5034\nEpoch 757/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.4576\nEpoch 758/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.4149\nEpoch 759/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.3709\nEpoch 760/1000\n5/5 [==============================] - 0s 5ms/step - loss: 18.3308\nEpoch 761/1000\n5/5 [==============================] - 0s 6ms/step - loss: 18.2876\nEpoch 762/1000\n5/5 [==============================] - 0s 5ms/step - loss: 18.2470\nEpoch 763/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.2037\nEpoch 764/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.1628\nEpoch 765/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.1210\nEpoch 766/1000\n5/5 [==============================] - 0s 4ms/step - loss: 18.0808\nEpoch 767/1000\n5/5 [==============================] - 0s 6ms/step - loss: 18.0376\nEpoch 768/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.9990\nEpoch 769/1000\n5/5 [==============================] - 0s 5ms/step - loss: 17.9573\nEpoch 770/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.9145\nEpoch 771/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.8727\nEpoch 772/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.8322\nEpoch 773/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.7922\nEpoch 774/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.7527\nEpoch 775/1000\n5/5 [==============================] - 0s 5ms/step - loss: 17.7128\nEpoch 776/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.6747\nEpoch 777/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.6327\nEpoch 778/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.5915\nEpoch 779/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.5535\nEpoch 780/1000\n5/5 [==============================] - 0s 5ms/step - loss: 17.5148\nEpoch 781/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.4732\nEpoch 782/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.4351\nEpoch 783/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.3966\nEpoch 784/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.3589\nEpoch 785/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.3195\nEpoch 786/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.2806\nEpoch 787/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.2435\nEpoch 788/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.2042\nEpoch 789/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.1644\nEpoch 790/1000\n5/5 [==============================] - 0s 7ms/step - loss: 17.1272\nEpoch 791/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.0902\nEpoch 792/1000\n5/5 [==============================] - 0s 4ms/step - loss: 17.0499\nEpoch 793/1000\n5/5 [==============================] - 0s 5ms/step - loss: 17.0135\nEpoch 794/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.9723\nEpoch 795/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.9364\nEpoch 796/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.8968\nEpoch 797/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.8590\nEpoch 798/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.8213\nEpoch 799/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.7827\nEpoch 800/1000\n5/5 [==============================] - 0s 6ms/step - loss: 16.7473\nEpoch 801/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.7087\nEpoch 802/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.6713\nEpoch 803/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.6355\nEpoch 804/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.5973\nEpoch 805/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.5621\nEpoch 806/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.5261\nEpoch 807/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.4891\nEpoch 808/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.4557\nEpoch 809/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.4184\nEpoch 810/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.3851\nEpoch 811/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.3494\nEpoch 812/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.3170\nEpoch 813/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.2836\nEpoch 814/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.2497\nEpoch 815/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.2143\nEpoch 816/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.1805\nEpoch 817/1000\n5/5 [==============================] - 0s 4ms/step - loss: 16.1487\nEpoch 818/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.1131\nEpoch 819/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.0810\nEpoch 820/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.0450\nEpoch 821/1000\n5/5 [==============================] - 0s 5ms/step - loss: 16.0117\nEpoch 822/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.9790\nEpoch 823/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.9432\nEpoch 824/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.9103\nEpoch 825/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.8774\nEpoch 826/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.8420\nEpoch 827/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.8084\nEpoch 828/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.7753\nEpoch 829/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.7433\nEpoch 830/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.7075\nEpoch 831/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.6762\nEpoch 832/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.6431\nEpoch 833/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.6102\nEpoch 834/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.5775\nEpoch 835/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.5461\nEpoch 836/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.5122\nEpoch 837/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.4812\nEpoch 838/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.4486\nEpoch 839/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.4148\nEpoch 840/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.3823\nEpoch 841/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.3497\nEpoch 842/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.3188\nEpoch 843/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.2887\nEpoch 844/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.2593\nEpoch 845/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.2279\nEpoch 846/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.1976\nEpoch 847/1000\n5/5 [==============================] - 0s 5ms/step - loss: 15.1683\nEpoch 848/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.1384\nEpoch 849/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.1088\nEpoch 850/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.0790\nEpoch 851/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.0501\nEpoch 852/1000\n5/5 [==============================] - 0s 4ms/step - loss: 15.0181\nEpoch 853/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.9893\nEpoch 854/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.9603\nEpoch 855/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.9315\nEpoch 856/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.9007\nEpoch 857/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.8717\nEpoch 858/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.8432\nEpoch 859/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.8141\nEpoch 860/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.7878\nEpoch 861/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.7549\nEpoch 862/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.7251\nEpoch 863/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.6958\nEpoch 864/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.6679\nEpoch 865/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.6372\nEpoch 866/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.6066\nEpoch 867/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.5777\nEpoch 868/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.5464\nEpoch 869/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.5178\nEpoch 870/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.4886\nEpoch 871/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.4583\nEpoch 872/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.4269\nEpoch 873/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.4006\nEpoch 874/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.3709\nEpoch 875/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.3406\nEpoch 876/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.3137\nEpoch 877/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.2828\nEpoch 878/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.2540\nEpoch 879/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.2294\nEpoch 880/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.2012\nEpoch 881/1000\n5/5 [==============================] - 0s 5ms/step - loss: 14.1744\nEpoch 882/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.1492\nEpoch 883/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.1223\nEpoch 884/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.0976\nEpoch 885/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.0702\nEpoch 886/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.0455\nEpoch 887/1000\n5/5 [==============================] - 0s 4ms/step - loss: 14.0173\nEpoch 888/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.9909\nEpoch 889/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.9662\nEpoch 890/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.9401\nEpoch 891/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.9123\nEpoch 892/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.8879\nEpoch 893/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.8615\nEpoch 894/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.8345\nEpoch 895/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.8085\nEpoch 896/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.7844\nEpoch 897/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.7580\nEpoch 898/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.7312\nEpoch 899/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.7062\nEpoch 900/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.6777\nEpoch 901/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.6538\nEpoch 902/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.6265\nEpoch 903/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.6034\nEpoch 904/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.5778\nEpoch 905/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.5521\nEpoch 906/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.5253\nEpoch 907/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.5041\nEpoch 908/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.4790\nEpoch 909/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.4532\nEpoch 910/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.4305\nEpoch 911/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.4080\nEpoch 912/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.3839\nEpoch 913/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.3604\nEpoch 914/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.3384\nEpoch 915/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.3132\nEpoch 916/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.2904\nEpoch 917/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.2656\nEpoch 918/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.2435\nEpoch 919/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.2204\nEpoch 920/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.1998\nEpoch 921/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.1765\nEpoch 922/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.1545\nEpoch 923/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.1336\nEpoch 924/1000\n5/5 [==============================] - 0s 6ms/step - loss: 13.1085\nEpoch 925/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.0871\nEpoch 926/1000\n5/5 [==============================] - 0s 5ms/step - loss: 13.0648\nEpoch 927/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.0433\nEpoch 928/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.0205\nEpoch 929/1000\n5/5 [==============================] - 0s 4ms/step - loss: 13.0012\nEpoch 930/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.9775\nEpoch 931/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.9545\nEpoch 932/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.9339\nEpoch 933/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.9135\nEpoch 934/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.8928\nEpoch 935/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.8698\nEpoch 936/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.8485\nEpoch 937/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.8285\nEpoch 938/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.8063\nEpoch 939/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.7837\nEpoch 940/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.7615\nEpoch 941/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.7387\nEpoch 942/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.7165\nEpoch 943/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.6954\nEpoch 944/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.6738\nEpoch 945/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.6491\nEpoch 946/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.6287\nEpoch 947/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.6080\nEpoch 948/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.5878\nEpoch 949/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.5661\nEpoch 950/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.5463\nEpoch 951/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.5268\nEpoch 952/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.5058\nEpoch 953/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.4866\nEpoch 954/1000\n5/5 [==============================] - 0s 6ms/step - loss: 12.4691\nEpoch 955/1000\n5/5 [==============================] - 0s 6ms/step - loss: 12.4456\nEpoch 956/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.4269\nEpoch 957/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.4066\nEpoch 958/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.3865\nEpoch 959/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.3668\nEpoch 960/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.3471\nEpoch 961/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.3278\nEpoch 962/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.3070\nEpoch 963/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.2914\nEpoch 964/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.2710\nEpoch 965/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.2539\nEpoch 966/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.2342\nEpoch 967/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.2169\nEpoch 968/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.1991\nEpoch 969/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.1802\nEpoch 970/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.1609\nEpoch 971/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.1426\nEpoch 972/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.1249\nEpoch 973/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.1083\nEpoch 974/1000\n5/5 [==============================] - 0s 4ms/step - loss: 12.0897\nEpoch 975/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.0725\nEpoch 976/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.0546\nEpoch 977/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.0373\nEpoch 978/1000\n5/5 [==============================] - 0s 5ms/step - loss: 12.0178\nEpoch 979/1000\n5/5 [==============================] - 0s 6ms/step - loss: 12.0016\nEpoch 980/1000\n5/5 [==============================] - 0s 6ms/step - loss: 11.9824\nEpoch 981/1000\n5/5 [==============================] - 0s 6ms/step - loss: 11.9669\nEpoch 982/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.9476\nEpoch 983/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.9313\nEpoch 984/1000\n5/5 [==============================] - 0s 4ms/step - loss: 11.9138\nEpoch 985/1000\n5/5 [==============================] - 0s 4ms/step - loss: 11.8972\nEpoch 986/1000\n5/5 [==============================] - 0s 6ms/step - loss: 11.8816\nEpoch 987/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.8637\nEpoch 988/1000\n5/5 [==============================] - 0s 6ms/step - loss: 11.8482\nEpoch 989/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.8293\nEpoch 990/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.8132\nEpoch 991/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.7973\nEpoch 992/1000\n5/5 [==============================] - 0s 6ms/step - loss: 11.7813\nEpoch 993/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.7659\nEpoch 994/1000\n5/5 [==============================] - 0s 6ms/step - loss: 11.7494\nEpoch 995/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.7349\nEpoch 996/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.7208\nEpoch 997/1000\n5/5 [==============================] - 0s 4ms/step - loss: 11.7033\nEpoch 998/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.6881\nEpoch 999/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.6716\nEpoch 1000/1000\n5/5 [==============================] - 0s 5ms/step - loss: 11.6556\n\n\nWARNING:tensorflow:6 out of the last 11 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7dde4c3111b0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n\n\n- epoch을 1000번쯤 셋팅하니 잘 예측한다..\n\n\nCode\nplt.figure(figsize = (12,4))\nplt.plot(y_test,label = r\"$y_{test}$\",alpha = 0.5)\nplt.plot(y_pred_init,label = r\"$\\hat {y}_{init}$\",alpha = 0.6)\nplt.plot(y_pred_5,label = r\"$\\hat {y}_{5}$\",alpha = 0.6)\nplt.plot(y_pred_final,label = r\"$\\hat {y}_{final}$\",alpha = 0.6)\nplt.title(r\"($y_{test}, \\hat {y}_{init}, \\hat {y}_{5},\\hat {y}_{final}$)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n- 검증해보자\n\n검증결과 이런 간단한 회귀 문제는 시간을 들여서 딥러닝 모델을 사용할 필요가 없어보인다.\n비교해보니, 걸리는 시간은 딥러닝 모델이 훨씬 길고, 예측 성능도 떨어진다.\n\n\nprint(\"ML model\")\nprint(f'RMSE  : {mean_squared_error(y_test, lm.pred, squared=False)}')\nprint(f'MAE   : {mean_absolute_error(y_test, lm.pred)}')\nprint(f'MAPE  : {mean_absolute_percentage_error(y_test, lm.pred)}')\n\nML model\nRMSE  : 1.5547807224924604\nMAE   : 1.2573619368638342\nMAPE  : 0.11717490489730135\n\n\n\nprint(\"DL model\")\nprint(f'RMSE  : {mean_squared_error(y_test, y_pred_final, squared=False)}')\nprint(f'MAE   : {mean_absolute_error(y_test, y_pred_final)}')\nprint(f'MAPE  : {mean_absolute_percentage_error(y_test, y_pred_final)}')\n\nDL model\nRMSE  : 2.895100478652866\nMAE   : 2.1337850681940713\nMAPE  : 0.15886854745380438"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#exercise-1.-carseat-회귀",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#exercise-1.-carseat-회귀",
    "title": "00. 딥러닝 (1)",
    "section": "exercise 1. Carseat (회귀)",
    "text": "exercise 1. Carseat (회귀)\n\n(1) 데이터 준비 및 이해\n\npath = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/Carseats.csv'\ncarseat = pd.read_csv(path)\ncarseat.head()\n\n\n  \n    \n\n\n\n\n\n\nSales\nCompPrice\nIncome\nAdvertising\nPopulation\nPrice\nShelveLoc\nAge\nEducation\nUrban\nUS\n\n\n\n\n0\n9.50\n138\n73\n11\n276\n120\nBad\n42\n17\nYes\nYes\n\n\n1\n11.22\n111\n48\n16\n260\n83\nGood\n65\n10\nYes\nYes\n\n\n2\n10.06\n113\n35\n10\n269\n80\nMedium\n59\n12\nYes\nYes\n\n\n3\n7.40\n117\n100\n4\n466\n97\nMedium\n55\n14\nYes\nYes\n\n\n4\n4.15\n141\n64\n3\n340\n128\nBad\n38\n13\nYes\nNo\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n- x, y 분리\n\ntarget = \"Sales\"\n\nx = carseat.drop(target, axis = 1)\ny = carseat[target]\n\n- 가변수화\n\ncat_cols = ['ShelveLoc', 'Education', 'US', 'Urban']\nx = pd.get_dummies(x, columns = cat_cols, drop_first = True)\n\n- 데이터셋 분할\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2, random_state = 20)\n\n- scaling\n\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_val = scaler.transform(x_val)\n\n\n\n(2) 모델링\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import clear_session\n\n\nn_f = x_train.shape[1]\n\n- 일단 비교를 위해 epochs = 5, 1000 으로 셋팅\n\ngpu name을 확인하고 돌리기\n\n\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\ndevice_name\n\n'/device:GPU:0'\n\n\n\nwith tf.device('/device:GPU:0'):\n  model1 = Sequential( Dense(1, input_shape = (n_f,)) )\n\n  model1.compile(optimizer = \"adam\", loss = \"mse\")\n  model1.fit(x_train, y_train, epochs = 5, verbose=0)\n\nwith tf.device('/device:GPU:0'):\n  model2 = Sequential( Dense(1, input_shape = (n_f,)) )\n\n  model2.compile(optimizer = \"adam\", loss = \"mse\")\n  model2.fit(x_train, y_train, epochs = 1000,verbose=0)\n\n- 결과 시각화\n\n\nCode\ny_pred_5 = model1.predict(x_val)\ny_pred_1000 = model2.predict(x_val)\n\nfig, axes = plt.subplots(1,2,figsize = (12, 4))\n\nax1, ax2 = axes\n\nax1.plot(y_test, label = r\"$y$\")\nax1.plot(y_pred_5, label = r\"$\\hat y_{5}$\")\nax1.legend()\n\nax2.plot(y_test, label = r\"$y$\")\nax2.plot(y_pred_1000, label = r\"$\\hat y_{1000}$\")\nax2.legend()\n\nfig.tight_layout()\nplt.show()\n\n\n3/3 [==============================] - 0s 13ms/step\n3/3 [==============================] - 0s 6ms/step\n\n\n\n\n\n- 뭐 epoch를 1000번으로 해도 딱히 성능이 좋아보이지 않음\n\n일단 두 model의 성능을 비교해보자\n\n\nprint(\"model1 : epochs = 5\")\nprint(f'RMSE  : {mean_squared_error(y_val, y_pred_5, squared=False)}')\nprint(f'MAE   : {mean_absolute_error(y_val, y_pred_5)}')\nprint(\"\\n-------------------------\\n\")\nprint(\"model1 : epochs = 1000\")\nprint(f'RMSE  : {mean_squared_error(y_val, y_pred_1000, squared=False)}')\nprint(f'MAE   : {mean_absolute_error(y_val, y_pred_1000)}')\n\nmodel1 : epochs = 5\nRMSE  : 7.343708509578071\nMAE   : 6.769834949548357\n\n-------------------------\n\nmodel1 : epochs = 1000\nRMSE  : 2.216046941057742\nMAE   : 1.7544673845767975"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#excercise-2.-mobile-분류",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#excercise-2.-mobile-분류",
    "title": "00. 딥러닝 (1)",
    "section": "excercise 2. mobile (분류)",
    "text": "excercise 2. mobile (분류)\n\n(1) 데이터 이해 및 준비\n\npath = \"https://raw.githubusercontent.com/DA4BAM/dataset/master/mobile_churn_simple.csv\"\ndata = pd.read_csv(path)\ndata['CHURN'] = data['CHURN'].map({'STAY':0, 'LEAVE':1})\ndata.head()\n\n\n  \n    \n\n\n\n\n\n\nINCOME\nOVERAGE\nLEFTOVER\nHOUSE\nHANDSET_PRICE\nOVER_15MINS_CALLS_PER_MONTH\nAVERAGE_CALL_DURATION\nCHURN\n\n\n\n\n0\n31953\n0\n6\n313378\n161\n0\n4\n0\n\n\n1\n36147\n0\n13\n800586\n244\n0\n6\n0\n\n\n2\n27273\n230\n0\n305049\n201\n16\n15\n0\n\n\n3\n120070\n38\n33\n788235\n780\n3\n2\n1\n\n\n4\n29215\n208\n85\n224784\n241\n21\n1\n0\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ntarget = 'CHURN'\nx = data.drop(target, axis=1)\ny = data[target]\n\n- 데이터 분할\n\nx_train, x_val, y_train, y_val = train_test_split(x,y, test_size = .2)\n\n- scaling\n\nscaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_val = scaler.fit_transform(x_val)\n\n\n\n(2) 모델링\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import clear_session\n\n\nnf = x_train.shape[1]\n\n\ny_train.unique()\n\narray([0, 1])\n\n\n- 여기서도 epochs에 따른 모델들 사이 성능 차이 비교\n\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\ndevice_name\n\n'/device:GPU:0'\n\n\n\ne = [5,100]\n\nfor i in range(2) :\n  with tf.device('/device:GPU:0'):\n    exec(f\"model{i} = Sequential([ Dense(1, input_shape = (nf,), activation = 'sigmoid') ])\")\n    exec(f\"model{i}.compile(optimizer='adam', loss='binary_crossentropy')\")\n    exec(f\"model{i}.fit(x_train,y_train,epochs = {e[i]},verbose=1)\")\n\nEpoch 1/5\n500/500 [==============================] - 3s 4ms/step - loss: 0.7537\nEpoch 2/5\n500/500 [==============================] - 1s 2ms/step - loss: 0.7043\nEpoch 3/5\n500/500 [==============================] - 1s 2ms/step - loss: 0.6776\nEpoch 4/5\n500/500 [==============================] - 1s 2ms/step - loss: 0.6612\nEpoch 5/5\n500/500 [==============================] - 1s 2ms/step - loss: 0.6513\nEpoch 1/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6921\nEpoch 2/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6716\nEpoch 3/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6589\nEpoch 4/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6509\nEpoch 5/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6457\nEpoch 6/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6423\nEpoch 7/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6399\nEpoch 8/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6383\nEpoch 9/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6372\nEpoch 10/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6363\nEpoch 11/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6358\nEpoch 12/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6354\nEpoch 13/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6351\nEpoch 14/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6348\nEpoch 15/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6346\nEpoch 16/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6344\nEpoch 17/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6343\nEpoch 18/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6341\nEpoch 19/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6341\nEpoch 20/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6340\nEpoch 21/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6339\nEpoch 22/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6339\nEpoch 23/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6338\nEpoch 24/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6338\nEpoch 25/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6337\nEpoch 26/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6337\nEpoch 27/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6337\nEpoch 28/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6336\nEpoch 29/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6336\nEpoch 30/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6336\nEpoch 31/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6336\nEpoch 32/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6336\nEpoch 33/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 34/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6335\nEpoch 35/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 36/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6336\nEpoch 37/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 38/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 39/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 40/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 41/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 42/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 43/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 44/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6335\nEpoch 45/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 46/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 47/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 48/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 49/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 50/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 51/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 52/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 53/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 54/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 55/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6335\nEpoch 56/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 57/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 58/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 59/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6335\nEpoch 60/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 61/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 62/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 63/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 64/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 65/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6335\nEpoch 66/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 67/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 68/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 69/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 70/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 71/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 72/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 73/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 74/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 75/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 76/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6334\nEpoch 77/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 78/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 79/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 80/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 81/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 82/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 83/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 84/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 85/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6335\nEpoch 86/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6334\nEpoch 87/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 88/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 89/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 90/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 91/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 92/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 93/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 94/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 95/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\nEpoch 96/100\n500/500 [==============================] - 2s 3ms/step - loss: 0.6334\nEpoch 97/100\n500/500 [==============================] - 1s 3ms/step - loss: 0.6334\nEpoch 98/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 99/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6334\nEpoch 100/100\n500/500 [==============================] - 1s 2ms/step - loss: 0.6335\n\n\n\ntrain_error_5 = model0.history.history[\"loss\"]\ntrain_error_100  = model1.history.history[\"loss\"]\n\n- epoch에 따른 train loss를 살펴본 결과 특정 epoch이후에는 loss값이 변화가 미비하다…\n\n대충보니 epoch = 10정도만 해도 될 것같음..\n\n\nplt.figure(figsize = (4,4))\nplt.plot(train_error_5,label = \"epochs = 5\")\nplt.plot(train_error_100,label = \"epochs = 100\")\nplt.legend()\nplt.show()\n\n\n\n\n- epoch = 10으로 셋팅 후 결과 리포트 작성\n\nmodel2 = Sequential([ Dense(1, input_shape = (nf,), activation = 'sigmoid') ])\nmodel2.compile(optimizer='adam', loss='binary_crossentropy')\nmodel2.fit(x_train,y_train,epochs = 10,verbose=1)\n\nEpoch 1/10\n500/500 [==============================] - 2s 2ms/step - loss: 0.7028\nEpoch 2/10\n500/500 [==============================] - 1s 3ms/step - loss: 0.6771\nEpoch 3/10\n500/500 [==============================] - 1s 2ms/step - loss: 0.6625\nEpoch 4/10\n500/500 [==============================] - 1s 2ms/step - loss: 0.6532\nEpoch 5/10\n500/500 [==============================] - 1s 2ms/step - loss: 0.6472\nEpoch 6/10\n500/500 [==============================] - 1s 3ms/step - loss: 0.6431\nEpoch 7/10\n500/500 [==============================] - 1s 3ms/step - loss: 0.6403\nEpoch 8/10\n500/500 [==============================] - 1s 2ms/step - loss: 0.6384\nEpoch 9/10\n500/500 [==============================] - 1s 2ms/step - loss: 0.6371\nEpoch 10/10\n500/500 [==============================] - 1s 2ms/step - loss: 0.6362\n\n\n&lt;keras.src.callbacks.History at 0x7dddd9705c00&gt;\n\n\n\nplt.figure(figsize = (4,4))\nplt.title(\"logistic model with DL (epochs = 10)\")\nplt.plot(model2.history.history[\"loss\"])\nplt.show()\n\n\n\n\n\ny_pred = np.where(model2.predict(x_val)&gt;= 0.5, 1, 0)\n\nprint(confusion_matrix(y_val, y_pred))\nprint('-'*50)\nprint(classification_report(y_val, y_pred))\n\n125/125 [==============================] - 0s 2ms/step\n[[1320  727]\n [ 729 1224]]\n--------------------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.64      0.64      0.64      2047\n           1       0.63      0.63      0.63      1953\n\n    accuracy                           0.64      4000\n   macro avg       0.64      0.64      0.64      4000\nweighted avg       0.64      0.64      0.64      4000\n\n\n\n- 최종 결과 시각화\n\nfrom sklearn.metrics import *\npre = precision_score(y_val, y_pred)\nrecall = recall_score(y_val, y_pred)\nf1 = f1_score(y_val, y_pred)\nacc = accuracy_score(y_val, y_pred)\n\n\nmeasure = [\"precision\", \"recall\", \"F1-score\", \"accuracy\"]\nvalue = [pre,recall,f1,acc]\n\nresult = pd.DataFrame(value,columns = [\"value\"])\nresult[\"measure\"] = measure\nfig = result.plot(x = \"measure\", y = \"value\", kind = \"bar\",\n            backend = \"plotly\",color = \"measure\")\n\nfig.update_yaxes(range = [0.62,0.64])\n\n\n\n\n\n                                \n                                            \n\n\n\n\n\n\nsummary\n1 epoch을 늘려도 성능이 그렇게 좋지 않음\n\nfrom keras.optimizers import Adam\nAdam?\n\n2 아마도 기존에 제공하는 학습률이 너무 작아서 로컬 미니멈에 빠지는 것 같음\n\n아래를 통해서 Adam에서 기본적으로 제공하는 학습률이 0.001임을 확인 가능\n\nfrom keras.optimizers import Adam\nAdam?\n3 또한, 모델 적합시 검증용 데이터를 이용하지 않아 학습시 잘못된 학습을 한 경우에도 그냥 반영하는 것 같음\n4 생각해볼 수 있는 접근법\n\n그렇다면, 학습 시 검증용 데이터를 이용\n그리고, epoch와 learning_rate를 적절히 이용한다면..모델 성능을 높일 수 있지 않을까??\n그리고 은닉층을 여러개 추가한다면???"
  },
  {
    "objectID": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#excercise-3.-boston-회귀",
    "href": "posts/DX/05. 딥러닝/2023-10-03-00. 딥러닝 (1).html#excercise-3.-boston-회귀",
    "title": "00. 딥러닝 (1)",
    "section": "excercise 3. Boston (회귀)",
    "text": "excercise 3. Boston (회귀)\n\n(1) 데이터 이해 및 준비\n\npath = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/boston.csv'\ndata = pd.read_csv(path)\ndata.head()\n\n\n  \n    \n\n\n\n\n\n\ncrim\nzn\nindus\nchas\nnox\nrm\nage\ndis\nrad\ntax\nptratio\nlstat\nmedv\n\n\n\n\n0\n0.00632\n18.0\n2.31\n0\n0.538\n6.575\n65.2\n4.0900\n1\n296\n15.3\n4.98\n24.0\n\n\n1\n0.02731\n0.0\n7.07\n0\n0.469\n6.421\n78.9\n4.9671\n2\n242\n17.8\n9.14\n21.6\n\n\n2\n0.02729\n0.0\n7.07\n0\n0.469\n7.185\n61.1\n4.9671\n2\n242\n17.8\n4.03\n34.7\n\n\n3\n0.03237\n0.0\n2.18\n0\n0.458\n6.998\n45.8\n6.0622\n3\n222\n18.7\n2.94\n33.4\n\n\n4\n0.06905\n0.0\n2.18\n0\n0.458\n7.147\n54.2\n6.0622\n3\n222\n18.7\n5.33\n36.2\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ntarget = \"medv\"\n\nx = data.drop(target, axis = 1)\ny= data[target]\n\n- 데이터 분할\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.2, random_state = 20)\n\n- scaling\n\n# 스케일러 선언\nscaler = MinMaxScaler()\n\n# train 셋으로 fitting & 적용\nx_train = scaler.fit_transform(x_train)\n\n# validation 셋은 적용만!\nx_val = scaler.transform(x_val)\n\n\n\n(2) 모델링\n- 이번시간에 알아볼 것!\n\n학습률은 0.01, activation = \"relu\", optimizer = \"adam\", epochs = 50 고정!\nvalidation_split = 0.2로 고정\n은닉층과 은닉노드 개수에 따라 어떻게 모델 성능이 변화하는지 비교해보자.\n\n\n\n\nmodel\n은닉층\n각 층에서 은닉노드의 개수\nparams\n\n\n\n\nmodel1\n2\n(2,1)\n26 + 3 = 29\n\n\nmodel2\n2\n(8,1)\n104 + 9 = 113\n\n\nmodel3\n2\n(8,4,1)\n104 + 36 + 5 = 145\n\n\n\n\nimport\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.backend import clear_session\nfrom keras.optimizers import Adam\n\n\n\nmodel1 설계\n\nnf = x_train.shape[1]\nlr = 0.01\nat = \"relu\" ## 활성화 함수\ne = 50 ## epochs\n\n\n\n\nmodel\n은닉층\n각 층에서 은닉노드의 개수\nparams\n\n\n\n\nmodel1\n2\n(2,1)\n26 + 3 = 29\n\n\nmodel2\n2\n(8,1)\n104 + 9 = 113\n\n\nmodel3\n2\n(8,4,1)\n104 + 36 + 5 = 145\n\n\n\n\nclear_session()\nmodel1 = Sequential(Dense(2, input_shape =(nf,),activation=at)) ## 첫 번째 은닉층\nmodel1.add(Dense(1,activation=at))\n\nmodel1.summary() ## 각 층에서 param 개수와 전체 param 개수 확인\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 2)                 26        \n                                                                 \n dense_1 (Dense)             (None, 1)                 3         \n                                                                 \n=================================================================\nTotal params: 29 (116.00 Byte)\nTrainable params: 29 (116.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n- compile & fit\n\nmodel1.compile(optimizer = Adam(learning_rate = lr), loss = \"mse\")\n\n\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\ndevice_name\n\n'/device:GPU:0'\n\n\n\nwith tf.device('/device:GPU:0') :\n     model1.fit(x_train,y_train,epochs = e, validation_split = 0.2, verbose = 0)\n\n- train 및 val error 저장\n\ntotal_train = pd.DataFrame()\ntotal_val = pd.DataFrame()\nmodel1_train_loss = model1.history.history[\"loss\"]\nmodel1_val_loss = model1.history.history[\"val_loss\"]\n\ntotal_train.loc[:,0] = model1_train_loss\ntotal_val.loc[:,0] = model1_val_loss\n\n- predict\n\ntotal_pred = pd.DataFrame()\nmodel1_pred = model1.predict(x_val).reshape(-1)\ntotal_pred.loc[:,0] = model1_pred\n#total_pred\n\n4/4 [==============================] - 0s 2ms/step\n\n\n\n\nmodel2 설계\n\n\n\nmodel\n은닉층\n각 층에서 은닉노드의 개수\nparams\n\n\n\n\nmodel1\n2\n(2,1)\n26 + 3 = 29\n\n\nmodel2\n2\n(8,1)\n104 + 9 = 113\n\n\nmodel3\n2\n(8,4,1)\n104 + 36 + 5 = 145\n\n\n\n\nmodel2 = Sequential(Dense(8, input_shape = (nf,), activation = at))\n\nmodel2.add(Dense(1,activation = at))\n\nmodel2.summary()\n\nModel: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_2 (Dense)             (None, 8)                 104       \n                                                                 \n dense_3 (Dense)             (None, 1)                 9         \n                                                                 \n=================================================================\nTotal params: 113 (452.00 Byte)\nTrainable params: 113 (452.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n- compile & fit\n\nmodel2.compile(optimizer = Adam(learning_rate = lr), loss = \"mse\")\n\n\nwith tf.device('/device:GPU:0') :\n     model2.fit(x_train,y_train,epochs = e, validation_split = 0.2, verbose = 0)\n\n\nmodel2_train_loss = model2.history.history[\"loss\"]\nmodel2_val_loss = model2.history.history[\"val_loss\"]\n\ntotal_train.loc[:,1] = model2_train_loss\ntotal_val.loc[:,1] = model2_val_loss\n\n\nmodel2_pred = model2.predict(x_val).reshape(-1)\ntotal_pred.loc[:,1] = model2_pred\n\n4/4 [==============================] - 0s 3ms/step\n\n\n\n\nmodel3 설계\n\n\n\nmodel\n은닉층\n각 층에서 은닉노드의 개수\nparams\n\n\n\n\nmodel1\n2\n(2,1)\n26 + 3 = 29\n\n\nmodel2\n2\n(8,1)\n104 + 9 = 113\n\n\nmodel3\n3\n(8,4,1)\n104 + 36 + 5 = 145\n\n\n\n\nmodel3 = Sequential(Dense(8, input_shape = (nf,), activation = at))\n\nmodel3.add(Dense(4, activation = at))\n\nmodel3.add(Dense(1, activation = at))\nmodel3.summary()\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_4 (Dense)             (None, 8)                 104       \n                                                                 \n dense_5 (Dense)             (None, 4)                 36        \n                                                                 \n dense_6 (Dense)             (None, 1)                 5         \n                                                                 \n=================================================================\nTotal params: 145 (580.00 Byte)\nTrainable params: 145 (580.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nmodel3.compile(optimizer=Adam(learning_rate=lr), loss = \"mse\")\n\n\nwith tf.device('/device:GPU:0') :\n     model3.fit(x_train,y_train,epochs = e, validation_split = 0.2, verbose = 0)\n\n\nmodel3_train_loss = model3.history.history[\"loss\"]\nmodel3_val_loss = model3.history.history[\"val_loss\"]\n\ntotal_train.loc[:,2] = model3_train_loss\ntotal_val.loc[:,2] = model3_val_loss\n\nmodel3_pred = model3.predict(x_val).reshape(-1)\ntotal_pred.loc[:,2] = model3_pred\n\n4/4 [==============================] - 0s 3ms/step\n\n\n-결과 시각화\n\n\n\nmodel\n은닉층\n각 층에서 은닉노드의 개수\nparams\n\n\n\n\nmodel1\n2\n(2,1)\n26 + 3 = 29\n\n\nmodel2\n2\n(8,1)\n104 + 9 = 113\n\n\nmodel3\n3\n(8,4,1)\n104 + 36 + 5 = 145\n\n\n\n\ntotal_train.columns = [\"model1\", \"model2\",\"model3\"]\ntotal_val.columns = [\"model1\", \"model2\",\"model3\"]\ntotal_pred.columns = [\"model1\", \"model2\",\"model3\"]\n\n- tidydata 생성\n\n\nCode\ntotal_train2 = total_train.melt(var_name = \"model\",\n                 value_name =\"loss\")\ntotal_train2[\"label\"] = \"train\"\ntotal_train2[\"epochs\"] = list(range(1,51))*3\n\n\ntotal_val2 = total_val.melt(var_name = \"model\",\n                 value_name =\"loss\")\ntotal_val2[\"label\"] = \"val\"\ntotal_val2[\"epochs\"] = list(range(1,51))*3\n\n\ntotal1 = pd.concat([total_train2, total_val2],axis = 0)\n\n\n- train, val loss 시각화\n\nfig = total1.plot(x= \"epochs\", y = \"loss\",\n            color = \"label\", facet_col = \"model\",kind = \"scatter\",\n            backend = \"plotly\", width = 1200, height = 400, opacity=0.5)\nfig.show()\n\n\n\n\n\n                                \n                                            \n\n\n\n\n- train, val loss만 보면 model2가 가장 잘 적합된 모델인 것 같다.\n- test data 예측결과 시각화\n\ntotal_pred[\"y_true\"] = y_val.reset_index(drop=True)\n\n\n\nCode\nfig, axes = plt.subplots(1,3,figsize = (12,4))\n\nax1, ax2, ax3 = axes\nax1.plot(total_pred[\"y_true\"], label =  r\"$y_{true}$\", alpha = 0.5)\nax1.plot(total_pred[\"model1\"],\"--g\", label =  r\"$y_{model1}$\")\nax1.legend()\n\nax2.plot(total_pred[\"y_true\"], label =  r\"$y_{true}$\", alpha = 0.5)\nax2.plot(total_pred[\"model2\"],\"--r\", label =  r\"$y_{model2}$\")\nax2.legend()\n\nax3.plot(total_pred[\"y_true\"], label =  r\"$y_{true}$\", alpha = 0.5)\nax3.plot(total_pred[\"model3\"],\"--b\", label =  r\"$y_{model3}$\")\nax3.legend()\n\nfig.tight_layout()\n\n\n\n\n\n- test data에 대한 예측결과 model3가 가장 잘 예측하고 있는것 같다.\n\n근데 이것을 수치적으로 확인하기 위해 MAE 수치만 비교해보자.\n\n\nmodel1_mae = mean_absolute_error(y_val, model1_pred)\nmodel2_mae = mean_absolute_error(y_val, model2_pred)\nmodel3_mae = mean_absolute_error(y_val, model3_pred)\n\nmae = [model1_mae, model2_mae, model3_mae]\nmodel = [\"model1\", \"model2\",\"model3\"]\n\nfig = pd.DataFrame({\"model\": model,\"mae\" : mae}).\\\n      plot(kind = \"bar\",backend = \"plotly\",\n           x = \"model\", y= \"mae\",color = \"model\",width = 400, height = 400,\n              title = \"Mean Absolute error by model\")\nfig.update_yaxes(range = (3,4.5))\n\n\n\n\n\n                                \n                                            \n\n\n\n\n\n\n\n(3) summary\n\n\n\nmodel\n은닉층\n각 층에서 은닉노드의 개수\nparams\n\n\n\n\nmodel1\n2\n(2,1)\n26 + 3 = 29\n\n\nmodel2\n2\n(8,1)\n104 + 9 = 113\n\n\nmodel3\n3\n(8,4,1)\n104 + 36 + 5 = 145\n\n\n\n\nepochs, activation, learning_rate, optimizer를 고정시켜놓고 은닉층의 수와 노드의 수에 따라 예측 성능을 비교해봤음\n비교결과 model2가 가장 학습 데이터에 적합했으나 실제로는 model3와 비교해보면 과적합 문제가 의심됨.\ninsight1 : 은닉층의 수와 노드의 수 즉, 파라미터 수를 어떻게 조절하냐에 따라서도 모델 성능이 달라질 수 있음!!"
  },
  {
    "objectID": "posts/DX/2023-08-19-01. Plotly test.html",
    "href": "posts/DX/2023-08-19-01. Plotly test.html",
    "title": "01. Plotly test",
    "section": "",
    "text": "import\n\nimport plotly.express as ex\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport numpy as np\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv')\ndf.head()\n\n\n\n\n\n\n\n\nDate\nSamsung\nApple\nHuawei\nXiaomi\nOppo\nMobicel\nMotorola\nLG\nOthers\nRealme\nGoogle\nNokia\nLenovo\nOnePlus\nSony\nAsus\n\n\n\n\n0\n2019-10\n31.49\n22.09\n10.02\n7.79\n4.10\n3.15\n2.41\n2.40\n9.51\n0.54\n2.35\n0.95\n0.96\n0.70\n0.84\n0.74\n\n\n1\n2019-11\n31.36\n22.90\n10.18\n8.16\n4.42\n3.41\n2.40\n2.40\n9.10\n0.78\n0.66\n0.97\n0.97\n0.73\n0.83\n0.75\n\n\n2\n2019-12\n31.37\n24.79\n9.95\n7.73\n4.23\n3.19\n2.50\n2.54\n8.13\n0.84\n0.75\n0.90\n0.87\n0.74\n0.77\n0.70\n\n\n3\n2020-01\n31.29\n24.76\n10.61\n8.10\n4.25\n3.02\n2.42\n2.40\n7.55\n0.88\n0.69\n0.88\n0.86\n0.79\n0.80\n0.69\n\n\n4\n2020-02\n30.91\n25.89\n10.98\n7.80\n4.31\n2.89\n2.36\n2.34\n7.06\n0.89\n0.70\n0.81\n0.77\n0.78\n0.80\n0.69\n\n\n\n\n\n\n\n\ndf.set_index(\"Date\").diff().\\\n  dropna().boxplot(backend = \"plotly\")"
  }
]